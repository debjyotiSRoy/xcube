{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq xcube #upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from fastcore.all import *\n",
    "from xcube.imports import *\n",
    "from xcube.torch_imports import *\n",
    "from xcube.fastai_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> Utilities needed for little repititive tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def namestr(obj, namespace=None):\n",
    "    \"Returns the name of the object `obj` passed\"\n",
    "    return [name for name in namespace if namespace[name] is obj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how `namestr` works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'some_var'\n",
    "test_eq(namestr(a, globals()), ['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def list_files(startpath):\n",
    "    \"\"\" [simulates the linux tree cmd] \n",
    "    (https://stackoverflow.com/questions/9727673/list-directory-tree-structure-in-python)\n",
    "    \"\"\" \n",
    "    \n",
    "    if isinstance(startpath, Path): startpath = str(startpath) \n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print('{}{}'.format(subindent, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_paths(path, prefix=None):\n",
    "    \"\"\"\n",
    "    with `path` as basedir, makes data and models dir and \n",
    "    returns a dictionary of relevant pathlib objects\n",
    "    \"\"\"\n",
    "    path_data = path/'data'\n",
    "    path_model = path/'models'\n",
    "\n",
    "    path_model.mkdir(exist_ok=True)\n",
    "    path_data.mkdir(exist_ok=True)\n",
    "    (path_model/'collab').mkdir(exist_ok=True)\n",
    "\n",
    "    data = path_data/(prefix+'.csv')\n",
    "    dls_lm_path, dls_lm_r_path = path_model/f\"{prefix}_dls_lm.pkl\", path_model/f\"{prefix}_dls_lm_r.pkl\"\n",
    "    dls_lm_vocab_path, dls_lm_vocab_r_path = path_model/f\"{prefix}_dls_lm_vocab.pkl\", path_model/f\"{prefix}_dls_lm_vocab_r.pkl\"\n",
    "    lm_path, lm_r_path = path_model/f\"{prefix}_lm.pth\", path_model/f\"{prefix}_lm_r.pth\"\n",
    "    lm_finetuned_path, lm_finetuned_r_path = path_model/f\"{prefix}_lm_finetuned.pth\", path_model/f\"{prefix}_lm_finetuned_r.pth\"\n",
    "    dsets_clas_path, dsets_clas_r_path = path_model/f\"{prefix}_dset_clas.pkl\", path_model/f\"{prefix}_dset_clas_r.pkl\"\n",
    "    dls_clas_path, dls_clas_r_path = path_model/f\"{prefix}_dls_clas.pkl\", path_model/f\"{prefix}_dls_clas_r.pkl\"\n",
    "    clas_path, clas_r_path = path_model/f\"{prefix}_clas.pth\", path_model/f\"{prefix}_clas_r.pth\"\n",
    "    collab_bootst_path = path_model/f\"{prefix}_tok_lbl_info.pkl\"\n",
    "    collab_data_path = path_data/f\"{prefix}_tok_lbl.ft\"\n",
    "    collab_tok_path = path_data/f\"{prefix}_tok.ft\"\n",
    "    collab_lbl_path = path_data/f\"{prefix}_lbl.ft\"\n",
    "    dls_collab_path = path_model/f\"{prefix}_dls_collab.pkl\"\n",
    "    dls_learn_rank_path = path_model/f\"{prefix}_dls_learn_rank.pkl\"\n",
    "    collab_path = path_model/'collab'/f\"{prefix}_collab.pth\"\n",
    "    plist = [path, path_data, path_model, \n",
    "             data, \n",
    "             dls_lm_path, dls_lm_r_path,\n",
    "             dls_lm_vocab_path, dls_lm_vocab_r_path,\n",
    "             lm_path, lm_r_path,\n",
    "             lm_finetuned_path, lm_finetuned_r_path,\n",
    "             dsets_clas_path, dsets_clas_r_path,\n",
    "             dls_clas_path, dls_clas_r_path,\n",
    "             clas_path, clas_r_path,\n",
    "             collab_bootst_path,\n",
    "             collab_data_path,\n",
    "             collab_tok_path,\n",
    "             collab_lbl_path,\n",
    "             dls_collab_path,\n",
    "             dls_learn_rank_path,\n",
    "             collab_path]\n",
    "    pdir = {}\n",
    "    for o in plist:  pdir[namestr(o, locals())[0]] = o\n",
    "    return pdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created temporary dir: /tmp/tmpi1evi3rs\n",
      "tmpi1evi3rs/\n",
      "    data/\n",
      "        mimic3-9k_tok.ft\n",
      "        mimic3-9k_lbl.ft\n",
      "        mimic3-9k.csv\n",
      "        mimic3-9k_tok_lbl.ft\n",
      "    models/\n",
      "        mimic3-9k_dls_clas.pkl\n",
      "        mimic3-9k_dls_lm.pkl\n",
      "        mimic3-9k_lm_r.pth\n",
      "        mimic3-9k_lm_finetuned_r.pth\n",
      "        mimic3-9k_tok_lbl_info.pkl\n",
      "        mimic3-9k_dls_lm_vocab_r.pkl\n",
      "        mimic3-9k_dls_collab.pkl\n",
      "        mimic3-9k_clas.pth\n",
      "        mimic3-9k_dset_clas.pkl\n",
      "        mimic3-9k_dls_lm_vocab.pkl\n",
      "        mimic3-9k_dls_learn_rank.pkl\n",
      "        mimic3-9k_dls_lm_r.pkl\n",
      "        mimic3-9k_dset_clas_r.pkl\n",
      "        mimic3-9k_lm.pth\n",
      "        mimic3-9k_clas_r.pth\n",
      "        mimic3-9k_lm_finetuned.pth\n",
      "        mimic3-9k_dls_clas_r.pkl\n",
      "        collab/\n",
      "            mimic3-9k_collab.pth\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tempdirname:\n",
    "    print(f\"created temporary dir: {tempdirname}\")\n",
    "    _paths = make_paths(Path(tempdirname), \"mimic3-9k\")\n",
    "    for v in _paths.values(): v.touch()\n",
    "    list_files(tempdirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_hist(data, x_label=None, y_label=None, title=\"Histogram\"):\n",
    "    n, bins, pathches = plt.hist(data)\n",
    "    plt.grid(axis='y', color='b')\n",
    "    # plt.yscale('log')\n",
    "    if x_label is not None: plt.xlabel(x_label)\n",
    "    if y_label is not None: plt.ylabel(y_label)\n",
    "    maxfreq = n.max()\n",
    "    plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\n",
    "    plt.title(title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_reduction(X, tSNE=True, n_comps=None, perplexity=30, figsize=(6,4)):\n",
    "    \"\"\"\n",
    "    PCA on X and plots the first two principal components, returns the decomposition \n",
    "    and the explained variances for each directions,\n",
    "    if `tSNE` then does a tSNE after PCA.\n",
    "    \"\"\"\n",
    "    reduction = \"tSNE\" if tSNE else \"PCA\"\n",
    "    pca = PCA(n_components=n_comps, svd_solver=\"full\")\n",
    "    X_red = pca.fit_transform(X)\n",
    "    if tSNE:\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity)\n",
    "        X_red = tsne.fit_transform(X_red[:, :50])\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(X_red[:, 0], X_red[:, 1], marker='x')\n",
    "    ax.set_xlabel(\"1st component\")\n",
    "    ax.set_ylabel(\"2nd component\")\n",
    "    ax.set_title(f\"{reduction} Decomposition\")\n",
    "    plt.show()\n",
    "    return X_red, pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def test_eqs(*args):\n",
    "    for i in range(len(args)-1):\n",
    "        test_eq(args[i], args[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eqs(1, 1, 9//9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.callback.tracker import SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate(learner, cb=SaveModelCallback, **kwargs):\n",
    "    \"validates a `learner` within a context manager after temporarily removing `cb` if it exists\"\n",
    "    save_cb_idx = learner.cbs.argfirst(lambda o: isinstance(o, cb))\n",
    "    if save_cb_idx is None:\n",
    "        print(learner.validate(**kwargs))\n",
    "        return\n",
    "    print(f'best so far = {learner.cbs[save_cb_idx].best}')\n",
    "    with learner.removed_cbs(learner.cbs[save_cb_idx]):\n",
    "        vals = learner.validate(**kwargs)\n",
    "        names = learner.recorder._valid_mets.map(Self.name())\n",
    "        print('\\n'.join([f\"{n} = {v}\" for n,v in zip(names,vals)]))\n",
    "    save_cb_idx = learner.cbs.argfirst(lambda o: isinstance(o, cb))\n",
    "    print(f'best so far = {learner.cbs[save_cb_idx].best}')\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cudamem(device=default_device()):\n",
    "    using = torch.cuda.max_memory_reserved(device)/1024**3\n",
    "    total = torch.cuda.get_device_properties(device).total_memory/1024**3\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(default_device())}\")\n",
    "    print(f\"You are using {using} GB\")\n",
    "    print(f\"Total GPU memory = {total} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def get_description(codes):\n",
    "    \"descriptions of ICD10 codes\"\n",
    "    # Initialize an empty dictionary to store code descriptions\n",
    "    icd10_descriptions = {}\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "    }\n",
    "    with requests.Session() as session:\n",
    "        for code in codes:\n",
    "            url_cm = f\"https://icd10coded.com/cm/{code}\"\n",
    "            url_pcs = f\"https://icd10coded.com/pcs/{code}\"\n",
    "            \n",
    "            for url in (url_pcs, url_cm):   \n",
    "                with session.get(url, headers=headers, timeout=5) as response:\n",
    "                    if response.status_code == 200:\n",
    "                        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                        description_element = soup.find('span', {'class': 'lead'})\n",
    "                        if description_element:\n",
    "                            description = description_element.text.strip()\n",
    "                            icd10_descriptions[code] = description\n",
    "                            break\n",
    "                        else:\n",
    "                            icd10_descriptions[code] = \"Description not found\"\n",
    "                    else:\n",
    "                        # print(f\"An error occurred.\")\n",
    "                        icd10_descriptions[code] = \"Code not found\"\n",
    "    return icd10_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
