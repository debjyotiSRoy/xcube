{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3b7cc-8ead-4343-a437-bc0fbfc28ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq xcube  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1d2dc-4959-4a79-b27a-77acbc54e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from fastai.data.all import *\n",
    "from fastai.text.models.core import *\n",
    "from fastai.text.models.awdlstm import *\n",
    "from xcube.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4e9f7-bc4b-454a-abb3-d7af066b7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp text.models.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff76fb-51c8-48eb-9a56-0820d20b2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c319081-5bc4-4dca-a277-e725860f2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "_model_meta = {AWD_LSTM: {'hid_name':'emb_sz', 'url':URLs.WT103_FWD, 'url_bwd':URLs.WT103_BWD,\n",
    "                          'config_lm':awd_lstm_lm_config, 'split_lm': awd_lstm_lm_split,\n",
    "                          'config_clas':awd_lstm_clas_config, 'split_clas': awd_lstm_clas_split},}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f138b28-457d-4c8c-b2a5-5a620c60c992",
   "metadata": {},
   "source": [
    "# Core XML Text Modules\n",
    "> Contain the modules needed to build different XML architectures and the generic functions to get those models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9247354-c15b-453e-9a60-5f5ba0336391",
   "metadata": {},
   "source": [
    "The models provided here are variations of the ones provided by [fastai](https://docs.fast.ai/text.models.core.html) with modifications tailored for XML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d811afdb-22d7-4e86-b15a-77b63e1a511e",
   "metadata": {},
   "source": [
    "## Basic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c5748-ef36-401c-bc6b-72f0fcb4dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SequentialRNN(nn.Sequential):\n",
    "    \"A sequential pytorch module that passes the reset call to its children.\"\n",
    "    def reset(self):\n",
    "        for c in self.children(): getattr(c, 'reset', noop)()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b84e3-067f-4110-9546-3500b69ceff2",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e098324-afd1-41ed-9d3e-a4f040f7a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _pad_tensor(t, bs):\n",
    "    if t.size(0) < bs: return torch.cat([t, t.new_zeros(bs-t.size(0), *t.shape[1:])])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e484bc0-feb2-48b0-9893-8718a1d01f45",
   "metadata": {},
   "source": [
    "The `SentenceEncoder` below is the [fastai's source code](https://docs.fast.ai/text.models.core.html#sentenceencoder). Copied here for understanding its components and chaning it to `AttentiveSentenceEncoder`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd05e3-f3ee-4080-a4a8-d22c93d2a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SentenceEncoder(Module):\n",
    "    \"Create an encoder over `module` that can process a full sentence.\"\n",
    "    def __init__(self, bptt, module, pad_idx=1, max_len=None): store_attr('bptt,module,pad_idx,max_len')\n",
    "    def reset(self): getattr(self.module, 'reset', noop)()\n",
    "\n",
    "    def forward(self, input):\n",
    "        bs,sl = input.size()\n",
    "        self.reset()\n",
    "        mask = input == self.pad_idx\n",
    "        outs,masks = [],[]\n",
    "        for i in range(0, sl, self.bptt):\n",
    "            #Note: this expects that sequence really begins on a round multiple of bptt\n",
    "            real_bs = (input[:,i] != self.pad_idx).long().sum()\n",
    "            o = self.module(input[:real_bs,i: min(i+self.bptt, sl)])\n",
    "            if self.max_len is None or sl-i <= self.max_len:\n",
    "                outs.append(o)\n",
    "                masks.append(mask[:,i: min(i+self.bptt, sl)])\n",
    "        outs = torch.cat([_pad_tensor(o, bs) for o in outs], dim=1)\n",
    "        inps = input[:, -outs.shape[1]:] # the ofsetted tokens for the outs\n",
    "        mask = torch.cat(masks, dim=1)\n",
    "        return inps,outs,mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d355c2-825a-4bb9-aae9-da6b3d56bb78",
   "metadata": {},
   "source": [
    ":::{.callout-warning}\n",
    "\n",
    "This module expects the inputs padded with most of the padding first, with the sequence beginning at a round multiple of bptt (and the rest of the padding at the end). Use `pad_input_chunk` to get your data in a suitable format.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20e905-af67-4257-8d65-71d964367d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class AttentiveSentenceEncoder(Module):\n",
    "    \"Create an encoder over `module` that can process a full sentence.\"\n",
    "    def __init__(self, bptt, module, decoder, pad_idx=1, max_len=None, running_decoder=True): \n",
    "        store_attr('bptt,module,decoder,pad_idx,max_len,running_decoder')\n",
    "        self.n_lbs = getattr(self.decoder, 'n_lbs', None)\n",
    "        \n",
    "    def reset(self): \n",
    "        getattr(self.module, 'reset', noop)()\n",
    "\n",
    "    def forward(self, input):\n",
    "        bs,sl = input.size()\n",
    "        self.reset()\n",
    "        self.decoder.hl = input.new_zeros((bs, self.n_lbs))\n",
    "        # print(f\"Starting to read a btch of docs start hl.sum() = {self.decoder.hl.sum()}\", end='\\n')\n",
    "        mask = input == self.pad_idx\n",
    "        outs,masks = [],[]\n",
    "        for i in range(0, sl, self.bptt):\n",
    "            #Note: this expects that sequence really begins on a round multiple of bptt\n",
    "            real_bs = (input[:,i] != self.pad_idx).long().sum()\n",
    "            chunk = slice(i, min(i+self.bptt, sl))\n",
    "            o = self.module(input[:real_bs, chunk]) # shape (bs, bptt, nh)\n",
    "            if self.max_len is None or sl-i <= self.max_len:\n",
    "                outs.append(o)\n",
    "                masks.append(mask[:, chunk])\n",
    "                # print(f\"\\t\\t (Within max_len) After reading bptt chunk: hl.sum() = {self.decoder.hl.sum()}\", end='\\n')\n",
    "            elif self.running_decoder:\n",
    "                mask_slice = mask[:real_bs, chunk] \n",
    "                inp = input[:real_bs, chunk]\n",
    "                # import pdb; pdb.set_trace()\n",
    "                hl, *_ = self.decoder((inp, o, mask_slice))\n",
    "                self.decoder.hl = hl.sigmoid()#.detach()\n",
    "                # print(f\"\\t (Outside max_len) After reading bptt chunk: hl.sum() = {self.decoder.hl.sum()}\", end='\\n')\n",
    "                \n",
    "        # import pdb; pdb.set_trace()\n",
    "        outs = torch.cat([_pad_tensor(o, bs) for o in outs], dim=1)\n",
    "        inps = input[:, -outs.shape[1]:] # the ofsetted tokens for the outs\n",
    "        mask = torch.cat(masks, dim=1)\n",
    "        return inps, outs, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbbcff-6828-4e9e-9fed-2fe7ec1ab0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def masked_concat_pool(output, mask, bptt):\n",
    "    \"Pool `MultiBatchEncoder` outputs into one vector [last_hidden, max_pool, avg_pool]\"\n",
    "    lens = output.shape[1] - mask.long().sum(dim=1)\n",
    "    last_lens = mask[:,-bptt:].long().sum(dim=1)\n",
    "    avg_pool = output.masked_fill(mask[:, :, None], 0).sum(dim=1)\n",
    "    avg_pool.div_(lens.type(avg_pool.dtype)[:,None])\n",
    "    max_pool = output.masked_fill(mask[:,:,None], -float('inf')).max(dim=1)[0]\n",
    "    x = torch.cat([output[torch.arange(0, output.size(0)),-last_lens-1], max_pool, avg_pool], 1) #Concat pooling.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f56bd99-2f56-4053-9792-7555b7893064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XPoolingLinearClassifier(Module):\n",
    "    def __init__(self, dims, ps, bptt, y_range=None):\n",
    "        self.layer = LinBnDrop(dims[0], dims[1], p=ps, act=None)\n",
    "        self.bptt = bptt\n",
    "\n",
    "    def forward(self, input):\n",
    "        out, mask = input\n",
    "        x = masked_concat_pool(out, mask, self.bptt)\n",
    "        x = self.layer(x)\n",
    "        return x, out, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae922f0-c0cc-4842-a2f9-23670ace4ade",
   "metadata": {},
   "source": [
    "Note that `XPoolingLinearClassifier` is exactly same as fastai's [`PoolingLinearClassifier`](https://docs.fast.ai/text.models.core.html#poolinglinearclassifier) except that we do not do the feature compression from 1200 to 50 linear features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba9d961-79ea-4342-874e-f9e10fb60daf",
   "metadata": {},
   "source": [
    "Note: Also try `XPoolingLinearClassifier` w/o dropouts and batch normalization (Verify this, but as far as what I found it does not work well as compared to /w batch normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270b3c9-fc59-4cdf-9404-882d251df043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcube.layers import _create_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2d405-a8b8-48ee-a1a0-c8fd0e22245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcube.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d48768-d9b8-4330-9c15-c30047a0a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LabelAttentionClassifier(Module):\n",
    "    initrange=0.1\n",
    "    def __init__(self, n_hidden, n_lbs, y_range=None):\n",
    "        store_attr('n_hidden,n_lbs,y_range')\n",
    "        self.pay_attn = XMLAttention(self.n_lbs, self.n_hidden)\n",
    "        self.boost_attn = ElemWiseLin(self.n_lbs, self.n_hidden)\n",
    "        self.label_bias = _create_bias((self.n_lbs,), with_zeros=False)\n",
    "        self.hl = torch.zeros(1)\n",
    "    \n",
    "    def forward(self, sentc):\n",
    "        if isinstance(sentc, tuple): inp, sentc, mask = sentc # sentc is the stuff coming outta SentenceEncoder i.e., shape (bs, max_len, nh) in other words the concatenated output of the AWD_LSTM\n",
    "        test_eqs(inp.shape, sentc.shape[:-1], mask.shape)\n",
    "        sentc = sentc.masked_fill(mask[:, :, None], 0)\n",
    "        attn, wgts, lbs_cf = self.pay_attn(inp, sentc, mask) #shape (bs, n_lbs, n_hidden)\n",
    "        attn = self.boost_attn(attn) # shape (bs, n_lbs, n_hidden)\n",
    "        bs = self.hl.size(0)\n",
    "        self.hl = self.hl.to(sentc.device)\n",
    "        pred = self.hl + _pad_tensor(attn.sum(dim=2), bs) + self.label_bias  # shape (bs, n_lbs)\n",
    "        \n",
    "        # if lbs_cf is not None: \n",
    "        #     lbs_cf = _pad_tensor(lbs_cf, bs)\n",
    "        #     pred.add_(lbs_cf) \n",
    "        \n",
    "        if self.y_range is not None: pred = sigmoid_range(pred, *self.y_range)\n",
    "        return pred, attn, wgts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b15a8-e4df-43cd-a005-4062bcaaa325",
   "metadata": {},
   "source": [
    "TODOS: Deb \n",
    "- ~Find out what happens with respect to RNN Regularizer callback after LabelAttentionClassifier returns a tuple of 3. (Check the learner cbs and follow the `RNNcallback`)~\n",
    "- ~Check if we are losing anything by ignoring the mask in `LabelAttentionClassifier`. That is should we be ignoring the masked tokens while computing atten wgts.~  \n",
    "- Change the label bias initial distribution from uniform to the one we leanerd seperately.\n",
    "- ~Implement Treacher Forcing~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313090ee-6b96-4cb0-bd77-27df2c9941bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%debug\n",
    "attn_clas = LabelAttentionClassifier(400, 1271)\n",
    "test_eq(getattrs(attn_clas, 'n_hidden', 'n_lbs'), (400, 1271))\n",
    "inps, outs, mask = torch.zeros(16, 72*20).random_(10), torch.randn(16, 72*20, 400), torch.randint(2, size=(16, 72*20))\n",
    "x, *_ = attn_clas((inps, outs, mask))\n",
    "test_eq(x.shape, (16, 1271))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f7b3e-f778-4758-bfb1-6eed725de8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_xmltext_classifier(arch, vocab_sz, n_class, seq_len=72, config=None, drop_mult=1., pad_idx=1, max_len=72*20, y_range=None):\n",
    "    \"Create a text classifier from `arch` and its `config`, maybe `pretrained`\"\n",
    "    meta = _model_meta[arch]\n",
    "    config = ifnone(config, meta['config_clas']).copy()\n",
    "    for k in config.keys():\n",
    "        if k.endswith('_p'): config[k] *= drop_mult\n",
    "    n_hidden = config[meta['hid_name']]\n",
    "    config.pop('output_p')\n",
    "    init = config.pop('init') if 'init' in config else None\n",
    "    encoder = SentenceEncoder(seq_len, arch(vocab_sz, **config), pad_idx=pad_idx, max_len=max_len)\n",
    "    decoder = LabelAttentionClassifier(n_hidden, n_class, y_range=y_range)\n",
    "    model = SequentialRNN(encoder, decoder)\n",
    "    return model if init is None else model.apply(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7793d31-693b-4d10-93e5-9e93e9051b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def awd_lstm_xclas_split(model):\n",
    "    \"Split a RNN `model` in groups for differential learning rates.\"\n",
    "    groups = [nn.Sequential(model[0].module.encoder, model[0].module.encoder_dp)]\n",
    "    groups += [nn.Sequential(rnn, dp) for rnn, dp in zip(model[0].module.rnns, model[0].module.hidden_dps)]\n",
    "    groups = L(groups + [model[1].pay_attn, model[1].boost_attn])\n",
    "    return groups.map(params)+model[1].label_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e699e-bb76-464d-95a9-c97324407d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_xmltext_classifier2(arch, vocab_sz, n_class, seq_len=72, config=None, drop_mult=1., pad_idx=1, max_len=72*20, y_range=None, running_decoder=True):\n",
    "    \"Create a text classifier from `arch` and its `config`, maybe `pretrained`\"\n",
    "    meta = _model_meta[arch]\n",
    "    config = ifnone(config, meta['config_clas']).copy()\n",
    "    for k in config.keys():\n",
    "        if k.endswith('_p'): config[k] *= drop_mult\n",
    "    n_hidden = config[meta['hid_name']]\n",
    "    config.pop('output_p')\n",
    "    init = config.pop('init') if 'init' in config else None\n",
    "    decoder = LabelAttentionClassifier(n_hidden, n_class, y_range=y_range)\n",
    "    encoder = AttentiveSentenceEncoder(seq_len, arch(vocab_sz, **config), decoder, pad_idx=pad_idx, max_len=max_len, running_decoder=running_decoder)\n",
    "    model =  SequentialRNN(encoder, decoder)\n",
    "    return model if init is None else model.apply(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858e4ea-1bd5-4b65-882e-2936795b259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "assert _model_meta[AWD_LSTM]['config_clas'] == awd_lstm_clas_config\n",
    "model = get_xmltext_classifier2(AWD_LSTM, 60000, 1271, seq_len=72, config=awd_lstm_clas_config, \n",
    "                               drop_mult=0.1, max_len=72*40)\n",
    "assert hasattr(model[0], 'decoder') # encoder knows about the decoder\n",
    "assert model[0].decoder is model[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c62b1-c29b-432a-9b8f-9ef7ca978bcf",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294269ac-6a2f-4bc0-8160-7e4ea3cab241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepk",
   "language": "python",
   "name": "deepk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
