{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8d823-2303-49fa-ba64-7881bcb70b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq xcube  # upgrade xcube on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6496c1-fab0-447f-af93-79cae9087894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.basics import *\n",
    "from fastai.text.learner import *\n",
    "from fastai.callback.rnn import *\n",
    "from fastai.text.models.awdlstm import *\n",
    "from fastai.text.models.core import get_text_classifier\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from xcube.text.models.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de734b9-c91e-42d1-a986-3d9a4f4e8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6918a5a-ce9c-4222-bf49-fde8e0268244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp text.learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d4897-0be6-47da-bd90-21217e9f184e",
   "metadata": {},
   "source": [
    "# Learner for the XML Text application:\n",
    "\n",
    "> All the functions necessary to build `Learner` suitable for transfer learning in XML text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6651917d-cd3b-4533-b19d-7ca3feb32873",
   "metadata": {},
   "source": [
    "The most important function of this module is `xmltext_classifier_learner`. This will help you define a `Learner` using a pretrained Language Model for the encoder and a pretrained Learning-to-Rank-Model for the decoder. (Tutorial: Coming Soon!). This module is inspired from [fastai's](https://github.com/fastai/fastai) [TextLearner](https://docs.fast.ai/text.learner.html) based on the paper [ULMFit](https://arxiv.org/pdf/1801.06146.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b331383-0c65-4d88-9689-4eaa2c0eef47",
   "metadata": {},
   "source": [
    "## Loading label embeddings from a pretrained colab model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dfc32-d2b6-4107-9b5e-5e3f9933380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_text_vocab(dls:DataLoaders) -> list:\n",
    "    \"Get text vocabulary from `DataLoaders`\"\n",
    "    vocab = dls.vocab\n",
    "    if isinstance(vocab, L): vocab = vocab[0]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbf616-ed91-4681-8733-ba59703b8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_label_vocab(dls:DataLoaders) -> list:\n",
    "    \"Get label vocabulary from `DataLoaders`\"\n",
    "    vocab = dls.vocab\n",
    "    if isinstance(vocab, L): vocab = vocab[1]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e749a-83ac-41ad-b5b8-b7d141bc0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def match_collab(\n",
    "    old_wgts:dict, # Embedding weights of the colab model\n",
    "    collab_vocab:dict, # Vocabulary of `token` and `label` used for colab pre-training\n",
    "    lbs_vocab:list # Current labels vocabulary\n",
    ") -> dict:\n",
    "    \"Convert the label embedding in `old_wgts` to go from `old_vocab` in colab to `lbs_vocab`\"\n",
    "    bias, wgts = old_wgts.get('i_bias.weight', None), old_wgts.get('i_weight.weight')\n",
    "    wgts_m = wgts.mean(0)\n",
    "    new_wgts = wgts.new_zeros((len(lbs_vocab), wgts.size(1)))\n",
    "    if bias is not None:\n",
    "        bias_m = bias.mean(0)\n",
    "        new_bias = bias.new_zeros((len(lbs_vocab), 1))\n",
    "    collab_lbs_vocab = collab_vocab['label']\n",
    "    collab_o2i = collab_lbs_vocab.o2i if hasattr(collab_lbs_vocab, 'o2i') else {w:i for i,w in enumerate(collab_lbs_vocab)}\n",
    "    missing = 0\n",
    "    for i,w in enumerate(lbs_vocab):\n",
    "        idx = collab_o2i.get(w, -1)\n",
    "        new_wgts[i] = wgts[idx] if idx>=0 else wgts_m\n",
    "        if bias is not None: new_bias[i] = bias[idx] if idx>=0 else bias_m\n",
    "        if idx == -1: missing = missing + 1\n",
    "    old_wgts['i_weight.weight'] = new_wgts\n",
    "    if bias is not None: old_wgts['i_bias.weight'] = new_bias\n",
    "    return old_wgts, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0c5d8-7104-4971-a78f-d17be39abccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = {'u_weight.weight': torch.randn(3,5), \n",
    "        'i_weight.weight': torch.randn(4,5),\n",
    "        'u_bias.weight'  : torch.randn(3,1),\n",
    "        'i_bias.weight'  : torch.randn(4,1)}\n",
    "collab_vocab = {'token': ['#na#', 'sun', 'moon', 'earth', 'mars'],\n",
    "                'label': ['#na#', 'a', 'c', 'b']}\n",
    "lbs_vocab = ['a', 'b', 'c']\n",
    "new_wgts, missing = match_collab(wgts.copy(), collab_vocab, lbs_vocab)\n",
    "test_eq(missing, 0)\n",
    "test_close(wgts['u_weight.weight'], new_wgts['u_weight.weight'])\n",
    "test_close(wgts['u_bias.weight'], new_wgts['u_bias.weight'])\n",
    "with ExceptionExpected(ex=AssertionError, regex=\"close\"):\n",
    "    test_close(wgts['i_weight.weight'][1:], new_wgts['i_weight.weight'])\n",
    "    test_close(wgts['i_bias.weight'][1:], new_wgts['i_bias.weight'])\n",
    "old_w, new_w = wgts['i_weight.weight'], new_wgts['i_weight.weight']\n",
    "old_b, new_b = wgts['i_bias.weight'], new_wgts['i_bias.weight']\n",
    "for (old_k,old_v), (new_k, new_v) in zip(wgts.items(), new_wgts.items()): \n",
    "    if old_k.startswith('u'): test_eq(old_v.size(), new_v.size())\n",
    "    else: test_ne(old_v.size(), new_v.size());\n",
    "    # print(f\"old: {old_k} = {old_v.size()}, new: {new_k} = {new_v.size()}\")\n",
    "test_eq(new_w[0], old_w[1]); test_eq(new_b[0], old_b[1])\n",
    "test_eq(new_w[1], old_w[3]); test_eq(new_b[1], old_b[3])\n",
    "test_eq(new_w[2], old_w[2]); test_eq(new_b[2], old_b[2])\n",
    "test_shuffled(list(old_b[1:].squeeze().numpy()), list(new_b.squeeze().numpy()))\n",
    "test_eq(torch.sort(old_b[1:], dim=0)[0], torch.sort(new_b, dim=0)[0])\n",
    "test_eq(torch.sort(old_w[1:], dim=0)[0], torch.sort(new_w, dim=0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341847dd-00a6-414d-98fb-e4922e1eccb4",
   "metadata": {},
   "source": [
    "## Loading Pretrained Information Gain as Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d51b56-f98f-426d-8d46-493d3552edc3",
   "metadata": {},
   "source": [
    "**1. Planting brain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49138f56-a5a3-4e12-b37c-eae2db651d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcube.l2r.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e08619-019a-4631-8f59-b46a70c44de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mimic = untar_xxx(XURLs.MIMIC3)\n",
    "xml_vocab = load_pickle(source_mimic/'mimic3-9k_clas_full_vocab.pkl')\n",
    "xml_vocab = L(xml_vocab).map(listify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ead7eb-6a67-4311-bbb8-871623a5121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_l2r = untar_xxx(XURLs.MIMIC3_L2R)\n",
    "boot_path = join_path_file('mimic3-9k_tok_lbl_info', source_l2r, ext='.pkl')\n",
    "bias_path = join_path_file('p_L', source_l2r, ext='.pkl')\n",
    "l2r_bootstrap = torch.load(boot_path, map_location=default_device())\n",
    "brain_bias = torch.load(bias_path, map_location=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcf19c-2416-4d14-8614-8a889fea0a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last two places in brain vocab has ['xxfake', 'xxfake']\n"
     ]
    }
   ],
   "source": [
    "*brain_vocab, brain = mapt(l2r_bootstrap.get, ['toks', 'lbs', 'mutual_info_jaccard'])\n",
    "brain_vocab = L(brain_vocab).map(listify)\n",
    "toks, lbs = brain_vocab\n",
    "print(f\"last two places in brain vocab has {toks[-2:]}\")\n",
    "# toks = CategoryMap(toks, sort=False)\n",
    "brain_bias = brain_bias[:, :, 0].squeeze(-1)\n",
    "lbs_des = load_pickle(source_mimic/'code_desc.pkl')\n",
    "assert isinstance(lbs_des, dict)\n",
    "test_eq(brain.shape, (len(toks), len(lbs))) # last two places has 'xxfake'\n",
    "test_eq(brain_bias.shape, [len(lbs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf1375-8dae-4531-99c3-b42947a28393",
   "metadata": {},
   "source": [
    "The tokens which are there in the xml vocab but not in the brain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddcd95-7b47-496f-8d91-cbebbf73ca96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#20) ['oncogenic','luteinizing','serendipitously','92k','q2day','mhc','promiscuity','foi','dobhoof','unrmarkable'...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found_in_brain = L(set(xml_vocab[0]).difference(set(brain_vocab[0])))\n",
    "not_found_in_brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ba7d8-9d37-4fdc-9045-40ce43d3b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(lambda : toks.index('cella'), contains='is not in list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7d566-7fcd-4542-809f-0591018405bf",
   "metadata": {},
   "source": [
    "The tokens which are in the brain but were not present in the xml vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b1933-81cd-4280-afca-8f009bd7688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(brain_vocab[0]).difference(xml_vocab[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb96cc-7c9d-4bad-9137-81e2f302ae21",
   "metadata": {},
   "source": [
    "Thankfully, we have `info` for all the labels in the xml vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef0876-d1ec-40af-b4d0-069a5b024b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(brain_vocab[1]).symmetric_difference(brain_vocab[1]) == set()\n",
    "# test_shuffled(xml_vocab[1], mimic_vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bae0e-536f-47f3-8433-ae7680c62fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _xml2brain(xml_vocab, brain_vocab, parent_bar=None):\n",
    "    \"Creates a mapping between the indices of the xml vocab and the brain vocab\"\n",
    "    pbar = progress_bar(xml_vocab, parent=parent_bar, leave=True)\n",
    "    xml2brain = {i: brain_vocab.index(o) if o in brain_vocab else np.inf  for i,o in enumerate(pbar)}\n",
    "    xml2brain_notfnd = [o for o in xml2brain if xml2brain[o] is np.inf]\n",
    "    return xml2brain, xml2brain_notfnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89677ad5-60bb-4758-b854-8d87d869b89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='57376' class='' max='57376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [57376/57376 00:20&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toks_xml2brain, toks_notfnd = _xml2brain(xml_vocab[0], brain_vocab[0])\n",
    "\n",
    "toks_found = set(toks_xml2brain).difference(set(toks_notfnd))\n",
    "test_shuffled(array(xml_vocab[0])[toks_notfnd], not_found_in_brain)\n",
    "some_xml_idxs = np.random.choice(array(L(toks_found)), size=10)\n",
    "some_xml_toks = array(xml_vocab[0])[some_xml_idxs]\n",
    "corres_brain_idxs = L(map(toks_xml2brain.get, some_xml_idxs))\n",
    "corres_brain_toks = array(toks)[corres_brain_idxs]\n",
    "assert all_equal(some_xml_toks, corres_brain_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61646a6f-4323-4f7f-9ca0-e341aa36b8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8922' class='' max='8922' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8922/8922 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lbs_xml2brain, lbs_notfnd = _xml2brain(xml_vocab[1], brain_vocab[1])\n",
    "\n",
    "lbs_found = set(lbs_xml2brain).difference(set(lbs_notfnd))\n",
    "some_xml_idxs = np.random.choice(array(L(lbs_found)), size=10)\n",
    "some_xml_lbs = array(xml_vocab[1])[some_xml_idxs]\n",
    "corres_brain_idxs = L(map(lbs_xml2brain.get, some_xml_idxs))\n",
    "corres_brain_lbs = array(lbs)[corres_brain_idxs]\n",
    "assert all_equal(some_xml_lbs, corres_brain_lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95a209-eba2-4e1f-9fbd-605b77393b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def brainsplant(xml_vocab, brain_vocab, brain, brain_bias, device=None):\n",
    "    toks_lbs = 'toks lbs'.split()\n",
    "    mb = master_bar(range(2))\n",
    "    for i in mb:\n",
    "        globals().update(dict(zip((toks_lbs[i]+'_xml2brain', toks_lbs[i]+'_notfnd'), (_xml2brain(xml_vocab[i], brain_vocab[i], parent_bar=mb)))))\n",
    "        mb.write = f\"Finished Loop {i}\"\n",
    "    xml_brain = torch.zeros(*xml_vocab.map(len)).to(default_device() if device is None else device) # initialize empty brain\n",
    "    xml_lbsbias = torch.zeros(len(xml_vocab[1])).to(default_device() if device is None else device)\n",
    "    toks_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in toks_xml2brain.items() if brn_idx is not np.inf) \n",
    "    lbs_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in lbs_xml2brain.items() if brn_idx is not np.inf) \n",
    "    xml_brain[toks_map.itemgot(0)] = brain[toks_map.itemgot(1)][:, lbs_map.itemgot(1)] # permute toks dim to match xml and brain\n",
    "    xml_brain[:, lbs_map.itemgot(0)] = xml_brain.clone() # permute lbs dim to match xml and brain\n",
    "    xml_lbsbias[lbs_map.itemgot(0)] = brain_bias[lbs_map.itemgot(1)].clone() # permute toks dim to match xml and brain\n",
    "    return xml_brain, xml_lbsbias, toks_map, lbs_map, toks_xml2brain, lbs_xml2brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655ab82-2986-471d-b628-aaee8fea1473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xml_brain, xml_lbsbias, toks_map, lbs_map, toks_xml2brain, lbs_xml2brain = brainsplant(xml_vocab, brain_vocab, brain, brain_bias)\n",
    "test_eq(xml_brain.shape, xml_vocab.map(len))\n",
    "test_eq(xml_brain[toks_notfnd], xml_brain.new_zeros(len(toks_notfnd), len(xml_vocab[1])))\n",
    "assert all_equal(array(xml_vocab[0])[toks_map.itemgot(0)], array(brain_vocab[0])[toks_map.itemgot(1)])\n",
    "assert all_equal(array(xml_vocab[1])[lbs_map.itemgot(0)], array(brain_vocab[1])[lbs_map.itemgot(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54faff-2352-437e-b72e-b4e1c3d6dca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the lbl 996.87 (Complications of transplanted intestine), the top tokens that needs attention are:\n",
      "+ ('consultued', 0.25548762)\n",
      "+ ('cip', 0.25548762)\n",
      "+ ('parlor', 0.24661502)\n",
      "+ ('transplantations', 0.18601614)\n",
      "+ ('scaffoid', 0.18601614)\n",
      "+ ('epineprine', 0.18601614)\n",
      "+ ('culinary', 0.17232327)\n",
      "+ ('coordinates', 0.1469037)\n",
      "+ ('aminotransferases', 0.12153866)\n",
      "+ ('hydronephroureter', 0.12153866)\n",
      "+ ('27yom', 0.12153866)\n",
      "+ ('27y', 0.103684604)\n",
      "+ ('hardward', 0.090407245)\n",
      "+ ('leukoreduction', 0.08014185)\n",
      "+ ('venting', 0.07831942)\n",
      "+ ('secrete', 0.07196123)\n",
      "+ ('orthogonal', 0.07196123)\n",
      "+ ('naac', 0.06891022)\n",
      "+ ('mgso4', 0.0662555)\n",
      "+ ('septecemia', 0.065286644)\n"
     ]
    }
   ],
   "source": [
    "# tests to ensure `brainsplant` was successful \n",
    "lbl = '642.41'\n",
    "lbl = '38.93'\n",
    "lbl = '51.10'\n",
    "lbl = '996.87'\n",
    "lbl_idx_from_brn = brain_vocab[1].index(lbl)\n",
    "tok_vals_from_brn, top_toks_from_brn= L(brain[:, lbl_idx_from_brn].topk(k=20)).map(Self.cpu())\n",
    "lbl_idx_from_xml = xml_vocab[1].index(lbl)\n",
    "tok_vals_from_xml, top_toks_from_xml = L(xml_brain[:, lbl_idx_from_xml].topk(k=20)).map(Self.cpu())\n",
    "test_eq(lbs_xml2brain[lbl_idx_from_xml], lbl_idx_from_brn)\n",
    "test_eq(tok_vals_from_brn, tok_vals_from_xml)\n",
    "test_eq(array(brain_vocab[0])[top_toks_from_brn], array(xml_vocab[0])[top_toks_from_xml])\n",
    "test_eq(brain_bias[lbl_idx_from_brn], xml_lbsbias[lbl_idx_from_xml])\n",
    "print(f\"For the lbl {lbl} ({lbs_des.get(lbl)}), the top tokens that needs attention are:\")\n",
    "print('\\n'.join(L(array(xml_vocab[0])[top_toks_from_xml], use_list=True).zipwith(L(tok_vals_from_xml.numpy(), use_list=True)).map(str).map(lambda o: \"+ \"+o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088612a-0f41-4458-9608-1ef421f145af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the token restitched, the top labels that needs attention are:\n",
      "+ ('Other operations on supporting structures of uterus', 0.29102018)\n",
      "+ ('Other proctopexy', 0.29102018)\n",
      "+ ('Other operations on cul-de-sac', 0.18601614)\n",
      "+ (None, 0.07494824)\n",
      "+ ('Intervertebral disc disorder with myelopathy, thoracic region', 0.055331517)\n",
      "+ ('Excision of scapula, clavicle, and thorax [ribs and sternum] for graft', 0.04382947)\n",
      "+ ('Other repair of omentum', 0.028067086)\n",
      "+ ('Chronic lymphocytic thyroiditis', 0.01986737)\n",
      "+ (None, 0.019236181)\n",
      "+ ('Reclosure of postoperative disruption of abdominal wall', 0.016585195)\n",
      "+ ('Other disorders of calcium metabolism', 0.009393147)\n",
      "+ ('Pain in joint involving pelvic region and thigh', 0.008421187)\n",
      "+ ('Exteriorization of small intestine', 0.00817792)\n",
      "+ ('Fusion or refusion of 9 or more vertebrae', 0.00762466)\n",
      "+ ('Kyphosis (acquired) (postural)', 0.0074228523)\n",
      "+ ('Unspecified procedure as the cause of abnormal reaction of patient, or of later complication, without mention of misadventure at time of procedure', 0.0063889036)\n",
      "+ ('Application or administration of adhesion barrier substance', 0.00610513)\n",
      "+ ('Acute osteomyelitis involving other specified sites', 0.0054434645)\n",
      "+ ('Body Mass Index less than 19, adult', 0.004719585)\n",
      "+ ('Dorsal and dorsolumbar fusion, anterior technique', 0.0046444684)\n"
     ]
    }
   ],
   "source": [
    "tok = 'fibrillation'\n",
    "tok = 'colpo'\n",
    "tok = 'amiodarone'\n",
    "tok = 'flagyl'\n",
    "tok = 'nasalilid'\n",
    "tok = 'hemetemesis'\n",
    "tok = 'restitched'\n",
    "tok_idx_from_brn = brain_vocab[0].index(tok)\n",
    "lbs_vals_from_brn, top_lbs_from_brn = L(brain[tok_idx_from_brn].topk(k=20)).map(Self.cpu())\n",
    "tok_idx_from_xml = xml_vocab[0].index(tok)\n",
    "test_eq(tok_idx_from_brn, toks_xml2brain[tok_idx_from_xml])\n",
    "lbs_vals_from_xml, top_lbs_from_xml = L(xml_brain[tok_idx_from_xml].topk(k=20)).map(Self.cpu())\n",
    "test_eq(lbs_vals_from_brn, lbs_vals_from_xml)\n",
    "try: \n",
    "    test_eq(array(brain_vocab[1])[top_lbs_from_brn], array(xml_vocab[1])[top_lbs_from_xml])\n",
    "except AssertionError as e: \n",
    "    print(type(e).__name__, \"due to instability in sorting (nothing to worry!)\");\n",
    "    test_shuffled(array(brain_vocab[1])[top_lbs_from_brn], array(xml_vocab[1])[top_lbs_from_xml])\n",
    "print('')\n",
    "print(f\"For the token {tok}, the top labels that needs attention are:\")\n",
    "print('\\n'.join(L(mapt(lbs_des.get, array(xml_vocab[1])[top_lbs_from_xml])).zipwith(L(lbs_vals_from_xml.numpy(), use_list=True)).map(str).map(lambda o: \"+ \"+o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e897af-7a67-4c27-aa86-74cdfcd6151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some tokens (with repetitions):\n",
      " -hr120\n",
      "-hypromellose\n",
      "-revieled\n",
      "-revieled\n",
      "-hr120\n",
      "-lever\n",
      "-optimum\n",
      "-sulfas\n",
      "-parasentesis\n",
      "-revieled\n",
      "-hr120\n",
      "-2007aw209\n",
      "-hr120\n",
      "-jirovecci\n",
      "-jirovecci\n",
      "-parasentesis\n",
      "-revieled\n",
      "-2007aw209\n",
      "-parasentesis\n",
      "-revieled\n"
     ]
    }
   ],
   "source": [
    "some_toks = random.sample(toks_map.itemgot(0), 10)\n",
    "counts = [c*6 for c in random.sample(range(10), 10)]\n",
    "some_toks = random.sample(some_toks, 20, counts=counts)\n",
    "# Counter(some_toks)\n",
    "cors_toks_brn = L(mapt(toks_xml2brain.get, some_toks))\n",
    "test_eq(array(brain_vocab[0])[cors_toks_brn], array(xml_vocab[0])[some_toks])\n",
    "print(\"some tokens (with repetitions):\\n\",'\\n'.join(['-'+xml_vocab[0][t]for t in some_toks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41799697-a3b3-4e0d-a53c-7a39246c218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = xml_brain[some_toks]\n",
    "test_eq(attn.shape, (len(some_toks), xml_brain.shape[1]))\n",
    "# semantics of attn\n",
    "# for each token we can compute the attention each label deserves by pulling out all the columns for a label\n",
    "for t, a in zip(some_toks,attn):\n",
    "    test_eq(xml_brain[t], a)\n",
    "# for each label we can compute the attention those tokens deserve by pulling out all rows for a label\n",
    "for lbl in range(xml_brain.shape[1]):\n",
    "    test_eq(xml_brain[:, lbl][some_toks], attn[:, lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728754ad-5181-4d23-bf88-9783ee2753fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>most_relevant_lbl</th>\n",
       "      <th>lbl_attn</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lever</td>\n",
       "      <td>77.39</td>\n",
       "      <td>0.097938</td>\n",
       "      <td>Other division of other bone, except facial bones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2007aw209</td>\n",
       "      <td>681.11</td>\n",
       "      <td>0.072454</td>\n",
       "      <td>Onychia and paronychia of toe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2007aw209</td>\n",
       "      <td>681.11</td>\n",
       "      <td>0.072454</td>\n",
       "      <td>Onychia and paronychia of toe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hypromellose</td>\n",
       "      <td>76.45</td>\n",
       "      <td>0.067027</td>\n",
       "      <td>Other total ostectomy of other facial bone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hr120</td>\n",
       "      <td>922.4</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>Contusion of genital organs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hr120</td>\n",
       "      <td>922.4</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>Contusion of genital organs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hr120</td>\n",
       "      <td>922.4</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>Contusion of genital organs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hr120</td>\n",
       "      <td>922.4</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>Contusion of genital organs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>revieled</td>\n",
       "      <td>572.1</td>\n",
       "      <td>0.039395</td>\n",
       "      <td>Portal pyemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>revieled</td>\n",
       "      <td>572.1</td>\n",
       "      <td>0.039395</td>\n",
       "      <td>Portal pyemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>revieled</td>\n",
       "      <td>572.1</td>\n",
       "      <td>0.039395</td>\n",
       "      <td>Portal pyemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revieled</td>\n",
       "      <td>572.1</td>\n",
       "      <td>0.039395</td>\n",
       "      <td>Portal pyemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>revieled</td>\n",
       "      <td>572.1</td>\n",
       "      <td>0.039395</td>\n",
       "      <td>Portal pyemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sulfas</td>\n",
       "      <td>375.15</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>Tear film insufficiency, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>parasentesis</td>\n",
       "      <td>265.1</td>\n",
       "      <td>0.028170</td>\n",
       "      <td>Other and unspecified manifestations of thiamine deficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>parasentesis</td>\n",
       "      <td>265.1</td>\n",
       "      <td>0.028170</td>\n",
       "      <td>Other and unspecified manifestations of thiamine deficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>parasentesis</td>\n",
       "      <td>265.1</td>\n",
       "      <td>0.028170</td>\n",
       "      <td>Other and unspecified manifestations of thiamine deficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>optimum</td>\n",
       "      <td>806.06</td>\n",
       "      <td>0.022296</td>\n",
       "      <td>Closed fracture of C(5)-C(7) level with complete lesion of cord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jirovecci</td>\n",
       "      <td>136.3</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>Pneumocystosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jirovecci</td>\n",
       "      <td>136.3</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>Pneumocystosis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           token most_relevant_lbl  lbl_attn   \n",
       "5          lever             77.39  0.097938  \\\n",
       "17     2007aw209            681.11  0.072454   \n",
       "11     2007aw209            681.11  0.072454   \n",
       "1   hypromellose             76.45  0.067027   \n",
       "0          hr120             922.4  0.060613   \n",
       "12         hr120             922.4  0.060613   \n",
       "10         hr120             922.4  0.060613   \n",
       "4          hr120             922.4  0.060613   \n",
       "9       revieled             572.1  0.039395   \n",
       "3       revieled             572.1  0.039395   \n",
       "16      revieled             572.1  0.039395   \n",
       "2       revieled             572.1  0.039395   \n",
       "19      revieled             572.1  0.039395   \n",
       "7         sulfas            375.15  0.035819   \n",
       "8   parasentesis             265.1  0.028170   \n",
       "15  parasentesis             265.1  0.028170   \n",
       "18  parasentesis             265.1  0.028170   \n",
       "6        optimum            806.06  0.022296   \n",
       "13     jirovecci             136.3  0.016813   \n",
       "14     jirovecci             136.3  0.016813   \n",
       "\n",
       "                                                        description  \n",
       "5                 Other division of other bone, except facial bones  \n",
       "17                                    Onychia and paronychia of toe  \n",
       "11                                    Onychia and paronychia of toe  \n",
       "1                        Other total ostectomy of other facial bone  \n",
       "0                                       Contusion of genital organs  \n",
       "12                                      Contusion of genital organs  \n",
       "10                                      Contusion of genital organs  \n",
       "4                                       Contusion of genital organs  \n",
       "9                                                     Portal pyemia  \n",
       "3                                                     Portal pyemia  \n",
       "16                                                    Portal pyemia  \n",
       "2                                                     Portal pyemia  \n",
       "19                                                    Portal pyemia  \n",
       "7                              Tear film insufficiency, unspecified  \n",
       "8       Other and unspecified manifestations of thiamine deficiency  \n",
       "15      Other and unspecified manifestations of thiamine deficiency  \n",
       "18      Other and unspecified manifestations of thiamine deficiency  \n",
       "6   Closed fracture of C(5)-C(7) level with complete lesion of cord  \n",
       "13                                                   Pneumocystosis  \n",
       "14                                                   Pneumocystosis  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(xml_vocab[0][t], l:=xml_vocab[1][lbl_idx], val.item(), lbs_des.get(l, 'NF')) for t,lbl_idx,val in zip(some_toks,attn.max(dim=1).indices.cpu(), attn.max(dim=1).values.cpu())],\n",
    "            columns=['token', 'most_relevant_lbl', 'lbl_attn', 'description']).sort_values(by='lbl_attn', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1739ab9-644d-4f65-bbe9-b8c0e1d141f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcube.layers import inattention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd67ea6-97a4-442b-b257-0843bf6868de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define label inattention cutoff\n",
    "k = 5\n",
    "# top_lbs_attn = attn.clone().unsqueeze(0).permute(0,2,1).inattention(k=k).permute(0,2,1).squeeze(0).contiguous() \n",
    "top_lbs_attn = attn.inattention(sort_dim=1, k=k) # applying `inattention` across the lbs dim\n",
    "test_eq(top_lbs_attn.shape, (len(some_toks), xml_brain.shape[1]))\n",
    "test_ne(attn, top_lbs_attn)\n",
    "test_eq(top_lbs_attn.argmax(dim=1), attn.argmax(dim=1))\n",
    "lbs_cf = top_lbs_attn.sum(dim=0) # the built confidence after seeing those 20 tokens\n",
    "test_eq(lbs_cf.shape, [top_lbs_attn.shape[1]])\n",
    "idxs = lbs_cf.nonzero().flatten().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ce29b-cd30-4ba2-bf67-2caf2679ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After looking at the tokens ['hr120', 'hypromellose', 'revieled', 'revieled', 'hr120', 'lever', 'optimum', 'sulfas', 'parasentesis', 'revieled', 'hr120', '2007aw209', 'hr120', 'jirovecci', 'jirovecci', 'parasentesis', 'revieled', '2007aw209', 'parasentesis', 'revieled'], I am confident about the following labels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbl</th>\n",
       "      <th>lbl_cf</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>922.4</td>\n",
       "      <td>0.242454</td>\n",
       "      <td>Contusion of genital organs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>71.71</td>\n",
       "      <td>0.211655</td>\n",
       "      <td>Suture of laceration of vulva or perineum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>572.1</td>\n",
       "      <td>0.196973</td>\n",
       "      <td>Portal pyemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>863.45</td>\n",
       "      <td>0.170439</td>\n",
       "      <td>Injury to rectum without open wound into cavity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>879.6</td>\n",
       "      <td>0.170439</td>\n",
       "      <td>Open wound of other and unspecified parts of trunk, without mention of complication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>681.11</td>\n",
       "      <td>0.144907</td>\n",
       "      <td>Onychia and paronychia of toe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>851.40</td>\n",
       "      <td>0.135465</td>\n",
       "      <td>Cerebellar or brain stem contusion without mention of open intracranial wound, with state of consciousness unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>867.6</td>\n",
       "      <td>0.132781</td>\n",
       "      <td>Injury to other specified pelvic organs without mention of open wound into cavity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>596.3</td>\n",
       "      <td>0.114191</td>\n",
       "      <td>Diverticulum of bladder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>908.9</td>\n",
       "      <td>0.108774</td>\n",
       "      <td>Late effect of unspecified injury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>77.39</td>\n",
       "      <td>0.097938</td>\n",
       "      <td>Other division of other bone, except facial bones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>225.0</td>\n",
       "      <td>0.086704</td>\n",
       "      <td>Benign neoplasm of brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>290.3</td>\n",
       "      <td>0.086704</td>\n",
       "      <td>Senile dementia with delirium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>265.1</td>\n",
       "      <td>0.084510</td>\n",
       "      <td>Other and unspecified manifestations of thiamine deficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>88.61</td>\n",
       "      <td>0.078788</td>\n",
       "      <td>Phlebography of veins of head and neck using contrast material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37.65</td>\n",
       "      <td>0.073254</td>\n",
       "      <td>Implant of external heart assist system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>76.45</td>\n",
       "      <td>0.067027</td>\n",
       "      <td>Other total ostectomy of other facial bone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>78.09</td>\n",
       "      <td>0.066995</td>\n",
       "      <td>Bone graft of other bone, except facial bones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>755.63</td>\n",
       "      <td>0.060612</td>\n",
       "      <td>Other congenital deformity of hip (joint)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>588.1</td>\n",
       "      <td>0.059581</td>\n",
       "      <td>Nephrogenic diabetes insipidus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>21.4</td>\n",
       "      <td>0.051033</td>\n",
       "      <td>Resection of nose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>054.12</td>\n",
       "      <td>0.051033</td>\n",
       "      <td>Herpetic ulceration of vulva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16.59</td>\n",
       "      <td>0.043830</td>\n",
       "      <td>Other exenteration of orbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>375.15</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>Tear film insufficiency, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>136.3</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>Pneumocystosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>80.15</td>\n",
       "      <td>0.032473</td>\n",
       "      <td>Other arthrotomy of hip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>362.03</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>Nonproliferative diabetic retinopathy NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>788.41</td>\n",
       "      <td>0.031426</td>\n",
       "      <td>Urinary frequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>344.81</td>\n",
       "      <td>0.027468</td>\n",
       "      <td>Locked-in state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.59</td>\n",
       "      <td>0.025726</td>\n",
       "      <td>Internal fixation of other bone, except facial bones, without fracture reduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39.65</td>\n",
       "      <td>0.025323</td>\n",
       "      <td>Extracorporeal membrane oxygenation [ECMO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>V15.1</td>\n",
       "      <td>0.022351</td>\n",
       "      <td>Personal history of surgery to heart and great vessels, presenting hazards to health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>806.06</td>\n",
       "      <td>0.022296</td>\n",
       "      <td>Closed fracture of C(5)-C(7) level with complete lesion of cord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>V09.90</td>\n",
       "      <td>0.020147</td>\n",
       "      <td>Infection with drug-resistant microorganisms, unspecified, without mention of multiple drug resistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.99</td>\n",
       "      <td>0.018430</td>\n",
       "      <td>Other operations on vessels of heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>358.00</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>Myasthenia gravis without (acute) exacerbation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>709.01</td>\n",
       "      <td>0.015913</td>\n",
       "      <td>Vitiligo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>952.06</td>\n",
       "      <td>0.015703</td>\n",
       "      <td>C(5)-C(7) level with complete lesion of spinal cord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>205.12</td>\n",
       "      <td>0.015703</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>607.3</td>\n",
       "      <td>0.015703</td>\n",
       "      <td>Priapism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>995.93</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>Systemic inflammatory response syndrome due to noninfectious process without acute organ dysfunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>487.0</td>\n",
       "      <td>0.014846</td>\n",
       "      <td>Influenza with pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>530.12</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>Acute esophagitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>191.3</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>Malignant neoplasm of parietal lobe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>451.84</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>Phlebitis and thrombophlebitis of upper extremities, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>530.10</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>Esophagitis, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>112.84</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>Candidal esophagitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>715.35</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>Osteoarthrosis, localized, not specified whether primary or secondary, involving pelvic region and thigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>205.10</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>Chronic myeloid leukemia without mention of remission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>572.3</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>Portal hypertension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>530.82</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>Esophageal hemorrhage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>456.21</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>Esophageal varices in diseases classified elsewhere, without mention of bleeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>535.50</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>Unspecified gastritis and gastroduodenitis, without mention of hemorrhage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>571.2</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>Alcoholic cirrhosis of liver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lbl    lbl_cf   \n",
       "43   922.4  0.242454  \\\n",
       "44   71.71  0.211655   \n",
       "49   572.1  0.196973   \n",
       "30  863.45  0.170439   \n",
       "42   879.6  0.170439   \n",
       "32  681.11  0.144907   \n",
       "37  851.40  0.135465   \n",
       "35   867.6  0.132781   \n",
       "24   596.3  0.114191   \n",
       "33   908.9  0.108774   \n",
       "40   77.39  0.097938   \n",
       "29   225.0  0.086704   \n",
       "19   290.3  0.086704   \n",
       "28   265.1  0.084510   \n",
       "45   88.61  0.078788   \n",
       "38   37.65  0.073254   \n",
       "52   76.45  0.067027   \n",
       "41   78.09  0.066995   \n",
       "26  755.63  0.060612   \n",
       "34   588.1  0.059581   \n",
       "36    21.4  0.051033   \n",
       "51  054.12  0.051033   \n",
       "39   16.59  0.043830   \n",
       "48  375.15  0.035819   \n",
       "14   136.3  0.033626   \n",
       "31   80.15  0.032473   \n",
       "46  362.03  0.032106   \n",
       "27  788.41  0.031426   \n",
       "50  344.81  0.027468   \n",
       "1    78.59  0.025726   \n",
       "9    39.65  0.025323   \n",
       "23   V15.1  0.022351   \n",
       "20  806.06  0.022296   \n",
       "22  V09.90  0.020147   \n",
       "18   36.99  0.018430   \n",
       "11  358.00  0.016356   \n",
       "3   709.01  0.015913   \n",
       "47  952.06  0.015703   \n",
       "53  205.12  0.015703   \n",
       "21   607.3  0.015703   \n",
       "25  995.93  0.015448   \n",
       "8    487.0  0.014846   \n",
       "17  530.12  0.013314   \n",
       "6    191.3  0.010390   \n",
       "10  451.84  0.010252   \n",
       "7   530.10  0.009709   \n",
       "15  112.84  0.009195   \n",
       "12  715.35  0.008061   \n",
       "13  205.10  0.006119   \n",
       "4    572.3  0.004869   \n",
       "16  530.82  0.004805   \n",
       "5   456.21  0.004329   \n",
       "2   535.50  0.004095   \n",
       "0    571.2  0.004086   \n",
       "\n",
       "                                                                                                               description  \n",
       "43                                                                                             Contusion of genital organs  \n",
       "44                                                                               Suture of laceration of vulva or perineum  \n",
       "49                                                                                                           Portal pyemia  \n",
       "30                                                                         Injury to rectum without open wound into cavity  \n",
       "42                                     Open wound of other and unspecified parts of trunk, without mention of complication  \n",
       "32                                                                                           Onychia and paronychia of toe  \n",
       "37  Cerebellar or brain stem contusion without mention of open intracranial wound, with state of consciousness unspecified  \n",
       "35                                       Injury to other specified pelvic organs without mention of open wound into cavity  \n",
       "24                                                                                                 Diverticulum of bladder  \n",
       "33                                                                                       Late effect of unspecified injury  \n",
       "40                                                                       Other division of other bone, except facial bones  \n",
       "29                                                                                                Benign neoplasm of brain  \n",
       "19                                                                                           Senile dementia with delirium  \n",
       "28                                                             Other and unspecified manifestations of thiamine deficiency  \n",
       "45                                                          Phlebography of veins of head and neck using contrast material  \n",
       "38                                                                                 Implant of external heart assist system  \n",
       "52                                                                              Other total ostectomy of other facial bone  \n",
       "41                                                                           Bone graft of other bone, except facial bones  \n",
       "26                                                                               Other congenital deformity of hip (joint)  \n",
       "34                                                                                          Nephrogenic diabetes insipidus  \n",
       "36                                                                                                       Resection of nose  \n",
       "51                                                                                            Herpetic ulceration of vulva  \n",
       "39                                                                                             Other exenteration of orbit  \n",
       "48                                                                                    Tear film insufficiency, unspecified  \n",
       "14                                                                                                          Pneumocystosis  \n",
       "31                                                                                                 Other arthrotomy of hip  \n",
       "46                                                                               Nonproliferative diabetic retinopathy NOS  \n",
       "27                                                                                                       Urinary frequency  \n",
       "50                                                                                                         Locked-in state  \n",
       "1                                         Internal fixation of other bone, except facial bones, without fracture reduction  \n",
       "9                                                                               Extracorporeal membrane oxygenation [ECMO]  \n",
       "23                                    Personal history of surgery to heart and great vessels, presenting hazards to health  \n",
       "20                                                         Closed fracture of C(5)-C(7) level with complete lesion of cord  \n",
       "22                  Infection with drug-resistant microorganisms, unspecified, without mention of multiple drug resistance  \n",
       "18                                                                                    Other operations on vessels of heart  \n",
       "11                                                                          Myasthenia gravis without (acute) exacerbation  \n",
       "3                                                                                                                 Vitiligo  \n",
       "47                                                                     C(5)-C(7) level with complete lesion of spinal cord  \n",
       "53                                                                                                                      NF  \n",
       "21                                                                                                                Priapism  \n",
       "25                    Systemic inflammatory response syndrome due to noninfectious process without acute organ dysfunction  \n",
       "8                                                                                                 Influenza with pneumonia  \n",
       "17                                                                                                       Acute esophagitis  \n",
       "6                                                                                      Malignant neoplasm of parietal lobe  \n",
       "10                                                        Phlebitis and thrombophlebitis of upper extremities, unspecified  \n",
       "7                                                                                                 Esophagitis, unspecified  \n",
       "15                                                                                                    Candidal esophagitis  \n",
       "12                Osteoarthrosis, localized, not specified whether primary or secondary, involving pelvic region and thigh  \n",
       "13                                                                   Chronic myeloid leukemia without mention of remission  \n",
       "4                                                                                                      Portal hypertension  \n",
       "16                                                                                                   Esophageal hemorrhage  \n",
       "5                                         Esophageal varices in diseases classified elsewhere, without mention of bleeding  \n",
       "2                                                Unspecified gastritis and gastroduodenitis, without mention of hemorrhage  \n",
       "0                                                                                             Alcoholic cirrhosis of liver  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"After looking at the tokens {[xml_vocab[0][t]for t in some_toks]}, I am confident about the following labels:\")\n",
    "pd.DataFrame([(l:=xml_vocab[1][idx], val.item(), lbs_des.get(l, 'NF')) for idx,val in zip(idxs,lbs_cf[idxs])],\n",
    "            columns=['lbl', 'lbl_cf', 'description']).sort_values(by='lbl_cf', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ec9bc-8d5c-498b-a868-3d5e43faf89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| t: tensor([[0, 0, 0],\n",
      "               [0, 0, 0],\n",
      "               [0, 0, 0],\n",
      "               [0, 0, 0]])\n",
      "    s: tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
      "               [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
      "ic| s[row_perm.itemgot(1)]: tensor([[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "                                    [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9]])\n",
      "ic| s[row_perm.itemgot(1)][:, col_perm.itemgot(1)]: tensor([[11, 13, 19],\n",
      "                                                            [ 1,  3,  9]])\n",
      "ic| t: tensor([[13, 19, 11],\n",
      "               [ 0,  0,  0],\n",
      "               [ 0,  0,  0],\n",
      "               [ 3,  9,  1]])\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# semantics: `s` pulling out its 1st and 0th row is equivalent to `t` pulling out its 0th and 3rd row respectively (i.e., the data residing in the 1st and 0th row of the s matrix is same as the data residing at the 0th and the 3rd row of t's matrix)\n",
    "t = torch.zeros(4, 3).long()\n",
    "s = torch.arange(20).view(2, 10).long()\n",
    "# s = torch.arange(6).view(2,3).long()\n",
    "row_perm = L((0, 1), (3, 0)) # \n",
    "col_perm = L((2, 1), (0, 3), (1, -1))\n",
    "# col_perm = L((0,2), (1,0), (2,1))\n",
    "ic(t,s);\n",
    "ic(s[row_perm.itemgot(1)]); # pull out relevant rows from s\n",
    "ic(s[row_perm.itemgot(1)][:, col_perm.itemgot(1)]); # pull out relevant cols from s\n",
    "t[row_perm.itemgot(0)] = s[row_perm.itemgot(1)][:, col_perm.itemgot(1)] # permute rows\n",
    "t[:, col_perm.itemgot(0)] = t.clone() # permute cols\n",
    "# t[row_perm.itemgot(0)] = s[row_perm.itemgot(1)][:, col_perm.itemgot(1)][:, col_perm.itemgot(0)]\n",
    "ic(t);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e6266-162a-4cc2-8aad-8a012a2b611c",
   "metadata": {},
   "source": [
    "**2. Planting differentiable brain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2530f3-f6e2-427d-9712-461e25b60fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2r_wgts = torch.load(join_path_file('lin_lambdarank_full', source_l2r, ext='.pth'), map_location=default_device())\n",
    "if 'model' in l2r_wgts: l2r_wgts = l2r_wgts['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62294c-fe30-4c66-832f-32f017def64d",
   "metadata": {},
   "source": [
    "Need to match the wgts in xml and brain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc99996-3591-47fb-8fe1-23aebad6121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def brainsplant_diffntble(xml_vocab, brain_vocab, l2r_wgts, device=None):\n",
    "    toks_lbs = 'toks lbs'.split()\n",
    "    mb = master_bar(range(2))\n",
    "    for i in mb:\n",
    "        globals().update(dict(zip((toks_lbs[i]+'_xml2brain', toks_lbs[i]+'_notfnd'), (_xml2brain(xml_vocab[i], brain_vocab[i], parent_bar=mb)))))\n",
    "        mb.write = f\"Finished Loop {i}\" \n",
    "    toks_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in toks_xml2brain.items() if brn_idx is not np.inf) \n",
    "    lbs_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in lbs_xml2brain.items() if brn_idx is not np.inf) \n",
    "    tf_xml = torch.zeros(len(xml_vocab[0]), 200).to(default_device() if device is None else device) \n",
    "    tb_xml = torch.zeros(len(xml_vocab[0]), 1).to(default_device() if device is None else device) \n",
    "    lf_xml = torch.zeros(len(xml_vocab[1]), 200).to(default_device() if device is None else device) \n",
    "    lb_xml = torch.zeros(len(xml_vocab[1]), 1).to(default_device() if device is None else device) \n",
    "    tf_l2r, tb_l2r, lf_l2r, lb_l2r = list(l2r_wgts.values())\n",
    "    tf_xml[toks_map.itemgot(0)] = tf_l2r[toks_map.itemgot(1)].clone()\n",
    "    tb_xml[toks_map.itemgot(0)] = tb_l2r[toks_map.itemgot(1)].clone()\n",
    "    lf_xml[lbs_map.itemgot(0)] = lf_l2r[lbs_map.itemgot(1)].clone()\n",
    "    lb_xml[lbs_map.itemgot(0)] = lb_l2r[lbs_map.itemgot(1)].clone()\n",
    "    # import pdb; pdb.set_trace()\n",
    "    xml_wgts = {k: xml_val for k, xml_val in zip(l2r_wgts.keys(), (tf_xml, tb_xml, lf_xml, lb_xml))}\n",
    "    mod_dict = nn.ModuleDict({k.split('.')[0]: nn.Embedding(*v.size()) for k,v in xml_wgts.items()}).to(default_device() if device is None else device) \n",
    "    mod_dict.load_state_dict(xml_wgts)\n",
    "    return mod_dict, toks_map, lbs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c38b89-60e6-4e67-83c4-2b1975936697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod_dict, toks_map, lbs_map = brainsplant_diffntble(xml_vocab, brain_vocab, l2r_wgts)\n",
    "assert isinstance(mod_dict, nn.Module)\n",
    "assert nn.Module in mod_dict.__class__.__mro__ \n",
    "\n",
    "test_eq(mod_dict['token_factors'].weight.data[toks_map.itemgot(0)], l2r_wgts['token_factors.weight'][toks_map.itemgot(1)])\n",
    "test_eq(mod_dict['token_bias'].weight.data[toks_map.itemgot(0)], l2r_wgts['token_bias.weight'][toks_map.itemgot(1)])\n",
    "test_eq(mod_dict['label_factors'].weight.data[lbs_map.itemgot(0)], l2r_wgts['label_factors.weight'][lbs_map.itemgot(1)])\n",
    "test_eq(mod_dict['label_bias'].weight.data[lbs_map.itemgot(0)], l2r_wgts['label_bias.weight'][lbs_map.itemgot(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb824726-4ddf-4c82-b225-c3ae05bea88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (token_factors): Embedding(57376, 200)\n",
       "  (token_bias): Embedding(57376, 1)\n",
       "  (label_factors): Embedding(8922, 200)\n",
       "  (label_bias): Embedding(8922, 1)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117026a-9679-4baa-bb49-145644e5093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996.87: Complications of transplanted intestine\n",
      "51.10: Endoscopic retrograde cholangiopancreatography [ERCP]\n",
      "38.93: Venous catheterization, not elsewhere classified\n"
     ]
    }
   ],
   "source": [
    "some_lbs = ['996.87', '51.10', '38.93']\n",
    "for lbl in some_lbs:\n",
    "    print(f\"{lbl}: {lbs_des.get(lbl, 'NF')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12eebf-29af-406d-8906-0db54a4865b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbs_idx = tensor(mapt(xml_vocab[1].index, some_lbs)).to(default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425d4d7-9e4c-4a58-a32c-53ed9e1f4844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-transfere\n",
      "-places\n",
      "-52yrs\n",
      "-stomahesive\n",
      "-prostheses\n",
      "-effecting\n",
      "-nemenda\n",
      "-28am\n",
      "-reccur\n",
      "-mutations\n",
      "-oxygenating\n",
      "-secret\n",
      "-yersinia\n",
      "-mamogram\n",
      "-emtricitabin\n",
      "-phenolate\n",
      "-climb\n",
      "-takayasu\n",
      "-osmolarity\n",
      "-aerosolized\n",
      "-diltia\n",
      "-unkept\n",
      "-tm98\n",
      "-teds\n",
      "-lastly\n",
      "-interarterial\n",
      "-bovona\n",
      "-distrubution\n",
      "-87bpm\n",
      "-expressible\n",
      "-4th\n",
      "-duel\n",
      "-3uprbcs\n",
      "-steroid\n",
      "-extrememely\n",
      "-coalescing\n",
      "-ictera\n",
      "-mthdne\n",
      "-mainted\n",
      "-chagne\n",
      "-wachusett\n",
      "-proverbs\n",
      "-meclazine\n",
      "-blocade\n",
      "-including\n",
      "-quadramniotic\n",
      "-enlarged\n",
      "-klebisiella\n",
      "-hcc\n",
      "-unambiguously\n",
      "-allowance\n",
      "-lih\n",
      "-reoperation\n",
      "-maldisplaced\n",
      "-85cc\n",
      "-blistering\n",
      "-quad\n",
      "-cruzi\n",
      "-airplanes\n",
      "-warranting\n",
      "-doubts\n",
      "-coa\n",
      "-acceleration\n",
      "-resuspension\n",
      "-logistically\n",
      "-harmonic\n",
      "-dysgenesis\n",
      "-leforte\n",
      "-bsi\n",
      "-67mmhg\n",
      "-snared\n",
      "-trastuzumab\n"
     ]
    }
   ],
   "source": [
    "toks_idx = torch.randint(0, len(xml_vocab[0]), (72,)).to(default_device())\n",
    "print(\"-\"+'\\n-'.join(array(xml_vocab[0])[toks_idx.cpu()].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f4900-3464-407f-b74c-48edf13d437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "apprx_brain = mod_dict['token_factors'](toks_idx) @ mod_dict['label_factors'](lbs_idx).T + mod_dict['token_bias'](toks_idx) + mod_dict['label_bias'](lbs_idx).T\n",
    "test_eq(apprx_brain.shape, (72,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b5ba4-6cf9-4874-95f8-91e857abfc27",
   "metadata": {},
   "source": [
    "These are the tokens as ranked by the pretrained L2R model (which is essentially an approximation of the actual brain):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6996907-1880-4bbb-88ad-038f8a1575b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>996.87: Complications of transplanted intestine</th>\n",
       "      <th>51.10: Endoscopic retrograde cholangiopancreatography [ERCP]</th>\n",
       "      <th>38.93: Venous catheterization, not elsewhere classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enlarged</td>\n",
       "      <td>4th</td>\n",
       "      <td>steroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>including</td>\n",
       "      <td>reoperation</td>\n",
       "      <td>including</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4th</td>\n",
       "      <td>climb</td>\n",
       "      <td>enlarged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hcc</td>\n",
       "      <td>steroid</td>\n",
       "      <td>oxygenating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28am</td>\n",
       "      <td>enlarged</td>\n",
       "      <td>4th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>warranting</td>\n",
       "      <td>oxygenating</td>\n",
       "      <td>28am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>steroid</td>\n",
       "      <td>effecting</td>\n",
       "      <td>quad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quad</td>\n",
       "      <td>places</td>\n",
       "      <td>yersinia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>blistering</td>\n",
       "      <td>blistering</td>\n",
       "      <td>aerosolized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aerosolized</td>\n",
       "      <td>including</td>\n",
       "      <td>climb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bsi</td>\n",
       "      <td>hcc</td>\n",
       "      <td>hcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>climb</td>\n",
       "      <td>lastly</td>\n",
       "      <td>blistering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>reoperation</td>\n",
       "      <td>28am</td>\n",
       "      <td>osmolarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>oxygenating</td>\n",
       "      <td>tm98</td>\n",
       "      <td>places</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>places</td>\n",
       "      <td>quad</td>\n",
       "      <td>teds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>phenolate</td>\n",
       "      <td>phenolate</td>\n",
       "      <td>ictera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>yersinia</td>\n",
       "      <td>52yrs</td>\n",
       "      <td>expressible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>teds</td>\n",
       "      <td>mainted</td>\n",
       "      <td>phenolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>transfere</td>\n",
       "      <td>85cc</td>\n",
       "      <td>warranting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lastly</td>\n",
       "      <td>teds</td>\n",
       "      <td>mainted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   996.87: Complications of transplanted intestine   \n",
       "0                                         enlarged  \\\n",
       "1                                        including   \n",
       "2                                              4th   \n",
       "3                                              hcc   \n",
       "4                                             28am   \n",
       "5                                       warranting   \n",
       "6                                          steroid   \n",
       "7                                             quad   \n",
       "8                                       blistering   \n",
       "9                                      aerosolized   \n",
       "10                                             bsi   \n",
       "11                                           climb   \n",
       "12                                     reoperation   \n",
       "13                                     oxygenating   \n",
       "14                                          places   \n",
       "15                                       phenolate   \n",
       "16                                        yersinia   \n",
       "17                                            teds   \n",
       "18                                       transfere   \n",
       "19                                          lastly   \n",
       "\n",
       "   51.10: Endoscopic retrograde cholangiopancreatography [ERCP]   \n",
       "0                                                           4th  \\\n",
       "1                                                   reoperation   \n",
       "2                                                         climb   \n",
       "3                                                       steroid   \n",
       "4                                                      enlarged   \n",
       "5                                                   oxygenating   \n",
       "6                                                     effecting   \n",
       "7                                                        places   \n",
       "8                                                    blistering   \n",
       "9                                                     including   \n",
       "10                                                          hcc   \n",
       "11                                                       lastly   \n",
       "12                                                         28am   \n",
       "13                                                         tm98   \n",
       "14                                                         quad   \n",
       "15                                                    phenolate   \n",
       "16                                                        52yrs   \n",
       "17                                                      mainted   \n",
       "18                                                         85cc   \n",
       "19                                                         teds   \n",
       "\n",
       "   38.93: Venous catheterization, not elsewhere classified  \n",
       "0                                                  steroid  \n",
       "1                                                including  \n",
       "2                                                 enlarged  \n",
       "3                                              oxygenating  \n",
       "4                                                      4th  \n",
       "5                                                     28am  \n",
       "6                                                     quad  \n",
       "7                                                 yersinia  \n",
       "8                                              aerosolized  \n",
       "9                                                    climb  \n",
       "10                                                     hcc  \n",
       "11                                              blistering  \n",
       "12                                              osmolarity  \n",
       "13                                                  places  \n",
       "14                                                    teds  \n",
       "15                                                  ictera  \n",
       "16                                             expressible  \n",
       "17                                               phenolate  \n",
       "18                                              warranting  \n",
       "19                                                 mainted  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(array(xml_vocab[0])[toks_idx[apprx_brain.argsort(dim=0, descending=True)].cpu()], columns=L(zip(some_lbs, mapt(lbs_des.get, some_lbs))).map(': '.join)).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932776b4-72da-4414-a647-0cdaa2993c3c",
   "metadata": {},
   "source": [
    "Just to compare: This is how an actual brain would rank those tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743832ed-bd2c-4ca0-9d91-a4e6c1a97bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>996.87: Complications of transplanted intestine</th>\n",
       "      <th>51.10: Endoscopic retrograde cholangiopancreatography [ERCP]</th>\n",
       "      <th>38.93: Venous catheterization, not elsewhere classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>including</td>\n",
       "      <td>climb</td>\n",
       "      <td>including</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enlarged</td>\n",
       "      <td>28am</td>\n",
       "      <td>steroid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>steroid</td>\n",
       "      <td>quad</td>\n",
       "      <td>oxygenating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>effecting</td>\n",
       "      <td>oxygenating</td>\n",
       "      <td>enlarged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phenolate</td>\n",
       "      <td>hcc</td>\n",
       "      <td>28am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diltia</td>\n",
       "      <td>teds</td>\n",
       "      <td>quad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>coalescing</td>\n",
       "      <td>lastly</td>\n",
       "      <td>yersinia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>expressible</td>\n",
       "      <td>places</td>\n",
       "      <td>4th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bsi</td>\n",
       "      <td>aerosolized</td>\n",
       "      <td>aerosolized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28am</td>\n",
       "      <td>4th</td>\n",
       "      <td>unkept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4th</td>\n",
       "      <td>yersinia</td>\n",
       "      <td>transfere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lih</td>\n",
       "      <td>coa</td>\n",
       "      <td>stomahesive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>climb</td>\n",
       "      <td>blistering</td>\n",
       "      <td>blistering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tm98</td>\n",
       "      <td>resuspension</td>\n",
       "      <td>prostheses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oxygenating</td>\n",
       "      <td>reoperation</td>\n",
       "      <td>allowance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>duel</td>\n",
       "      <td>mthdne</td>\n",
       "      <td>diltia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>leforte</td>\n",
       "      <td>osmolarity</td>\n",
       "      <td>hcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>quad</td>\n",
       "      <td>prostheses</td>\n",
       "      <td>airplanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yersinia</td>\n",
       "      <td>mutations</td>\n",
       "      <td>harmonic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dysgenesis</td>\n",
       "      <td>warranting</td>\n",
       "      <td>takayasu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   996.87: Complications of transplanted intestine   \n",
       "0                                        including  \\\n",
       "1                                         enlarged   \n",
       "2                                          steroid   \n",
       "3                                        effecting   \n",
       "4                                        phenolate   \n",
       "5                                           diltia   \n",
       "6                                       coalescing   \n",
       "7                                      expressible   \n",
       "8                                              bsi   \n",
       "9                                             28am   \n",
       "10                                             4th   \n",
       "11                                             lih   \n",
       "12                                           climb   \n",
       "13                                            tm98   \n",
       "14                                     oxygenating   \n",
       "15                                            duel   \n",
       "16                                         leforte   \n",
       "17                                            quad   \n",
       "18                                        yersinia   \n",
       "19                                      dysgenesis   \n",
       "\n",
       "   51.10: Endoscopic retrograde cholangiopancreatography [ERCP]   \n",
       "0                                                         climb  \\\n",
       "1                                                          28am   \n",
       "2                                                          quad   \n",
       "3                                                   oxygenating   \n",
       "4                                                           hcc   \n",
       "5                                                          teds   \n",
       "6                                                        lastly   \n",
       "7                                                        places   \n",
       "8                                                   aerosolized   \n",
       "9                                                           4th   \n",
       "10                                                     yersinia   \n",
       "11                                                          coa   \n",
       "12                                                   blistering   \n",
       "13                                                 resuspension   \n",
       "14                                                  reoperation   \n",
       "15                                                       mthdne   \n",
       "16                                                   osmolarity   \n",
       "17                                                   prostheses   \n",
       "18                                                    mutations   \n",
       "19                                                   warranting   \n",
       "\n",
       "   38.93: Venous catheterization, not elsewhere classified  \n",
       "0                                                including  \n",
       "1                                                  steroid  \n",
       "2                                              oxygenating  \n",
       "3                                                 enlarged  \n",
       "4                                                     28am  \n",
       "5                                                     quad  \n",
       "6                                                 yersinia  \n",
       "7                                                      4th  \n",
       "8                                              aerosolized  \n",
       "9                                                   unkept  \n",
       "10                                               transfere  \n",
       "11                                             stomahesive  \n",
       "12                                              blistering  \n",
       "13                                              prostheses  \n",
       "14                                               allowance  \n",
       "15                                                  diltia  \n",
       "16                                                     hcc  \n",
       "17                                               airplanes  \n",
       "18                                                harmonic  \n",
       "19                                                takayasu  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array(xml_vocab[0])[xml_brain[:, lbl_idx].topk(k=20, dim=0).indices.cpu()]\n",
    "pd.DataFrame(array(xml_vocab[0])[toks_idx[xml_brain[:, lbs_idx][toks_idx].argsort(descending=True, dim=0)].cpu()], columns=L(zip(some_lbs, mapt(lbs_des.get, some_lbs))).map(': '.join)).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029a87d-200a-4bbb-b87a-f91528e8f544",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebca74e-f7e8-4970-a62f-d37cbe93b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88M\t/home/deb/.xcube/data/mimic3/mimic3-9k_lm_decoder_r.pth\n",
      "88M\t/home/deb/.xcube/data/mimic3/mimic3-9k_lm_decoder.pth\n"
     ]
    }
   ],
   "source": [
    "!find {source_mimic} -name \"*lm*decoder*.pth\" | xargs du -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62a479-14bc-4c47-a9b2-2bd1c04edc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_decoder_wgts = torch.load(join_path_file('mimic3-9k_lm_decoder', source_mimic, ext='.pth'), map_location=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255febc-9372-45ca-9489-608d03632688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [torch.Size([57376, 400]),torch.Size([57376])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(lm_decoder_wgts.values()).map(Self.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43bc73-32b7-4bb0-9b0c-7ff55aaa4124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('decoder.weight',\n",
       "              tensor([[-0.0305,  0.0738, -0.0172,  ..., -0.0500, -0.1311,  0.0177],\n",
       "                      [-0.0040,  0.0021, -0.0021,  ..., -0.0055,  0.0038, -0.0010],\n",
       "                      [-0.2785, -0.1316,  0.1003,  ..., -0.1472,  0.1957, -0.1504],\n",
       "                      ...,\n",
       "                      [-0.0097,  0.0057, -0.0115,  ..., -0.0217,  0.0112, -0.0018],\n",
       "                      [-0.0097,  0.0057, -0.0115,  ..., -0.0217,  0.0112, -0.0018],\n",
       "                      [-0.0097,  0.0057, -0.0115,  ..., -0.0217,  0.0112, -0.0018]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.bias',\n",
       "              tensor([ 6.0846, -4.8585,  0.6055,  ..., -3.2417, -3.2417, -3.2417],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_decoder_wgts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c861c18-839f-4423-972c-1632fc3289e6",
   "metadata": {},
   "source": [
    "## Base `Learner` for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e89ee-1737-4069-9627-8a5c6b31db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_collab_keys(\n",
    "    model, # Model architecture\n",
    "    wgts:dict # Model weights\n",
    ") -> tuple:\n",
    "    \"Load only collab `wgts` (`i_weight` and `i_bias`) in `model`, keeping the rest as is\"\n",
    "    sd = model.state_dict()\n",
    "    lbs_weight, i_weight = sd.get('1.attn.lbs_weight.weight', None), wgts.get('i_weight.weight', None)\n",
    "    lbs_bias, i_bias = sd.get('1.attn.lbs_weight.bias', None), wgts.get('i_bias.weight', None) \n",
    "    if lbs_weight is not None and i_weight is not None: lbs_weight.data = i_weight.data\n",
    "    if lbs_bias is not None and i_bias is not None: lbs_bias.data = i_bias.data\n",
    "    if '1.attn.lbs_weight_dp.emb.weight' in sd:\n",
    "        sd['1.attn.lbs_weight_dp.emb.weight'] = i_weight.data.clone()\n",
    "    return model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81941404-34e8-4a65-b369-7fa293b97b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.pay_attn.lbs.weight\n",
      "1.boost_attn.lin.weight\n",
      "1.boost_attn.lin.bias\n"
     ]
    }
   ],
   "source": [
    "config = awd_lstm_clas_config.copy()\n",
    "config.update({'n_hid': 10, 'emb_sz': 5})\n",
    "# tst = get_text_classifier(AWD_LSTM, 100, 3, config=config)\n",
    "tst = get_xmltext_classifier(AWD_LSTM, 100, 3, config=config)\n",
    "old_sd = tst.state_dict().copy()\n",
    "r = re.compile(\".*attn.*\")\n",
    "test_eq([key for key in old_sd if 'attn' in key], list(filter(r.match, old_sd)))\n",
    "print(\"\\n\".join(list(filter(r.match, old_sd))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af00554-0fba-4e8d-b75e-a01e5fec4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53294433-b75e-4d54-a574-6af80e705b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_sd = copy.deepcopy(tst.state_dict())\n",
    "load_collab_keys(tst, new_wgts)\n",
    "# <TODO: Deb> fix the following tests later\n",
    "# test_ne(old_sd['1.attn.lbs_weight.weight'], tst.state_dict()['1.attn.lbs_weight.weight'])\n",
    "# test_eq(tst.state_dict()['1.pay_attn.lbs_weight.weight'], new_wgts['i_weight.weight'])\n",
    "# test_ne(old_sd['1.attn.lbs_weight_dp.emb.weight'], tst.state_dict()['1.attn.lbs_weight_dp.emb.weight'])\n",
    "# test_eq(tst.state_dict()['1.attn.lbs_weight_dp.emb.weight'], new_wgts['i_weight.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e5ac5-9a18-4139-9cf1-030977f84eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcube.layers import *\n",
    "from xcube.layers import _planted_attention, _diffntble_planted_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af50343-383d-4284-b11e-d3016d54e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(Learner.__init__)\n",
    "class TextLearner(Learner):\n",
    "    \"Basic class for a `Learner` in NLP.\"\n",
    "    def __init__(self, \n",
    "        dls:DataLoaders, # Text `DataLoaders`\n",
    "        model, # A standard PyTorch model\n",
    "        alpha:float=2., # Param for `RNNRegularizer`\n",
    "        beta:float=1., # Param for `RNNRegularizer`\n",
    "        moms:tuple=(0.8,0.7,0.8), # Momentum for `Cosine Annealing Scheduler`\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(dls, model, moms=moms, **kwargs)\n",
    "        self.add_cbs(rnn_cbs())\n",
    "\n",
    "    def save_encoder(self, \n",
    "        file:str # Filename for `Encoder` \n",
    "    ):\n",
    "        \"Save the encoder to `file` in the model directory\"\n",
    "        if rank_distrib(): return # don't save if child proc\n",
    "        encoder = get_model(self.model)[0]\n",
    "        if hasattr(encoder, 'module'): encoder = encoder.module\n",
    "        torch.save(encoder.state_dict(), join_path_file(file, self.path/self.model_dir, ext='.pth'))\n",
    "    \n",
    "    @delegates(save_model)\n",
    "    def save(self,\n",
    "        file:str, # Filename for the state_directory of the model\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Save model and optimizer state (if `with_opt`) to `self.path/self.model_dir/file`\n",
    "        Save `self.dls.vocab` to `self.path/self.model_dir/clas_vocab.pkl`\n",
    "        \"\"\"\n",
    "        model_file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n",
    "        vocab_file = join_path_file(file+'_vocab', self.path/self.model_dir, ext='.pkl')\n",
    "        save_model(model_file, self.model, getattr(self, 'opt', None), **kwargs)\n",
    "        save_pickle(vocab_file, self.dls.vocab)\n",
    "        return model_file\n",
    "\n",
    "    def load_encoder(self, \n",
    "        file:str, # Filename of the saved encoder \n",
    "        device:(int,str,torch.device)=None # Device used to load, defaults to `dls` device\n",
    "    ):\n",
    "        \"Load the encoder `file` from the model directory, optionally ensuring it's on `device`\"\n",
    "        encoder = get_model(self.model)[0]\n",
    "        if device is None: device = self.dls.device\n",
    "        if hasattr(encoder, 'module'): encoder = encoder.module\n",
    "        distrib_barrier()\n",
    "        wgts = torch.load(join_path_file(file,self.path/self.model_dir, ext='.pth'), map_location=device)\n",
    "        encoder.load_state_dict(clean_raw_keys(wgts))\n",
    "        self.freeze()\n",
    "        return self\n",
    "\n",
    "    def load_pretrained(self, \n",
    "        wgts_fname:str, # Filename of saved weights \n",
    "        vocab_fname:str, # Saved vocabulary filename in pickle format\n",
    "        model=None # Model to load parameters from, defaults to `Learner.model`\n",
    "    ):\n",
    "        \"Load a pretrained model and adapt it to the data vocabulary.\"\n",
    "        old_vocab = load_pickle(vocab_fname)\n",
    "        new_vocab = _get_text_vocab(self.dls)\n",
    "        distrib_barrier()\n",
    "        wgts = torch.load(wgts_fname, map_location = lambda storage,loc: storage)\n",
    "        if 'model' in wgts: wgts = wgts['model'] #Just in case the pretrained model was saved with an optimizer\n",
    "        wgts = match_embeds(wgts, old_vocab, new_vocab)\n",
    "        load_ignore_keys(self.model if model is None else model, clean_raw_keys(wgts))\n",
    "        self.freeze()\n",
    "        return self\n",
    "\n",
    "    #For previous versions compatibility. Remove at release\n",
    "    @delegates(load_model_text)\n",
    "    def load(self, \n",
    "        file:str, # Filename of saved model \n",
    "        with_opt:bool=None, # Enable to load `Optimizer` state\n",
    "        device:(int,str,torch.device)=None, # Device used to load, defaults to `dls` device\n",
    "        **kwargs\n",
    "    ):\n",
    "        if device is None: device = self.dls.device\n",
    "        if self.opt is None: self.create_opt()\n",
    "        file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n",
    "        load_model_text(file, self.model, self.opt, device=device, **kwargs)\n",
    "        return self\n",
    "    \n",
    "    def load_collab(self,\n",
    "        wgts_fname:str, # Filename of the saved collab model\n",
    "        collab_vocab_fname:str, # Saved Vocabulary of collab labels in pickle format \n",
    "        model=None # Model to load parameters from, defaults to `Learner.model`\n",
    "    ):\n",
    "        \"Load the label embeddings learned by collab model`, and adapt it to the label vocabulary.\"\n",
    "        collab_vocab = load_pickle(collab_vocab_fname)\n",
    "        lbs_vocab = _get_label_vocab(self.dls)\n",
    "        distrib_barrier()\n",
    "        wgts = torch.load(wgts_fname, map_location=lambda storage,loc: storage)\n",
    "        if 'model' in wgts: wgts = wgts['model'] #Just in case the pretrained model was saved with an optimizer\n",
    "        wgts, _ = match_collab(wgts, collab_vocab, lbs_vocab)\n",
    "        load_collab_keys(self.model if model is None else model, wgts)\n",
    "        self.freeze()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c077c1d-1fde-4c45-ae1e-6f6cd3f58b4c",
   "metadata": {},
   "source": [
    "Adds a `ModelResetter` and an `RNNRegularizer` with `alpha` and `beta` to the callbacks, the rest is the same as `Learner` init. \n",
    "\n",
    "This `Learner` adds functionality to the base class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40448b2-664e-43c2-8c78-2f02de9faf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def save_decoder(self:LMLearner,\n",
    "                 file:str # Filename for `Decoder`\n",
    "    ):\n",
    "    \"Save the decoder to `file` in the model directory\"\n",
    "    if rank_distrib(): return # don't save if child proc\n",
    "    decoder = get_model(self.model)[1]\n",
    "    if hasattr(decoder, 'module'): decoder = decoder.module\n",
    "    torch.save(decoder.state_dict(), join_path_file(file, self.path/self.model_dir, ext='.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca03ad-94e9-44d6-8943-980c11b75408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def load_brain(self:TextLearner,\n",
    "               file_wgts: str, # Filename of the saved attention wgts\n",
    "               file_bias: str, # Filename of the saved label bias\n",
    "               device:(int,str,torch.device)=None # Device used to load, defaults to `default_device()`\n",
    "              ):\n",
    "    \"\"\"Load the pre-learnt label specific attention weights for each token from `file` located in the model directory, \n",
    "    optionally ensuring it's one `device`\n",
    "    \"\"\"\n",
    "    brain_path = join_path_file(file_wgts, self.path/self.model_dir, ext='.pkl')\n",
    "    bias_path = join_path_file(file_bias, self.path/self.model_dir, ext='.pkl')\n",
    "    brain_bootstrap = torch.load(brain_path, map_location=default_device() if device is None else device)\n",
    "    *brain_vocab, brain = mapt(brain_bootstrap.get, ['toks', 'lbs', 'mutual_info_jaccard'])\n",
    "    brain_vocab = L(brain_vocab).map(listify)\n",
    "    vocab = L(_get_text_vocab(self.dls), _get_label_vocab(self.dls)).map(listify)\n",
    "    brain_bias = torch.load(bias_path, map_location=default_device() if device is None else device)\n",
    "    brain_bias = brain_bias[:, :, 0].squeeze(-1)\n",
    "    print(\"Performing brainsplant...\")\n",
    "    self.brain, self.lbsbias, *_ = brainsplant(vocab, brain_vocab, brain, brain_bias)\n",
    "    print(\"Successfull!\")\n",
    "    # import pdb; pdb.set_trace()\n",
    "    plant_attn_layer = Lambda(Planted_Attention(self.brain))\n",
    "    setattr(self.model[1].pay_attn, 'attn', plant_attn_layer)\n",
    "    assert self.model[1].pay_attn.attn.func.f is _planted_attention\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14945a94-6d19-4ca8-87d1-2219827c7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def load_diffntble_brain(self:TextLearner,\n",
    "                         file_brain:str, # Filename of the bootstrap info for l2r\n",
    "                         file_l2r_wgts:str, # Filename of the pretrained l2r wgts\n",
    "                         file_lm_decoder_wgts:str, # Filename of the pretrained LM decoder wgts\n",
    "                         device:(int,str,torch.device)=None # # Device used to load, defaults to `default_device()`\n",
    "                        ):\n",
    "    \"\"\"Loads the pre-learnt L2R and LM decoder wgts from `file_l2r_wgts` and ` file_lm_decoder_wgts` located in the\n",
    "    model directory, optionally ensuring it's on `device`\n",
    "    \"\"\"\n",
    "    brain_bootstrap = torch.load(join_path_file(file_brain, self.path/self.model_dir, ext='.pkl'), map_location=default_device() if device is None else device)\n",
    "    brain_vocab = mapt(brain_bootstrap.get, ['toks', 'lbs'])\n",
    "    brain_vocab = L(brain_vocab).map(listify)\n",
    "    vocab = L(_get_text_vocab(self.dls), _get_label_vocab(self.dls)).map(listify)\n",
    "    l2r_wgts = torch.load(join_path_file(file_l2r_wgts, self.path/self.model_dir, ext='.pth'), map_location=default_device() if device is None else device)\n",
    "    if 'model' in l2r_wgts: l2r_wgts = l2r_wgts['model']\n",
    "    print(\"Performing 'differentiable' brainsplant...\")\n",
    "    l2r, toks_map, lbs_map = brainsplant_diffntble(vocab, brain_vocab, l2r_wgts)\n",
    "    print(\"Successfull!\")\n",
    "    lm_decoder_pretrained_wgts = torch.load(join_path_file(file_lm_decoder_wgts, self.path/self.model_dir, ext='.pth'), map_location=default_device() if device is None else device)\n",
    "    config = awd_lstm_lm_config.copy()\n",
    "    emb_sz, output_p, out_bias = map(config.get, ['emb_sz', 'output_p', 'out_bias'])\n",
    "    lm_decoder = PlantedLMDecoder(len(vocab[0]), emb_sz, output_p=output_p*0.3, plant_wgts=lm_decoder_pretrained_wgts, bias=out_bias).to(default_device() if device is None else device)\n",
    "    test_eq(lm_decoder.decoder.weight, lm_decoder_pretrained_wgts['decoder.weight'])\n",
    "    test_eq(lm_decoder.decoder.bias, lm_decoder_pretrained_wgts['decoder.bias'])\n",
    "    plant_attn_layer = Lambda(Diffntble_Planted_Attention(l2r))\n",
    "    setattr(self.model[1].pay_attn, 'attn', plant_attn_layer)\n",
    "    assert self.model[1].pay_attn.attn.func.f is _diffntble_planted_attention\n",
    "    setattr(self.model[1].pay_attn, 'lm_decoder', lm_decoder)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f083a-116c-4c40-805e-121c9fb0876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def load_both(self:TextLearner,\n",
    "                         file_brain:str, # Filename of the bootstrap info for l2r\n",
    "                         file_bias: str, # Filename of the saved label bias\n",
    "                         file_l2r_wgts:str, # Filename of the pretrained l2r wgts\n",
    "                         file_lm_decoder_wgts:str, # Filename of the pretrained LM decoder wgts\n",
    "                         device:(int,str,torch.device)=None # # Device used to load, defaults to `default_device()`\n",
    "                        ):\n",
    "    bias_path = join_path_file(file_bias, self.path/self.model_dir, ext='.pkl')\n",
    "    brain_path = join_path_file(file_brain, self.path/self.model_dir, ext='.pkl')\n",
    "    brain_bootstrap = torch.load(brain_path, map_location=default_device() if device is None else device)\n",
    "    *brain_vocab, brain = mapt(brain_bootstrap.get, ['toks', 'lbs', 'mutual_info_jaccard'])\n",
    "    brain_vocab = L(brain_vocab).map(listify)\n",
    "    vocab = L(_get_text_vocab(self.dls), _get_label_vocab(self.dls)).map(listify)\n",
    "    brain_bias = torch.load(bias_path, map_location=default_device() if device is None else device)\n",
    "    brain_bias = brain_bias[:, :, 0].squeeze(-1)\n",
    "    print(\"Performing static brainsplant...\")\n",
    "    self.brain, self.lbsbias, *_ = brainsplant(vocab, brain_vocab, brain, brain_bias)\n",
    "    print(\"Successfull!\")\n",
    "    plant_attn_layer = Lambda(Planted_Attention(self.brain))\n",
    "    setattr(self.model[1].pay_attn, 'plant_attn', plant_attn_layer)\n",
    "    assert self.model[1].pay_attn.plant_attn.func.f is _planted_attention\n",
    "    \n",
    "    l2r_wgts = torch.load(join_path_file(file_l2r_wgts, self.path/self.model_dir, ext='.pth'), map_location=default_device() if device is None else device)\n",
    "    if 'model' in l2r_wgts: l2r_wgts = l2r_wgts['model']\n",
    "    print(\"Performing 'differentiable' brainsplant...\")\n",
    "    l2r, toks_map, lbs_map = brainsplant_diffntble(vocab, brain_vocab, l2r_wgts)\n",
    "    print(\"Successfull!\")\n",
    "    plant_attn_layer = Lambda(Diffntble_Planted_Attention(l2r))\n",
    "    lm_decoder_pretrained_wgts = torch.load(join_path_file(file_lm_decoder_wgts, self.path/self.model_dir, ext='.pth'), map_location=default_device() if device is None else device)\n",
    "    config = awd_lstm_lm_config.copy()\n",
    "    emb_sz, output_p, out_bias = map(config.get, ['emb_sz', 'output_p', 'out_bias'])\n",
    "    lm_decoder = PlantedLMDecoder(len(vocab[0]), emb_sz, output_p=output_p*0.3, plant_wgts=lm_decoder_pretrained_wgts, bias=out_bias).to(default_device() if device is None else device)\n",
    "    test_eq(lm_decoder.decoder.weight, lm_decoder_pretrained_wgts['decoder.weight'])\n",
    "    test_eq(lm_decoder.decoder.bias, lm_decoder_pretrained_wgts['decoder.bias'])\n",
    "    \n",
    "    lin_attn = getattr(self.model[1].pay_attn, 'attn')\n",
    "    setattr(self.model[1].pay_attn, 'attn', plant_attn_layer)\n",
    "    setattr(self.model[1].pay_attn, 'l2r', l2r)\n",
    "    setattr(self.model[1].pay_attn, 'lin_attn', lin_attn)\n",
    "    assert self.model[1].pay_attn.attn.func.f is _diffntble_planted_attention\n",
    "    setattr(self.model[1].pay_attn, 'lm_decoder', lm_decoder)\n",
    "    \n",
    "    return self "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9001ab92-67ce-4357-b447-0b85c0cbd384",
   "metadata": {},
   "source": [
    "## `Learner` convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a39c937-70c1-438b-84d9-34d7ef4a8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcube.text.models.core import _model_meta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38916689-ddc4-498f-881d-36ddebd9e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@delegates(Learner.__init__)\n",
    "def xmltext_classifier_learner(dls, arch, seq_len=72, config=None, backwards=False, pretrained=True, collab=False, drop_mult=0.5, n_out=None,\n",
    "                           lin_ftrs=None, ps=None, max_len=72*20, y_range=None, splitter=None, running_decoder=True, plant=0.5, **kwargs):\n",
    "    \"Create a `Learner` with a text classifier from `dls` and `arch`.\"\n",
    "    vocab = _get_text_vocab(dls)\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from the data, set `dls.c` or pass `n_out`\"\n",
    "    model = get_xmltext_classifier2(arch, len(vocab), n_out, seq_len=seq_len, config=config, y_range=y_range,\n",
    "                                drop_mult=drop_mult, max_len=max_len, running_decoder=running_decoder, plant=plant)\n",
    "    # model = get_xmltext_classifier(arch, len(vocab), n_out, seq_len=seq_len, config=config, y_range=y_range,\n",
    "                                # drop_mult=drop_mult, max_len=max_len)\n",
    "    meta = _model_meta[arch]\n",
    "    learn = TextLearner(dls, model, splitter=splitter if splitter is not None else meta['split_clas'], **kwargs)\n",
    "    url = 'url_bwd' if backwards else 'url'\n",
    "    if pretrained:\n",
    "        if url not in meta:\n",
    "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
    "            return learn\n",
    "        model_path = untar_data(meta[url], c_key='model')\n",
    "        try: fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        except IndexError: print(f'The model in {model_path} is incomplete, download again'); raise\n",
    "        learn = learn.load_pretrained(*fnames, model=learn.model[0])\n",
    "    if collab:\n",
    "        try: fnames = [list(learn.path.glob(f'**/collab/*collab*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        except IndexError: print(f'The collab model in {learn.path} is incomplete, re-train it!'); raise\n",
    "        learn = learn.load_colab(*fnames, model=learn.model[1])\n",
    "    learn.freeze()\n",
    "    return learn   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e66275-882c-4fce-b021-a0e3cc0c5b69",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f6c93-6031-40fb-8bc9-e32a9c519643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
