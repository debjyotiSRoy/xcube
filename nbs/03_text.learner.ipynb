{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8d823-2303-49fa-ba64-7881bcb70b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq xcube  # upgrade xcube on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6496c1-fab0-447f-af93-79cae9087894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.basics import *\n",
    "from fastai.text.learner import *\n",
    "from fastai.callback.rnn import *\n",
    "from fastai.text.models.awdlstm import *\n",
    "from fastai.text.models.core import get_text_classifier\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from xcube.text.models.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de734b9-c91e-42d1-a986-3d9a4f4e8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6918a5a-ce9c-4222-bf49-fde8e0268244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp text.learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d4897-0be6-47da-bd90-21217e9f184e",
   "metadata": {},
   "source": [
    "# Learner for the XML Text application:\n",
    "\n",
    "> All the functions necessary to build `Learner` suitable for transfer learning in XML text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6651917d-cd3b-4533-b19d-7ca3feb32873",
   "metadata": {},
   "source": [
    "The most important function of this module is `xmltext_classifier_learner`. This will help you define a `Learner` using a pretrained Language Model for the encoder and a pretrained Learning-to-Rank-Model for the decoder. (Tutorial: Coming Soon!). This module is inspired from [fastai's](https://github.com/fastai/fastai) [TextLearner](https://docs.fast.ai/text.learner.html) based on the paper [ULMFit](https://arxiv.org/pdf/1801.06146.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b331383-0c65-4d88-9689-4eaa2c0eef47",
   "metadata": {},
   "source": [
    "## Loading label embeddings from a pretrained colab model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dfc32-d2b6-4107-9b5e-5e3f9933380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_text_vocab(dls:DataLoaders) -> list:\n",
    "    \"Get text vocabulary from `DataLoaders`\"\n",
    "    vocab = dls.vocab\n",
    "    if isinstance(vocab, L): vocab = vocab[0]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbf616-ed91-4681-8733-ba59703b8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_label_vocab(dls:DataLoaders) -> list:\n",
    "    \"Get label vocabulary from `DataLoaders`\"\n",
    "    vocab = dls.vocab\n",
    "    if isinstance(vocab, L): vocab = vocab[1]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e749a-83ac-41ad-b5b8-b7d141bc0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def match_collab(\n",
    "    old_wgts:dict, # Embedding weights of the colab model\n",
    "    collab_vocab:dict, # Vocabulary of `token` and `label` used for colab pre-training\n",
    "    lbs_vocab:list # Current labels vocabulary\n",
    ") -> dict:\n",
    "    \"Convert the label embedding in `old_wgts` to go from `old_vocab` in colab to `lbs_vocab`\"\n",
    "    bias, wgts = old_wgts.get('i_bias.weight', None), old_wgts.get('i_weight.weight')\n",
    "    wgts_m = wgts.mean(0)\n",
    "    new_wgts = wgts.new_zeros((len(lbs_vocab), wgts.size(1)))\n",
    "    if bias is not None:\n",
    "        bias_m = bias.mean(0)\n",
    "        new_bias = bias.new_zeros((len(lbs_vocab), 1))\n",
    "    collab_lbs_vocab = collab_vocab['label']\n",
    "    collab_o2i = collab_lbs_vocab.o2i if hasattr(collab_lbs_vocab, 'o2i') else {w:i for i,w in enumerate(collab_lbs_vocab)}\n",
    "    missing = 0\n",
    "    for i,w in enumerate(lbs_vocab):\n",
    "        idx = collab_o2i.get(w, -1)\n",
    "        new_wgts[i] = wgts[idx] if idx>=0 else wgts_m\n",
    "        if bias is not None: new_bias[i] = bias[idx] if idx>=0 else bias_m\n",
    "        if idx == -1: missing = missing + 1\n",
    "    old_wgts['i_weight.weight'] = new_wgts\n",
    "    if bias is not None: old_wgts['i_bias.weight'] = new_bias\n",
    "    return old_wgts, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0c5d8-7104-4971-a78f-d17be39abccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = {'u_weight.weight': torch.randn(3,5), \n",
    "        'i_weight.weight': torch.randn(4,5),\n",
    "        'u_bias.weight'  : torch.randn(3,1),\n",
    "        'i_bias.weight'  : torch.randn(4,1)}\n",
    "collab_vocab = {'token': ['#na#', 'sun', 'moon', 'earth', 'mars'],\n",
    "                'label': ['#na#', 'a', 'c', 'b']}\n",
    "lbs_vocab = ['a', 'b', 'c']\n",
    "new_wgts, missing = match_collab(wgts.copy(), collab_vocab, lbs_vocab)\n",
    "test_eq(missing, 0)\n",
    "test_close(wgts['u_weight.weight'], new_wgts['u_weight.weight'])\n",
    "test_close(wgts['u_bias.weight'], new_wgts['u_bias.weight'])\n",
    "with ExceptionExpected(ex=AssertionError, regex=\"close\"):\n",
    "    test_close(wgts['i_weight.weight'][1:], new_wgts['i_weight.weight'])\n",
    "    test_close(wgts['i_bias.weight'][1:], new_wgts['i_bias.weight'])\n",
    "old_w, new_w = wgts['i_weight.weight'], new_wgts['i_weight.weight']\n",
    "old_b, new_b = wgts['i_bias.weight'], new_wgts['i_bias.weight']\n",
    "for (old_k,old_v), (new_k, new_v) in zip(wgts.items(), new_wgts.items()): \n",
    "    if old_k.startswith('u'): test_eq(old_v.size(), new_v.size())\n",
    "    else: test_ne(old_v.size(), new_v.size());\n",
    "    # print(f\"old: {old_k} = {old_v.size()}, new: {new_k} = {new_v.size()}\")\n",
    "test_eq(new_w[0], old_w[1]); test_eq(new_b[0], old_b[1])\n",
    "test_eq(new_w[1], old_w[3]); test_eq(new_b[1], old_b[3])\n",
    "test_eq(new_w[2], old_w[2]); test_eq(new_b[2], old_b[2])\n",
    "test_shuffled(list(old_b[1:].squeeze().numpy()), list(new_b.squeeze().numpy()))\n",
    "test_eq(torch.sort(old_b[1:], dim=0)[0], torch.sort(new_b, dim=0)[0])\n",
    "test_eq(torch.sort(old_w[1:], dim=0)[0], torch.sort(new_w, dim=0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341847dd-00a6-414d-98fb-e4922e1eccb4",
   "metadata": {},
   "source": [
    "## Loading Pretrained Information Gain as Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49138f56-a5a3-4e12-b37c-eae2db651d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcube.l2r.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e08619-019a-4631-8f59-b46a70c44de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mimic = untar_xxx(XURLs.MIMIC3)\n",
    "xml_vocab = load_pickle(source_mimic/'mimic3-9k_clas_full_vocab.pkl')\n",
    "xml_vocab = L(xml_vocab).map(listify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ead7eb-6a67-4311-bbb8-871623a5121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_l2r = untar_xxx(XURLs.MIMIC3_L2R)\n",
    "boot_path = join_path_file('mimic3-9k_tok_lbl_info', source_l2r, ext='.pkl')\n",
    "bias_path = join_path_file('p_L', source_l2r, ext='.pkl')\n",
    "l2r_bootstrap = torch.load(boot_path, map_location=default_device())\n",
    "brain_bias = torch.load(bias_path, map_location=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcf19c-2416-4d14-8614-8a889fea0a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last two places in brain vocab has ['xxfake', 'xxfake']\n"
     ]
    }
   ],
   "source": [
    "*brain_vocab, brain = mapt(l2r_bootstrap.get, ['toks', 'lbs', 'mutual_info_jaccard'])\n",
    "brain_vocab = L(brain_vocab).map(listify)\n",
    "toks, lbs = brain_vocab\n",
    "print(f\"last two places in brain vocab has {toks[-2:]}\")\n",
    "# toks = CategoryMap(toks, sort=False)\n",
    "brain_bias = brain_bias[:, :, 0].squeeze(-1)\n",
    "lbs_des = load_pickle(source_mimic/'code_desc.pkl')\n",
    "assert isinstance(lbs_des, dict)\n",
    "test_eq(brain.shape, (len(toks), len(lbs))) # last two places has 'xxfake'\n",
    "test_eq(brain_bias.shape, [len(lbs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf1375-8dae-4531-99c3-b42947a28393",
   "metadata": {},
   "source": [
    "The tokens which are there in the xml vocab but not in the brain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddcd95-7b47-496f-8d91-cbebbf73ca96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#20) ['cella','q2day','remiained','luteinizing','promiscuity','sharpio','calcijex','dissension','mhc','theses'...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found_in_brain = L(set(xml_vocab[0]).difference(set(brain_vocab[0])))\n",
    "not_found_in_brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ba7d8-9d37-4fdc-9045-40ce43d3b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(lambda : toks.index('cella'), contains='is not in list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7d566-7fcd-4542-809f-0591018405bf",
   "metadata": {},
   "source": [
    "The tokens which are in the brain but were not present in the xml vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b1933-81cd-4280-afca-8f009bd7688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(brain_vocab[0]).difference(xml_vocab[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb96cc-7c9d-4bad-9137-81e2f302ae21",
   "metadata": {},
   "source": [
    "Thankfully, we have `info` for all the labels in the xml vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef0876-d1ec-40af-b4d0-069a5b024b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(brain_vocab[1]).symmetric_difference(brain_vocab[1]) == set()\n",
    "# test_shuffled(xml_vocab[1], mimic_vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bae0e-536f-47f3-8433-ae7680c62fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _xml2brain(xml_vocab, brain_vocab, parent_bar=None):\n",
    "    \"Creates a mapping between the indices of the xml vocab and the brain vocab\"\n",
    "    pbar = progress_bar(xml_vocab, parent=parent_bar, leave=True)\n",
    "    xml2brain = {i: brain_vocab.index(o) if o in brain_vocab else np.inf  for i,o in enumerate(pbar)}\n",
    "    xml2brain_notfnd = [o for o in xml2brain if xml2brain[o] is np.inf]\n",
    "    return xml2brain, xml2brain_notfnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89677ad5-60bb-4758-b854-8d87d869b89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='57376' class='' max='57376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [57376/57376 00:19&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toks_xml2brain, toks_notfnd = _xml2brain(xml_vocab[0], brain_vocab[0])\n",
    "\n",
    "toks_found = set(toks_xml2brain).difference(set(toks_notfnd))\n",
    "test_shuffled(array(xml_vocab[0])[toks_notfnd], not_found_in_brain)\n",
    "some_xml_idxs = np.random.choice(array(L(toks_found)), size=10)\n",
    "some_xml_toks = array(xml_vocab[0])[some_xml_idxs]\n",
    "corres_brain_idxs = L(map(toks_xml2brain.get, some_xml_idxs))\n",
    "corres_brain_toks = array(toks)[corres_brain_idxs]\n",
    "assert all_equal(some_xml_toks, corres_brain_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61646a6f-4323-4f7f-9ca0-e341aa36b8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8922' class='' max='8922' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8922/8922 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lbs_xml2brain, lbs_notfnd = _xml2brain(xml_vocab[1], brain_vocab[1])\n",
    "\n",
    "lbs_found = set(lbs_xml2brain).difference(set(lbs_notfnd))\n",
    "some_xml_idxs = np.random.choice(array(L(lbs_found)), size=10)\n",
    "some_xml_lbs = array(xml_vocab[1])[some_xml_idxs]\n",
    "corres_brain_idxs = L(map(lbs_xml2brain.get, some_xml_idxs))\n",
    "corres_brain_lbs = array(lbs)[corres_brain_idxs]\n",
    "assert all_equal(some_xml_lbs, corres_brain_lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95a209-eba2-4e1f-9fbd-605b77393b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def brainsplant(xml_vocab, brain_vocab, brain, brain_bias, device=None):\n",
    "    toks_lbs = 'toks lbs'.split()\n",
    "    mb = master_bar(range(2))\n",
    "    for i in mb:\n",
    "        globals().update(dict(zip((toks_lbs[i]+'_xml2brain', toks_lbs[i]+'_notfnd'), (_xml2brain(xml_vocab[i], brain_vocab[i], parent_bar=mb)))))\n",
    "        mb.write = f\"Finished Loop {i}\"\n",
    "    xml_brain = torch.zeros(*xml_vocab.map(len)).to(default_device() if device is None else device) # initialize empty brain\n",
    "    xml_lbsbias = torch.zeros(len(xml_vocab[1])).to(default_device() if device is None else device)\n",
    "    toks_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in toks_xml2brain.items() if brn_idx is not np.inf) \n",
    "    lbs_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in lbs_xml2brain.items() if brn_idx is not np.inf) \n",
    "    xml_brain[toks_map.itemgot(0)] = brain[toks_map.itemgot(1)][:, lbs_map.itemgot(1)] # permute toks dim to match xml and brain\n",
    "    xml_brain[:, lbs_map.itemgot(0)] = xml_brain.clone() # permute lbs dim to match xml and brain\n",
    "    xml_lbsbias[lbs_map.itemgot(0)] = brain_bias[lbs_map.itemgot(1)].clone() # permute toks dim to match xml and brain\n",
    "    return xml_brain, xml_lbsbias, toks_map, lbs_map, toks_xml2brain, lbs_xml2brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655ab82-2986-471d-b628-aaee8fea1473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xml_brain, xml_lbsbias, toks_map, lbs_map, toks_xml2brain, lbs_xml2brain = brainsplant(xml_vocab, brain_vocab, brain, brain_bias)\n",
    "test_eq(xml_brain.shape, xml_vocab.map(len))\n",
    "test_eq(xml_brain[toks_notfnd], xml_brain.new_zeros(len(toks_notfnd), len(xml_vocab[1])))\n",
    "assert all_equal(array(xml_vocab[0])[toks_map.itemgot(0)], array(brain_vocab[0])[toks_map.itemgot(1)])\n",
    "assert all_equal(array(xml_vocab[1])[lbs_map.itemgot(0)], array(brain_vocab[1])[lbs_map.itemgot(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54faff-2352-437e-b72e-b4e1c3d6dca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the lbl 996.87 (Complications of transplanted intestine), the top tokens that needs attention are:\n",
      "+ ('consultued', 0.25548762)\n",
      "+ ('cip', 0.25548762)\n",
      "+ ('parlor', 0.24661502)\n",
      "+ ('transplantations', 0.18601614)\n",
      "+ ('scaffoid', 0.18601614)\n",
      "+ ('epineprine', 0.18601614)\n",
      "+ ('culinary', 0.17232327)\n",
      "+ ('coordinates', 0.1469037)\n",
      "+ ('aminotransferases', 0.12153866)\n",
      "+ ('hydronephroureter', 0.12153866)\n",
      "+ ('27yom', 0.12153866)\n",
      "+ ('27y', 0.103684604)\n",
      "+ ('hardward', 0.090407245)\n",
      "+ ('leukoreduction', 0.08014185)\n",
      "+ ('venting', 0.07831942)\n",
      "+ ('secrete', 0.07196123)\n",
      "+ ('orthogonal', 0.07196123)\n",
      "+ ('naac', 0.06891022)\n",
      "+ ('mgso4', 0.0662555)\n",
      "+ ('septecemia', 0.065286644)\n"
     ]
    }
   ],
   "source": [
    "# tests to ensure `brainsplant` was successful \n",
    "lbl = '642.41'\n",
    "lbl = '38.93'\n",
    "lbl = '51.10'\n",
    "lbl = '996.87'\n",
    "lbl_idx_from_brn = brain_vocab[1].index(lbl)\n",
    "tok_vals_from_brn, top_toks_from_brn= L(brain[:, lbl_idx_from_brn].topk(k=20)).map(Self.cpu())\n",
    "lbl_idx_from_xml = xml_vocab[1].index(lbl)\n",
    "tok_vals_from_xml, top_toks_from_xml = L(xml_brain[:, lbl_idx_from_xml].topk(k=20)).map(Self.cpu())\n",
    "test_eq(lbs_xml2brain[lbl_idx_from_xml], lbl_idx_from_brn)\n",
    "test_eq(tok_vals_from_brn, tok_vals_from_xml)\n",
    "test_eq(array(brain_vocab[0])[top_toks_from_brn], array(xml_vocab[0])[top_toks_from_xml])\n",
    "test_eq(brain_bias[lbl_idx_from_brn], xml_lbsbias[lbl_idx_from_xml])\n",
    "print(f\"For the lbl {lbl} ({lbs_des.get(lbl)}), the top tokens that needs attention are:\")\n",
    "print('\\n'.join(L(array(xml_vocab[0])[top_toks_from_xml], use_list=True).zipwith(L(tok_vals_from_xml.numpy(), use_list=True)).map(str).map(lambda o: \"+ \"+o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088612a-0f41-4458-9608-1ef421f145af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the token restitched, the top labels that needs attention are:\n",
      "+ ('Other operations on supporting structures of uterus', 0.29102018)\n",
      "+ ('Other proctopexy', 0.29102018)\n",
      "+ ('Other operations on cul-de-sac', 0.18601614)\n",
      "+ (None, 0.07494824)\n",
      "+ ('Intervertebral disc disorder with myelopathy, thoracic region', 0.055331517)\n",
      "+ ('Excision of scapula, clavicle, and thorax [ribs and sternum] for graft', 0.04382947)\n",
      "+ ('Other repair of omentum', 0.028067086)\n",
      "+ ('Chronic lymphocytic thyroiditis', 0.01986737)\n",
      "+ (None, 0.019236181)\n",
      "+ ('Reclosure of postoperative disruption of abdominal wall', 0.016585195)\n",
      "+ ('Other disorders of calcium metabolism', 0.009393147)\n",
      "+ ('Pain in joint involving pelvic region and thigh', 0.008421187)\n",
      "+ ('Exteriorization of small intestine', 0.00817792)\n",
      "+ ('Fusion or refusion of 9 or more vertebrae', 0.00762466)\n",
      "+ ('Kyphosis (acquired) (postural)', 0.0074228523)\n",
      "+ ('Unspecified procedure as the cause of abnormal reaction of patient, or of later complication, without mention of misadventure at time of procedure', 0.0063889036)\n",
      "+ ('Application or administration of adhesion barrier substance', 0.00610513)\n",
      "+ ('Acute osteomyelitis involving other specified sites', 0.0054434645)\n",
      "+ ('Body Mass Index less than 19, adult', 0.004719585)\n",
      "+ ('Dorsal and dorsolumbar fusion, anterior technique', 0.0046444684)\n"
     ]
    }
   ],
   "source": [
    "tok = 'fibrillation'\n",
    "tok = 'colpo'\n",
    "tok = 'amiodarone'\n",
    "tok = 'flagyl'\n",
    "tok = 'nasalilid'\n",
    "tok = 'hemetemesis'\n",
    "tok = 'restitched'\n",
    "tok_idx_from_brn = brain_vocab[0].index(tok)\n",
    "lbs_vals_from_brn, top_lbs_from_brn = L(brain[tok_idx_from_brn].topk(k=20)).map(Self.cpu())\n",
    "tok_idx_from_xml = xml_vocab[0].index(tok)\n",
    "test_eq(tok_idx_from_brn, toks_xml2brain[tok_idx_from_xml])\n",
    "lbs_vals_from_xml, top_lbs_from_xml = L(xml_brain[tok_idx_from_xml].topk(k=20)).map(Self.cpu())\n",
    "test_eq(lbs_vals_from_brn, lbs_vals_from_xml)\n",
    "try: \n",
    "    test_eq(array(brain_vocab[1])[top_lbs_from_brn], array(xml_vocab[1])[top_lbs_from_xml])\n",
    "except AssertionError as e: \n",
    "    print(type(e).__name__, \"due to instability in sorting (nothing to worry!)\");\n",
    "    test_shuffled(array(brain_vocab[1])[top_lbs_from_brn], array(xml_vocab[1])[top_lbs_from_xml])\n",
    "print('')\n",
    "print(f\"For the token {tok}, the top labels that needs attention are:\")\n",
    "print('\\n'.join(L(mapt(lbs_des.get, array(xml_vocab[1])[top_lbs_from_xml])).zipwith(L(lbs_vals_from_xml.numpy(), use_list=True)).map(str).map(lambda o: \"+ \"+o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e897af-7a67-4c27-aa86-74cdfcd6151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some tokens (with repetitions):\n",
      " -disorientated\n",
      "-disorientated\n",
      "-dmh\n",
      "-ibp\n",
      "-literacy\n",
      "-abruptly\n",
      "-faxed\n",
      "-delsym\n",
      "-literacy\n",
      "-delsym\n",
      "-literacy\n",
      "-ibp\n",
      "-literacy\n",
      "-delsym\n",
      "-abruptly\n",
      "-caox3\n",
      "-caox3\n",
      "-caox3\n",
      "-caox3\n",
      "-literacy\n"
     ]
    }
   ],
   "source": [
    "some_toks = random.sample(toks_map.itemgot(0), 10)\n",
    "counts = [c*6 for c in random.sample(range(10), 10)]\n",
    "some_toks = random.sample(some_toks, 20, counts=counts)\n",
    "# Counter(some_toks)\n",
    "cors_toks_brn = L(mapt(toks_xml2brain.get, some_toks))\n",
    "test_eq(array(brain_vocab[0])[cors_toks_brn], array(xml_vocab[0])[some_toks])\n",
    "print(\"some tokens (with repetitions):\\n\",'\\n'.join(['-'+xml_vocab[0][t]for t in some_toks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41799697-a3b3-4e0d-a53c-7a39246c218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = xml_brain[some_toks]\n",
    "test_eq(attn.shape, (len(some_toks), xml_brain.shape[1]))\n",
    "# semantics of attn\n",
    "# for each token we can compute the attention each label deserves by pulling out all the columns for a label\n",
    "for t, a in zip(some_toks,attn):\n",
    "    test_eq(xml_brain[t], a)\n",
    "# for each label we can compute the attention those tokens deserve by pulling out all rows for a label\n",
    "for lbl in range(xml_brain.shape[1]):\n",
    "    test_eq(xml_brain[:, lbl][some_toks], attn[:, lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728754ad-5181-4d23-bf88-9783ee2753fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>most_relevant_lbl</th>\n",
       "      <th>lbl_attn</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>delsym</td>\n",
       "      <td>344.2</td>\n",
       "      <td>0.096369</td>\n",
       "      <td>Diplegia of upper limbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>delsym</td>\n",
       "      <td>344.2</td>\n",
       "      <td>0.096369</td>\n",
       "      <td>Diplegia of upper limbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>delsym</td>\n",
       "      <td>344.2</td>\n",
       "      <td>0.096369</td>\n",
       "      <td>Diplegia of upper limbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dmh</td>\n",
       "      <td>983.1</td>\n",
       "      <td>0.041843</td>\n",
       "      <td>Toxic effect of acids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disorientated</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>Malignant neoplasm of connective and other soft tissue of head, face, and neck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disorientated</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>Malignant neoplasm of connective and other soft tissue of head, face, and neck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>caox3</td>\n",
       "      <td>375.01</td>\n",
       "      <td>0.028963</td>\n",
       "      <td>Acute dacryoadenitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>caox3</td>\n",
       "      <td>375.01</td>\n",
       "      <td>0.028963</td>\n",
       "      <td>Acute dacryoadenitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>caox3</td>\n",
       "      <td>375.01</td>\n",
       "      <td>0.028963</td>\n",
       "      <td>Acute dacryoadenitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>caox3</td>\n",
       "      <td>375.01</td>\n",
       "      <td>0.028963</td>\n",
       "      <td>Acute dacryoadenitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>literacy</td>\n",
       "      <td>449</td>\n",
       "      <td>0.018083</td>\n",
       "      <td>Septic arterial embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>literacy</td>\n",
       "      <td>449</td>\n",
       "      <td>0.018083</td>\n",
       "      <td>Septic arterial embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>literacy</td>\n",
       "      <td>449</td>\n",
       "      <td>0.018083</td>\n",
       "      <td>Septic arterial embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>literacy</td>\n",
       "      <td>449</td>\n",
       "      <td>0.018083</td>\n",
       "      <td>Septic arterial embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>literacy</td>\n",
       "      <td>449</td>\n",
       "      <td>0.018083</td>\n",
       "      <td>Septic arterial embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>faxed</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>Other operations on extraocular muscles and tendons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ibp</td>\n",
       "      <td>39.90</td>\n",
       "      <td>0.006865</td>\n",
       "      <td>Insertion of non-drug-eluting peripheral vessel stent(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ibp</td>\n",
       "      <td>39.90</td>\n",
       "      <td>0.006865</td>\n",
       "      <td>Insertion of non-drug-eluting peripheral vessel stent(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abruptly</td>\n",
       "      <td>315.8</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>Other specified delays in development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abruptly</td>\n",
       "      <td>315.8</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>Other specified delays in development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token most_relevant_lbl  lbl_attn   \n",
       "7          delsym             344.2  0.096369  \\\n",
       "13         delsym             344.2  0.096369   \n",
       "9          delsym             344.2  0.096369   \n",
       "2             dmh             983.1  0.041843   \n",
       "0   disorientated             171.0  0.036627   \n",
       "1   disorientated             171.0  0.036627   \n",
       "18          caox3            375.01  0.028963   \n",
       "17          caox3            375.01  0.028963   \n",
       "16          caox3            375.01  0.028963   \n",
       "15          caox3            375.01  0.028963   \n",
       "12       literacy               449  0.018083   \n",
       "10       literacy               449  0.018083   \n",
       "8        literacy               449  0.018083   \n",
       "4        literacy               449  0.018083   \n",
       "19       literacy               449  0.018083   \n",
       "6           faxed              15.9  0.012289   \n",
       "11            ibp             39.90  0.006865   \n",
       "3             ibp             39.90  0.006865   \n",
       "14       abruptly             315.8  0.006252   \n",
       "5        abruptly             315.8  0.006252   \n",
       "\n",
       "                                                                       description  \n",
       "7                                                          Diplegia of upper limbs  \n",
       "13                                                         Diplegia of upper limbs  \n",
       "9                                                          Diplegia of upper limbs  \n",
       "2                                                            Toxic effect of acids  \n",
       "0   Malignant neoplasm of connective and other soft tissue of head, face, and neck  \n",
       "1   Malignant neoplasm of connective and other soft tissue of head, face, and neck  \n",
       "18                                                            Acute dacryoadenitis  \n",
       "17                                                            Acute dacryoadenitis  \n",
       "16                                                            Acute dacryoadenitis  \n",
       "15                                                            Acute dacryoadenitis  \n",
       "12                                                        Septic arterial embolism  \n",
       "10                                                        Septic arterial embolism  \n",
       "8                                                         Septic arterial embolism  \n",
       "4                                                         Septic arterial embolism  \n",
       "19                                                        Septic arterial embolism  \n",
       "6                              Other operations on extraocular muscles and tendons  \n",
       "11                        Insertion of non-drug-eluting peripheral vessel stent(s)  \n",
       "3                         Insertion of non-drug-eluting peripheral vessel stent(s)  \n",
       "14                                           Other specified delays in development  \n",
       "5                                            Other specified delays in development  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(xml_vocab[0][t], l:=xml_vocab[1][lbl_idx], val.item(), lbs_des.get(l, 'NF')) for t,lbl_idx,val in zip(some_toks,attn.max(dim=1).indices.cpu(), attn.max(dim=1).values.cpu())],\n",
    "            columns=['token', 'most_relevant_lbl', 'lbl_attn', 'description']).sort_values(by='lbl_attn', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1739ab9-644d-4f65-bbe9-b8c0e1d141f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcube.layers import inattention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23826717-0b57-43dc-8eba-3ec964956398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define label inattention cutoff\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fe1a7-c063-4cb9-9b36-cd2942fd84e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After looking at the tokens ['disorientated', 'disorientated', 'dmh', 'ibp', 'literacy', 'abruptly', 'faxed', 'delsym', 'literacy', 'delsym', 'literacy', 'ibp', 'literacy', 'delsym', 'abruptly', 'caox3', 'caox3', 'caox3', 'caox3', 'literacy'], I am confident about the following labels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbl</th>\n",
       "      <th>lbl_cf</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>344.2</td>\n",
       "      <td>0.289106</td>\n",
       "      <td>Diplegia of upper limbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>367.1</td>\n",
       "      <td>0.289106</td>\n",
       "      <td>Myopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>706.1</td>\n",
       "      <td>0.158741</td>\n",
       "      <td>Other acne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>691.8</td>\n",
       "      <td>0.145640</td>\n",
       "      <td>Other atopic dermatitis and related conditions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>442.89</td>\n",
       "      <td>0.134519</td>\n",
       "      <td>Aneurysm of other specified site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>374.89</td>\n",
       "      <td>0.115853</td>\n",
       "      <td>Other disorders of eyelid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>375.01</td>\n",
       "      <td>0.115853</td>\n",
       "      <td>Acute dacryoadenitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>449</td>\n",
       "      <td>0.090417</td>\n",
       "      <td>Septic arterial embolism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>438.13</td>\n",
       "      <td>0.087779</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>423.1</td>\n",
       "      <td>0.080689</td>\n",
       "      <td>Adhesive pericarditis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>304.71</td>\n",
       "      <td>0.080689</td>\n",
       "      <td>Combinations of opioid type drug with any other drug dependence, continuous use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>315.9</td>\n",
       "      <td>0.079333</td>\n",
       "      <td>Unspecified delay in development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>171.0</td>\n",
       "      <td>0.073254</td>\n",
       "      <td>Malignant neoplasm of connective and other soft tissue of head, face, and neck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>259.9</td>\n",
       "      <td>0.072001</td>\n",
       "      <td>Unspecified endocrine disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>701.2</td>\n",
       "      <td>0.072001</td>\n",
       "      <td>Acquired acanthosis nigricans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>370.00</td>\n",
       "      <td>0.066347</td>\n",
       "      <td>Corneal ulcer, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>814.00</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>Closed fracture of carpal bone, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E968.8</td>\n",
       "      <td>0.050906</td>\n",
       "      <td>Assault by other specified means</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>722.72</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>Intervertebral disc disorder with myelopathy, thoracic region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>444.21</td>\n",
       "      <td>0.047748</td>\n",
       "      <td>Arterial embolism and thrombosis of upper extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>618.1</td>\n",
       "      <td>0.045409</td>\n",
       "      <td>Uterine prolapse without mention of vaginal wall prolapse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>531.30</td>\n",
       "      <td>0.041843</td>\n",
       "      <td>Acute gastric ulcer without mention of hemorrhage or perforation, without mention of obstruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>54.73</td>\n",
       "      <td>0.041843</td>\n",
       "      <td>Other repair of peritoneum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>983.1</td>\n",
       "      <td>0.041843</td>\n",
       "      <td>Toxic effect of acids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>824.7</td>\n",
       "      <td>0.041843</td>\n",
       "      <td>Trimalleolar fracture, open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>921.0</td>\n",
       "      <td>0.039063</td>\n",
       "      <td>Black eye, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>959.9</td>\n",
       "      <td>0.036281</td>\n",
       "      <td>Other and unspecified injury to unspecified site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>290.3</td>\n",
       "      <td>0.032885</td>\n",
       "      <td>Senile dementia with delirium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>784.92</td>\n",
       "      <td>0.032388</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>444.89</td>\n",
       "      <td>0.028912</td>\n",
       "      <td>Embolism and thrombosis of other artery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>39.90</td>\n",
       "      <td>0.013729</td>\n",
       "      <td>Insertion of non-drug-eluting peripheral vessel stent(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>315.8</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>Other specified delays in development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.9</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>Other operations on extraocular muscles and tendons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38.12</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>Endarterectomy of other vessels of head and neck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68.16</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>Closed biopsy of uterus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>674.14</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>Disruption of cesarean wound, postpartum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>654.44</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>Other abnormalities in shape or position of gravid uterus and of neighboring structures, postpartum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>669.44</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>Other complications of obstetrical surgery and procedures, postpartum condition or complication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>205.90</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>Unspecified myeloid leukemia without mention of remission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>86.19</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>Other diagnostic procedures on skin and subcutaneous tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>021.8</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>Other specified tularemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>362.07</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>Diabetic macular edema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>989.3</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>Toxic effect of organophosphate and carbamate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17.7</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>706.9</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>Unspecified disease of sebaceous glands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>39.50</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>Angioplasty or atherectomy of other non-coronary vessel(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>421.0</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>Acute and subacute bacterial endocarditis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348.5</td>\n",
       "      <td>0.007448</td>\n",
       "      <td>Cerebral edema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.1</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>Intracapsular extraction of lens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>Diagnostic physical therapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.2</td>\n",
       "      <td>0.005648</td>\n",
       "      <td>Diagnostic procedures on nose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>36.05</td>\n",
       "      <td>0.005054</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>440.1</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>Atherosclerosis of renal artery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37.94</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>Implantation or replacement of automatic cardioverter/defibrillator, total system [AICD]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lbl    lbl_cf   \n",
       "10   344.2  0.289106  \\\n",
       "22   367.1  0.289106   \n",
       "36   706.1  0.158741   \n",
       "35   691.8  0.145640   \n",
       "21  442.89  0.134519   \n",
       "50  374.89  0.115853   \n",
       "49  375.01  0.115853   \n",
       "20     449  0.090417   \n",
       "11  438.13  0.087779   \n",
       "23   423.1  0.080689   \n",
       "13  304.71  0.080689   \n",
       "18   315.9  0.079333   \n",
       "24   171.0  0.073254   \n",
       "29   259.9  0.072001   \n",
       "28   701.2  0.072001   \n",
       "44  370.00  0.066347   \n",
       "34  814.00  0.057924   \n",
       "7   E968.8  0.050906   \n",
       "30  722.72  0.049080   \n",
       "17  444.21  0.047748   \n",
       "42   618.1  0.045409   \n",
       "45  531.30  0.041843   \n",
       "41   54.73  0.041843   \n",
       "37   983.1  0.041843   \n",
       "52   824.7  0.041843   \n",
       "6    921.0  0.039063   \n",
       "39   959.9  0.036281   \n",
       "16   290.3  0.032885   \n",
       "43  784.92  0.032388   \n",
       "15  444.89  0.028912   \n",
       "32   39.90  0.013729   \n",
       "19   315.8  0.012504   \n",
       "2     15.9  0.012289   \n",
       "14   38.12  0.011341   \n",
       "9    68.16  0.010278   \n",
       "46  674.14  0.009737   \n",
       "47  654.44  0.009737   \n",
       "48  669.44  0.009737   \n",
       "51  205.90  0.009737   \n",
       "27   86.19  0.009737   \n",
       "53   021.8  0.009737   \n",
       "40  362.07  0.009737   \n",
       "38   989.3  0.009737   \n",
       "26    17.7  0.009737   \n",
       "25   706.9  0.009737   \n",
       "31   39.50  0.009523   \n",
       "5    421.0  0.008755   \n",
       "0    348.5  0.007448   \n",
       "1     13.1  0.006795   \n",
       "4     93.0  0.005886   \n",
       "3     21.2  0.005648   \n",
       "33   36.05  0.005054   \n",
       "8    440.1  0.004669   \n",
       "12   37.94  0.004538   \n",
       "\n",
       "                                                                                            description  \n",
       "10                                                                              Diplegia of upper limbs  \n",
       "22                                                                                               Myopia  \n",
       "36                                                                                           Other acne  \n",
       "35                                                       Other atopic dermatitis and related conditions  \n",
       "21                                                                     Aneurysm of other specified site  \n",
       "50                                                                            Other disorders of eyelid  \n",
       "49                                                                                 Acute dacryoadenitis  \n",
       "20                                                                             Septic arterial embolism  \n",
       "11                                                                                                   NF  \n",
       "23                                                                                Adhesive pericarditis  \n",
       "13                      Combinations of opioid type drug with any other drug dependence, continuous use  \n",
       "18                                                                     Unspecified delay in development  \n",
       "24                       Malignant neoplasm of connective and other soft tissue of head, face, and neck  \n",
       "29                                                                       Unspecified endocrine disorder  \n",
       "28                                                                        Acquired acanthosis nigricans  \n",
       "44                                                                           Corneal ulcer, unspecified  \n",
       "34                                                          Closed fracture of carpal bone, unspecified  \n",
       "7                                                                      Assault by other specified means  \n",
       "30                                        Intervertebral disc disorder with myelopathy, thoracic region  \n",
       "17                                                  Arterial embolism and thrombosis of upper extremity  \n",
       "42                                            Uterine prolapse without mention of vaginal wall prolapse  \n",
       "45     Acute gastric ulcer without mention of hemorrhage or perforation, without mention of obstruction  \n",
       "41                                                                           Other repair of peritoneum  \n",
       "37                                                                                Toxic effect of acids  \n",
       "52                                                                          Trimalleolar fracture, open  \n",
       "6                                                                                        Black eye, NOS  \n",
       "39                                                     Other and unspecified injury to unspecified site  \n",
       "16                                                                        Senile dementia with delirium  \n",
       "43                                                                                                   NF  \n",
       "15                                                              Embolism and thrombosis of other artery  \n",
       "32                                             Insertion of non-drug-eluting peripheral vessel stent(s)  \n",
       "19                                                                Other specified delays in development  \n",
       "2                                                   Other operations on extraocular muscles and tendons  \n",
       "14                                                     Endarterectomy of other vessels of head and neck  \n",
       "9                                                                               Closed biopsy of uterus  \n",
       "46                                                             Disruption of cesarean wound, postpartum  \n",
       "47  Other abnormalities in shape or position of gravid uterus and of neighboring structures, postpartum  \n",
       "48      Other complications of obstetrical surgery and procedures, postpartum condition or complication  \n",
       "51                                            Unspecified myeloid leukemia without mention of remission  \n",
       "27                                          Other diagnostic procedures on skin and subcutaneous tissue  \n",
       "53                                                                            Other specified tularemia  \n",
       "40                                                                               Diabetic macular edema  \n",
       "38                                                        Toxic effect of organophosphate and carbamate  \n",
       "26                                                                                                   NF  \n",
       "25                                                              Unspecified disease of sebaceous glands  \n",
       "31                                           Angioplasty or atherectomy of other non-coronary vessel(s)  \n",
       "5                                                             Acute and subacute bacterial endocarditis  \n",
       "0                                                                                        Cerebral edema  \n",
       "1                                                                      Intracapsular extraction of lens  \n",
       "4                                                                           Diagnostic physical therapy  \n",
       "3                                                                         Diagnostic procedures on nose  \n",
       "33                                                                                                   NF  \n",
       "8                                                                       Atherosclerosis of renal artery  \n",
       "12             Implantation or replacement of automatic cardioverter/defibrillator, total system [AICD]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_lbs_attn = attn.clone().unsqueeze(0).permute(0,2,1).inattention(k=k).permute(0,2,1).squeeze(0).contiguous() # applying `inattention` across the lbs dim\n",
    "test_eq(top_lbs_attn.shape, (len(some_toks), xml_brain.shape[1]))\n",
    "test_ne(attn, top_lbs_attn)\n",
    "test_eq(top_lbs_attn.argmax(dim=1), attn.argmax(dim=1))\n",
    "lbs_cf = top_lbs_attn.sum(dim=0)\n",
    "test_eq(lbs_cf.shape, [top_lbs_attn.shape[1]])\n",
    "idxs = lbs_cf.nonzero().flatten().cpu()\n",
    "print(f\"After looking at the tokens {[xml_vocab[0][t]for t in some_toks]}, I am confident about the following labels:\")\n",
    "pd.DataFrame([(l:=xml_vocab[1][idx], val.item(), lbs_des.get(l, 'NF')) for idx,val in zip(idxs,lbs_cf[idxs])],\n",
    "            columns=['lbl', 'lbl_cf', 'description']).sort_values(by='lbl_cf', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ec9bc-8d5c-498b-a868-3d5e43faf89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# semantics: `s` pulling out its 1st and 0th row is equivalent to `t` pulling out its 0th and 3rd row respectively (i.e., the data residing in the 1st and 0th row of the s matrix is same as the data residing at the 0th and the 3rd row of t's matrix)\n",
    "t = torch.zeros(4, 3).long()\n",
    "s = torch.arange(20).view(2, 10).long()\n",
    "# s = torch.arange(6).view(2,3).long()\n",
    "row_perm = L((0, 1), (3, 0)) # \n",
    "col_perm = L((2, 1), (0, 3), (1, -1))\n",
    "# col_perm = L((0,2), (1,0), (2,1))\n",
    "ic(t,s);\n",
    "ic(s[row_perm.itemgot(1)]); # pull out relevant rows from s\n",
    "ic(s[row_perm.itemgot(1)][:, col_perm.itemgot(1)]); # pull out relevant cols from s\n",
    "t[row_perm.itemgot(0)] = s[row_perm.itemgot(1)][:, col_perm.itemgot(1)] # permute rows\n",
    "t[:, col_perm.itemgot(0)] = t.clone() # permute cols\n",
    "# t[row_perm.itemgot(0)] = s[row_perm.itemgot(1)][:, col_perm.itemgot(1)][:, col_perm.itemgot(0)]\n",
    "ic(t);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2530f3-f6e2-427d-9712-461e25b60fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2r_wgts = torch.load(join_path_file('lin_lambdarank_full', source_l2r, ext='.pth'), map_location=default_device())\n",
    "if 'model' in l2r_wgts: l2r_wgts = l2r_wgts['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62294c-fe30-4c66-832f-32f017def64d",
   "metadata": {},
   "source": [
    "Need to match the wgts in xml and brain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc99996-3591-47fb-8fe1-23aebad6121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brainsplant_diffntble(xml_vocab, brain_vocab, l2r_wgts, device=None):\n",
    "    toks_lbs = 'toks lbs'.split()\n",
    "    mb = master_bar(range(2))\n",
    "    for i in mb:\n",
    "        globals().update(dict(zip((toks_lbs[i]+'_xml2brain', toks_lbs[i]+'_notfnd'), (_xml2brain(xml_vocab[i], brain_vocab[i], parent_bar=mb)))))\n",
    "        mb.write = f\"Finished Loop {i}\" \n",
    "    toks_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in toks_xml2brain.items() if brn_idx is not np.inf) \n",
    "    lbs_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in lbs_xml2brain.items() if brn_idx is not np.inf) \n",
    "    tf_xml = torch.zeros(len(xml_vocab[0]), 200).to(default_device() if device is None else device) \n",
    "    tb_xml = torch.zeros(len(xml_vocab[0]), 1).to(default_device() if device is None else device) \n",
    "    lf_xml = torch.zeros(len(xml_vocab[1]), 200).to(default_device() if device is None else device) \n",
    "    lb_xml = torch.zeros(len(xml_vocab[1]), 1).to(default_device() if device is None else device) \n",
    "    tf_l2r, tb_l2r, lf_l2r, lb_l2r = list(l2r_wgts.values())\n",
    "    tf_xml[toks_map.itemgot(0)] = tf_l2r[toks_map.itemgot(1)].clone()\n",
    "    tb_xml[toks_map.itemgot(0)] = tb_l2r[toks_map.itemgot(1)].clone()\n",
    "    lf_xml[lbs_map.itemgot(0)] = lf_l2r[lbs_map.itemgot(1)].clone()\n",
    "    lb_xml[lbs_map.itemgot(0)] = lb_l2r[lbs_map.itemgot(1)].clone()\n",
    "    # import pdb; pdb.set_trace()\n",
    "    xml_wgts = {k: xml_val for k, xml_val in zip(l2r_wgts.keys(), (tf_xml, tb_xml, lf_xml, lb_xml))}\n",
    "    mod_dict = nn.ModuleDict({k.split('.')[0]: nn.Embedding(*v.size()) for k,v in xml_wgts.items()}).to(default_device() if device is None else device) \n",
    "    mod_dict.load_state_dict(xml_wgts)\n",
    "    return mod_dict, toks_map, lbs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c38b89-60e6-4e67-83c4-2b1975936697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod_dict, toks_map, lbs_map = brainsplant_diffntble(xml_vocab, brain_vocab, l2r_wgts)\n",
    "assert isinstance(mod_dict, nn.Module)\n",
    "assert nn.Module in mod_dict.__class__.__mro__ \n",
    "\n",
    "test_eq(mod_dict['token_factors'].weight.data[toks_map.itemgot(0)], l2r_wgts['token_factors.weight'][toks_map.itemgot(1)])\n",
    "test_eq(mod_dict['token_bias'].weight.data[toks_map.itemgot(0)], l2r_wgts['token_bias.weight'][toks_map.itemgot(1)])\n",
    "test_eq(mod_dict['label_factors'].weight.data[lbs_map.itemgot(0)], l2r_wgts['label_factors.weight'][lbs_map.itemgot(1)])\n",
    "test_eq(mod_dict['label_bias'].weight.data[lbs_map.itemgot(0)], l2r_wgts['label_bias.weight'][lbs_map.itemgot(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb824726-4ddf-4c82-b225-c3ae05bea88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (token_factors): Embedding(57376, 200)\n",
       "  (token_bias): Embedding(57376, 1)\n",
       "  (label_factors): Embedding(8922, 200)\n",
       "  (label_bias): Embedding(8922, 1)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117026a-9679-4baa-bb49-145644e5093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996.87: Complications of transplanted intestine\n",
      "51.10: Endoscopic retrograde cholangiopancreatography [ERCP]\n",
      "38.93: Venous catheterization, not elsewhere classified\n"
     ]
    }
   ],
   "source": [
    "some_lbs = ['996.87', '51.10', '38.93']\n",
    "\n",
    "for lbl in some_lbs:\n",
    "    print(f\"{lbl}: {lbs_des.get(lbl, 'NF')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12eebf-29af-406d-8906-0db54a4865b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbs_idx = tensor(mapt(xml_vocab[1].index, some_lbs)).to(default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425d4d7-9e4c-4a58-a32c-53ed9e1f4844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-influx\n",
      "-latissimus\n",
      "-equinovarus\n",
      "-deteriorates\n",
      "-aap\n",
      "-mvh\n",
      "-135\n",
      "-incipient\n",
      "-rhubarb\n",
      "-nizhoni\n",
      "-trancutaneous\n",
      "-indicaton\n",
      "-subset\n",
      "-largyngeal\n",
      "-lemonade\n",
      "-debulk\n",
      "-aerations\n",
      "-l34\n",
      "-perserverates\n",
      "-trendelenberg\n",
      "-kettr\n",
      "-meningitic\n",
      "-bored\n",
      "-hashimoto\n",
      "-mountains\n",
      "-wit\n",
      "-asts\n",
      "-ellicits\n",
      "-pax\n",
      "-adb\n",
      "-alcholism\n",
      "-violinist\n",
      "-301b\n",
      "-subpopulation\n",
      "-intraorally\n",
      "-98o2\n",
      "-agreesive\n",
      "-monilla\n",
      "-jig\n",
      "-paroxysmalatrial\n",
      "-10pts\n",
      "-knees\n",
      "-conventionally\n",
      "-soonest\n",
      "-recap\n",
      "-rediscuss\n",
      "-spontanous\n",
      "-pulmary\n",
      "-repletement\n",
      "-450x12\n",
      "-symetrically\n",
      "-fdi\n",
      "-pshx\n",
      "-svco2\n",
      "-topimax\n",
      "-2100cc\n",
      "-conceal\n",
      "-nauasea\n",
      "-decontamination\n",
      "-administrator\n",
      "-fraction\n",
      "-tachyarrythmia\n",
      "-oversee\n",
      "-dabigutran\n",
      "-reiterated\n",
      "-aftetr\n",
      "-bues\n",
      "-symettric\n",
      "-powerful\n",
      "-depocyte\n",
      "-hyperextension\n",
      "-hepsc\n"
     ]
    }
   ],
   "source": [
    "toks_idx = torch.randint(0, len(xml_vocab[0]), (72,)).to(default_device())\n",
    "print(\"-\"+'\\n-'.join(array(xml_vocab[0])[toks_idx.cpu()].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f4900-3464-407f-b74c-48edf13d437d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apprx_brain = mod_dict['token_factors'](toks_idx) @ mod_dict['label_factors'](lbs_idx).T + mod_dict['token_bias'](toks_idx) + mod_dict['label_bias'](lbs_idx).T\n",
    "apprx_brain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b5ba4-6cf9-4874-95f8-91e857abfc27",
   "metadata": {},
   "source": [
    "These are the tokens as ranked by the pretrained L2R model (which is essentially an approximation of the actual brain):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6996907-1880-4bbb-88ad-038f8a1575b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>996.87: Complications of transplanted intestine</th>\n",
       "      <th>51.10: Endoscopic retrograde cholangiopancreatography [ERCP]</th>\n",
       "      <th>38.93: Venous catheterization, not elsewhere classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fraction</td>\n",
       "      <td>wit</td>\n",
       "      <td>fraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knees</td>\n",
       "      <td>fraction</td>\n",
       "      <td>subpopulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subpopulation</td>\n",
       "      <td>administrator</td>\n",
       "      <td>knees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wit</td>\n",
       "      <td>subset</td>\n",
       "      <td>subset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>administrator</td>\n",
       "      <td>knees</td>\n",
       "      <td>pshx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>paroxysmalatrial</td>\n",
       "      <td>mvh</td>\n",
       "      <td>powerful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>indicaton</td>\n",
       "      <td>ellicits</td>\n",
       "      <td>indicaton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>rhubarb</td>\n",
       "      <td>indicaton</td>\n",
       "      <td>perserverates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>depocyte</td>\n",
       "      <td>aftetr</td>\n",
       "      <td>rhubarb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>aftetr</td>\n",
       "      <td>conceal</td>\n",
       "      <td>monilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   996.87: Complications of transplanted intestine   \n",
       "0                                         fraction  \\\n",
       "1                                            knees   \n",
       "2                                    subpopulation   \n",
       "3                                              wit   \n",
       "4                                    administrator   \n",
       "..                                             ...   \n",
       "67                                paroxysmalatrial   \n",
       "68                                       indicaton   \n",
       "69                                         rhubarb   \n",
       "70                                        depocyte   \n",
       "71                                          aftetr   \n",
       "\n",
       "   51.10: Endoscopic retrograde cholangiopancreatography [ERCP]   \n",
       "0                                                           wit  \\\n",
       "1                                                      fraction   \n",
       "2                                                 administrator   \n",
       "3                                                        subset   \n",
       "4                                                         knees   \n",
       "..                                                          ...   \n",
       "67                                                          mvh   \n",
       "68                                                     ellicits   \n",
       "69                                                    indicaton   \n",
       "70                                                       aftetr   \n",
       "71                                                      conceal   \n",
       "\n",
       "   38.93: Venous catheterization, not elsewhere classified  \n",
       "0                                                 fraction  \n",
       "1                                            subpopulation  \n",
       "2                                                    knees  \n",
       "3                                                   subset  \n",
       "4                                                     pshx  \n",
       "..                                                     ...  \n",
       "67                                                powerful  \n",
       "68                                               indicaton  \n",
       "69                                           perserverates  \n",
       "70                                                 rhubarb  \n",
       "71                                                 monilla  \n",
       "\n",
       "[72 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(array(xml_vocab[0])[toks_idx[apprx_brain.argsort(dim=0, descending=True)].cpu()], columns=L(zip(some_lbs, mapt(lbs_des.get, some_lbs))).map(': '.join))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932776b4-72da-4414-a647-0cdaa2993c3c",
   "metadata": {},
   "source": [
    "Just to compare: This is how an actual brain would rank those tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743832ed-bd2c-4ca0-9d91-a4e6c1a97bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>996.87: Complications of transplanted intestine</th>\n",
       "      <th>51.10: Endoscopic retrograde cholangiopancreatography [ERCP]</th>\n",
       "      <th>38.93: Venous catheterization, not elsewhere classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fraction</td>\n",
       "      <td>wit</td>\n",
       "      <td>knees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knees</td>\n",
       "      <td>administrator</td>\n",
       "      <td>svco2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hyperextension</td>\n",
       "      <td>pshx</td>\n",
       "      <td>meningitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meningitic</td>\n",
       "      <td>hashimoto</td>\n",
       "      <td>fraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301b</td>\n",
       "      <td>reiterated</td>\n",
       "      <td>subset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>latissimus</td>\n",
       "      <td>topimax</td>\n",
       "      <td>pshx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>monilla</td>\n",
       "      <td>conceal</td>\n",
       "      <td>equinovarus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>dabigutran</td>\n",
       "      <td>aftetr</td>\n",
       "      <td>debulk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>trendelenberg</td>\n",
       "      <td>symettric</td>\n",
       "      <td>oversee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>deteriorates</td>\n",
       "      <td>depocyte</td>\n",
       "      <td>l34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   996.87: Complications of transplanted intestine   \n",
       "0                                         fraction  \\\n",
       "1                                            knees   \n",
       "2                                   hyperextension   \n",
       "3                                       meningitic   \n",
       "4                                             301b   \n",
       "..                                             ...   \n",
       "67                                      latissimus   \n",
       "68                                         monilla   \n",
       "69                                      dabigutran   \n",
       "70                                   trendelenberg   \n",
       "71                                    deteriorates   \n",
       "\n",
       "   51.10: Endoscopic retrograde cholangiopancreatography [ERCP]   \n",
       "0                                                           wit  \\\n",
       "1                                                 administrator   \n",
       "2                                                          pshx   \n",
       "3                                                     hashimoto   \n",
       "4                                                    reiterated   \n",
       "..                                                          ...   \n",
       "67                                                      topimax   \n",
       "68                                                      conceal   \n",
       "69                                                       aftetr   \n",
       "70                                                    symettric   \n",
       "71                                                     depocyte   \n",
       "\n",
       "   38.93: Venous catheterization, not elsewhere classified  \n",
       "0                                                    knees  \n",
       "1                                                    svco2  \n",
       "2                                               meningitic  \n",
       "3                                                 fraction  \n",
       "4                                                   subset  \n",
       "..                                                     ...  \n",
       "67                                                    pshx  \n",
       "68                                             equinovarus  \n",
       "69                                                  debulk  \n",
       "70                                                 oversee  \n",
       "71                                                     l34  \n",
       "\n",
       "[72 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array(xml_vocab[0])[xml_brain[:, lbl_idx].topk(k=20, dim=0).indices.cpu()]\n",
    "pd.DataFrame(array(xml_vocab[0])[toks_idx[xml_brain[:, lbs_idx][toks_idx].argsort(descending=True, dim=0)].cpu()], columns=L(zip(some_lbs, mapt(lbs_des.get, some_lbs))).map(': '.join))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62a479-14bc-4c47-a9b2-2bd1c04edc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255febc-9372-45ca-9489-608d03632688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43bc73-32b7-4bb0-9b0c-7ff55aaa4124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c861c18-839f-4423-972c-1632fc3289e6",
   "metadata": {},
   "source": [
    "## Base `Learner` for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e89ee-1737-4069-9627-8a5c6b31db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_collab_keys(\n",
    "    model, # Model architecture\n",
    "    wgts:dict # Model weights\n",
    ") -> tuple:\n",
    "    \"Load only collab `wgts` (`i_weight` and `i_bias`) in `model`, keeping the rest as is\"\n",
    "    sd = model.state_dict()\n",
    "    lbs_weight, i_weight = sd.get('1.attn.lbs_weight.weight', None), wgts.get('i_weight.weight', None)\n",
    "    lbs_bias, i_bias = sd.get('1.attn.lbs_weight.bias', None), wgts.get('i_bias.weight', None) \n",
    "    if lbs_weight is not None and i_weight is not None: lbs_weight.data = i_weight.data\n",
    "    if lbs_bias is not None and i_bias is not None: lbs_bias.data = i_bias.data\n",
    "    if '1.attn.lbs_weight_dp.emb.weight' in sd:\n",
    "        sd['1.attn.lbs_weight_dp.emb.weight'] = i_weight.data.clone()\n",
    "    return model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81941404-34e8-4a65-b369-7fa293b97b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.pay_attn.lbs.weight\n",
      "1.boost_attn.lin.weight\n",
      "1.boost_attn.lin.bias\n"
     ]
    }
   ],
   "source": [
    "config = awd_lstm_clas_config.copy()\n",
    "config.update({'n_hid': 10, 'emb_sz': 5})\n",
    "# tst = get_text_classifier(AWD_LSTM, 100, 3, config=config)\n",
    "tst = get_xmltext_classifier(AWD_LSTM, 100, 3, config=config)\n",
    "old_sd = tst.state_dict().copy()\n",
    "r = re.compile(\".*attn.*\")\n",
    "test_eq([key for key in old_sd if 'attn' in key], list(filter(r.match, old_sd)))\n",
    "print(\"\\n\".join(list(filter(r.match, old_sd))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af00554-0fba-4e8d-b75e-a01e5fec4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53294433-b75e-4d54-a574-6af80e705b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_sd = copy.deepcopy(tst.state_dict())\n",
    "load_collab_keys(tst, new_wgts)\n",
    "# <TODO: Deb> fix the following tests later\n",
    "# test_ne(old_sd['1.attn.lbs_weight.weight'], tst.state_dict()['1.attn.lbs_weight.weight'])\n",
    "# test_eq(tst.state_dict()['1.pay_attn.lbs_weight.weight'], new_wgts['i_weight.weight'])\n",
    "# test_ne(old_sd['1.attn.lbs_weight_dp.emb.weight'], tst.state_dict()['1.attn.lbs_weight_dp.emb.weight'])\n",
    "# test_eq(tst.state_dict()['1.attn.lbs_weight_dp.emb.weight'], new_wgts['i_weight.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e5ac5-9a18-4139-9cf1-030977f84eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcube.layers import *\n",
    "from xcube.layers import _planted_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af50343-383d-4284-b11e-d3016d54e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(Learner.__init__)\n",
    "class TextLearner(Learner):\n",
    "    \"Basic class for a `Learner` in NLP.\"\n",
    "    def __init__(self, \n",
    "        dls:DataLoaders, # Text `DataLoaders`\n",
    "        model, # A standard PyTorch model\n",
    "        alpha:float=2., # Param for `RNNRegularizer`\n",
    "        beta:float=1., # Param for `RNNRegularizer`\n",
    "        moms:tuple=(0.8,0.7,0.8), # Momentum for `Cosine Annealing Scheduler`\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(dls, model, moms=moms, **kwargs)\n",
    "        self.add_cbs(rnn_cbs())\n",
    "\n",
    "    def save_encoder(self, \n",
    "        file:str # Filename for `Encoder` \n",
    "    ):\n",
    "        \"Save the encoder to `file` in the model directory\"\n",
    "        if rank_distrib(): return # don't save if child proc\n",
    "        encoder = get_model(self.model)[0]\n",
    "        if hasattr(encoder, 'module'): encoder = encoder.module\n",
    "        torch.save(encoder.state_dict(), join_path_file(file, self.path/self.model_dir, ext='.pth'))\n",
    "    \n",
    "    @delegates(save_model)\n",
    "    def save(self,\n",
    "        file:str, # Filename for the state_directory of the model\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Save model and optimizer state (if `with_opt`) to `self.path/self.model_dir/file`\n",
    "        Save `self.dls.vocab` to `self.path/self.model_dir/clas_vocab.pkl`\n",
    "        \"\"\"\n",
    "        model_file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n",
    "        vocab_file = join_path_file(file+'_vocab', self.path/self.model_dir, ext='.pkl')\n",
    "        save_model(model_file, self.model, getattr(self, 'opt', None), **kwargs)\n",
    "        save_pickle(vocab_file, self.dls.vocab)\n",
    "        return model_file\n",
    "\n",
    "    def load_encoder(self, \n",
    "        file:str, # Filename of the saved encoder \n",
    "        device:(int,str,torch.device)=None # Device used to load, defaults to `dls` device\n",
    "    ):\n",
    "        \"Load the encoder `file` from the model directory, optionally ensuring it's on `device`\"\n",
    "        encoder = get_model(self.model)[0]\n",
    "        if device is None: device = self.dls.device\n",
    "        if hasattr(encoder, 'module'): encoder = encoder.module\n",
    "        distrib_barrier()\n",
    "        wgts = torch.load(join_path_file(file,self.path/self.model_dir, ext='.pth'), map_location=device)\n",
    "        encoder.load_state_dict(clean_raw_keys(wgts))\n",
    "        self.freeze()\n",
    "        return self\n",
    "    \n",
    "    def load_brain(self,\n",
    "        file_wgts: str, # Filename of the saved attention wgts\n",
    "        file_bias: str, # Filename of the saved label bias\n",
    "        device:(int,str,torch.device)=None # Device used to load, defaults to `dls` device\n",
    "    ):\n",
    "        \"\"\"Load the pre-learnt label specific attention weights for each token from `file` located in the \n",
    "        model directory, optionally ensuring it's one `device`\n",
    "        \"\"\"\n",
    "        brain_path = join_path_file(file_wgts, self.path/self.model_dir, ext='.pkl')\n",
    "        bias_path = join_path_file(file_bias, self.path/self.model_dir, ext='.pkl')\n",
    "        brain_bootstrap = torch.load(brain_path, map_location=default_device() if device is None else device)\n",
    "        *brain_vocab, brain = mapt(brain_bootstrap.get, ['toks', 'lbs', 'mutual_info_jaccard'])\n",
    "        brain_vocab = L(brain_vocab).map(listify)\n",
    "        vocab = L(_get_text_vocab(self.dls), _get_label_vocab(self.dls)).map(listify)\n",
    "        brain_bias = torch.load(bias_path, map_location=default_device() if device is None else device)\n",
    "        brain_bias = brain_bias[:, :, 0].squeeze(-1)\n",
    "        print(\"Performing brainsplant...\")\n",
    "        self.brain, self.lbsbias, *_ = brainsplant(vocab, brain_vocab, brain, brain_bias)\n",
    "        print(\"Successfull!\")\n",
    "        # import pdb; pdb.set_trace()\n",
    "        plant_attn_layer = Lambda(Planted_Attention(self.brain))\n",
    "        setattr(self.model[1].pay_attn, 'attn', plant_attn_layer)\n",
    "        assert self.model[1].pay_attn.attn.func.f is _planted_attention\n",
    "        return self\n",
    "\n",
    "    def load_pretrained(self, \n",
    "        wgts_fname:str, # Filename of saved weights \n",
    "        vocab_fname:str, # Saved vocabulary filename in pickle format\n",
    "        model=None # Model to load parameters from, defaults to `Learner.model`\n",
    "    ):\n",
    "        \"Load a pretrained model and adapt it to the data vocabulary.\"\n",
    "        old_vocab = load_pickle(vocab_fname)\n",
    "        new_vocab = _get_text_vocab(self.dls)\n",
    "        distrib_barrier()\n",
    "        wgts = torch.load(wgts_fname, map_location = lambda storage,loc: storage)\n",
    "        if 'model' in wgts: wgts = wgts['model'] #Just in case the pretrained model was saved with an optimizer\n",
    "        wgts = match_embeds(wgts, old_vocab, new_vocab)\n",
    "        load_ignore_keys(self.model if model is None else model, clean_raw_keys(wgts))\n",
    "        self.freeze()\n",
    "        return self\n",
    "\n",
    "    #For previous versions compatibility. Remove at release\n",
    "    @delegates(load_model_text)\n",
    "    def load(self, \n",
    "        file:str, # Filename of saved model \n",
    "        with_opt:bool=None, # Enable to load `Optimizer` state\n",
    "        device:(int,str,torch.device)=None, # Device used to load, defaults to `dls` device\n",
    "        **kwargs\n",
    "    ):\n",
    "        if device is None: device = self.dls.device\n",
    "        if self.opt is None: self.create_opt()\n",
    "        file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n",
    "        load_model_text(file, self.model, self.opt, device=device, **kwargs)\n",
    "        return self\n",
    "    \n",
    "    def load_collab(self,\n",
    "        wgts_fname:str, # Filename of the saved collab model\n",
    "        collab_vocab_fname:str, # Saved Vocabulary of collab labels in pickle format \n",
    "        model=None # Model to load parameters from, defaults to `Learner.model`\n",
    "    ):\n",
    "        \"Load the label embeddings learned by collab model`, and adapt it to the label vocabulary.\"\n",
    "        collab_vocab = load_pickle(collab_vocab_fname)\n",
    "        lbs_vocab = _get_label_vocab(self.dls)\n",
    "        distrib_barrier()\n",
    "        wgts = torch.load(wgts_fname, map_location=lambda storage,loc: storage)\n",
    "        if 'model' in wgts: wgts = wgts['model'] #Just in case the pretrained model was saved with an optimizer\n",
    "        wgts, _ = match_collab(wgts, collab_vocab, lbs_vocab)\n",
    "        load_collab_keys(self.model if model is None else model, wgts)\n",
    "        self.freeze()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c077c1d-1fde-4c45-ae1e-6f6cd3f58b4c",
   "metadata": {},
   "source": [
    "Adds a `ModelResetter` and an `RNNRegularizer` with `alpha` and `beta` to the callbacks, the rest is the same as `Learner` init. \n",
    "\n",
    "This `Learner` adds functionality to the base class:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9001ab92-67ce-4357-b447-0b85c0cbd384",
   "metadata": {},
   "source": [
    "## `Learner` convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a39c937-70c1-438b-84d9-34d7ef4a8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcube.text.models.core import _model_meta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38916689-ddc4-498f-881d-36ddebd9e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@delegates(Learner.__init__)\n",
    "def xmltext_classifier_learner(dls, arch, seq_len=72, config=None, backwards=False, pretrained=True, collab=False, drop_mult=0.5, n_out=None,\n",
    "                           lin_ftrs=None, ps=None, max_len=72*20, y_range=None, splitter=None, running_decoder=True, **kwargs):\n",
    "    \"Create a `Learner` with a text classifier from `dls` and `arch`.\"\n",
    "    vocab = _get_text_vocab(dls)\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from the data, set `dls.c` or pass `n_out`\"\n",
    "    model = get_xmltext_classifier2(arch, len(vocab), n_out, seq_len=seq_len, config=config, y_range=y_range,\n",
    "                                drop_mult=drop_mult, max_len=max_len, running_decoder=running_decoder)\n",
    "    # model = get_xmltext_classifier(arch, len(vocab), n_out, seq_len=seq_len, config=config, y_range=y_range,\n",
    "                                # drop_mult=drop_mult, max_len=max_len)\n",
    "    meta = _model_meta[arch]\n",
    "    learn = TextLearner(dls, model, splitter=splitter if splitter is not None else meta['split_clas'], **kwargs)\n",
    "    url = 'url_bwd' if backwards else 'url'\n",
    "    if pretrained:\n",
    "        if url not in meta:\n",
    "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
    "            return learn\n",
    "        model_path = untar_data(meta[url], c_key='model')\n",
    "        try: fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        except IndexError: print(f'The model in {model_path} is incomplete, download again'); raise\n",
    "        learn = learn.load_pretrained(*fnames, model=learn.model[0])\n",
    "    if collab:\n",
    "        try: fnames = [list(learn.path.glob(f'**/collab/*collab*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        except IndexError: print(f'The collab model in {learn.path} is incomplete, re-train it!'); raise\n",
    "        learn = learn.load_colab(*fnames, model=learn.model[1])\n",
    "    learn.freeze()\n",
    "    return learn   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e66275-882c-4fce-b021-a0e3cc0c5b69",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f6c93-6031-40fb-8bc9-e32a9c519643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepk",
   "language": "python",
   "name": "deepk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
