{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8d823-2303-49fa-ba64-7881bcb70b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq xcube  # upgrade xcube on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6496c1-fab0-447f-af93-79cae9087894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.basics import *\n",
    "from fastai.text.learner import *\n",
    "from fastai.callback.rnn import *\n",
    "from fastai.text.models.awdlstm import *\n",
    "from fastai.text.models.core import get_text_classifier\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from xcube.text.models.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de734b9-c91e-42d1-a986-3d9a4f4e8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6918a5a-ce9c-4222-bf49-fde8e0268244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp text.learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259d4897-0be6-47da-bd90-21217e9f184e",
   "metadata": {},
   "source": [
    "# Learner for the XML Text application:\n",
    "\n",
    "> All the functions necessary to build `Learner` suitable for transfer learning in XML text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6651917d-cd3b-4533-b19d-7ca3feb32873",
   "metadata": {},
   "source": [
    "The most important function of this module is `xmltext_classifier_learner`. This will help you define a `Learner` using a pretrained Language Model for the encoder and a pretrained Learning-to-Rank-Model for the decoder. (Tutorial: Coming Soon!). This module is inspired from [fastai's](https://github.com/fastai/fastai) [TextLearner](https://docs.fast.ai/text.learner.html) based on the paper [ULMFit](https://arxiv.org/pdf/1801.06146.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b331383-0c65-4d88-9689-4eaa2c0eef47",
   "metadata": {},
   "source": [
    "## Loading label embeddings from a pretrained colab model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dfc32-d2b6-4107-9b5e-5e3f9933380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_text_vocab(dls:DataLoaders) -> list:\n",
    "    \"Get text vocabulary from `DataLoaders`\"\n",
    "    vocab = dls.vocab\n",
    "    if isinstance(vocab, L): vocab = vocab[0]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbf616-ed91-4681-8733-ba59703b8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_label_vocab(dls:DataLoaders) -> list:\n",
    "    \"Get label vocabulary from `DataLoaders`\"\n",
    "    vocab = dls.vocab\n",
    "    if isinstance(vocab, L): vocab = vocab[1]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e749a-83ac-41ad-b5b8-b7d141bc0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def match_collab(\n",
    "    old_wgts:dict, # Embedding weights of the colab model\n",
    "    collab_vocab:dict, # Vocabulary of `token` and `label` used for colab pre-training\n",
    "    lbs_vocab:list # Current labels vocabulary\n",
    ") -> dict:\n",
    "    \"Convert the label embedding in `old_wgts` to go from `old_vocab` in colab to `lbs_vocab`\"\n",
    "    bias, wgts = old_wgts.get('i_bias.weight', None), old_wgts.get('i_weight.weight')\n",
    "    wgts_m = wgts.mean(0)\n",
    "    new_wgts = wgts.new_zeros((len(lbs_vocab), wgts.size(1)))\n",
    "    if bias is not None:\n",
    "        bias_m = bias.mean(0)\n",
    "        new_bias = bias.new_zeros((len(lbs_vocab), 1))\n",
    "    collab_lbs_vocab = collab_vocab['label']\n",
    "    collab_o2i = collab_lbs_vocab.o2i if hasattr(collab_lbs_vocab, 'o2i') else {w:i for i,w in enumerate(collab_lbs_vocab)}\n",
    "    missing = 0\n",
    "    for i,w in enumerate(lbs_vocab):\n",
    "        idx = collab_o2i.get(w, -1)\n",
    "        new_wgts[i] = wgts[idx] if idx>=0 else wgts_m\n",
    "        if bias is not None: new_bias[i] = bias[idx] if idx>=0 else bias_m\n",
    "        if idx == -1: missing = missing + 1\n",
    "    old_wgts['i_weight.weight'] = new_wgts\n",
    "    if bias is not None: old_wgts['i_bias.weight'] = new_bias\n",
    "    return old_wgts, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0c5d8-7104-4971-a78f-d17be39abccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = {'u_weight.weight': torch.randn(3,5), \n",
    "        'i_weight.weight': torch.randn(4,5),\n",
    "        'u_bias.weight'  : torch.randn(3,1),\n",
    "        'i_bias.weight'  : torch.randn(4,1)}\n",
    "collab_vocab = {'token': ['#na#', 'sun', 'moon', 'earth', 'mars'],\n",
    "                'label': ['#na#', 'a', 'c', 'b']}\n",
    "lbs_vocab = ['a', 'b', 'c']\n",
    "new_wgts, missing = match_collab(wgts.copy(), collab_vocab, lbs_vocab)\n",
    "test_eq(missing, 0)\n",
    "test_close(wgts['u_weight.weight'], new_wgts['u_weight.weight'])\n",
    "test_close(wgts['u_bias.weight'], new_wgts['u_bias.weight'])\n",
    "with ExceptionExpected(ex=AssertionError, regex=\"close\"):\n",
    "    test_close(wgts['i_weight.weight'][1:], new_wgts['i_weight.weight'])\n",
    "    test_close(wgts['i_bias.weight'][1:], new_wgts['i_bias.weight'])\n",
    "old_w, new_w = wgts['i_weight.weight'], new_wgts['i_weight.weight']\n",
    "old_b, new_b = wgts['i_bias.weight'], new_wgts['i_bias.weight']\n",
    "for (old_k,old_v), (new_k, new_v) in zip(wgts.items(), new_wgts.items()): \n",
    "    if old_k.startswith('u'): test_eq(old_v.size(), new_v.size())\n",
    "    else: test_ne(old_v.size(), new_v.size());\n",
    "    # print(f\"old: {old_k} = {old_v.size()}, new: {new_k} = {new_v.size()}\")\n",
    "test_eq(new_w[0], old_w[1]); test_eq(new_b[0], old_b[1])\n",
    "test_eq(new_w[1], old_w[3]); test_eq(new_b[1], old_b[3])\n",
    "test_eq(new_w[2], old_w[2]); test_eq(new_b[2], old_b[2])\n",
    "test_shuffled(list(old_b[1:].squeeze().numpy()), list(new_b.squeeze().numpy()))\n",
    "test_eq(torch.sort(old_b[1:], dim=0)[0], torch.sort(new_b, dim=0)[0])\n",
    "test_eq(torch.sort(old_w[1:], dim=0)[0], torch.sort(new_w, dim=0)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341847dd-00a6-414d-98fb-e4922e1eccb4",
   "metadata": {},
   "source": [
    "## Loading Pretrained Information Gain as Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d51b56-f98f-426d-8d46-493d3552edc3",
   "metadata": {},
   "source": [
    "**1. Planting brain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49138f56-a5a3-4e12-b37c-eae2db651d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcube.l2r.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e08619-019a-4631-8f59-b46a70c44de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mimic = untar_xxx(XURLs.MIMIC3)\n",
    "xml_vocab = load_pickle(source_mimic/'mimic3-9k_clas_full_vocab.pkl')\n",
    "xml_vocab = L(xml_vocab).map(listify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ead7eb-6a67-4311-bbb8-871623a5121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_l2r = untar_xxx(XURLs.MIMIC3_L2R)\n",
    "boot_path = join_path_file('mimic3-9k_tok_lbl_info', source_l2r, ext='.pkl')\n",
    "bias_path = join_path_file('p_L', source_l2r, ext='.pkl')\n",
    "l2r_bootstrap = torch.load(boot_path, map_location=default_device())\n",
    "brain_bias = torch.load(bias_path, map_location=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcf19c-2416-4d14-8614-8a889fea0a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last two places in brain vocab has ['xxfake', 'xxfake']\n"
     ]
    }
   ],
   "source": [
    "*brain_vocab, brain = mapt(l2r_bootstrap.get, ['toks', 'lbs', 'mutual_info_jaccard'])\n",
    "brain_vocab = L(brain_vocab).map(listify)\n",
    "toks, lbs = brain_vocab\n",
    "print(f\"last two places in brain vocab has {toks[-2:]}\")\n",
    "# toks = CategoryMap(toks, sort=False)\n",
    "brain_bias = brain_bias[:, :, 0].squeeze(-1)\n",
    "lbs_des = load_pickle(source_mimic/'code_desc.pkl')\n",
    "assert isinstance(lbs_des, dict)\n",
    "test_eq(brain.shape, (len(toks), len(lbs))) # last two places has 'xxfake'\n",
    "test_eq(brain_bias.shape, [len(lbs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf1375-8dae-4531-99c3-b42947a28393",
   "metadata": {},
   "source": [
    "The tokens which are there in the xml vocab but not in the brain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddcd95-7b47-496f-8d91-cbebbf73ca96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#20) ['dobhoof','langauge','southbay','1193p','supicious','unrmarkable','q2day','sharpio','92k','dissension'...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found_in_brain = L(set(xml_vocab[0]).difference(set(brain_vocab[0])))\n",
    "not_found_in_brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ba7d8-9d37-4fdc-9045-40ce43d3b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(lambda : toks.index('cella'), contains='is not in list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc7d566-7fcd-4542-809f-0591018405bf",
   "metadata": {},
   "source": [
    "The tokens which are in the brain but were not present in the xml vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b1933-81cd-4280-afca-8f009bd7688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(brain_vocab[0]).difference(xml_vocab[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb96cc-7c9d-4bad-9137-81e2f302ae21",
   "metadata": {},
   "source": [
    "Thankfully, we have `info` for all the labels in the xml vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef0876-d1ec-40af-b4d0-069a5b024b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(brain_vocab[1]).symmetric_difference(brain_vocab[1]) == set()\n",
    "# test_shuffled(xml_vocab[1], mimic_vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bae0e-536f-47f3-8433-ae7680c62fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _xml2brain(xml_vocab, brain_vocab, parent_bar=None):\n",
    "    \"Creates a mapping between the indices of the xml vocab and the brain vocab\"\n",
    "    pbar = progress_bar(xml_vocab, parent=parent_bar, leave=True)\n",
    "    xml2brain = {i: brain_vocab.index(o) if o in brain_vocab else np.inf  for i,o in enumerate(pbar)}\n",
    "    xml2brain_notfnd = [o for o in xml2brain if xml2brain[o] is np.inf]\n",
    "    return xml2brain, xml2brain_notfnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89677ad5-60bb-4758-b854-8d87d869b89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='57376' class='' max='57376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [57376/57376 00:20&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toks_xml2brain, toks_notfnd = _xml2brain(xml_vocab[0], brain_vocab[0])\n",
    "\n",
    "toks_found = set(toks_xml2brain).difference(set(toks_notfnd))\n",
    "test_shuffled(array(xml_vocab[0])[toks_notfnd], not_found_in_brain)\n",
    "some_xml_idxs = np.random.choice(array(L(toks_found)), size=10)\n",
    "some_xml_toks = array(xml_vocab[0])[some_xml_idxs]\n",
    "corres_brain_idxs = L(map(toks_xml2brain.get, some_xml_idxs))\n",
    "corres_brain_toks = array(toks)[corres_brain_idxs]\n",
    "assert all_equal(some_xml_toks, corres_brain_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61646a6f-4323-4f7f-9ca0-e341aa36b8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8922' class='' max='8922' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8922/8922 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lbs_xml2brain, lbs_notfnd = _xml2brain(xml_vocab[1], brain_vocab[1])\n",
    "\n",
    "lbs_found = set(lbs_xml2brain).difference(set(lbs_notfnd))\n",
    "some_xml_idxs = np.random.choice(array(L(lbs_found)), size=10)\n",
    "some_xml_lbs = array(xml_vocab[1])[some_xml_idxs]\n",
    "corres_brain_idxs = L(map(lbs_xml2brain.get, some_xml_idxs))\n",
    "corres_brain_lbs = array(lbs)[corres_brain_idxs]\n",
    "assert all_equal(some_xml_lbs, corres_brain_lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95a209-eba2-4e1f-9fbd-605b77393b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def brainsplant(xml_vocab, brain_vocab, brain, brain_bias, device=None):\n",
    "    toks_lbs = 'toks lbs'.split()\n",
    "    mb = master_bar(range(2))\n",
    "    for i in mb:\n",
    "        globals().update(dict(zip((toks_lbs[i]+'_xml2brain', toks_lbs[i]+'_notfnd'), (_xml2brain(xml_vocab[i], brain_vocab[i], parent_bar=mb)))))\n",
    "        mb.write = f\"Finished Loop {i}\"\n",
    "    xml_brain = torch.zeros(*xml_vocab.map(len)).to(default_device() if device is None else device) # initialize empty brain\n",
    "    xml_lbsbias = torch.zeros(len(xml_vocab[1])).to(default_device() if device is None else device)\n",
    "    toks_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in toks_xml2brain.items() if brn_idx is not np.inf) \n",
    "    lbs_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in lbs_xml2brain.items() if brn_idx is not np.inf) \n",
    "    xml_brain[toks_map.itemgot(0)] = brain[toks_map.itemgot(1)][:, lbs_map.itemgot(1)] # permute toks dim to match xml and brain\n",
    "    xml_brain[:, lbs_map.itemgot(0)] = xml_brain.clone() # permute lbs dim to match xml and brain\n",
    "    xml_lbsbias[lbs_map.itemgot(0)] = brain_bias[lbs_map.itemgot(1)].clone() # permute toks dim to match xml and brain\n",
    "    return xml_brain, xml_lbsbias, toks_map, lbs_map, toks_xml2brain, lbs_xml2brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655ab82-2986-471d-b628-aaee8fea1473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xml_brain, xml_lbsbias, toks_map, lbs_map, toks_xml2brain, lbs_xml2brain = brainsplant(xml_vocab, brain_vocab, brain, brain_bias)\n",
    "test_eq(xml_brain.shape, xml_vocab.map(len))\n",
    "test_eq(xml_brain[toks_notfnd], xml_brain.new_zeros(len(toks_notfnd), len(xml_vocab[1])))\n",
    "assert all_equal(array(xml_vocab[0])[toks_map.itemgot(0)], array(brain_vocab[0])[toks_map.itemgot(1)])\n",
    "assert all_equal(array(xml_vocab[1])[lbs_map.itemgot(0)], array(brain_vocab[1])[lbs_map.itemgot(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54faff-2352-437e-b72e-b4e1c3d6dca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the lbl 996.87 (Complications of transplanted intestine), the top tokens that needs attention are:\n",
      "+ ('consultued', 0.25548762)\n",
      "+ ('cip', 0.25548762)\n",
      "+ ('parlor', 0.24661502)\n",
      "+ ('transplantations', 0.18601614)\n",
      "+ ('scaffoid', 0.18601614)\n",
      "+ ('epineprine', 0.18601614)\n",
      "+ ('culinary', 0.17232327)\n",
      "+ ('coordinates', 0.1469037)\n",
      "+ ('aminotransferases', 0.12153866)\n",
      "+ ('hydronephroureter', 0.12153866)\n",
      "+ ('27yom', 0.12153866)\n",
      "+ ('27y', 0.103684604)\n",
      "+ ('hardward', 0.090407245)\n",
      "+ ('leukoreduction', 0.08014185)\n",
      "+ ('venting', 0.07831942)\n",
      "+ ('secrete', 0.07196123)\n",
      "+ ('orthogonal', 0.07196123)\n",
      "+ ('naac', 0.06891022)\n",
      "+ ('mgso4', 0.0662555)\n",
      "+ ('septecemia', 0.065286644)\n"
     ]
    }
   ],
   "source": [
    "# tests to ensure `brainsplant` was successful \n",
    "lbl = '642.41'\n",
    "lbl = '38.93'\n",
    "lbl = '51.10'\n",
    "lbl = '996.87'\n",
    "lbl_idx_from_brn = brain_vocab[1].index(lbl)\n",
    "tok_vals_from_brn, top_toks_from_brn= L(brain[:, lbl_idx_from_brn].topk(k=20)).map(Self.cpu())\n",
    "lbl_idx_from_xml = xml_vocab[1].index(lbl)\n",
    "tok_vals_from_xml, top_toks_from_xml = L(xml_brain[:, lbl_idx_from_xml].topk(k=20)).map(Self.cpu())\n",
    "test_eq(lbs_xml2brain[lbl_idx_from_xml], lbl_idx_from_brn)\n",
    "test_eq(tok_vals_from_brn, tok_vals_from_xml)\n",
    "test_eq(array(brain_vocab[0])[top_toks_from_brn], array(xml_vocab[0])[top_toks_from_xml])\n",
    "test_eq(brain_bias[lbl_idx_from_brn], xml_lbsbias[lbl_idx_from_xml])\n",
    "print(f\"For the lbl {lbl} ({lbs_des.get(lbl)}), the top tokens that needs attention are:\")\n",
    "print('\\n'.join(L(array(xml_vocab[0])[top_toks_from_xml], use_list=True).zipwith(L(tok_vals_from_xml.numpy(), use_list=True)).map(str).map(lambda o: \"+ \"+o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088612a-0f41-4458-9608-1ef421f145af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the token restitched, the top labels that needs attention are:\n",
      "+ ('Other operations on supporting structures of uterus', 0.29102018)\n",
      "+ ('Other proctopexy', 0.29102018)\n",
      "+ ('Other operations on cul-de-sac', 0.18601614)\n",
      "+ (None, 0.07494824)\n",
      "+ ('Intervertebral disc disorder with myelopathy, thoracic region', 0.055331517)\n",
      "+ ('Excision of scapula, clavicle, and thorax [ribs and sternum] for graft', 0.04382947)\n",
      "+ ('Other repair of omentum', 0.028067086)\n",
      "+ ('Chronic lymphocytic thyroiditis', 0.01986737)\n",
      "+ (None, 0.019236181)\n",
      "+ ('Reclosure of postoperative disruption of abdominal wall', 0.016585195)\n",
      "+ ('Other disorders of calcium metabolism', 0.009393147)\n",
      "+ ('Pain in joint involving pelvic region and thigh', 0.008421187)\n",
      "+ ('Exteriorization of small intestine', 0.00817792)\n",
      "+ ('Fusion or refusion of 9 or more vertebrae', 0.00762466)\n",
      "+ ('Kyphosis (acquired) (postural)', 0.0074228523)\n",
      "+ ('Unspecified procedure as the cause of abnormal reaction of patient, or of later complication, without mention of misadventure at time of procedure', 0.0063889036)\n",
      "+ ('Application or administration of adhesion barrier substance', 0.00610513)\n",
      "+ ('Acute osteomyelitis involving other specified sites', 0.0054434645)\n",
      "+ ('Body Mass Index less than 19, adult', 0.004719585)\n",
      "+ ('Dorsal and dorsolumbar fusion, anterior technique', 0.0046444684)\n"
     ]
    }
   ],
   "source": [
    "tok = 'fibrillation'\n",
    "tok = 'colpo'\n",
    "tok = 'amiodarone'\n",
    "tok = 'flagyl'\n",
    "tok = 'nasalilid'\n",
    "tok = 'hemetemesis'\n",
    "tok = 'restitched'\n",
    "tok_idx_from_brn = brain_vocab[0].index(tok)\n",
    "lbs_vals_from_brn, top_lbs_from_brn = L(brain[tok_idx_from_brn].topk(k=20)).map(Self.cpu())\n",
    "tok_idx_from_xml = xml_vocab[0].index(tok)\n",
    "test_eq(tok_idx_from_brn, toks_xml2brain[tok_idx_from_xml])\n",
    "lbs_vals_from_xml, top_lbs_from_xml = L(xml_brain[tok_idx_from_xml].topk(k=20)).map(Self.cpu())\n",
    "test_eq(lbs_vals_from_brn, lbs_vals_from_xml)\n",
    "try: \n",
    "    test_eq(array(brain_vocab[1])[top_lbs_from_brn], array(xml_vocab[1])[top_lbs_from_xml])\n",
    "except AssertionError as e: \n",
    "    print(type(e).__name__, \"due to instability in sorting (nothing to worry!)\");\n",
    "    test_shuffled(array(brain_vocab[1])[top_lbs_from_brn], array(xml_vocab[1])[top_lbs_from_xml])\n",
    "print('')\n",
    "print(f\"For the token {tok}, the top labels that needs attention are:\")\n",
    "print('\\n'.join(L(mapt(lbs_des.get, array(xml_vocab[1])[top_lbs_from_xml])).zipwith(L(lbs_vals_from_xml.numpy(), use_list=True)).map(str).map(lambda o: \"+ \"+o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e897af-7a67-4c27-aa86-74cdfcd6151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some tokens (with repetitions):\n",
      " -orhtostatic\n",
      "-blanch\n",
      "-orhtostatic\n",
      "-orhtostatic\n",
      "-blanch\n",
      "-sand\n",
      "-blanch\n",
      "-mv1\n",
      "-sand\n",
      "-orhtostatic\n",
      "-tolnaftate\n",
      "-sand\n",
      "-sand\n",
      "-eyedrops\n",
      "-tolnaftate\n",
      "-tolnaftate\n",
      "-mv1\n",
      "-orhtostatic\n",
      "-tolnaftate\n",
      "-sand\n"
     ]
    }
   ],
   "source": [
    "some_toks = random.sample(toks_map.itemgot(0), 10)\n",
    "counts = [c*6 for c in random.sample(range(10), 10)]\n",
    "some_toks = random.sample(some_toks, 20, counts=counts)\n",
    "# Counter(some_toks)\n",
    "cors_toks_brn = L(mapt(toks_xml2brain.get, some_toks))\n",
    "test_eq(array(brain_vocab[0])[cors_toks_brn], array(xml_vocab[0])[some_toks])\n",
    "print(\"some tokens (with repetitions):\\n\",'\\n'.join(['-'+xml_vocab[0][t]for t in some_toks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41799697-a3b3-4e0d-a53c-7a39246c218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = xml_brain[some_toks]\n",
    "test_eq(attn.shape, (len(some_toks), xml_brain.shape[1]))\n",
    "# semantics of attn\n",
    "# for each token we can compute the attention each label deserves by pulling out all the columns for a label\n",
    "for t, a in zip(some_toks,attn):\n",
    "    test_eq(xml_brain[t], a)\n",
    "# for each label we can compute the attention those tokens deserve by pulling out all rows for a label\n",
    "for lbl in range(xml_brain.shape[1]):\n",
    "    test_eq(xml_brain[:, lbl][some_toks], attn[:, lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728754ad-5181-4d23-bf88-9783ee2753fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>most_relevant_lbl</th>\n",
       "      <th>lbl_attn</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tolnaftate</td>\n",
       "      <td>279.03</td>\n",
       "      <td>0.069757</td>\n",
       "      <td>Other selective immunoglobulin deficiencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tolnaftate</td>\n",
       "      <td>279.03</td>\n",
       "      <td>0.069757</td>\n",
       "      <td>Other selective immunoglobulin deficiencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tolnaftate</td>\n",
       "      <td>279.03</td>\n",
       "      <td>0.069757</td>\n",
       "      <td>Other selective immunoglobulin deficiencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tolnaftate</td>\n",
       "      <td>279.03</td>\n",
       "      <td>0.069757</td>\n",
       "      <td>Other selective immunoglobulin deficiencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sand</td>\n",
       "      <td>E883.0</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>Accident from diving or jumping into water [swimming pool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sand</td>\n",
       "      <td>E883.0</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>Accident from diving or jumping into water [swimming pool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sand</td>\n",
       "      <td>E883.0</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>Accident from diving or jumping into water [swimming pool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sand</td>\n",
       "      <td>E883.0</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>Accident from diving or jumping into water [swimming pool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sand</td>\n",
       "      <td>E883.0</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>Accident from diving or jumping into water [swimming pool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mv1</td>\n",
       "      <td>493.81</td>\n",
       "      <td>0.042219</td>\n",
       "      <td>Exercise induced bronchospasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mv1</td>\n",
       "      <td>493.81</td>\n",
       "      <td>0.042219</td>\n",
       "      <td>Exercise induced bronchospasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blanch</td>\n",
       "      <td>772.14</td>\n",
       "      <td>0.040267</td>\n",
       "      <td>Intraventricular hemorrhage, grade IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blanch</td>\n",
       "      <td>772.14</td>\n",
       "      <td>0.040267</td>\n",
       "      <td>Intraventricular hemorrhage, grade IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blanch</td>\n",
       "      <td>772.14</td>\n",
       "      <td>0.040267</td>\n",
       "      <td>Intraventricular hemorrhage, grade IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>orhtostatic</td>\n",
       "      <td>45.22</td>\n",
       "      <td>0.034220</td>\n",
       "      <td>Endoscopy of large intestine through artificial stoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orhtostatic</td>\n",
       "      <td>45.22</td>\n",
       "      <td>0.034220</td>\n",
       "      <td>Endoscopy of large intestine through artificial stoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>orhtostatic</td>\n",
       "      <td>45.22</td>\n",
       "      <td>0.034220</td>\n",
       "      <td>Endoscopy of large intestine through artificial stoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orhtostatic</td>\n",
       "      <td>45.22</td>\n",
       "      <td>0.034220</td>\n",
       "      <td>Endoscopy of large intestine through artificial stoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orhtostatic</td>\n",
       "      <td>45.22</td>\n",
       "      <td>0.034220</td>\n",
       "      <td>Endoscopy of large intestine through artificial stoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eyedrops</td>\n",
       "      <td>370.00</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>Corneal ulcer, unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token most_relevant_lbl  lbl_attn   \n",
       "10   tolnaftate            279.03  0.069757  \\\n",
       "18   tolnaftate            279.03  0.069757   \n",
       "15   tolnaftate            279.03  0.069757   \n",
       "14   tolnaftate            279.03  0.069757   \n",
       "8          sand            E883.0  0.051170   \n",
       "12         sand            E883.0  0.051170   \n",
       "11         sand            E883.0  0.051170   \n",
       "19         sand            E883.0  0.051170   \n",
       "5          sand            E883.0  0.051170   \n",
       "7           mv1            493.81  0.042219   \n",
       "16          mv1            493.81  0.042219   \n",
       "1        blanch            772.14  0.040267   \n",
       "6        blanch            772.14  0.040267   \n",
       "4        blanch            772.14  0.040267   \n",
       "9   orhtostatic             45.22  0.034220   \n",
       "3   orhtostatic             45.22  0.034220   \n",
       "17  orhtostatic             45.22  0.034220   \n",
       "2   orhtostatic             45.22  0.034220   \n",
       "0   orhtostatic             45.22  0.034220   \n",
       "13     eyedrops            370.00  0.009403   \n",
       "\n",
       "                                                   description  \n",
       "10                 Other selective immunoglobulin deficiencies  \n",
       "18                 Other selective immunoglobulin deficiencies  \n",
       "15                 Other selective immunoglobulin deficiencies  \n",
       "14                 Other selective immunoglobulin deficiencies  \n",
       "8   Accident from diving or jumping into water [swimming pool]  \n",
       "12  Accident from diving or jumping into water [swimming pool]  \n",
       "11  Accident from diving or jumping into water [swimming pool]  \n",
       "19  Accident from diving or jumping into water [swimming pool]  \n",
       "5   Accident from diving or jumping into water [swimming pool]  \n",
       "7                                Exercise induced bronchospasm  \n",
       "16                               Exercise induced bronchospasm  \n",
       "1                        Intraventricular hemorrhage, grade IV  \n",
       "6                        Intraventricular hemorrhage, grade IV  \n",
       "4                        Intraventricular hemorrhage, grade IV  \n",
       "9        Endoscopy of large intestine through artificial stoma  \n",
       "3        Endoscopy of large intestine through artificial stoma  \n",
       "17       Endoscopy of large intestine through artificial stoma  \n",
       "2        Endoscopy of large intestine through artificial stoma  \n",
       "0        Endoscopy of large intestine through artificial stoma  \n",
       "13                                  Corneal ulcer, unspecified  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([(xml_vocab[0][t], l:=xml_vocab[1][lbl_idx], val.item(), lbs_des.get(l, 'NF')) for t,lbl_idx,val in zip(some_toks,attn.max(dim=1).indices.cpu(), attn.max(dim=1).values.cpu())],\n",
    "            columns=['token', 'most_relevant_lbl', 'lbl_attn', 'description']).sort_values(by='lbl_attn', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1739ab9-644d-4f65-bbe9-b8c0e1d141f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcube.layers import inattention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd67ea6-97a4-442b-b257-0843bf6868de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define label inattention cutoff\n",
    "k = 5\n",
    "# top_lbs_attn = attn.clone().unsqueeze(0).permute(0,2,1).inattention(k=k).permute(0,2,1).squeeze(0).contiguous() \n",
    "top_lbs_attn = attn.inattention(sort_dim=1, k=k) # applying `inattention` across the lbs dim\n",
    "test_eq(top_lbs_attn.shape, (len(some_toks), xml_brain.shape[1]))\n",
    "test_ne(attn, top_lbs_attn)\n",
    "test_eq(top_lbs_attn.argmax(dim=1), attn.argmax(dim=1))\n",
    "lbs_cf = top_lbs_attn.sum(dim=0) # the built confidence after seeing those 20 tokens\n",
    "test_eq(lbs_cf.shape, [top_lbs_attn.shape[1]])\n",
    "idxs = lbs_cf.nonzero().flatten().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ce29b-cd30-4ba2-bf67-2caf2679ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After looking at the tokens ['orhtostatic', 'blanch', 'orhtostatic', 'orhtostatic', 'blanch', 'sand', 'blanch', 'mv1', 'sand', 'orhtostatic', 'tolnaftate', 'sand', 'sand', 'eyedrops', 'tolnaftate', 'tolnaftate', 'mv1', 'orhtostatic', 'tolnaftate', 'sand'], I am confident about the following labels:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbl</th>\n",
       "      <th>lbl_cf</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>279.03</td>\n",
       "      <td>0.279027</td>\n",
       "      <td>Other selective immunoglobulin deficiencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>334.9</td>\n",
       "      <td>0.267990</td>\n",
       "      <td>Spinocerebellar disease, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E883.0</td>\n",
       "      <td>0.255850</td>\n",
       "      <td>Accident from diving or jumping into water [swimming pool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>780.71</td>\n",
       "      <td>0.247991</td>\n",
       "      <td>Chronic fatigue syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>V10.29</td>\n",
       "      <td>0.235505</td>\n",
       "      <td>Personal history of malignant neoplasm of other respiratory and intrathoracic organs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>332.1</td>\n",
       "      <td>0.208260</td>\n",
       "      <td>Secondary Parkinsonism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53.81</td>\n",
       "      <td>0.187603</td>\n",
       "      <td>Plication of the diaphragm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>E910.2</td>\n",
       "      <td>0.187599</td>\n",
       "      <td>Accidental drowning and submersion while engaged in other sport or recreational activity without diving equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.22</td>\n",
       "      <td>0.171101</td>\n",
       "      <td>Endoscopy of large intestine through artificial stoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>011.90</td>\n",
       "      <td>0.155005</td>\n",
       "      <td>Unspecified pulmonary tuberculosis, unspecified examination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>E950.1</td>\n",
       "      <td>0.143276</td>\n",
       "      <td>Suicide and self-inflicted poisoning by barbiturates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200.30</td>\n",
       "      <td>0.133211</td>\n",
       "      <td>Marginal zone lymphoma, unspecified site, extranodal and solid organ sites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>202.40</td>\n",
       "      <td>0.127392</td>\n",
       "      <td>Leukemic reticuloendotheliosis, unspecified site, extranodal and solid organ sites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>772.14</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>Intraventricular hemorrhage, grade IV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>331.5</td>\n",
       "      <td>0.102681</td>\n",
       "      <td>Idiopathic normal pressure hydrocephalus (INPH)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>14.24</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>Destruction of chorioretinal lesion by laser photocoagulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>334.1</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>Hereditary spastic paraplegia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>96.27</td>\n",
       "      <td>0.088324</td>\n",
       "      <td>Manual reduction of hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>777.6</td>\n",
       "      <td>0.088322</td>\n",
       "      <td>Perinatal intestinal perforation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>493.81</td>\n",
       "      <td>0.084438</td>\n",
       "      <td>Exercise induced bronchospasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>729.9</td>\n",
       "      <td>0.079676</td>\n",
       "      <td>Other and unspecified disorders of soft tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>555.0</td>\n",
       "      <td>0.074951</td>\n",
       "      <td>Regional enteritis of small intestine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>292.12</td>\n",
       "      <td>0.070643</td>\n",
       "      <td>Drug-induced psychotic disorder with hallucinations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>787.3</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>Flatulence, eructation, and gas pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52.09</td>\n",
       "      <td>0.062234</td>\n",
       "      <td>Other pancreatotomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>45.12</td>\n",
       "      <td>0.051912</td>\n",
       "      <td>Endoscopy of small intestine through artificial stoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54.24</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>Closed [percutaneous] [needle] biopsy of intra-abdominal mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.19</td>\n",
       "      <td>0.037363</td>\n",
       "      <td>Other diagnostic procedures on nasal sinuses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>780.03</td>\n",
       "      <td>0.037363</td>\n",
       "      <td>Persistent vegetative state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>568.89</td>\n",
       "      <td>0.028981</td>\n",
       "      <td>Other specified disorders of peritoneum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>370.00</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>Corneal ulcer, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>365.9</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>Unspecified glaucoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.82</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>Repair of rupture of eyeball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>871.1</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>Ocular laceration with prolapse or exposure of intraocular tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>341.0</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>Neuromyelitis optica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>483.0</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>Pneumonia due to Mycoplasma pneumoniae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lbl    lbl_cf   \n",
       "30  279.03  0.279027  \\\n",
       "25   334.9  0.267990   \n",
       "7   E883.0  0.255850   \n",
       "17  780.71  0.247991   \n",
       "14  V10.29  0.235505   \n",
       "21   332.1  0.208260   \n",
       "15   53.81  0.187603   \n",
       "22  E910.2  0.187599   \n",
       "2    45.22  0.171101   \n",
       "3   011.90  0.155005   \n",
       "32  E950.1  0.143276   \n",
       "16  200.30  0.133211   \n",
       "19  202.40  0.127392   \n",
       "24  772.14  0.120800   \n",
       "11   331.5  0.102681   \n",
       "34   14.24  0.099010   \n",
       "28   334.1  0.099010   \n",
       "18   96.27  0.088324   \n",
       "31   777.6  0.088322   \n",
       "29  493.81  0.084438   \n",
       "27   729.9  0.079676   \n",
       "20   555.0  0.074951   \n",
       "13  292.12  0.070643   \n",
       "4    787.3  0.065002   \n",
       "5    52.09  0.062234   \n",
       "10   45.12  0.051912   \n",
       "6    54.24  0.038986   \n",
       "8    22.19  0.037363   \n",
       "12  780.03  0.037363   \n",
       "1   568.89  0.028981   \n",
       "33  370.00  0.009403   \n",
       "0    365.9  0.005845   \n",
       "26   16.82  0.005451   \n",
       "23   871.1  0.004811   \n",
       "35   341.0  0.004811   \n",
       "9    483.0  0.004358   \n",
       "\n",
       "                                                                                                          description  \n",
       "30                                                                        Other selective immunoglobulin deficiencies  \n",
       "25                                                                               Spinocerebellar disease, unspecified  \n",
       "7                                                          Accident from diving or jumping into water [swimming pool]  \n",
       "17                                                                                           Chronic fatigue syndrome  \n",
       "14                               Personal history of malignant neoplasm of other respiratory and intrathoracic organs  \n",
       "21                                                                                             Secondary Parkinsonism  \n",
       "15                                                                                         Plication of the diaphragm  \n",
       "22  Accidental drowning and submersion while engaged in other sport or recreational activity without diving equipment  \n",
       "2                                                               Endoscopy of large intestine through artificial stoma  \n",
       "3                                                         Unspecified pulmonary tuberculosis, unspecified examination  \n",
       "32                                                               Suicide and self-inflicted poisoning by barbiturates  \n",
       "16                                         Marginal zone lymphoma, unspecified site, extranodal and solid organ sites  \n",
       "19                                 Leukemic reticuloendotheliosis, unspecified site, extranodal and solid organ sites  \n",
       "24                                                                              Intraventricular hemorrhage, grade IV  \n",
       "11                                                                    Idiopathic normal pressure hydrocephalus (INPH)  \n",
       "34                                                      Destruction of chorioretinal lesion by laser photocoagulation  \n",
       "28                                                                                      Hereditary spastic paraplegia  \n",
       "18                                                                                         Manual reduction of hernia  \n",
       "31                                                                                   Perinatal intestinal perforation  \n",
       "29                                                                                      Exercise induced bronchospasm  \n",
       "27                                                                     Other and unspecified disorders of soft tissue  \n",
       "20                                                                              Regional enteritis of small intestine  \n",
       "13                                                                Drug-induced psychotic disorder with hallucinations  \n",
       "4                                                                                Flatulence, eructation, and gas pain  \n",
       "5                                                                                                 Other pancreatotomy  \n",
       "10                                                              Endoscopy of small intestine through artificial stoma  \n",
       "6                                                       Closed [percutaneous] [needle] biopsy of intra-abdominal mass  \n",
       "8                                                                        Other diagnostic procedures on nasal sinuses  \n",
       "12                                                                                        Persistent vegetative state  \n",
       "1                                                                             Other specified disorders of peritoneum  \n",
       "33                                                                                         Corneal ulcer, unspecified  \n",
       "0                                                                                                Unspecified glaucoma  \n",
       "26                                                                                       Repair of rupture of eyeball  \n",
       "23                                                  Ocular laceration with prolapse or exposure of intraocular tissue  \n",
       "35                                                                                               Neuromyelitis optica  \n",
       "9                                                                              Pneumonia due to Mycoplasma pneumoniae  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"After looking at the tokens {[xml_vocab[0][t]for t in some_toks]}, I am confident about the following labels:\")\n",
    "pd.DataFrame([(l:=xml_vocab[1][idx], val.item(), lbs_des.get(l, 'NF')) for idx,val in zip(idxs,lbs_cf[idxs])],\n",
    "            columns=['lbl', 'lbl_cf', 'description']).sort_values(by='lbl_cf', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ec9bc-8d5c-498b-a868-3d5e43faf89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "# semantics: `s` pulling out its 1st and 0th row is equivalent to `t` pulling out its 0th and 3rd row respectively (i.e., the data residing in the 1st and 0th row of the s matrix is same as the data residing at the 0th and the 3rd row of t's matrix)\n",
    "t = torch.zeros(4, 3).long()\n",
    "s = torch.arange(20).view(2, 10).long()\n",
    "# s = torch.arange(6).view(2,3).long()\n",
    "row_perm = L((0, 1), (3, 0)) # \n",
    "col_perm = L((2, 1), (0, 3), (1, -1))\n",
    "# col_perm = L((0,2), (1,0), (2,1))\n",
    "ic(t,s);\n",
    "ic(s[row_perm.itemgot(1)]); # pull out relevant rows from s\n",
    "ic(s[row_perm.itemgot(1)][:, col_perm.itemgot(1)]); # pull out relevant cols from s\n",
    "t[row_perm.itemgot(0)] = s[row_perm.itemgot(1)][:, col_perm.itemgot(1)] # permute rows\n",
    "t[:, col_perm.itemgot(0)] = t.clone() # permute cols\n",
    "# t[row_perm.itemgot(0)] = s[row_perm.itemgot(1)][:, col_perm.itemgot(1)][:, col_perm.itemgot(0)]\n",
    "ic(t);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e6266-162a-4cc2-8aad-8a012a2b611c",
   "metadata": {},
   "source": [
    "**2. Planting differentiable brain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2530f3-f6e2-427d-9712-461e25b60fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2r_wgts = torch.load(join_path_file('lin_lambdarank_full', source_l2r, ext='.pth'), map_location=default_device())\n",
    "if 'model' in l2r_wgts: l2r_wgts = l2r_wgts['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62294c-fe30-4c66-832f-32f017def64d",
   "metadata": {},
   "source": [
    "Need to match the wgts in xml and brain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc99996-3591-47fb-8fe1-23aebad6121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def brainsplant_diffntble(xml_vocab, brain_vocab, l2r_wgts, device=None):\n",
    "    toks_lbs = 'toks lbs'.split()\n",
    "    mb = master_bar(range(2))\n",
    "    for i in mb:\n",
    "        globals().update(dict(zip((toks_lbs[i]+'_xml2brain', toks_lbs[i]+'_notfnd'), (_xml2brain(xml_vocab[i], brain_vocab[i], parent_bar=mb)))))\n",
    "        mb.write = f\"Finished Loop {i}\" \n",
    "    toks_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in toks_xml2brain.items() if brn_idx is not np.inf) \n",
    "    lbs_map = L((xml_idx, brn_idx) for xml_idx, brn_idx in lbs_xml2brain.items() if brn_idx is not np.inf) \n",
    "    tf_xml = torch.zeros(len(xml_vocab[0]), 200).to(default_device() if device is None else device) \n",
    "    tb_xml = torch.zeros(len(xml_vocab[0]), 1).to(default_device() if device is None else device) \n",
    "    lf_xml = torch.zeros(len(xml_vocab[1]), 200).to(default_device() if device is None else device) \n",
    "    lb_xml = torch.zeros(len(xml_vocab[1]), 1).to(default_device() if device is None else device) \n",
    "    tf_l2r, tb_l2r, lf_l2r, lb_l2r = list(l2r_wgts.values())\n",
    "    tf_xml[toks_map.itemgot(0)] = tf_l2r[toks_map.itemgot(1)].clone()\n",
    "    tb_xml[toks_map.itemgot(0)] = tb_l2r[toks_map.itemgot(1)].clone()\n",
    "    lf_xml[lbs_map.itemgot(0)] = lf_l2r[lbs_map.itemgot(1)].clone()\n",
    "    lb_xml[lbs_map.itemgot(0)] = lb_l2r[lbs_map.itemgot(1)].clone()\n",
    "    # import pdb; pdb.set_trace()\n",
    "    xml_wgts = {k: xml_val for k, xml_val in zip(l2r_wgts.keys(), (tf_xml, tb_xml, lf_xml, lb_xml))}\n",
    "    mod_dict = nn.ModuleDict({k.split('.')[0]: nn.Embedding(*v.size()) for k,v in xml_wgts.items()}).to(default_device() if device is None else device) \n",
    "    mod_dict.load_state_dict(xml_wgts)\n",
    "    return mod_dict, toks_map, lbs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c38b89-60e6-4e67-83c4-2b1975936697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod_dict, toks_map, lbs_map = brainsplant_diffntble(xml_vocab, brain_vocab, l2r_wgts)\n",
    "assert isinstance(mod_dict, nn.Module)\n",
    "assert nn.Module in mod_dict.__class__.__mro__ \n",
    "\n",
    "test_eq(mod_dict['token_factors'].weight.data[toks_map.itemgot(0)], l2r_wgts['token_factors.weight'][toks_map.itemgot(1)])\n",
    "test_eq(mod_dict['token_bias'].weight.data[toks_map.itemgot(0)], l2r_wgts['token_bias.weight'][toks_map.itemgot(1)])\n",
    "test_eq(mod_dict['label_factors'].weight.data[lbs_map.itemgot(0)], l2r_wgts['label_factors.weight'][lbs_map.itemgot(1)])\n",
    "test_eq(mod_dict['label_bias'].weight.data[lbs_map.itemgot(0)], l2r_wgts['label_bias.weight'][lbs_map.itemgot(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb824726-4ddf-4c82-b225-c3ae05bea88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (token_factors): Embedding(57376, 200)\n",
       "  (token_bias): Embedding(57376, 1)\n",
       "  (label_factors): Embedding(8922, 200)\n",
       "  (label_bias): Embedding(8922, 1)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117026a-9679-4baa-bb49-145644e5093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996.87: Complications of transplanted intestine\n",
      "51.10: Endoscopic retrograde cholangiopancreatography [ERCP]\n",
      "38.93: Venous catheterization, not elsewhere classified\n"
     ]
    }
   ],
   "source": [
    "some_lbs = ['996.87', '51.10', '38.93']\n",
    "for lbl in some_lbs:\n",
    "    print(f\"{lbl}: {lbs_des.get(lbl, 'NF')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12eebf-29af-406d-8906-0db54a4865b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbs_idx = tensor(mapt(xml_vocab[1].index, some_lbs)).to(default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425d4d7-9e4c-4a58-a32c-53ed9e1f4844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-avoid\n",
      "-ctap\n",
      "-paralyzation\n",
      "-prochlorperazine\n",
      "-obease\n",
      "-azitrhomycin\n",
      "-strategize\n",
      "-alanine\n",
      "-rofecoxib\n",
      "-aabdominal\n",
      "-believe\n",
      "-objects\n",
      "-fibrosing\n",
      "-janeaway\n",
      "-revsion\n",
      "-eliciting\n",
      "-patellar\n",
      "-cadiology\n",
      "-cirrhois\n",
      "-bf\n",
      "-banded\n",
      "-blader\n",
      "-desynchronous\n",
      "-ensure\n",
      "-folgard\n",
      "-asthmacort\n",
      "-comforably\n",
      "-correlates\n",
      "-fermenter\n",
      "-cefalosporins\n",
      "-hypercoagubility\n",
      "-downwarded\n",
      "-drowned\n",
      "-rehydrated\n",
      "-leukopheresis\n",
      "-duraplasty\n",
      "-unfortunantly\n",
      "-guards\n",
      "-bouncing\n",
      "-swaddling\n",
      "-bronchopleurocutaneous\n",
      "-bialt\n",
      "-clousre\n",
      "-obstacles\n",
      "-abz\n",
      "-bases\n",
      "-dp2\n",
      "-bicarbonates\n",
      "-articulated\n",
      "-86yo\n",
      "-hemochromatosis\n",
      "-rhoncherous\n",
      "-crippling\n",
      "-melenotic\n",
      "-cogwheeling\n",
      "-synergy\n",
      "-thousand\n",
      "-shsf\n",
      "-unnecessarily\n",
      "-hyperattenuated\n",
      "-hr85\n",
      "-inches\n",
      "-tobradex\n",
      "-wosening\n",
      "-inebriated\n",
      "-equiv\n",
      "-synthryoid\n",
      "-rehabe\n",
      "-jo1\n",
      "-tetrahydrozoline\n",
      "-metalozone\n",
      "-vaco\n"
     ]
    }
   ],
   "source": [
    "toks_idx = torch.randint(0, len(xml_vocab[0]), (72,)).to(default_device())\n",
    "print(\"-\"+'\\n-'.join(array(xml_vocab[0])[toks_idx.cpu()].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f4900-3464-407f-b74c-48edf13d437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "apprx_brain = mod_dict['token_factors'](toks_idx) @ mod_dict['label_factors'](lbs_idx).T + mod_dict['token_bias'](toks_idx) + mod_dict['label_bias'](lbs_idx).T\n",
    "test_eq(apprx_brain.shape, (72,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b5ba4-6cf9-4874-95f8-91e857abfc27",
   "metadata": {},
   "source": [
    "These are the tokens as ranked by the pretrained L2R model (which is essentially an approximation of the actual brain):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6996907-1880-4bbb-88ad-038f8a1575b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>996.87: Complications of transplanted intestine</th>\n",
       "      <th>51.10: Endoscopic retrograde cholangiopancreatography [ERCP]</th>\n",
       "      <th>38.93: Venous catheterization, not elsewhere classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avoid</td>\n",
       "      <td>thousand</td>\n",
       "      <td>bases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bases</td>\n",
       "      <td>avoid</td>\n",
       "      <td>synergy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>believe</td>\n",
       "      <td>objects</td>\n",
       "      <td>objects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prochlorperazine</td>\n",
       "      <td>hemochromatosis</td>\n",
       "      <td>avoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ensure</td>\n",
       "      <td>alanine</td>\n",
       "      <td>ensure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hemochromatosis</td>\n",
       "      <td>cogwheeling</td>\n",
       "      <td>fermenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>synergy</td>\n",
       "      <td>bases</td>\n",
       "      <td>banded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>melenotic</td>\n",
       "      <td>believe</td>\n",
       "      <td>prochlorperazine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>objects</td>\n",
       "      <td>banded</td>\n",
       "      <td>believe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>correlates</td>\n",
       "      <td>synergy</td>\n",
       "      <td>rehydrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ctap</td>\n",
       "      <td>prochlorperazine</td>\n",
       "      <td>correlates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thousand</td>\n",
       "      <td>inches</td>\n",
       "      <td>thousand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>folgard</td>\n",
       "      <td>patellar</td>\n",
       "      <td>alanine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>inches</td>\n",
       "      <td>ensure</td>\n",
       "      <td>inches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>patellar</td>\n",
       "      <td>abz</td>\n",
       "      <td>patellar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>banded</td>\n",
       "      <td>fermenter</td>\n",
       "      <td>rhoncherous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fermenter</td>\n",
       "      <td>rehydrated</td>\n",
       "      <td>ctap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tobradex</td>\n",
       "      <td>rofecoxib</td>\n",
       "      <td>leukopheresis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>alanine</td>\n",
       "      <td>melenotic</td>\n",
       "      <td>hemochromatosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>equiv</td>\n",
       "      <td>86yo</td>\n",
       "      <td>inebriated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   996.87: Complications of transplanted intestine   \n",
       "0                                            avoid  \\\n",
       "1                                            bases   \n",
       "2                                          believe   \n",
       "3                                 prochlorperazine   \n",
       "4                                           ensure   \n",
       "5                                  hemochromatosis   \n",
       "6                                          synergy   \n",
       "7                                        melenotic   \n",
       "8                                          objects   \n",
       "9                                       correlates   \n",
       "10                                            ctap   \n",
       "11                                        thousand   \n",
       "12                                         folgard   \n",
       "13                                          inches   \n",
       "14                                        patellar   \n",
       "15                                          banded   \n",
       "16                                       fermenter   \n",
       "17                                        tobradex   \n",
       "18                                         alanine   \n",
       "19                                           equiv   \n",
       "\n",
       "   51.10: Endoscopic retrograde cholangiopancreatography [ERCP]   \n",
       "0                                                      thousand  \\\n",
       "1                                                         avoid   \n",
       "2                                                       objects   \n",
       "3                                               hemochromatosis   \n",
       "4                                                       alanine   \n",
       "5                                                   cogwheeling   \n",
       "6                                                         bases   \n",
       "7                                                       believe   \n",
       "8                                                        banded   \n",
       "9                                                       synergy   \n",
       "10                                             prochlorperazine   \n",
       "11                                                       inches   \n",
       "12                                                     patellar   \n",
       "13                                                       ensure   \n",
       "14                                                          abz   \n",
       "15                                                    fermenter   \n",
       "16                                                   rehydrated   \n",
       "17                                                    rofecoxib   \n",
       "18                                                    melenotic   \n",
       "19                                                         86yo   \n",
       "\n",
       "   38.93: Venous catheterization, not elsewhere classified  \n",
       "0                                                    bases  \n",
       "1                                                  synergy  \n",
       "2                                                  objects  \n",
       "3                                                    avoid  \n",
       "4                                                   ensure  \n",
       "5                                                fermenter  \n",
       "6                                                   banded  \n",
       "7                                         prochlorperazine  \n",
       "8                                                  believe  \n",
       "9                                               rehydrated  \n",
       "10                                              correlates  \n",
       "11                                                thousand  \n",
       "12                                                 alanine  \n",
       "13                                                  inches  \n",
       "14                                                patellar  \n",
       "15                                             rhoncherous  \n",
       "16                                                    ctap  \n",
       "17                                           leukopheresis  \n",
       "18                                         hemochromatosis  \n",
       "19                                              inebriated  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(array(xml_vocab[0])[toks_idx[apprx_brain.argsort(dim=0, descending=True)].cpu()], columns=L(zip(some_lbs, mapt(lbs_des.get, some_lbs))).map(': '.join)).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932776b4-72da-4414-a647-0cdaa2993c3c",
   "metadata": {},
   "source": [
    "Just to compare: This is how an actual brain would rank those tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743832ed-bd2c-4ca0-9d91-a4e6c1a97bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>996.87: Complications of transplanted intestine</th>\n",
       "      <th>51.10: Endoscopic retrograde cholangiopancreatography [ERCP]</th>\n",
       "      <th>38.93: Venous catheterization, not elsewhere classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>believe</td>\n",
       "      <td>thousand</td>\n",
       "      <td>bases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bases</td>\n",
       "      <td>objects</td>\n",
       "      <td>synergy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avoid</td>\n",
       "      <td>patellar</td>\n",
       "      <td>ensure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ensure</td>\n",
       "      <td>believe</td>\n",
       "      <td>objects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>objects</td>\n",
       "      <td>inches</td>\n",
       "      <td>inches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fibrosing</td>\n",
       "      <td>banded</td>\n",
       "      <td>fermenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tobradex</td>\n",
       "      <td>hemochromatosis</td>\n",
       "      <td>leukopheresis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>metalozone</td>\n",
       "      <td>rehydrated</td>\n",
       "      <td>rehydrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>patellar</td>\n",
       "      <td>correlates</td>\n",
       "      <td>desynchronous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prochlorperazine</td>\n",
       "      <td>synergy</td>\n",
       "      <td>alanine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>folgard</td>\n",
       "      <td>cogwheeling</td>\n",
       "      <td>azitrhomycin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>inches</td>\n",
       "      <td>alanine</td>\n",
       "      <td>hemochromatosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>leukopheresis</td>\n",
       "      <td>melenotic</td>\n",
       "      <td>folgard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>articulated</td>\n",
       "      <td>86yo</td>\n",
       "      <td>prochlorperazine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>inebriated</td>\n",
       "      <td>ctap</td>\n",
       "      <td>cefalosporins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abz</td>\n",
       "      <td>duraplasty</td>\n",
       "      <td>banded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bicarbonates</td>\n",
       "      <td>rhoncherous</td>\n",
       "      <td>believe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hr85</td>\n",
       "      <td>rofecoxib</td>\n",
       "      <td>melenotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>guards</td>\n",
       "      <td>fermenter</td>\n",
       "      <td>unfortunantly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dp2</td>\n",
       "      <td>prochlorperazine</td>\n",
       "      <td>aabdominal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   996.87: Complications of transplanted intestine   \n",
       "0                                          believe  \\\n",
       "1                                            bases   \n",
       "2                                            avoid   \n",
       "3                                           ensure   \n",
       "4                                          objects   \n",
       "5                                        fibrosing   \n",
       "6                                         tobradex   \n",
       "7                                       metalozone   \n",
       "8                                         patellar   \n",
       "9                                 prochlorperazine   \n",
       "10                                         folgard   \n",
       "11                                          inches   \n",
       "12                                   leukopheresis   \n",
       "13                                     articulated   \n",
       "14                                      inebriated   \n",
       "15                                             abz   \n",
       "16                                    bicarbonates   \n",
       "17                                            hr85   \n",
       "18                                          guards   \n",
       "19                                             dp2   \n",
       "\n",
       "   51.10: Endoscopic retrograde cholangiopancreatography [ERCP]   \n",
       "0                                                      thousand  \\\n",
       "1                                                       objects   \n",
       "2                                                      patellar   \n",
       "3                                                       believe   \n",
       "4                                                        inches   \n",
       "5                                                        banded   \n",
       "6                                               hemochromatosis   \n",
       "7                                                    rehydrated   \n",
       "8                                                    correlates   \n",
       "9                                                       synergy   \n",
       "10                                                  cogwheeling   \n",
       "11                                                      alanine   \n",
       "12                                                    melenotic   \n",
       "13                                                         86yo   \n",
       "14                                                         ctap   \n",
       "15                                                   duraplasty   \n",
       "16                                                  rhoncherous   \n",
       "17                                                    rofecoxib   \n",
       "18                                                    fermenter   \n",
       "19                                             prochlorperazine   \n",
       "\n",
       "   38.93: Venous catheterization, not elsewhere classified  \n",
       "0                                                    bases  \n",
       "1                                                  synergy  \n",
       "2                                                   ensure  \n",
       "3                                                  objects  \n",
       "4                                                   inches  \n",
       "5                                                fermenter  \n",
       "6                                            leukopheresis  \n",
       "7                                               rehydrated  \n",
       "8                                            desynchronous  \n",
       "9                                                  alanine  \n",
       "10                                            azitrhomycin  \n",
       "11                                         hemochromatosis  \n",
       "12                                                 folgard  \n",
       "13                                        prochlorperazine  \n",
       "14                                           cefalosporins  \n",
       "15                                                  banded  \n",
       "16                                                 believe  \n",
       "17                                               melenotic  \n",
       "18                                           unfortunantly  \n",
       "19                                              aabdominal  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array(xml_vocab[0])[xml_brain[:, lbl_idx].topk(k=20, dim=0).indices.cpu()]\n",
    "pd.DataFrame(array(xml_vocab[0])[toks_idx[xml_brain[:, lbs_idx][toks_idx].argsort(descending=True, dim=0)].cpu()], columns=L(zip(some_lbs, mapt(lbs_des.get, some_lbs))).map(': '.join)).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029a87d-200a-4bbb-b87a-f91528e8f544",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebca74e-f7e8-4970-a62f-d37cbe93b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88M\t/home/deb/.xcube/data/mimic3/mimic3-9k_lm_decoder_r.pth\n",
      "88M\t/home/deb/.xcube/data/mimic3/mimic3-9k_lm_decoder.pth\n"
     ]
    }
   ],
   "source": [
    "!find {source_mimic} -name \"*lm*decoder*.pth\" | xargs du -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62a479-14bc-4c47-a9b2-2bd1c04edc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_decoder_wgts = torch.load(join_path_file('mimic3-9k_lm_decoder', source_mimic, ext='.pth'), map_location=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0255febc-9372-45ca-9489-608d03632688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [torch.Size([57376, 400]),torch.Size([57376])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(lm_decoder_wgts.values()).map(Self.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43bc73-32b7-4bb0-9b0c-7ff55aaa4124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('decoder.weight',\n",
       "              tensor([[-0.0305,  0.0738, -0.0172,  ..., -0.0500, -0.1311,  0.0177],\n",
       "                      [-0.0040,  0.0021, -0.0021,  ..., -0.0055,  0.0038, -0.0010],\n",
       "                      [-0.2785, -0.1316,  0.1003,  ..., -0.1472,  0.1957, -0.1504],\n",
       "                      ...,\n",
       "                      [-0.0097,  0.0057, -0.0115,  ..., -0.0217,  0.0112, -0.0018],\n",
       "                      [-0.0097,  0.0057, -0.0115,  ..., -0.0217,  0.0112, -0.0018],\n",
       "                      [-0.0097,  0.0057, -0.0115,  ..., -0.0217,  0.0112, -0.0018]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.bias',\n",
       "              tensor([ 6.0846, -4.8585,  0.6055,  ..., -3.2417, -3.2417, -3.2417],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_decoder_wgts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c861c18-839f-4423-972c-1632fc3289e6",
   "metadata": {},
   "source": [
    "## Base `Learner` for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e89ee-1737-4069-9627-8a5c6b31db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_collab_keys(\n",
    "    model, # Model architecture\n",
    "    wgts:dict # Model weights\n",
    ") -> tuple:\n",
    "    \"Load only collab `wgts` (`i_weight` and `i_bias`) in `model`, keeping the rest as is\"\n",
    "    sd = model.state_dict()\n",
    "    lbs_weight, i_weight = sd.get('1.attn.lbs_weight.weight', None), wgts.get('i_weight.weight', None)\n",
    "    lbs_bias, i_bias = sd.get('1.attn.lbs_weight.bias', None), wgts.get('i_bias.weight', None) \n",
    "    if lbs_weight is not None and i_weight is not None: lbs_weight.data = i_weight.data\n",
    "    if lbs_bias is not None and i_bias is not None: lbs_bias.data = i_bias.data\n",
    "    if '1.attn.lbs_weight_dp.emb.weight' in sd:\n",
    "        sd['1.attn.lbs_weight_dp.emb.weight'] = i_weight.data.clone()\n",
    "    return model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81941404-34e8-4a65-b369-7fa293b97b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.pay_attn.lbs.weight\n",
      "1.boost_attn.lin.weight\n",
      "1.boost_attn.lin.bias\n"
     ]
    }
   ],
   "source": [
    "config = awd_lstm_clas_config.copy()\n",
    "config.update({'n_hid': 10, 'emb_sz': 5})\n",
    "# tst = get_text_classifier(AWD_LSTM, 100, 3, config=config)\n",
    "tst = get_xmltext_classifier(AWD_LSTM, 100, 3, config=config)\n",
    "old_sd = tst.state_dict().copy()\n",
    "r = re.compile(\".*attn.*\")\n",
    "test_eq([key for key in old_sd if 'attn' in key], list(filter(r.match, old_sd)))\n",
    "print(\"\\n\".join(list(filter(r.match, old_sd))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af00554-0fba-4e8d-b75e-a01e5fec4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53294433-b75e-4d54-a574-6af80e705b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_sd = copy.deepcopy(tst.state_dict())\n",
    "load_collab_keys(tst, new_wgts)\n",
    "# <TODO: Deb> fix the following tests later\n",
    "# test_ne(old_sd['1.attn.lbs_weight.weight'], tst.state_dict()['1.attn.lbs_weight.weight'])\n",
    "# test_eq(tst.state_dict()['1.pay_attn.lbs_weight.weight'], new_wgts['i_weight.weight'])\n",
    "# test_ne(old_sd['1.attn.lbs_weight_dp.emb.weight'], tst.state_dict()['1.attn.lbs_weight_dp.emb.weight'])\n",
    "# test_eq(tst.state_dict()['1.attn.lbs_weight_dp.emb.weight'], new_wgts['i_weight.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e5ac5-9a18-4139-9cf1-030977f84eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcube.layers import *\n",
    "from xcube.layers import _planted_attention, _diffntble_planted_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af50343-383d-4284-b11e-d3016d54e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(Learner.__init__)\n",
    "class TextLearner(Learner):\n",
    "    \"Basic class for a `Learner` in NLP.\"\n",
    "    def __init__(self, \n",
    "        dls:DataLoaders, # Text `DataLoaders`\n",
    "        model, # A standard PyTorch model\n",
    "        alpha:float=2., # Param for `RNNRegularizer`\n",
    "        beta:float=1., # Param for `RNNRegularizer`\n",
    "        moms:tuple=(0.8,0.7,0.8), # Momentum for `Cosine Annealing Scheduler`\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(dls, model, moms=moms, **kwargs)\n",
    "        self.add_cbs(rnn_cbs())\n",
    "\n",
    "    def save_encoder(self, \n",
    "        file:str # Filename for `Encoder` \n",
    "    ):\n",
    "        \"Save the encoder to `file` in the model directory\"\n",
    "        if rank_distrib(): return # don't save if child proc\n",
    "        encoder = get_model(self.model)[0]\n",
    "        if hasattr(encoder, 'module'): encoder = encoder.module\n",
    "        torch.save(encoder.state_dict(), join_path_file(file, self.path/self.model_dir, ext='.pth'))\n",
    "    \n",
    "    @delegates(save_model)\n",
    "    def save(self,\n",
    "        file:str, # Filename for the state_directory of the model\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Save model and optimizer state (if `with_opt`) to `self.path/self.model_dir/file`\n",
    "        Save `self.dls.vocab` to `self.path/self.model_dir/clas_vocab.pkl`\n",
    "        \"\"\"\n",
    "        model_file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n",
    "        vocab_file = join_path_file(file+'_vocab', self.path/self.model_dir, ext='.pkl')\n",
    "        save_model(model_file, self.model, getattr(self, 'opt', None), **kwargs)\n",
    "        save_pickle(vocab_file, self.dls.vocab)\n",
    "        return model_file\n",
    "\n",
    "    def load_encoder(self, \n",
    "        file:str, # Filename of the saved encoder \n",
    "        device:(int,str,torch.device)=None # Device used to load, defaults to `dls` device\n",
    "    ):\n",
    "        \"Load the encoder `file` from the model directory, optionally ensuring it's on `device`\"\n",
    "        encoder = get_model(self.model)[0]\n",
    "        if device is None: device = self.dls.device\n",
    "        if hasattr(encoder, 'module'): encoder = encoder.module\n",
    "        distrib_barrier()\n",
    "        wgts = torch.load(join_path_file(file,self.path/self.model_dir, ext='.pth'), map_location=device)\n",
    "        encoder.load_state_dict(clean_raw_keys(wgts))\n",
    "        self.freeze()\n",
    "        return self\n",
    "\n",
    "    def load_pretrained(self, \n",
    "        wgts_fname:str, # Filename of saved weights \n",
    "        vocab_fname:str, # Saved vocabulary filename in pickle format\n",
    "        model=None # Model to load parameters from, defaults to `Learner.model`\n",
    "    ):\n",
    "        \"Load a pretrained model and adapt it to the data vocabulary.\"\n",
    "        old_vocab = load_pickle(vocab_fname)\n",
    "        new_vocab = _get_text_vocab(self.dls)\n",
    "        distrib_barrier()\n",
    "        wgts = torch.load(wgts_fname, map_location = lambda storage,loc: storage)\n",
    "        if 'model' in wgts: wgts = wgts['model'] #Just in case the pretrained model was saved with an optimizer\n",
    "        wgts = match_embeds(wgts, old_vocab, new_vocab)\n",
    "        load_ignore_keys(self.model if model is None else model, clean_raw_keys(wgts))\n",
    "        self.freeze()\n",
    "        return self\n",
    "\n",
    "    #For previous versions compatibility. Remove at release\n",
    "    @delegates(load_model_text)\n",
    "    def load(self, \n",
    "        file:str, # Filename of saved model \n",
    "        with_opt:bool=None, # Enable to load `Optimizer` state\n",
    "        device:(int,str,torch.device)=None, # Device used to load, defaults to `dls` device\n",
    "        **kwargs\n",
    "    ):\n",
    "        if device is None: device = self.dls.device\n",
    "        if self.opt is None: self.create_opt()\n",
    "        file = join_path_file(file, self.path/self.model_dir, ext='.pth')\n",
    "        load_model_text(file, self.model, self.opt, device=device, **kwargs)\n",
    "        return self\n",
    "    \n",
    "    def load_collab(self,\n",
    "        wgts_fname:str, # Filename of the saved collab model\n",
    "        collab_vocab_fname:str, # Saved Vocabulary of collab labels in pickle format \n",
    "        model=None # Model to load parameters from, defaults to `Learner.model`\n",
    "    ):\n",
    "        \"Load the label embeddings learned by collab model`, and adapt it to the label vocabulary.\"\n",
    "        collab_vocab = load_pickle(collab_vocab_fname)\n",
    "        lbs_vocab = _get_label_vocab(self.dls)\n",
    "        distrib_barrier()\n",
    "        wgts = torch.load(wgts_fname, map_location=lambda storage,loc: storage)\n",
    "        if 'model' in wgts: wgts = wgts['model'] #Just in case the pretrained model was saved with an optimizer\n",
    "        wgts, _ = match_collab(wgts, collab_vocab, lbs_vocab)\n",
    "        load_collab_keys(self.model if model is None else model, wgts)\n",
    "        self.freeze()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c077c1d-1fde-4c45-ae1e-6f6cd3f58b4c",
   "metadata": {},
   "source": [
    "Adds a `ModelResetter` and an `RNNRegularizer` with `alpha` and `beta` to the callbacks, the rest is the same as `Learner` init. \n",
    "\n",
    "This `Learner` adds functionality to the base class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40448b2-664e-43c2-8c78-2f02de9faf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def save_decoder(self:LMLearner,\n",
    "                 file:str # Filename for `Decoder`\n",
    "    ):\n",
    "    \"Save the decoder to `file` in the model directory\"\n",
    "    if rank_distrib(): return # don't save if child proc\n",
    "    decoder = get_model(self.model)[1]\n",
    "    if hasattr(decoder, 'module'): decoder = decoder.module\n",
    "    torch.save(decoder.state_dict(), join_path_file(file, self.path/self.model_dir, ext='.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca03ad-94e9-44d6-8943-980c11b75408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def load_brain(self:TextLearner,\n",
    "               file_wgts: str, # Filename of the saved attention wgts\n",
    "               file_bias: str, # Filename of the saved label bias\n",
    "               device:(int,str,torch.device)=None # Device used to load, defaults to `default_device()`\n",
    "              ):\n",
    "    \"\"\"Load the pre-learnt label specific attention weights for each token from `file` located in the model directory, \n",
    "    optionally ensuring it's one `device`\n",
    "    \"\"\"\n",
    "    brain_path = join_path_file(file_wgts, self.path/self.model_dir, ext='.pkl')\n",
    "    bias_path = join_path_file(file_bias, self.path/self.model_dir, ext='.pkl')\n",
    "    brain_bootstrap = torch.load(brain_path, map_location=default_device() if device is None else device)\n",
    "    *brain_vocab, brain = mapt(brain_bootstrap.get, ['toks', 'lbs', 'mutual_info_jaccard'])\n",
    "    brain_vocab = L(brain_vocab).map(listify)\n",
    "    vocab = L(_get_text_vocab(self.dls), _get_label_vocab(self.dls)).map(listify)\n",
    "    brain_bias = torch.load(bias_path, map_location=default_device() if device is None else device)\n",
    "    brain_bias = brain_bias[:, :, 0].squeeze(-1)\n",
    "    print(\"Performing brainsplant...\")\n",
    "    self.brain, self.lbsbias, *_ = brainsplant(vocab, brain_vocab, brain, brain_bias)\n",
    "    print(\"Successfull!\")\n",
    "    # import pdb; pdb.set_trace()\n",
    "    plant_attn_layer = Lambda(Planted_Attention(self.brain))\n",
    "    setattr(self.model[1].pay_attn, 'attn', plant_attn_layer)\n",
    "    assert self.model[1].pay_attn.attn.func.f is _planted_attention\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14945a94-6d19-4ca8-87d1-2219827c7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def load_diffntble_brain(self:TextLearner,\n",
    "                         file_brain:str, # Filename of the bootstrap info for l2r\n",
    "                         file_l2r_wgts:str, # Filename of the pretrained l2r wgts\n",
    "                         file_lm_decoder_wgts:str, # Filename of the pretrained LM decoder wgts\n",
    "                         device:(int,str,torch.device)=None # # Device used to load, defaults to `default_device()`\n",
    "                        ):\n",
    "    \"\"\"Loads the pre-learnt L2R and LM decoder wgts from `file_l2r_wgts` and ` file_lm_decoder_wgts` located in the\n",
    "    model directory, optionally ensuring it's on `device`\n",
    "    \"\"\"\n",
    "    brain_bootstrap = torch.load(join_path_file(file_brain, self.path/self.model_dir, ext='.pkl'), map_location=default_device() if device is None else device)\n",
    "    brain_vocab = mapt(brain_bootstrap.get, ['toks', 'lbs'])\n",
    "    brain_vocab = L(brain_vocab).map(listify)\n",
    "    vocab = L(_get_text_vocab(self.dls), _get_label_vocab(self.dls)).map(listify)\n",
    "    l2r_wgts = torch.load(join_path_file(file_l2r_wgts, self.path/self.model_dir, ext='.pth'), map_location=default_device() if device is None else device)\n",
    "    if 'model' in l2r_wgts: l2r_wgts = l2r_wgts['model']\n",
    "    print(\"Performing 'differentiable' brainsplant...\")\n",
    "    l2r, toks_map, lbs_map = brainsplant_diffntble(vocab, brain_vocab, l2r_wgts)\n",
    "    print(\"Successfull!\")\n",
    "    lm_decoder_pretrained_wgts = torch.load(join_path_file(file_lm_decoder_wgts, self.path/self.model_dir, ext='.pth'), map_location=default_device() if device is None else device)\n",
    "    config = awd_lstm_lm_config.copy()\n",
    "    emb_sz, output_p, out_bias = map(config.get, ['emb_sz', 'output_p', 'out_bias'])\n",
    "    lm_decoder = PlantedLMDecoder(len(vocab[0]), emb_sz, output_p=output_p*0.3, plant_wgts=lm_decoder_pretrained_wgts, bias=out_bias).to(default_device() if device is None else device)\n",
    "    test_eq(lm_decoder.decoder.weight, lm_decoder_pretrained_wgts['decoder.weight'])\n",
    "    test_eq(lm_decoder.decoder.bias, lm_decoder_pretrained_wgts['decoder.bias'])\n",
    "    plant_attn_layer = Lambda(Diffntble_Planted_Attention(l2r))\n",
    "    setattr(self.model[1].pay_attn, 'attn', plant_attn_layer)\n",
    "    assert self.model[1].pay_attn.attn.func.f is _diffntble_planted_attention\n",
    "    setattr(self.model[1].pay_attn, 'lm_decoder', lm_decoder)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8fcc78-a86c-4a6a-98ad-5fc0160242e6",
   "metadata": {},
   "source": [
    "TODO: Freeze the l2r and lm_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9001ab92-67ce-4357-b447-0b85c0cbd384",
   "metadata": {},
   "source": [
    "## `Learner` convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a39c937-70c1-438b-84d9-34d7ef4a8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from xcube.text.models.core import _model_meta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38916689-ddc4-498f-881d-36ddebd9e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@delegates(Learner.__init__)\n",
    "def xmltext_classifier_learner(dls, arch, seq_len=72, config=None, backwards=False, pretrained=True, collab=False, drop_mult=0.5, n_out=None,\n",
    "                           lin_ftrs=None, ps=None, max_len=72*20, y_range=None, splitter=None, running_decoder=True, **kwargs):\n",
    "    \"Create a `Learner` with a text classifier from `dls` and `arch`.\"\n",
    "    vocab = _get_text_vocab(dls)\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from the data, set `dls.c` or pass `n_out`\"\n",
    "    model = get_xmltext_classifier2(arch, len(vocab), n_out, seq_len=seq_len, config=config, y_range=y_range,\n",
    "                                drop_mult=drop_mult, max_len=max_len, running_decoder=running_decoder)\n",
    "    # model = get_xmltext_classifier(arch, len(vocab), n_out, seq_len=seq_len, config=config, y_range=y_range,\n",
    "                                # drop_mult=drop_mult, max_len=max_len)\n",
    "    meta = _model_meta[arch]\n",
    "    learn = TextLearner(dls, model, splitter=splitter if splitter is not None else meta['split_clas'], **kwargs)\n",
    "    url = 'url_bwd' if backwards else 'url'\n",
    "    if pretrained:\n",
    "        if url not in meta:\n",
    "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
    "            return learn\n",
    "        model_path = untar_data(meta[url], c_key='model')\n",
    "        try: fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        except IndexError: print(f'The model in {model_path} is incomplete, download again'); raise\n",
    "        learn = learn.load_pretrained(*fnames, model=learn.model[0])\n",
    "    if collab:\n",
    "        try: fnames = [list(learn.path.glob(f'**/collab/*collab*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        except IndexError: print(f'The collab model in {learn.path} is incomplete, re-train it!'); raise\n",
    "        learn = learn.load_colab(*fnames, model=learn.model[1])\n",
    "    learn.freeze()\n",
    "    return learn   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e66275-882c-4fce-b021-a0e3cc0c5b69",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f6c93-6031-40fb-8bc9-e32a9c519643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepk",
   "language": "python",
   "name": "deepk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
