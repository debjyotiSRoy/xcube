{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488bfb2-194f-4ee5-bc10-e174a54421a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq xcube # upgrade xcube on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b20a4-5a7c-4fd5-814f-cb64921b4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import *\n",
    "from xcube.l2r.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce8aea4-abfa-4ab7-a98b-fbe0d7a38b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55be356e-7dc8-46fa-afa6-88268f035a91",
   "metadata": {},
   "source": [
    "# Boot L2R \n",
    "\n",
    "> Bootstrapping a learning-to-rank model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed5e8d7-7262-49aa-8a85-c61eac2db1b8",
   "metadata": {},
   "source": [
    "In this tutorial we will find a needle in the haystack with mutual infomation gain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de5907-9dbb-45a9-938a-c9f0935ae74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = make_paths(Path.cwd(), 'mimic3-9k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec6de06-8a50-47b7-8ca6-9a41e7b6d1b0",
   "metadata": {},
   "source": [
    "#### Mutual-Information Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ae32d-3022-4191-a412-9c95d6be0c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/deb/.xcube/data/mimic3_l2r/mimic3-9k.csv')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = untar_xxx(XURLs.MIMIC3_L2R)\n",
    "data = source/'mimic3-9k.csv'\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076b02e-71fc-4447-bec8-63355d640cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52726"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data,\n",
    "                 header=0,\n",
    "                 names=['subject_id', 'hadm_id', 'text', 'labels', 'length', 'is_valid'],\n",
    "                 dtype={'subject_id': str, 'hadm_id': str, 'text': str, 'labels': str, 'length': np.int64, 'is_valid': bool})\n",
    "df[['text', 'labels']] = df[['text', 'labels']].astype(str)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab32fe4-f8a8-4bf5-902e-129445c72fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>length</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86006</td>\n",
       "      <td>111912</td>\n",
       "      <td>admission date discharge date date of birth sex f service surgery allergies patient recorded as having no known allergies to drugs attending first name3 lf chief complaint 60f on coumadin was found slightly drowsy tonight then fell down stairs paramedic found her unconscious and she was intubated w o any medication head ct shows multiple iph transferred to hospital1 for further eval major surgical or invasive procedure none past medical history her medical history is significant for hypertension osteoarthritis involving bilateral knee joints with a dependence on cane for ambulation chronic...</td>\n",
       "      <td>801.35;348.4;805.06;807.01;998.30;707.24;E880.9;427.31;414.01;401.9;V58.61;V43.64;707.00;E878.1;96.71</td>\n",
       "      <td>230</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85950</td>\n",
       "      <td>189769</td>\n",
       "      <td>admission date discharge date service neurosurgery allergies sulfa sulfonamides attending first name3 lf chief complaint cc cc contact info major surgical or invasive procedure none history of present illness hpi 88m who lives with family had fall yesterday today had decline in mental status ems called pt was unresponsive on arrival went to osh head ct showed large r sdh pt was intubated at osh and transferred to hospital1 for further care past medical history cad s p mi in s p cabg in ventricular aneurysm at that time cath in with occluded rca unable to intervene chf reported ef 1st degre...</td>\n",
       "      <td>852.25;E888.9;403.90;585.9;250.00;414.00;V45.81;96.71</td>\n",
       "      <td>304</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88025</td>\n",
       "      <td>180431</td>\n",
       "      <td>admission date discharge date date of birth sex f service surgery allergies no known allergies adverse drug reactions attending first name3 lf chief complaint s p fall major surgical or invasive procedure none history of present illness 45f etoh s p fall from window at feet found ambulating and slurring speech on scene intubated en route for declining mental status in the er the patient was found to be bradycardic to the s with bp of systolic she was given atropine dilantin and was started on saline past medical history unknown social history unknown family history unknown physical exam ex...</td>\n",
       "      <td>518.81;348.4;348.82;801.25;427.89;E882;V49.86;305.00;96.71;38.93</td>\n",
       "      <td>359</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id hadm_id  \\\n",
       "0      86006  111912   \n",
       "1      85950  189769   \n",
       "2      88025  180431   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  admission date discharge date date of birth sex f service surgery allergies patient recorded as having no known allergies to drugs attending first name3 lf chief complaint 60f on coumadin was found slightly drowsy tonight then fell down stairs paramedic found her unconscious and she was intubated w o any medication head ct shows multiple iph transferred to hospital1 for further eval major surgical or invasive procedure none past medical history her medical history is significant for hypertension osteoarthritis involving bilateral knee joints with a dependence on cane for ambulation chronic...   \n",
       "1  admission date discharge date service neurosurgery allergies sulfa sulfonamides attending first name3 lf chief complaint cc cc contact info major surgical or invasive procedure none history of present illness hpi 88m who lives with family had fall yesterday today had decline in mental status ems called pt was unresponsive on arrival went to osh head ct showed large r sdh pt was intubated at osh and transferred to hospital1 for further care past medical history cad s p mi in s p cabg in ventricular aneurysm at that time cath in with occluded rca unable to intervene chf reported ef 1st degre...   \n",
       "2  admission date discharge date date of birth sex f service surgery allergies no known allergies adverse drug reactions attending first name3 lf chief complaint s p fall major surgical or invasive procedure none history of present illness 45f etoh s p fall from window at feet found ambulating and slurring speech on scene intubated en route for declining mental status in the er the patient was found to be bradycardic to the s with bp of systolic she was given atropine dilantin and was started on saline past medical history unknown social history unknown family history unknown physical exam ex...   \n",
       "\n",
       "                                                                                                  labels  \\\n",
       "0  801.35;348.4;805.06;807.01;998.30;707.24;E880.9;427.31;414.01;401.9;V58.61;V43.64;707.00;E878.1;96.71   \n",
       "1                                                  852.25;E888.9;403.90;585.9;250.00;414.00;V45.81;96.71   \n",
       "2                                       518.81;348.4;348.82;801.25;427.89;E882;V49.86;305.00;96.71;38.93   \n",
       "\n",
       "   length  is_valid  \n",
       "0     230     False  \n",
       "1     304     False  \n",
       "2     359     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc7e09-64c8-4153-ac28-11aa668b78ab",
   "metadata": {},
   "source": [
    "**Run the cell below only if you want to sample from the full dataset to create a tiny dataset for the purpose of quick iterations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95adc89c-6ec8-4155-8252-899edb598d4b",
   "metadata": {},
   "source": [
    "*Technical Point:* If we want to sample to perform quick iterations, we need to make sure the number of data points in the sample is a multiple of `bs`. So that we do not have to do a `drop_last=True` while creating the `Dataloaders`. This is because we are about to do some probability computations, and dropping data points is not a good idea as probabilities would not sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5544cdf-0934-4604-930d-e95822f323ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52720"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut = len(df) - len(df)%8\n",
    "df = df[:cut]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfac811-91d6-425b-bf49-5a0ffedabc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4376"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 8\n",
    "_arr = np.arange(0, len(df), bs)\n",
    "mask = (_arr > 4000) & (_arr < 5000)\n",
    "_n = np.random.choice(_arr[mask], 1)\n",
    "df = df.sample(n=_n, random_state=89, ignore_index=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0470a3bc-b554-4961-83e5-a0e106b6d1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>length</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2258</td>\n",
       "      <td>139169</td>\n",
       "      <td>admission date discharge date date of birth sex m service cardiothoracic surgery history of present illness the patient is a year old male with a past medical history significant for poorly controlled diabetes mellitus and hypertension as well as known coronary disease and a previous non q myocardial infarction and right coronary artery stenting in he was admitted to an outside hospital on the day prior to admission with unstable angina and found to have borderline positive troponin hypertension and st depressions in the lateral lead he was given aspirin nitrates beta blockers morphine and...</td>\n",
       "      <td>414.01;998.31;411.1;599.0;412;V45.82;250.00;401.9;530.81;36.13;37.22;36.15;36.19;39.61;39.64;88.56;88.53;33.23;96.56;33.24;78.41</td>\n",
       "      <td>1271</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41217</td>\n",
       "      <td>161582</td>\n",
       "      <td>admission date discharge date date of birth sex m service medicine allergies no known allergies adverse drug reactions attending first name3 lf chief complaint new diagnosis of scc of base of tongue major surgical or invasive procedure egd w biopsy history of present illness yo man with h o cad heavy smoking and new diagnosis of scc of base of tongue with lymph node involvement pt was referred to dr last name stitle ent in for a rt neck mass at that time a cm rt cervical lymph node was palpated and fiberoptic laryngoscopy showed a cm rt base of tongue mass a ct and biopsy were recommended ...</td>\n",
       "      <td>141.0;507.0;196.0;293.0;519.09;786.30;286.9;427.89;790.29;276.52;414.01;338.3;280.0;272.0;412;V69.4;V15.82;V45.82;V66.7;E879.8;E932.0;31.42;25.01;42.23;43.11;96.6;38.93;99.25;38.93</td>\n",
       "      <td>2743</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30204</td>\n",
       "      <td>172114</td>\n",
       "      <td>admission date discharge date date of birth sex f service medicine allergies etomidate norpace quinidine demerol penicillins lipitor attending doctor first name chief complaint cardiac tamponade s p pulmonary vein isolation major surgical or invasive procedure attempted pulmonary vein isolation pericardiocentesis history of present illness year old woman with a long history of paroxysmal atrial fibrillation refractory to mulitple pharmacologic interventions and multiple cardioversions who presents to the ccu with cardiac tamponade s p pulmonary vein isolation procedure past medical history...</td>\n",
       "      <td>427.31;998.2;423.3;423.9;573.0;276.6;E878.8;37.34;37.27;37.0;37.21</td>\n",
       "      <td>1764</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id hadm_id  \\\n",
       "0       2258  139169   \n",
       "1      41217  161582   \n",
       "2      30204  172114   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  admission date discharge date date of birth sex m service cardiothoracic surgery history of present illness the patient is a year old male with a past medical history significant for poorly controlled diabetes mellitus and hypertension as well as known coronary disease and a previous non q myocardial infarction and right coronary artery stenting in he was admitted to an outside hospital on the day prior to admission with unstable angina and found to have borderline positive troponin hypertension and st depressions in the lateral lead he was given aspirin nitrates beta blockers morphine and...   \n",
       "1  admission date discharge date date of birth sex m service medicine allergies no known allergies adverse drug reactions attending first name3 lf chief complaint new diagnosis of scc of base of tongue major surgical or invasive procedure egd w biopsy history of present illness yo man with h o cad heavy smoking and new diagnosis of scc of base of tongue with lymph node involvement pt was referred to dr last name stitle ent in for a rt neck mass at that time a cm rt cervical lymph node was palpated and fiberoptic laryngoscopy showed a cm rt base of tongue mass a ct and biopsy were recommended ...   \n",
       "2  admission date discharge date date of birth sex f service medicine allergies etomidate norpace quinidine demerol penicillins lipitor attending doctor first name chief complaint cardiac tamponade s p pulmonary vein isolation major surgical or invasive procedure attempted pulmonary vein isolation pericardiocentesis history of present illness year old woman with a long history of paroxysmal atrial fibrillation refractory to mulitple pharmacologic interventions and multiple cardioversions who presents to the ccu with cardiac tamponade s p pulmonary vein isolation procedure past medical history...   \n",
       "\n",
       "                                                                                                                                                                                 labels  \\\n",
       "0                                                      414.01;998.31;411.1;599.0;412;V45.82;250.00;401.9;530.81;36.13;37.22;36.15;36.19;39.61;39.64;88.56;88.53;33.23;96.56;33.24;78.41   \n",
       "1  141.0;507.0;196.0;293.0;519.09;786.30;286.9;427.89;790.29;276.52;414.01;338.3;280.0;272.0;412;V69.4;V15.82;V45.82;V66.7;E879.8;E932.0;31.42;25.01;42.23;43.11;96.6;38.93;99.25;38.93   \n",
       "2                                                                                                                    427.31;998.2;423.3;423.9;573.0;276.6;E878.8;37.34;37.27;37.0;37.21   \n",
       "\n",
       "   length  is_valid  \n",
       "0    1271     False  \n",
       "1    2743     False  \n",
       "2    1764     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b73953-378e-475b-abba-d4d15c10fb26",
   "metadata": {},
   "source": [
    "**[Mutual Information](https://en.wikipedia.org/wiki/Mutual_information#)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8735be8-9113-4607-84fb-7af1df07e7f1",
   "metadata": {},
   "source": [
    "<img alt=\"Pictorial representation of simple neural network\" width=\"400\" src=\"info-gain.svg\" caption=\"Pictorial representation of a simple neural network\" id=\"img_simple_nn\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6311846-96bc-4809-99a5-8f538bb648a1",
   "metadata": {},
   "source": [
    "The mutual information of two jointly discrete random variables X and  Y is calculated as a double sum:\n",
    "\n",
    "$$I(T;L) = \\sum_{l \\in \\mathcal{L}} \\sum_{t in \\mathcal{T}} P_{(T,L)}(t,l) \\log \\Bigg(\\frac{P_{(T,L)}(t,l)}{P_T(t) P_L(l)} \\Bigg)$$\n",
    "\n",
    "where $P_{(T,L)}$ is the [joint probability mass function](https://en.wikipedia.org/wiki/Joint_distribution) of $T$ and $L$, and $P_T$ and $P_L$ are the [marginal probability mass fucntions](https://en.wikipedia.org/wiki/Marginal_probability) of $T$ and $L$ respectively. To compute $I$, the only quantity we need to compute is the joint pmf $P_{(T,L)}$, as the marginal pmfs can be computed from the joint pmf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570b5995-6a9a-47ab-91f6-978eb9b703be",
   "metadata": {},
   "source": [
    "With regard to implementation, $P_{(T,L)}$ can be thought of as a 2x2 tensor as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f4bae-f49f-48b4-a73c-a4b4d02f5b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>not t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lbl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not lbl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         t  not t\n",
       "lbl      0      0\n",
       "not lbl  0      0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_TL = pd.DataFrame(0, columns=['t', 'not t'], index=['lbl', 'not lbl'])\n",
    "p_TL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe632b57-9870-4925-b0d2-919f9696995a",
   "metadata": {},
   "source": [
    "...and we need to compute this $P_{(T,L)}$ for every token-label pair. In other words, we need to fill in the `joint_pmf` dataframe shown below. Note that each cell in `joint_pmf` dataframe can be thought of to be further subdivided into a 2x2 grid containing the corresponding `p_TL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca365815-b93f-45bd-a6b8-eff4be0cee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot = Booting(df, bs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13a481-3023-491b-8dc4-8eeddb9226c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ecd54-bf7a-48a6-9d76-132f9b5fd985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.33 s, sys: 455 ms, total: 2.79 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "boot.onehotify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359e690-7ebd-4777-bc1c-7b6eed8f8ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#20744) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the'...],\n",
       " (#4397) ['005.81','008.45','008.5','008.69','008.8','009.0','009.1','011.90','027.2','031.0'...],\n",
       " 91211368)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks, lbs = boot.dsets.vocab\n",
    "L(toks), L(lbs), len(toks)*len(lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7892c-6b09-459c-8185-bdb2d03a79ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>lbs (L)</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4387</th>\n",
       "      <th>4388</th>\n",
       "      <th>4389</th>\n",
       "      <th>4390</th>\n",
       "      <th>4391</th>\n",
       "      <th>4392</th>\n",
       "      <th>4393</th>\n",
       "      <th>4394</th>\n",
       "      <th>4395</th>\n",
       "      <th>4396</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toks (T)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20739</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20740</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20741</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20742</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20743</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20744 rows × 4397 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "lbs (L)   0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "toks (T)                                                              ...   \n",
       "0            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "1            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "2            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "3            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "4            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "20739        0     0     0     0     0     0     0     0     0     0  ...   \n",
       "20740        0     0     0     0     0     0     0     0     0     0  ...   \n",
       "20741        0     0     0     0     0     0     0     0     0     0  ...   \n",
       "20742        0     0     0     0     0     0     0     0     0     0  ...   \n",
       "20743        0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "lbs (L)   4387  4388  4389  4390  4391  4392  4393  4394  4395  4396  \n",
       "toks (T)                                                              \n",
       "0            0     0     0     0     0     0     0     0     0     0  \n",
       "1            0     0     0     0     0     0     0     0     0     0  \n",
       "2            0     0     0     0     0     0     0     0     0     0  \n",
       "3            0     0     0     0     0     0     0     0     0     0  \n",
       "4            0     0     0     0     0     0     0     0     0     0  \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "20739        0     0     0     0     0     0     0     0     0     0  \n",
       "20740        0     0     0     0     0     0     0     0     0     0  \n",
       "20741        0     0     0     0     0     0     0     0     0     0  \n",
       "20742        0     0     0     0     0     0     0     0     0     0  \n",
       "20743        0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[20744 rows x 4397 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint = pd.DataFrame(0, columns=range(len(lbs)), index=range(len(toks)))\n",
    "joint.index.name = 'toks (T)'\n",
    "joint.columns.name = 'lbs (L)'\n",
    "joint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fcca13-1c3a-405d-bbed-2da74776ccb3",
   "metadata": {},
   "source": [
    "We can perform tensorized computation if we think of `p_TL` as a 4 dim tensor of size `(len(toks), len(lbs), 2, 2)`. Next, to be able to estimate `p_TL` we just need to iterate over the dataset and for each data point and each token-label pair record the `p_TL` information in the last two dimension of the tensor `p_TL`. And, at the end divide by size of the dataset. \n",
    "\n",
    "Some more implementation details (Skip this if not iterested): \n",
    "\n",
    "- We are going to one-hot encode the dataset (both `text` and `labels` field in the `df`). This is done by `onehot_dsets` \n",
    "- For efficieny, in reality we are not going to iterate over the dataset one by one, instead we are going to use a dataloader and perform `p_TL` computation on a mini-batch.\n",
    "- Unless you are doing this in 2035 you probably do not have enogh GPU-RAM to fit the entire `p_TL` tensor of dimension `(len(toks), len(lbs), 2, 2)`. So we are going to split the lbs dimension into chunks. (Why the `lbs` dimension and not the `toks`? Because in XML datsets `toks` are approximately 60000, but the number of `lbs` could be really large of the order of millions.) With reagrd to implementation this would mean that instead of one dataloader we would roll with multiple dataloaders. And each dataloader would load the dataset in a way that mini-batches would contain the full one-hot encoding of the `text` field but only a certain `chunk` of the one-hot encoded `labels` field in `df`. Another way to think about this is that each datapoint, specifically the `labels` are splitted across multiple dataloaders. This way once we are done iterating over one such dataloader we would have filled a ceratin chunk of the `joint` dataframe shown above. And we would fill the entire `joint` only once we are done iterating over all the dataloaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc0923-4b3b-4e13-9796-010c03a163fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x, y \u001b[38;5;241m=\u001b[39m boot\u001b[38;5;241m.\u001b[39mdsets[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m test_eq(tensor(\u001b[43mdsets\u001b[49m\u001b[38;5;241m.\u001b[39mtfms[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(y)), torch\u001b[38;5;241m.\u001b[39mwhere(y\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      3\u001b[0m test_eq(tensor(dsets\u001b[38;5;241m.\u001b[39mtfms[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(x)), torch\u001b[38;5;241m.\u001b[39mwhere(x\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dsets' is not defined"
     ]
    }
   ],
   "source": [
    "x, y = boot.dsets[0]\n",
    "test_eq(tensor(dsets.tfms[1][2].decode(y)), torch.where(y==1)[0])\n",
    "test_eq(tensor(dsets.tfms[0][-1].decode(x)), torch.where(x==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9f50d-32c1-400c-bbfc-268f9246cc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxunk xxbos the and to of was with a on in for mg no patient is he blood at name or discharge as day one his left last history were right by had this admission pain date pt hospital normal an that from p first has have which medications but up chest d hours o well time status also dr given please course care stable after follow started stitle known disease x continued two days service m per showed prior artery medical q aortic past post glucose namepattern1 it heart cardiac present pulmonary weeks without md unit physical i edema year transferred allergies pressure due condition t number surgical b procedure surgery did admitted lower prn remained further hypertension soft fluid non diagnosis rate all bilaterally coronary should over found increased placed birth sodium three old illness aspirin social abdomen secondary take sex however than following bilateral floor primary namepattern4 positive disposition some lung insulin examination room back moderate regular discharged f upper use significant rhythm extremities count lasix lungs sinus continue alert bleeding facility heparin job therapy intubated underwent off contrast felt hematocrit sounds nausea transfer down diabetes four anterior distress diet creatinine wound made pulses removed alcohol male postoperative extended followed hospital3 white do oriented morning very s1 note both name11 drainage oral carotid office control intensive catheterization previous sent greater through drip bypass albuterol pattern1 extremity stent worsening currently warm weaned extubated incision lesion tolerated site dictated strength controlled st physician issues increase next afebrile night medquist36 levofloxacin difficulty amiodarone descending patch plavix dyspnea infarction repair lesions venous lateral operative peripheral increasing beta minimal laboratory cardiology inferior hospital6 perfused operating though morphine incisions later murmurs went masses denied persistent outside mellitus diuresis drain go lopressor nontender bun occasional began colace myocardial smoking wheezing evening help lipitor knee ap cardiologist wave rubs meds cardiothoracic bruits instructed sternal intermittent commands nondistended puffs system despite ambulating troponin came main intra dependent meq pump tubes nitroglycerin obese secretions lovenox dilaudid aggressive exertion bronchoscopy decision platelet heavy minute referred pacing palpable ibuprofen balloon jugular stabilized stenting follows many frequency put leads paroxysmal diabetic seven electrocardiogram borderline wires propofol diameter distention grafting orthopnea attempt begun half index reflux treat ten neo waves angina lead urinalysis depressions diffusely codeine quite little dominant circumflex hepatosplenomegaly ready gastroesophageal poorly coarse occurred mobility hemodynamic afternoon extremely observation transdermal wire zantac refer encouraged activities moved 1l includes synephrine standpoint nicotine coughing unstable nocturnal pole incentive sternum toilet uneventful drips enteric allergic blockers weaning coated complain inhalers stability burning kcl dye dobutamine pericarditis nexium packs spirometry inversions cks serosanguinous participate urination restenosis exercises spent lyme noninsulin isordil rhonchorous nitrates disabled uncooperative amaryl refusal build marginally integrelin concurrently instant tightening k4 reclosure'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(L(toks)[torch.where(x==1)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d476b-0890-4549-93eb-b6ccf0af4958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#21) ['250.00','33.23','33.24','36.13','36.15','36.19','37.22','39.61','39.64','401.9'...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbs.map_ids(torch.where(y==1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814cff6-5281-47ef-bc44-0f908dff12de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#4503) [0,1,2,3,5,6,9,10,11,12...],\n",
       " (#337) [4,7,8,51,64,74,120,125,132,141...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = ColSplitter()(df)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b7f2c-da57-4d95-924d-fcd0c94c0355",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_vocab = torch.load(dls_lm_vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d822636-519d-40ac-aee7-7ef8edade513",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def Cleanser(toks): return [o for o in toks if o in lm_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e8481-7ce5-44af-8427-21bc4549b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNumericalize(Transform):\n",
    "    \"Transform to remove tokens not present in `vocab`\"\n",
    "    def __init__(self, vocab=None, min_freq=3, max_vocab=60000, special_toks=None):\n",
    "        store_attr('vocab,min_freq,max_vocab,special_toks')\n",
    "        self.o2i = None if vocab is None else defaultdict(int, {v: i for i,v in enumerate(vocab)})\n",
    "    \n",
    "    def setups(self, dsets):\n",
    "        if dsets is None: return\n",
    "        if self.vocab is None:\n",
    "            count = dsets.counter if getattr(dsets, 'counter', None) is not None else Counter(p for o in dsets for p in o)\n",
    "            if self.special_toks is None and hasattr(dsets, 'special_toks'):\n",
    "                self.special_toks = dsets.special_toks\n",
    "            self.vocab = make_vocab(count, min_freq=self.min_freq, max_vocab=self.max_vocab, special_toks=self.special_toks)\n",
    "            self.o2i = defaultdict(int, {v:i for i,v in enumerate(self.vocab) if v != 'xxfake'})\n",
    "    \n",
    "    def encodes(self, o): return TensorText(tensor([self.o2i[o_] for o_ in o if o_ in self.vocab]))\n",
    "    def decodes(self, o): return L(self.vocab[o_] for o_ in o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461b924-c5ad-4578-aba7-560fe24c751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resort to this if anythiong goes wrong below\n",
    "x_tfms = [Tokenizer.from_df('text', n_workers=num_cpus()), attrgetter(\"text\"), Cleanser, MultiCategorize(vocab=lm_vocab), OneHotEncode()]\n",
    "y_tfms = [ColReader('labels', label_delim=';'), MultiCategorize(), OneHotEncode()]\n",
    "tfms = [x_tfms, y_tfms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e9ed4-7fe7-412c-a032-000a997817d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunkifize(Transform):\n",
    "    order = 4\n",
    "    def __init__(self, num_chunks=3): store_attr('num_chunks')\n",
    "    def encodes(self, o): \n",
    "        return list(torch.chunk(o, self.num_chunks))\n",
    "    def decodes(self, o): \n",
    "        return torch.cat(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06529945-b17f-4e5f-a937-2f9edb826afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chnk_tfm = Chunkifize()\n",
    "chnks = chnk_tfm(torch.arange(10))\n",
    "test_eq(type(chnks), list)\n",
    "test_eq(chnks, [tensor([0, 1, 2, 3]), tensor([4, 5, 6, 7]), tensor([8, 9])])\n",
    "# test_fail(lambda: chnk_tfm.decode(chnks), tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "test_eq(chnk_tfm.decode(chnks), tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da9195-6129-4436-af9a-6a4753fde730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_tfms = [ColReader('labels', label_delim=';'), MultiCategorize(), OneHotEncode(), Chunkifize()]\n",
    "# tfmd_y = TfmdLists(df, tfms=y_tfms)\n",
    "# tfmd_y.decode(tfmd_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25630387-15fc-418f-8df2-2cb2f8b2612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dsets, 'dsets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0151a0-c200-4513-bc14-914bc14b469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = torch.load('dsets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824531b-e1eb-4236-92a6-379512ede829",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, chnk_sz = 8, 200\n",
    "dls = lbs_chunked(dsets, bs=bs, chnk_sz=chnk_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d435b-3ecf-4fbd-89dd-17a4c7f108b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(dls[0], TfmdDL)\n",
    "test_eq(len(dls),  np.ceil(len(lbs)/200))\n",
    "test_eq(len(dls[0]), np.ceil(len(dsets)/bs)) # drop_last is False\n",
    "# test to prove that the labels for each data point is split across multiple dataloaders\n",
    "lbs_0 = torch.cat([yb[0] for dl in dls for _,yb in itertools.islice(dl, 1)])\n",
    "y = y.to(default_device())\n",
    "test_eq(lbs_0, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a2e238-6e73-46e9-9175-491d57849182",
   "metadata": {},
   "source": [
    "Now let's compute the `joint_pmf` table we had seen earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447016a-eec2-46cb-9435-adba632be506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/23 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'dsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/xcube/xcube/l2r/data/boot.py:69\u001b[0m, in \u001b[0;36mjoint_pmf\u001b[0;34m(dls)\u001b[0m\n\u001b[1;32m     67\u001b[0m p_TL_full \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dl \u001b[38;5;129;01min\u001b[39;00m progress_bar(dls):\n\u001b[0;32m---> 69\u001b[0m     p_TL \u001b[38;5;241m=\u001b[39m \u001b[43mmutual_info_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     p_TL_full\u001b[38;5;241m.\u001b[39mappend(p_TL)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m p_TL; \u001b[38;5;28;01mdel\u001b[39;00m p_T; \u001b[38;5;28;01mdel\u001b[39;00m p_L; \u001b[38;5;28;01mdel\u001b[39;00m p_TxL; \u001b[38;5;28;01mdel\u001b[39;00m I_TL; torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/xcube/xcube/l2r/data/boot.py:61\u001b[0m, in \u001b[0;36mmutual_info_gain\u001b[0;34m(dl)\u001b[0m\n\u001b[1;32m     59\u001b[0m     p_TL_ff \u001b[38;5;241m=\u001b[39m tl[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlogical_not()\u001b[38;5;241m.\u001b[39mlogical_and(tl[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlogical_not()) ; test_eq(p_TL_ff\u001b[38;5;241m.\u001b[39mshape, (dl\u001b[38;5;241m.\u001b[39mbs, toksize, lblsize)) \n\u001b[1;32m     60\u001b[0m     p_TL \u001b[38;5;241m=\u001b[39m p_TL \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack((p_TL_tt, p_TL_tf, p_TL_ft, p_TL_ff), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m p_TL \u001b[38;5;241m=\u001b[39m p_TL \u001b[38;5;241m/\u001b[39m tensor(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdsets\u001b[49m))\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     62\u001b[0m p_TL \u001b[38;5;241m=\u001b[39m p_TL\u001b[38;5;241m.\u001b[39mview(toksize, lblsize, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m) ; test_eq(p_TL\u001b[38;5;241m.\u001b[39mshape, (toksize, lblsize, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\u001b[38;5;66;03m# last axis: lbl axis, 2nd last axis: token axis\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p_TL\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dsets' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_TL = joint_pmf(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf34053-8deb-4f7d-91d6-644f1a0dee4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f598f952-736d-479e-8f52-ed1798a7a66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='45' class='' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [45/45 3:13:47<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 10min 23s, sys: 3min 22s, total: 3h 13min 46s\n",
      "Wall time: 3h 13min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_TL_full = [] \n",
    "for dl in progress_bar(dls):\n",
    "    p_TL = mutual_info_gain(dl)\n",
    "    p_TL_full.append(p_TL)\n",
    "    del p_TL; del p_T; del p_L; del p_TxL; del I_TL; torch.cuda.empty_cache()\n",
    "p_TL_full = torch.cat(p_TL_full, dim=1); test_eq(p_TL_full.shape, (len(toks), len(lbs), 2, 2))\n",
    "# torch.save(p_TL_full, 'p_TL.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206750a-b41f-4f70-a5ad-5f74f2a62f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 11.5 s, total: 24 s\n",
      "Wall time: 30 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_TL = torch.load('p_TL.pkl')\n",
    "p_T, p_L, p_TxL, H_T, H_L, I_TL = _compute(p_TL)\n",
    "torch.save((p_T, p_L, p_TxL, H_T, H_L, I_TL), 'info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e855d-f01c-4fbe-b718-1ba45d4e8ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.61 s, sys: 3.62 s, total: 12.2 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "p_TL = torch.load('p_TL.pkl')\n",
    "p_T, p_L, p_TxL, H_T, H_L, I_TL = torch.load('info.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cde5c5-02c5-47dd-a448-ba9812a5c853",
   "metadata": {},
   "source": [
    "Make sure that aren't any of those pesky nans or negs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ac023-b993-4573-8ff5-f3a87e1c0280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_TL failed\n"
     ]
    }
   ],
   "source": [
    "for o in (p_TL, p_T, p_L, p_TxL, H_T, H_L, I_TL):\n",
    "    try:\n",
    "        assert not o.isnan().all() # check for nans\n",
    "        test_eq(torch.where(o>=0, True, False).all(), True) # check for negs\n",
    "    except AssertionError:\n",
    "        print(f\"{namestr(o, globals())[0]} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faae0b4-2d60-4a2c-af35-66e4ca37703e",
   "metadata": {},
   "source": [
    "Theoretically, Mutual-Info as defined [here](https://en.wikipedia.org/wiki/Mutual_information) is suposed to be non-negative (can be proved by tossing in [Jensen](https://en.wikipedia.org/wiki/Jensen%27s_inequality)). But, practically, it turns out `I_TL` has some negs because we distorted the `p_TL` and `p_TxL`  with `eps` in the `I_TL` computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6271f2b0-0af6-4a0c-808f-350195940361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=TensorMultiCategory([-1.9016e-07, -1.8314e-07, -1.8314e-07, -1.7385e-07, -1.7277e-07, -1.7277e-07, -1.6798e-07, -1.6798e-07, -1.6798e-07, -1.6767e-07], device='cuda:0'),\n",
       "indices=TensorMultiCategory([22423614,  2731838,  2735913,  1911099,  6389159,  6393113,  6693073,  6695018,  6695355, 32253137], device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(I_TL.flatten(), 10, largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf9476-4bc1-40f4-9ff2-d32f86226833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMultiCategory(-3.9054e-08, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "howmany = torch.where(I_TL < 0, True, False).sum().item()\n",
    "negs = torch.where(I_TL < 0, I_TL, I_TL.new_zeros(I_TL.shape))\n",
    "negs.sum()/howmany"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afd7d6-f0ff-4ac8-95c1-68516baa44fe",
   "metadata": {},
   "source": [
    "Those negs on an avg are pretty close to zero. So we need not worry. Let's roll!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed0a1a-c281-47c7-a3d4-0c59fac95182",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(p_TL.shape, (len(toks), len(lbs), 2, 2))\n",
    "test_eq(p_T.shape, (len(toks), 2, 1))\n",
    "test_eq(p_L.shape, (len(lbs), 1, 2))\n",
    "test_eq(p_TxL.shape, (len(toks), len(lbs), 2, 2))\n",
    "test_eq(H_T.shape, [len(toks)])\n",
    "test_eq(H_L.shape, [len(lbs)])\n",
    "test_eq(I_TL.shape, (len(toks), len(lbs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08c0e9-8f9d-4341-ba93-e525751a9ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_t, r_l = random.randrange(0, len(toks)), random.randrange(0, len(lbs))\n",
    "# toks[r_t], lbs[r_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f084cfa4-42ac-40bd-a7a7-192593756de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_close(p_TL[r_t,r_l].sum(), 1, eps=1e-1)\n",
    "# test_eq(p_T[r_t].sum(), 1)\n",
    "# test_eq(p_L[r_l].sum(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ec5da-c02d-40e3-a8cb-1ba44047c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_TL[r_t,r_l].sum(-1), p_TL[r_t, 400].sum(-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684d3f32-acf5-4a0f-a84a-7950b9aee280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_T[r_t], p_L[r_l]\n",
    "# I_TL[r_t,r_l]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b382a-27c2-4346-af81-3686994e0143",
   "metadata": {},
   "source": [
    "Let's save the `info`, we will use this bootstrap the collab model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05429dda-8ebd-441b-a69d-46ec898cfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = I_TL.new_empty(1).fill_(1e-15)\n",
    "info_lbl_entropy = I_TL/(H_L + eps)\n",
    "info_jaccard = I_TL/(H_T.unsqueeze(-1) + H_L.unsqueeze(0) - I_TL + eps)\n",
    "assert not info_lbl_entropy.isnan().all(); assert not info_jaccard.isnan().all()\n",
    "collab_bootstrap = {'toks': toks, 'lbs': lbs, 'mut_info_lbl_entropy': info_lbl_entropy, 'mutual_info_jaccard': info_jaccard}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e56290-ba80-4240-a5ef-3bcdcb39644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(collab_bootstrap, collab_bootst_path)\n",
    "assert collab_bootst_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5816a639-8592-4cb8-b1fe-5e08752082c4",
   "metadata": {},
   "source": [
    "#### Save those Mutual Information Gain values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db898c6f-2338-4141-b7d4-3b634f7a85a1",
   "metadata": {},
   "source": [
    "Let's take a look at the *Mutual Information Gain* (`I_TL`) for each of the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c340cb-2dcc-4087-a289-485486e33344",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ColReader('labels', label_delim=';')\n",
    "lbs_frqs = Counter()\n",
    "for o in df.itertuples(): lbs_frqs.update(f(o))\n",
    "with open(path.parent/'data'/'code_desc.pkl', 'rb') as f: lbs_desc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee477c75-dc14-495e-a429-4bcd88265c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen(toks, lbs, lbs_frqs, lbs_desc, p_TL, p_T, p_L, info, H_T, H_L, k=5):\n",
    "    sorted_by_tok, tok_idxs = torch.sort(info, dim=0, descending=True) \n",
    "    for i,o in enumerate(lbs):\n",
    "        topk_tok_idxs = tok_idxs[:k, i].cpu()\n",
    "        topk_toks = toks[topk_tok_idxs]\n",
    "        topk_toks_probs = p_T.squeeze()[:,0][topk_tok_idxs].cpu().numpy()\n",
    "        topk_info_gains = sorted_by_tok[:k, i].cpu().numpy()\n",
    "        topk_jnt_probs = p_TL[topk_tok_idxs, [i]][:,0,0].cpu().numpy()\n",
    "        lbl_entropy = H_L[i].cpu().numpy()\n",
    "        topk_tok_entrops = H_T[topk_tok_idxs].cpu().numpy()\n",
    "        yield (o, lbs_frqs[o], p_L[i][0,0].cpu().numpy(), lbl_entropy, lbs_desc.get(o, 'Not Found'), \n",
    "               array(list(zip(topk_toks, topk_toks_probs, topk_tok_entrops, topk_jnt_probs, topk_info_gains))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318809c-f3dd-4189-834b-f2d3cb32cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_infogain(data, save_as=None):\n",
    "    df = pd.DataFrame(data, columns=['label', 'freq', 'prob', 'entropy', 'description', 'top-k (token, prob, entropy, joint, info)'],)\n",
    "    df[['prob', 'entropy',]] = df[['prob', 'entropy']].astype(np.float)\n",
    "    df[['top-k (token, prob, entropy, joint, info)']] = df[['top-k (token, prob, entropy, joint, info)']].astype(np.str_) \n",
    "    if save_as is not None: df.to_feather(save_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d69602-796f-4645-a527-3b0901f8ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 593 ms, total: 15.1 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eps = I_TL.new_empty(1).fill_(1e-15)\n",
    "# info = I_TL/H_L\n",
    "info = I_TL/(H_T.unsqueeze(-1) + H_L.unsqueeze(0) - I_TL + eps)\n",
    "_data = _gen(array(toks), lbs, lbs_frqs, lbs_desc, p_TL, p_T, p_L, info, H_T, H_L, k=10)\n",
    "show_infogain(_data, save_as='mut_info_jaccard.ft')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e629ea-7672-44ac-b875-7c5b663740d6",
   "metadata": {},
   "source": [
    "#### Let's look at those Mutual-Information Gain values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d02274-5eb9-4650-8fb9-444d6aa616b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jc = pd.read_feather('mut_info_jaccard.ft')\n",
    "df_le = pd.read_feather('mut_info_lbl_entropy.ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c7ea5-a2e6-4dfe-b92f-60231ccf2468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lbs.sort_values(by='freq', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed83f23-789e-480e-81b5-545e8e3cbd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = None\n",
    "df_jc[df_jc.label == '032.9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99678fb-4db4-407f-becc-efbb43e38dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(822, 822)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_le.freq>50) & (df_le.freq<150)\n",
    "# with pd.option_context('display.max_colwidth', 100):\n",
    "# pd.reset_option('all')\n",
    "_df_jc = df_jc[mask].reset_index(drop=True)\n",
    "_df_le = df_le[mask].reset_index(drop=True)\n",
    "len(_df_jc), len(_df_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb31ac-fddd-4624-b9fd-dd273ceccb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911f7513-1a69-446e-84d5-f9ec68eb7006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>freq</th>\n",
       "      <th>prob</th>\n",
       "      <th>entropy</th>\n",
       "      <th>description</th>\n",
       "      <th>top-k (token, prob, entropy, joint, info)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008.8</td>\n",
       "      <td>132</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.017498</td>\n",
       "      <td>Intestinal infection due to other organism, not elsewhere classified</td>\n",
       "      <td>[['gastroenteritis' '0.008327011' '0.048164062' '0.0018778453' '0.135108']\\n ['gasteroenteritis' '0.000113808805' '0.0011472754' '7.587254e-05' '0.020989483']\\n ['viral' '0.06646434' '0.24439576' '0.002124431' '0.018479552']\\n ['norovirus' '0.0006259484' '0.0052429195' '0.000113808805' '0.017389983']\\n ['watery' '0.013770865' '0.07268653' '0.00056904403' '0.01273447']\\n ['monobasic' '5.6904402e-05' '0.00061311224' '3.793627e-05' '0.010679064']\\n ['profuse' '0.006866465' '0.041045412' '0.00026555388' '0.008544236']\\n ['gestures' '0.0008345979' '0.0067503336' '7.587254e-05' '0.00845181']\\n ['virally' '0.000113808805' '0.0011472754' '3.793627e-05' '0.008393114']\\n ['ksb' '0.000113808805' '0.0011472754' '3.793627e-05' '0.008393114']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038.12</td>\n",
       "      <td>116</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.015662</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>[['carbacephems' '0.0061836117' '0.037613403' '0.0006638847' '0.040515352']\\n ['carbapenems' '0.0064491658' '0.038956657' '0.0006638847' '0.03890332']\\n ['staphylococci' '0.0067336876' '0.04038363' '0.0006828528' '0.038864423']\\n ['combinations' '0.006904401' '0.041234046' '0.0006638847' '0.036400057']\\n ['consultations' '0.0042109257' '0.027236082' '0.00041729896' '0.029816346']\\n ['rifampin' '0.013694993' '0.072362244' '0.00092943857' '0.029683795']\\n ['lactamase' '0.010944613' '0.060298413' '0.0006638847' '0.022703482']\\n ['protochol' '0.001972686' '0.014257325' '0.00018968133' '0.018664824']\\n ['dysthesia' '9.484067e-05' '0.0009733652' '5.6904402e-05' '0.017445711']\\n ['fungi' '0.0027883158' '0.019186173' '0.00020864948' '0.016050713']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038.19</td>\n",
       "      <td>148</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.019298</td>\n",
       "      <td>Other staphylococcal septicemia</td>\n",
       "      <td>[['epidermidis' '0.0024279212' '0.01704282' '0.00024658575' '0.0187256']\\n ['coagulase' '0.02348255' '0.111299396' '0.0011001518' '0.018020378']\\n ['coag' '0.04516313' '0.18401921' '0.0015174507' '0.014196403']\\n ['staph' '0.06320182' '0.23568806' '0.0018778453' '0.013870501']\\n ['staphylococcus' '0.041388467' '0.17233191' '0.0011191199' '0.0092715']\\n ['staphlococcus' '0.0003414264' '0.003066752' '5.6904402e-05' '0.008194677']\\n ['surveillance' '0.021509863' '0.103858486' '0.0006259484' '0.007927067']\\n ['mrse' '0.0008156298' '0.006615689' '7.587254e-05' '0.0076404638']\\n ['rvg' '0.00013277694' '0.0013180688' '3.793627e-05' '0.007032873']\\n ['oxacillin' '0.028414264' '0.12918602' '0.00070182094' '0.0067001204']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038.2</td>\n",
       "      <td>85</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>Pneumococcal septicemia [Streptococcus pneumoniae septicemia]</td>\n",
       "      <td>[['pneumococcus' '0.0013277694' '0.010122354' '0.00030349015' '0.060944773']\\n ['streptococcal' '0.0020675266' '0.014845582' '0.00030349015' '0.043650616']\\n ['pneumo' '0.0066767833' '0.040099256' '0.0006259484' '0.041905276']\\n ['pneumococcal' '0.008421851' '0.048616834' '0.0006828528' '0.03765242']\\n ['pneumoniae' '0.013808802' '0.0728485' '0.00091047044' '0.03456903']\\n ['breakpoints' '0.00036039454' '0.0032176247' '9.484067e-05' '0.027405556']\\n ['asplenia' '0.00037936267' '0.0033675581' '7.587254e-05' '0.019955589']\\n ['streptococcus' '0.018209409' '0.09098615' '0.0007397572' '0.018613825']\\n ['mus' '5.6904402e-05' '0.00061311224' '3.793627e-05' '0.016812751']\\n ['mucousa' '5.6904402e-05' '0.00061311224' '3.793627e-05' '0.016812751']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038.3</td>\n",
       "      <td>108</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>Septicemia due to anaerobes</td>\n",
       "      <td>[['septicum' '0.00085356605' '0.006884547' '0.000113808805' '0.017611679']\\n ['perfringens' '0.00142261' '0.010747153' '0.00013277694' '0.015447679']\\n ['megacolon' '0.0030728378' '0.020844972' '0.00018968133' '0.013581591']\\n ['bacteroides' '0.0023141124' '0.01635513' '0.00013277694' '0.010470199']\\n ['ulitmately' '0.000113808805' '0.0011472754' '3.793627e-05' '0.010368616']\\n ['pancolitis' '0.0023520486' '0.016584992' '0.00013277694' '0.010324825']\\n ['klebisella' '0.00013277694' '0.0013180688' '3.793627e-05' '0.009809668']\\n ['clostridial' '0.00013277694' '0.0013180688' '3.793627e-05' '0.009809668']\\n ['citracel' '0.00015174507' '0.0014860831' '3.793627e-05' '0.0093412995']\\n ['culutures' '0.0001707132' '0.0016517199' '3.793627e-05' '0.008926498']]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  freq      prob   entropy  \\\n",
       "0   008.8   132  0.002504  0.017498   \n",
       "1  038.12   116  0.002200  0.015662   \n",
       "2  038.19   148  0.002807  0.019298   \n",
       "3   038.2    85  0.001612  0.011978   \n",
       "4   038.3   108  0.002049  0.014728   \n",
       "\n",
       "                                                            description  \\\n",
       "0  Intestinal infection due to other organism, not elsewhere classified   \n",
       "1                                                             Not Found   \n",
       "2                                       Other staphylococcal septicemia   \n",
       "3         Pneumococcal septicemia [Streptococcus pneumoniae septicemia]   \n",
       "4                                           Septicemia due to anaerobes   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   top-k (token, prob, entropy, joint, info)  \n",
       "0                        [['gastroenteritis' '0.008327011' '0.048164062' '0.0018778453' '0.135108']\\n ['gasteroenteritis' '0.000113808805' '0.0011472754' '7.587254e-05' '0.020989483']\\n ['viral' '0.06646434' '0.24439576' '0.002124431' '0.018479552']\\n ['norovirus' '0.0006259484' '0.0052429195' '0.000113808805' '0.017389983']\\n ['watery' '0.013770865' '0.07268653' '0.00056904403' '0.01273447']\\n ['monobasic' '5.6904402e-05' '0.00061311224' '3.793627e-05' '0.010679064']\\n ['profuse' '0.006866465' '0.041045412' '0.00026555388' '0.008544236']\\n ['gestures' '0.0008345979' '0.0067503336' '7.587254e-05' '0.00845181']\\n ['virally' '0.000113808805' '0.0011472754' '3.793627e-05' '0.008393114']\\n ['ksb' '0.000113808805' '0.0011472754' '3.793627e-05' '0.008393114']]  \n",
       "1             [['carbacephems' '0.0061836117' '0.037613403' '0.0006638847' '0.040515352']\\n ['carbapenems' '0.0064491658' '0.038956657' '0.0006638847' '0.03890332']\\n ['staphylococci' '0.0067336876' '0.04038363' '0.0006828528' '0.038864423']\\n ['combinations' '0.006904401' '0.041234046' '0.0006638847' '0.036400057']\\n ['consultations' '0.0042109257' '0.027236082' '0.00041729896' '0.029816346']\\n ['rifampin' '0.013694993' '0.072362244' '0.00092943857' '0.029683795']\\n ['lactamase' '0.010944613' '0.060298413' '0.0006638847' '0.022703482']\\n ['protochol' '0.001972686' '0.014257325' '0.00018968133' '0.018664824']\\n ['dysthesia' '9.484067e-05' '0.0009733652' '5.6904402e-05' '0.017445711']\\n ['fungi' '0.0027883158' '0.019186173' '0.00020864948' '0.016050713']]  \n",
       "2                                         [['epidermidis' '0.0024279212' '0.01704282' '0.00024658575' '0.0187256']\\n ['coagulase' '0.02348255' '0.111299396' '0.0011001518' '0.018020378']\\n ['coag' '0.04516313' '0.18401921' '0.0015174507' '0.014196403']\\n ['staph' '0.06320182' '0.23568806' '0.0018778453' '0.013870501']\\n ['staphylococcus' '0.041388467' '0.17233191' '0.0011191199' '0.0092715']\\n ['staphlococcus' '0.0003414264' '0.003066752' '5.6904402e-05' '0.008194677']\\n ['surveillance' '0.021509863' '0.103858486' '0.0006259484' '0.007927067']\\n ['mrse' '0.0008156298' '0.006615689' '7.587254e-05' '0.0076404638']\\n ['rvg' '0.00013277694' '0.0013180688' '3.793627e-05' '0.007032873']\\n ['oxacillin' '0.028414264' '0.12918602' '0.00070182094' '0.0067001204']]  \n",
       "3              [['pneumococcus' '0.0013277694' '0.010122354' '0.00030349015' '0.060944773']\\n ['streptococcal' '0.0020675266' '0.014845582' '0.00030349015' '0.043650616']\\n ['pneumo' '0.0066767833' '0.040099256' '0.0006259484' '0.041905276']\\n ['pneumococcal' '0.008421851' '0.048616834' '0.0006828528' '0.03765242']\\n ['pneumoniae' '0.013808802' '0.0728485' '0.00091047044' '0.03456903']\\n ['breakpoints' '0.00036039454' '0.0032176247' '9.484067e-05' '0.027405556']\\n ['asplenia' '0.00037936267' '0.0033675581' '7.587254e-05' '0.019955589']\\n ['streptococcus' '0.018209409' '0.09098615' '0.0007397572' '0.018613825']\\n ['mus' '5.6904402e-05' '0.00061311224' '3.793627e-05' '0.016812751']\\n ['mucousa' '5.6904402e-05' '0.00061311224' '3.793627e-05' '0.016812751']]  \n",
       "4  [['septicum' '0.00085356605' '0.006884547' '0.000113808805' '0.017611679']\\n ['perfringens' '0.00142261' '0.010747153' '0.00013277694' '0.015447679']\\n ['megacolon' '0.0030728378' '0.020844972' '0.00018968133' '0.013581591']\\n ['bacteroides' '0.0023141124' '0.01635513' '0.00013277694' '0.010470199']\\n ['ulitmately' '0.000113808805' '0.0011472754' '3.793627e-05' '0.010368616']\\n ['pancolitis' '0.0023520486' '0.016584992' '0.00013277694' '0.010324825']\\n ['klebisella' '0.00013277694' '0.0013180688' '3.793627e-05' '0.009809668']\\n ['clostridial' '0.00013277694' '0.0013180688' '3.793627e-05' '0.009809668']\\n ['citracel' '0.00015174507' '0.0014860831' '3.793627e-05' '0.0093412995']\\n ['culutures' '0.0001707132' '0.0016517199' '3.793627e-05' '0.008926498']]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_jc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588768e1-331d-44f7-9d4d-f2188246aaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>freq</th>\n",
       "      <th>prob</th>\n",
       "      <th>entropy</th>\n",
       "      <th>description</th>\n",
       "      <th>top-k (token, prob, entropy, joint, info)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008.8</td>\n",
       "      <td>132</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.017498</td>\n",
       "      <td>Intestinal infection due to other organism, not elsewhere classified</td>\n",
       "      <td>[['gastroenteritis' '0.008327011' '0.048164062' '0.0018778453' '0.44664875']\\n ['viral' '0.06646434' '0.24439576' '0.002124431' '0.2715633']\\n ['diarrhea' '0.23753795' '0.5482253' '0.0020295903' '0.10494876']\\n ['vomiting' '0.31278452' '0.62131053' '0.002143399' '0.09137799']\\n ['nausea' '0.3579097' '0.652206' '0.0021054628' '0.07120143']\\n ['watery' '0.013770865' '0.07268653' '0.00056904403' '0.064807415']\\n ['medicine' '0.47397572' '0.691792' '0.0022382399' '0.056979857']\\n ['sick' '0.049734447' '0.19773257' '0.0008156298' '0.054789137']\\n ['emesis' '0.06274659' '0.23445892' '0.0008725342' '0.051838394']\\n ['ns' '0.12010623' '0.3671366' '0.0011191199' '0.047479752']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038.12</td>\n",
       "      <td>116</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.015662</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>[['mrsa' '0.09195752' '0.30704355' '0.0019347497' '0.24584907']\\n ['bacteremia' '0.068304256' '0.24923033' '0.0014984825' '0.17290637']\\n ['rifampin' '0.013694993' '0.072362244' '0.00092943857' '0.16202216']\\n ['vancomycin' '0.2591047' '0.5721184' '0.0020864948' '0.15388577']\\n ['aureus' '0.05064492' '0.20040981' '0.001270865' '0.15034734']\\n ['staph' '0.06320182' '0.23568806' '0.0013467375' '0.14798154']\\n ['vegetations' '0.032720033' '0.14407371' '0.0011001518' '0.14625418']\\n ['staphylococci' '0.0067336876' '0.04038363' '0.0006828528' '0.13387245']\\n ['carbacephems' '0.0061836117' '0.037613403' '0.0006638847' '0.13245058']\\n ['carbapenems' '0.0064491658' '0.038956657' '0.0006638847' '0.1305896']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038.19</td>\n",
       "      <td>148</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.019298</td>\n",
       "      <td>Other staphylococcal septicemia</td>\n",
       "      <td>[['staph' '0.06320182' '0.23568806' '0.0018778453' '0.18076809']\\n ['coag' '0.04516313' '0.18401921' '0.0015174507' '0.14747754']\\n ['vancomycin' '0.2591047' '0.5721184' '0.0024658574' '0.124441765']\\n ['coagulase' '0.02348255' '0.111299396' '0.0011001518' '0.11979452']\\n ['grew' '0.11272762' '0.3521803' '0.0016312596' '0.09334226']\\n ['staphylococcus' '0.041388467' '0.17233191' '0.0011191199' '0.09122223']\\n ['cultures' '0.28729135' '0.59970856' '0.0023141124' '0.09089726']\\n ['line' '0.30273142' '0.61316085' '0.002143399' '0.06575568']\\n ['bacteremia' '0.068304256' '0.24923033' '0.0010811837' '0.060057342']\\n ['sepsis' '0.18167679' '0.4739266' '0.0016502277' '0.059517227']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038.2</td>\n",
       "      <td>85</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>Pneumococcal septicemia [Streptococcus pneumoniae septicemia]</td>\n",
       "      <td>[['pneumoniae' '0.013808802' '0.0728485' '0.00091047044' '0.23663042']\\n ['strep' '0.048691202' '0.19464338' '0.0010811837' '0.19061059']\\n ['pneumococcal' '0.008421851' '0.048616834' '0.0006828528' '0.1835643']\\n ['pneumo' '0.0066767833' '0.040099256' '0.0006259484' '0.174864']\\n ['ceftriaxone' '0.122742794' '0.3723544' '0.001270865' '0.1572411']\\n ['streptococcus' '0.018209409' '0.09098615' '0.0007397572' '0.15708087']\\n ['sepsis' '0.18167679' '0.4739266' '0.0012329287' '0.10871605']\\n ['pneumococcus' '0.0013277694' '0.010122354' '0.00030349015' '0.1059879']\\n ['pneumonia' '0.29294384' '0.60476655' '0.0014036419' '0.09822925']\\n ['vancomycin' '0.2591047' '0.5721184' '0.0013277694' '0.09428377']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038.3</td>\n",
       "      <td>108</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>Septicemia due to anaerobes</td>\n",
       "      <td>[['sepsis' '0.18167679' '0.4739266' '0.0014036419' '0.084921986']\\n ['septic' '0.06329666' '0.23594368' '0.00092943857' '0.08369133']\\n ['diff' '0.08988999' '0.3022832' '0.0010432474' '0.08100143']\\n ['colitis' '0.05694234' '0.21847004' '0.00085356605' '0.07671062']\\n ['flagyl' '0.14711685' '0.4176752' '0.0012329287' '0.07597934']\\n ['clostridium' '0.034427166' '0.14980963' '0.0006828528' '0.07129074']\\n ['difficile' '0.050929442' '0.20124286' '0.0007397572' '0.06350024']\\n ['metronidazole' '0.051915783' '0.20411795' '0.00064491655' '0.048172895']\\n ['vancomycin' '0.2591047' '0.5721184' '0.0013277694' '0.046320684']\\n ['shock' '0.06874052' '0.25036877' '0.0006638847' '0.039911266']]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  freq      prob   entropy  \\\n",
       "0   008.8   132  0.002504  0.017498   \n",
       "1  038.12   116  0.002200  0.015662   \n",
       "2  038.19   148  0.002807  0.019298   \n",
       "3   038.2    85  0.001612  0.011978   \n",
       "4   038.3   108  0.002049  0.014728   \n",
       "\n",
       "                                                            description  \\\n",
       "0  Intestinal infection due to other organism, not elsewhere classified   \n",
       "1                                                             Not Found   \n",
       "2                                       Other staphylococcal septicemia   \n",
       "3         Pneumococcal septicemia [Streptococcus pneumoniae septicemia]   \n",
       "4                                           Septicemia due to anaerobes   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              top-k (token, prob, entropy, joint, info)  \n",
       "0                                 [['gastroenteritis' '0.008327011' '0.048164062' '0.0018778453' '0.44664875']\\n ['viral' '0.06646434' '0.24439576' '0.002124431' '0.2715633']\\n ['diarrhea' '0.23753795' '0.5482253' '0.0020295903' '0.10494876']\\n ['vomiting' '0.31278452' '0.62131053' '0.002143399' '0.09137799']\\n ['nausea' '0.3579097' '0.652206' '0.0021054628' '0.07120143']\\n ['watery' '0.013770865' '0.07268653' '0.00056904403' '0.064807415']\\n ['medicine' '0.47397572' '0.691792' '0.0022382399' '0.056979857']\\n ['sick' '0.049734447' '0.19773257' '0.0008156298' '0.054789137']\\n ['emesis' '0.06274659' '0.23445892' '0.0008725342' '0.051838394']\\n ['ns' '0.12010623' '0.3671366' '0.0011191199' '0.047479752']]  \n",
       "1  [['mrsa' '0.09195752' '0.30704355' '0.0019347497' '0.24584907']\\n ['bacteremia' '0.068304256' '0.24923033' '0.0014984825' '0.17290637']\\n ['rifampin' '0.013694993' '0.072362244' '0.00092943857' '0.16202216']\\n ['vancomycin' '0.2591047' '0.5721184' '0.0020864948' '0.15388577']\\n ['aureus' '0.05064492' '0.20040981' '0.001270865' '0.15034734']\\n ['staph' '0.06320182' '0.23568806' '0.0013467375' '0.14798154']\\n ['vegetations' '0.032720033' '0.14407371' '0.0011001518' '0.14625418']\\n ['staphylococci' '0.0067336876' '0.04038363' '0.0006828528' '0.13387245']\\n ['carbacephems' '0.0061836117' '0.037613403' '0.0006638847' '0.13245058']\\n ['carbapenems' '0.0064491658' '0.038956657' '0.0006638847' '0.1305896']]  \n",
       "2                          [['staph' '0.06320182' '0.23568806' '0.0018778453' '0.18076809']\\n ['coag' '0.04516313' '0.18401921' '0.0015174507' '0.14747754']\\n ['vancomycin' '0.2591047' '0.5721184' '0.0024658574' '0.124441765']\\n ['coagulase' '0.02348255' '0.111299396' '0.0011001518' '0.11979452']\\n ['grew' '0.11272762' '0.3521803' '0.0016312596' '0.09334226']\\n ['staphylococcus' '0.041388467' '0.17233191' '0.0011191199' '0.09122223']\\n ['cultures' '0.28729135' '0.59970856' '0.0023141124' '0.09089726']\\n ['line' '0.30273142' '0.61316085' '0.002143399' '0.06575568']\\n ['bacteremia' '0.068304256' '0.24923033' '0.0010811837' '0.060057342']\\n ['sepsis' '0.18167679' '0.4739266' '0.0016502277' '0.059517227']]  \n",
       "3    [['pneumoniae' '0.013808802' '0.0728485' '0.00091047044' '0.23663042']\\n ['strep' '0.048691202' '0.19464338' '0.0010811837' '0.19061059']\\n ['pneumococcal' '0.008421851' '0.048616834' '0.0006828528' '0.1835643']\\n ['pneumo' '0.0066767833' '0.040099256' '0.0006259484' '0.174864']\\n ['ceftriaxone' '0.122742794' '0.3723544' '0.001270865' '0.1572411']\\n ['streptococcus' '0.018209409' '0.09098615' '0.0007397572' '0.15708087']\\n ['sepsis' '0.18167679' '0.4739266' '0.0012329287' '0.10871605']\\n ['pneumococcus' '0.0013277694' '0.010122354' '0.00030349015' '0.1059879']\\n ['pneumonia' '0.29294384' '0.60476655' '0.0014036419' '0.09822925']\\n ['vancomycin' '0.2591047' '0.5721184' '0.0013277694' '0.09428377']]  \n",
       "4                   [['sepsis' '0.18167679' '0.4739266' '0.0014036419' '0.084921986']\\n ['septic' '0.06329666' '0.23594368' '0.00092943857' '0.08369133']\\n ['diff' '0.08988999' '0.3022832' '0.0010432474' '0.08100143']\\n ['colitis' '0.05694234' '0.21847004' '0.00085356605' '0.07671062']\\n ['flagyl' '0.14711685' '0.4176752' '0.0012329287' '0.07597934']\\n ['clostridium' '0.034427166' '0.14980963' '0.0006828528' '0.07129074']\\n ['difficile' '0.050929442' '0.20124286' '0.0007397572' '0.06350024']\\n ['metronidazole' '0.051915783' '0.20411795' '0.00064491655' '0.048172895']\\n ['vancomycin' '0.2591047' '0.5721184' '0.0013277694' '0.046320684']\\n ['shock' '0.06874052' '0.25036877' '0.0006638847' '0.039911266']]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df_le.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9aaf3-3906-4b7e-b3f2-265ebc8942fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff381c-cc78-4417-92d5-e8871cc64b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_jc.to_excel('jaccard.xls', index=False)\n",
    "_df_le.to_excel('label-entropy.xls', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepK",
   "language": "python",
   "name": "deepk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
