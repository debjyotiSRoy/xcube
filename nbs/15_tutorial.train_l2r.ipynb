{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250b634-6386-4092-8cd7-6a061998ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "! [ -e /content ] && pip install -Uqq xcube # upgrade xcube on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32dbb09-2578-46ac-8c99-6449d4ae8320",
   "metadata": {},
   "source": [
    "# L2R\n",
    "\n",
    "> Building a learning-to-rank model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b995d-df8b-497f-a707-c28b79a07832",
   "metadata": {},
   "source": [
    "### Collab Model (Attempt #2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5460b777-b812-4d6b-8f0e-5a831e24c7e8",
   "metadata": {},
   "source": [
    "#### Getting the collab data ready for fastai's `CollabDataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1555798-45a9-4dcd-aca3-f0820b24c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert collab_bootst_path.exists()\n",
    "collab_bootstrap = torch.load(collab_bootst_path)\n",
    "test_eq(collab_bootstrap.keys(), ['toks', 'lbs', 'mut_info_lbl_entropy', 'mutual_info_jaccard'])\n",
    "toks = collab_bootstrap.get('toks', None)\n",
    "lbs = collab_bootstrap.get('lbs', None)\n",
    "info = collab_bootstrap.get('mutual_info_jaccard', None)\n",
    "for o in (toks, lbs, info): assert o is not None\n",
    "test_eq(info.shape, (len(toks), len(lbs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d01d1-3212-4f90-ac18-9c94d3f7262c",
   "metadata": {},
   "source": [
    "Tossing in some pandas to get the data ready so that we can use fastai's collab `DataLoaders`:\n",
    "\n",
    "*Note:* Storing the tokens and the labels in a dataframe as `object` will take up a lot of RAM space when we prepare that `DataLoader`. So we are going to store the corresponding token and label indices instead in a dataframe called `df_collab`. We are also going to store the tokens and the labels with their corresponding indices in seperate dataframes (this will help in quick merging for analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463865c1-96ef-41e2-a1e0-863fa5380069",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ab483-1c84-46f2-bae3-410e50847bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = info.argsort(descending=True, dim=0).argsort(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6cabb-8678-4d72-82b7-ba9839fc58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_ranked =torch.stack((info, ranked), dim=2).flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59abc5cc-9fa7-4866-b7c6-a3a2a05bb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.MultiIndex.from_product([range(len(lbs)), ['mutual_info', 'rank']], names=['label', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cdd7c-0613-450e-b37e-159872e4c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collab = pd.DataFrame(info_ranked, index=range(len(toks)), columns=cols)\n",
    "df_collab.index.name='token'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894efcff-9187-4620-9778-bfc827851e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">4</th>\n",
       "      <th colspan=\"2\" halign=\"left\">5</th>\n",
       "      <th colspan=\"2\" halign=\"left\">6</th>\n",
       "      <th colspan=\"2\" halign=\"left\">7</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8</th>\n",
       "      <th colspan=\"2\" halign=\"left\">9</th>\n",
       "      <th colspan=\"2\" halign=\"left\">10</th>\n",
       "      <th colspan=\"2\" halign=\"left\">11</th>\n",
       "      <th colspan=\"2\" halign=\"left\">12</th>\n",
       "      <th colspan=\"2\" halign=\"left\">13</th>\n",
       "      <th colspan=\"2\" halign=\"left\">14</th>\n",
       "      <th colspan=\"2\" halign=\"left\">15</th>\n",
       "      <th colspan=\"2\" halign=\"left\">16</th>\n",
       "      <th colspan=\"2\" halign=\"left\">17</th>\n",
       "      <th colspan=\"2\" halign=\"left\">18</th>\n",
       "      <th colspan=\"2\" halign=\"left\">19</th>\n",
       "      <th colspan=\"2\" halign=\"left\">20</th>\n",
       "      <th colspan=\"2\" halign=\"left\">21</th>\n",
       "      <th colspan=\"2\" halign=\"left\">22</th>\n",
       "      <th colspan=\"2\" halign=\"left\">23</th>\n",
       "      <th colspan=\"2\" halign=\"left\">24</th>\n",
       "      <th colspan=\"2\" halign=\"left\">25</th>\n",
       "      <th colspan=\"2\" halign=\"left\">26</th>\n",
       "      <th colspan=\"2\" halign=\"left\">27</th>\n",
       "      <th colspan=\"2\" halign=\"left\">28</th>\n",
       "      <th colspan=\"2\" halign=\"left\">29</th>\n",
       "      <th colspan=\"2\" halign=\"left\">30</th>\n",
       "      <th colspan=\"2\" halign=\"left\">31</th>\n",
       "      <th colspan=\"2\" halign=\"left\">32</th>\n",
       "      <th colspan=\"2\" halign=\"left\">33</th>\n",
       "      <th colspan=\"2\" halign=\"left\">34</th>\n",
       "      <th colspan=\"2\" halign=\"left\">35</th>\n",
       "      <th colspan=\"2\" halign=\"left\">36</th>\n",
       "      <th colspan=\"2\" halign=\"left\">37</th>\n",
       "      <th colspan=\"2\" halign=\"left\">38</th>\n",
       "      <th colspan=\"2\" halign=\"left\">39</th>\n",
       "      <th colspan=\"2\" halign=\"left\">40</th>\n",
       "      <th colspan=\"2\" halign=\"left\">41</th>\n",
       "      <th colspan=\"2\" halign=\"left\">42</th>\n",
       "      <th colspan=\"2\" halign=\"left\">43</th>\n",
       "      <th colspan=\"2\" halign=\"left\">44</th>\n",
       "      <th colspan=\"2\" halign=\"left\">45</th>\n",
       "      <th colspan=\"2\" halign=\"left\">46</th>\n",
       "      <th colspan=\"2\" halign=\"left\">47</th>\n",
       "      <th colspan=\"2\" halign=\"left\">48</th>\n",
       "      <th colspan=\"2\" halign=\"left\">49</th>\n",
       "      <th colspan=\"2\" halign=\"left\">50</th>\n",
       "      <th colspan=\"2\" halign=\"left\">51</th>\n",
       "      <th colspan=\"2\" halign=\"left\">52</th>\n",
       "      <th colspan=\"2\" halign=\"left\">53</th>\n",
       "      <th colspan=\"2\" halign=\"left\">54</th>\n",
       "      <th colspan=\"2\" halign=\"left\">55</th>\n",
       "      <th colspan=\"2\" halign=\"left\">56</th>\n",
       "      <th colspan=\"2\" halign=\"left\">57</th>\n",
       "      <th colspan=\"2\" halign=\"left\">58</th>\n",
       "      <th colspan=\"2\" halign=\"left\">59</th>\n",
       "      <th colspan=\"2\" halign=\"left\">60</th>\n",
       "      <th colspan=\"2\" halign=\"left\">61</th>\n",
       "      <th colspan=\"2\" halign=\"left\">62</th>\n",
       "      <th colspan=\"2\" halign=\"left\">63</th>\n",
       "      <th colspan=\"2\" halign=\"left\">64</th>\n",
       "      <th colspan=\"2\" halign=\"left\">65</th>\n",
       "      <th colspan=\"2\" halign=\"left\">66</th>\n",
       "      <th colspan=\"2\" halign=\"left\">67</th>\n",
       "      <th colspan=\"2\" halign=\"left\">68</th>\n",
       "      <th colspan=\"2\" halign=\"left\">69</th>\n",
       "      <th colspan=\"2\" halign=\"left\">70</th>\n",
       "      <th colspan=\"2\" halign=\"left\">71</th>\n",
       "      <th colspan=\"2\" halign=\"left\">72</th>\n",
       "      <th colspan=\"2\" halign=\"left\">73</th>\n",
       "      <th colspan=\"2\" halign=\"left\">74</th>\n",
       "      <th colspan=\"2\" halign=\"left\">75</th>\n",
       "      <th colspan=\"2\" halign=\"left\">76</th>\n",
       "      <th colspan=\"2\" halign=\"left\">77</th>\n",
       "      <th colspan=\"2\" halign=\"left\">78</th>\n",
       "      <th colspan=\"2\" halign=\"left\">79</th>\n",
       "      <th colspan=\"2\" halign=\"left\">80</th>\n",
       "      <th colspan=\"2\" halign=\"left\">81</th>\n",
       "      <th colspan=\"2\" halign=\"left\">82</th>\n",
       "      <th colspan=\"2\" halign=\"left\">83</th>\n",
       "      <th colspan=\"2\" halign=\"left\">84</th>\n",
       "      <th colspan=\"2\" halign=\"left\">85</th>\n",
       "      <th colspan=\"2\" halign=\"left\">86</th>\n",
       "      <th colspan=\"2\" halign=\"left\">87</th>\n",
       "      <th colspan=\"2\" halign=\"left\">88</th>\n",
       "      <th colspan=\"2\" halign=\"left\">89</th>\n",
       "      <th colspan=\"2\" halign=\"left\">90</th>\n",
       "      <th colspan=\"2\" halign=\"left\">91</th>\n",
       "      <th colspan=\"2\" halign=\"left\">92</th>\n",
       "      <th colspan=\"2\" halign=\"left\">93</th>\n",
       "      <th colspan=\"2\" halign=\"left\">94</th>\n",
       "      <th colspan=\"2\" halign=\"left\">95</th>\n",
       "      <th colspan=\"2\" halign=\"left\">96</th>\n",
       "      <th colspan=\"2\" halign=\"left\">97</th>\n",
       "      <th colspan=\"2\" halign=\"left\">98</th>\n",
       "      <th colspan=\"2\" halign=\"left\">99</th>\n",
       "      <th colspan=\"2\" halign=\"left\">100</th>\n",
       "      <th colspan=\"2\" halign=\"left\">101</th>\n",
       "      <th colspan=\"2\" halign=\"left\">102</th>\n",
       "      <th colspan=\"2\" halign=\"left\">103</th>\n",
       "      <th colspan=\"2\" halign=\"left\">104</th>\n",
       "      <th colspan=\"2\" halign=\"left\">105</th>\n",
       "      <th colspan=\"2\" halign=\"left\">106</th>\n",
       "      <th colspan=\"2\" halign=\"left\">107</th>\n",
       "      <th colspan=\"2\" halign=\"left\">108</th>\n",
       "      <th colspan=\"2\" halign=\"left\">109</th>\n",
       "      <th colspan=\"2\" halign=\"left\">110</th>\n",
       "      <th colspan=\"2\" halign=\"left\">111</th>\n",
       "      <th colspan=\"2\" halign=\"left\">112</th>\n",
       "      <th colspan=\"2\" halign=\"left\">113</th>\n",
       "      <th colspan=\"2\" halign=\"left\">114</th>\n",
       "      <th colspan=\"2\" halign=\"left\">115</th>\n",
       "      <th colspan=\"2\" halign=\"left\">116</th>\n",
       "      <th colspan=\"2\" halign=\"left\">117</th>\n",
       "      <th colspan=\"2\" halign=\"left\">118</th>\n",
       "      <th colspan=\"2\" halign=\"left\">119</th>\n",
       "      <th colspan=\"2\" halign=\"left\">120</th>\n",
       "      <th colspan=\"2\" halign=\"left\">121</th>\n",
       "      <th colspan=\"2\" halign=\"left\">122</th>\n",
       "      <th colspan=\"2\" halign=\"left\">123</th>\n",
       "      <th colspan=\"2\" halign=\"left\">124</th>\n",
       "      <th colspan=\"2\" halign=\"left\">125</th>\n",
       "      <th colspan=\"2\" halign=\"left\">126</th>\n",
       "      <th colspan=\"2\" halign=\"left\">127</th>\n",
       "      <th colspan=\"2\" halign=\"left\">128</th>\n",
       "      <th colspan=\"2\" halign=\"left\">129</th>\n",
       "      <th colspan=\"2\" halign=\"left\">130</th>\n",
       "      <th colspan=\"2\" halign=\"left\">131</th>\n",
       "      <th colspan=\"2\" halign=\"left\">132</th>\n",
       "      <th colspan=\"2\" halign=\"left\">133</th>\n",
       "      <th colspan=\"2\" halign=\"left\">134</th>\n",
       "      <th colspan=\"2\" halign=\"left\">135</th>\n",
       "      <th colspan=\"2\" halign=\"left\">136</th>\n",
       "      <th colspan=\"2\" halign=\"left\">137</th>\n",
       "      <th colspan=\"2\" halign=\"left\">138</th>\n",
       "      <th colspan=\"2\" halign=\"left\">139</th>\n",
       "      <th colspan=\"2\" halign=\"left\">140</th>\n",
       "      <th colspan=\"2\" halign=\"left\">141</th>\n",
       "      <th colspan=\"2\" halign=\"left\">142</th>\n",
       "      <th colspan=\"2\" halign=\"left\">143</th>\n",
       "      <th colspan=\"2\" halign=\"left\">144</th>\n",
       "      <th colspan=\"2\" halign=\"left\">145</th>\n",
       "      <th colspan=\"2\" halign=\"left\">146</th>\n",
       "      <th colspan=\"2\" halign=\"left\">147</th>\n",
       "      <th colspan=\"2\" halign=\"left\">148</th>\n",
       "      <th colspan=\"2\" halign=\"left\">149</th>\n",
       "      <th colspan=\"2\" halign=\"left\">150</th>\n",
       "      <th colspan=\"2\" halign=\"left\">151</th>\n",
       "      <th colspan=\"2\" halign=\"left\">152</th>\n",
       "      <th colspan=\"2\" halign=\"left\">153</th>\n",
       "      <th colspan=\"2\" halign=\"left\">154</th>\n",
       "      <th colspan=\"2\" halign=\"left\">155</th>\n",
       "      <th colspan=\"2\" halign=\"left\">156</th>\n",
       "      <th colspan=\"2\" halign=\"left\">157</th>\n",
       "      <th colspan=\"2\" halign=\"left\">158</th>\n",
       "      <th colspan=\"2\" halign=\"left\">159</th>\n",
       "      <th colspan=\"2\" halign=\"left\">160</th>\n",
       "      <th colspan=\"2\" halign=\"left\">161</th>\n",
       "      <th colspan=\"2\" halign=\"left\">162</th>\n",
       "      <th colspan=\"2\" halign=\"left\">163</th>\n",
       "      <th colspan=\"2\" halign=\"left\">164</th>\n",
       "      <th colspan=\"2\" halign=\"left\">165</th>\n",
       "      <th colspan=\"2\" halign=\"left\">166</th>\n",
       "      <th colspan=\"2\" halign=\"left\">167</th>\n",
       "      <th colspan=\"2\" halign=\"left\">168</th>\n",
       "      <th colspan=\"2\" halign=\"left\">169</th>\n",
       "      <th colspan=\"2\" halign=\"left\">170</th>\n",
       "      <th colspan=\"2\" halign=\"left\">171</th>\n",
       "      <th colspan=\"2\" halign=\"left\">172</th>\n",
       "      <th colspan=\"2\" halign=\"left\">173</th>\n",
       "      <th colspan=\"2\" halign=\"left\">174</th>\n",
       "      <th colspan=\"2\" halign=\"left\">175</th>\n",
       "      <th colspan=\"2\" halign=\"left\">176</th>\n",
       "      <th colspan=\"2\" halign=\"left\">177</th>\n",
       "      <th colspan=\"2\" halign=\"left\">178</th>\n",
       "      <th colspan=\"2\" halign=\"left\">179</th>\n",
       "      <th colspan=\"2\" halign=\"left\">180</th>\n",
       "      <th colspan=\"2\" halign=\"left\">181</th>\n",
       "      <th colspan=\"2\" halign=\"left\">182</th>\n",
       "      <th colspan=\"2\" halign=\"left\">183</th>\n",
       "      <th colspan=\"2\" halign=\"left\">184</th>\n",
       "      <th colspan=\"2\" halign=\"left\">185</th>\n",
       "      <th colspan=\"2\" halign=\"left\">186</th>\n",
       "      <th colspan=\"2\" halign=\"left\">187</th>\n",
       "      <th colspan=\"2\" halign=\"left\">188</th>\n",
       "      <th colspan=\"2\" halign=\"left\">189</th>\n",
       "      <th colspan=\"2\" halign=\"left\">190</th>\n",
       "      <th colspan=\"2\" halign=\"left\">191</th>\n",
       "      <th colspan=\"2\" halign=\"left\">192</th>\n",
       "      <th colspan=\"2\" halign=\"left\">193</th>\n",
       "      <th colspan=\"2\" halign=\"left\">194</th>\n",
       "      <th colspan=\"2\" halign=\"left\">195</th>\n",
       "      <th colspan=\"2\" halign=\"left\">196</th>\n",
       "      <th colspan=\"2\" halign=\"left\">197</th>\n",
       "      <th colspan=\"2\" halign=\"left\">198</th>\n",
       "      <th colspan=\"2\" halign=\"left\">199</th>\n",
       "      <th colspan=\"2\" halign=\"left\">200</th>\n",
       "      <th colspan=\"2\" halign=\"left\">201</th>\n",
       "      <th colspan=\"2\" halign=\"left\">202</th>\n",
       "      <th colspan=\"2\" halign=\"left\">203</th>\n",
       "      <th colspan=\"2\" halign=\"left\">204</th>\n",
       "      <th colspan=\"2\" halign=\"left\">205</th>\n",
       "      <th colspan=\"2\" halign=\"left\">206</th>\n",
       "      <th colspan=\"2\" halign=\"left\">207</th>\n",
       "      <th colspan=\"2\" halign=\"left\">208</th>\n",
       "      <th colspan=\"2\" halign=\"left\">209</th>\n",
       "      <th colspan=\"2\" halign=\"left\">210</th>\n",
       "      <th colspan=\"2\" halign=\"left\">211</th>\n",
       "      <th colspan=\"2\" halign=\"left\">212</th>\n",
       "      <th colspan=\"2\" halign=\"left\">213</th>\n",
       "      <th colspan=\"2\" halign=\"left\">214</th>\n",
       "      <th colspan=\"2\" halign=\"left\">215</th>\n",
       "      <th colspan=\"2\" halign=\"left\">216</th>\n",
       "      <th colspan=\"2\" halign=\"left\">217</th>\n",
       "      <th colspan=\"2\" halign=\"left\">218</th>\n",
       "      <th colspan=\"2\" halign=\"left\">219</th>\n",
       "      <th colspan=\"2\" halign=\"left\">220</th>\n",
       "      <th colspan=\"2\" halign=\"left\">221</th>\n",
       "      <th colspan=\"2\" halign=\"left\">222</th>\n",
       "      <th colspan=\"2\" halign=\"left\">223</th>\n",
       "      <th colspan=\"2\" halign=\"left\">224</th>\n",
       "      <th colspan=\"2\" halign=\"left\">225</th>\n",
       "      <th colspan=\"2\" halign=\"left\">226</th>\n",
       "      <th colspan=\"2\" halign=\"left\">227</th>\n",
       "      <th colspan=\"2\" halign=\"left\">228</th>\n",
       "      <th colspan=\"2\" halign=\"left\">229</th>\n",
       "      <th colspan=\"2\" halign=\"left\">230</th>\n",
       "      <th colspan=\"2\" halign=\"left\">231</th>\n",
       "      <th colspan=\"2\" halign=\"left\">232</th>\n",
       "      <th colspan=\"2\" halign=\"left\">233</th>\n",
       "      <th colspan=\"2\" halign=\"left\">234</th>\n",
       "      <th colspan=\"2\" halign=\"left\">235</th>\n",
       "      <th colspan=\"2\" halign=\"left\">236</th>\n",
       "      <th colspan=\"2\" halign=\"left\">237</th>\n",
       "      <th colspan=\"2\" halign=\"left\">238</th>\n",
       "      <th colspan=\"2\" halign=\"left\">239</th>\n",
       "      <th colspan=\"2\" halign=\"left\">240</th>\n",
       "      <th colspan=\"2\" halign=\"left\">241</th>\n",
       "      <th colspan=\"2\" halign=\"left\">242</th>\n",
       "      <th colspan=\"2\" halign=\"left\">243</th>\n",
       "      <th colspan=\"2\" halign=\"left\">244</th>\n",
       "      <th colspan=\"2\" halign=\"left\">245</th>\n",
       "      <th colspan=\"2\" halign=\"left\">246</th>\n",
       "      <th colspan=\"2\" halign=\"left\">247</th>\n",
       "      <th colspan=\"2\" halign=\"left\">248</th>\n",
       "      <th>249</th>\n",
       "      <th>...</th>\n",
       "      <th>8672</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8673</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8674</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8675</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8676</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8677</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8678</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8679</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8680</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8681</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8682</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8683</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8684</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8685</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8686</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8687</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8688</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8689</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8690</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8691</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8692</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8693</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8694</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8695</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8696</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8697</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8698</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8699</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8700</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8701</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8702</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8703</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8704</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8705</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8706</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8707</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8708</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8709</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8710</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8711</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8712</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8713</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8714</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8715</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8716</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8717</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8718</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8719</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8720</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8721</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8722</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8723</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8724</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8725</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8726</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8727</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8728</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8729</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8730</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8731</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8732</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8733</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8734</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8735</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8736</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8737</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8738</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8739</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8740</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8741</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8742</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8743</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8744</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8745</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8746</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8747</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8748</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8749</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8750</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8751</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8752</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8753</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8754</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8755</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8756</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8757</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8758</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8759</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8760</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8761</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8762</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8763</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8764</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8765</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8766</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8767</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8768</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8769</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8770</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8771</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8772</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8773</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8774</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8775</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8776</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8777</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8778</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8779</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8780</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8781</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8782</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8783</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8784</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8785</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8786</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8787</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8788</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8789</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8790</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8791</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8792</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8793</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8794</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8795</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8796</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8797</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8798</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8799</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8800</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8801</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8802</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8803</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8804</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8805</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8806</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8807</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8808</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8809</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8810</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8811</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8812</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8813</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8814</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8815</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8816</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8817</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8818</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8819</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8820</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8821</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8822</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8823</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8824</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8825</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8826</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8827</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8828</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8829</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8830</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8831</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8832</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8833</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8834</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8835</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8836</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8837</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8838</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8839</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8840</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8841</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8842</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8843</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8844</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8845</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8846</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8847</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8848</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8849</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8850</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8851</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8852</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8853</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8854</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8855</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8856</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8857</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8858</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8859</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8860</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8861</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8862</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8863</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8864</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8865</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8866</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8867</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8868</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8869</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8870</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8871</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8872</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8873</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8874</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8875</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8876</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8877</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8878</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8879</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8880</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8881</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8882</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8883</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8884</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8885</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8886</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8887</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8888</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8889</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8890</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8891</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8892</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8893</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8894</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8895</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8896</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8897</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8898</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8899</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8900</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8901</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8902</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8903</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8904</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8905</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8906</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8907</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8908</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8909</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8910</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8911</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8912</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8913</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8914</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8915</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8916</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8917</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8918</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8919</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8920</th>\n",
       "      <th colspan=\"2\" halign=\"left\">8921</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key2</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>...</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>866.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>823.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>984.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>643.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>779.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>793.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>819.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1432.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>665.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>634.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>761.0</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31864.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>979.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>910.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>2533.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>20655.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>2654.0</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>4403.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>38786.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31812.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>993.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>623.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>691.0</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>8325.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>861.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>962.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27404.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>881.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1318.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>645.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>727.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>631.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>944.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>926.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>954.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>921.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31825.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>837.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>957.0</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>798.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>762.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>543.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>830.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>919.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>9881.0</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>22575.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>38759.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>914.0</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>21827.0</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>4784.0</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>4135.0</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>11934.0</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>9171.0</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>12081.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>27807.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31817.0</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>4253.0</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>3984.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>11603.0</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>5461.0</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>13066.0</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>946.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>11112.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>362.0</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>22557.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>38844.0</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>6105.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>930.0</td>\n",
       "      <td>3.929606e-07</td>\n",
       "      <td>43349.0</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>12844.0</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>3630.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31867.0</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>341.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>7976.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>12207.0</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>3174.0</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>2519.0</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>2563.0</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>607.0</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>4213.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>21779.0</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>3961.0</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>3151.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>16202.0</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>4947.0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>12344.0</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>14112.0</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>4389.0</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>5125.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>38662.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>691.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>988.0</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>22590.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18497.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>38707.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>868.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>922.0</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>22545.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>4104.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>798.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>5143.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>5058.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>2788.0</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>3777.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>752.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>859.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>861.0</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>22552.0</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>2763.0</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>5254.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>667.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>847.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>769.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>33918.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>19308.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>16688.0</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>10352.0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>11958.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>558.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>35857.0</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>5834.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>940.0</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>4599.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>607.0</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>5082.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>1822.0</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>2068.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>917.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27433.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>616.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>752.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>38744.0</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>4912.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>923.0</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>22557.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>815.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>11246.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>16674.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>19079.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>855.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>14786.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31824.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>871.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>689.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>289.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31854.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>718.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>38799.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>9967.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>686.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>720.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>767.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>820.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>38864.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27462.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>705.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>651.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>678.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>996.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>19290.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>20403.0</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>6418.0</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>10144.0</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>7278.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>47337.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>559.0</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>22557.0</td>\n",
       "      <td>-1.107487e-07</td>\n",
       "      <td>57246.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>4175.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>11307.0</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>...</td>\n",
       "      <td>12905.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>13841.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>769.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>11067.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>11085.0</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>9079.0</td>\n",
       "      <td>9.242802e-07</td>\n",
       "      <td>41954.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>2487.0</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>699.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>3243.0</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>6530.0</td>\n",
       "      <td>0.00026</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>7352.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31811.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>645.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>33701.0</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>2551.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>812.0</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>19617.0</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>-7.447866e-08</td>\n",
       "      <td>35617.0</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>12891.0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>14907.0</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>8785.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>27780.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>38672.0</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>9637.0</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>5444.0</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>6887.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>15997.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>35910.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>22051.0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>6222.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>14134.0</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>8560.0</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>11569.0</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>7137.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>5774.0</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>24694.0</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>3587.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>693.0</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>2853.0</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>4148.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>561.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>9693.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27432.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>30389.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>911.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>851.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>767.0</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>4730.0</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>8399.0</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>5219.0</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>10857.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>669.0</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>6527.0</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>878.0</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>3230.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>721.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>716.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>15372.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>9957.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>876.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31834.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>935.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>591.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>841.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>2075.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>12144.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1543.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>35900.0</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>859.0</td>\n",
       "      <td>7.732244e-07</td>\n",
       "      <td>54820.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>352.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>814.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>38120.0</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>22587.0</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>9907.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31858.0</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>4318.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>28358.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>21911.0</td>\n",
       "      <td>7.732244e-07</td>\n",
       "      <td>54855.0</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>3362.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27411.0</td>\n",
       "      <td>-6.477539e-08</td>\n",
       "      <td>26549.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27461.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>947.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>10011.0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>15277.0</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>21063.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27414.0</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1576.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>38662.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27419.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>2710.0</td>\n",
       "      <td>-3.151087e-08</td>\n",
       "      <td>36727.0</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>3267.0</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>362.0</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>8279.0</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>363.0</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>4262.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27422.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>825.0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>23976.0</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>15830.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>673.0</td>\n",
       "      <td>6.455791e-07</td>\n",
       "      <td>54799.0</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>22540.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27442.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>982.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>880.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>596.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>683.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>982.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31825.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>35938.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>15933.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>762.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>27439.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>17061.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>789.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>612.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>816.0</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>24146.0</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>2584.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>21887.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>14923.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>34985.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>16859.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>48540.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>38164.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>8733.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>527.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>12250.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>533.0</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>634.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31833.0</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1431.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>688.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>865.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>893.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>721.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>851.0</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>3322.0</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>6802.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>31362.0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>5943.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>38083.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>938.0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>2675.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>18955.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>33750.0</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>34174.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>2153.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>38636.0</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>11357.0</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>17134.0</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>9263.0</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>4159.0</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>5236.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>16826.0</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>33705.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>924.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>740.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>9752.0</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>819.0</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>5414.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>11115.0</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>22588.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>803.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>944.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>771.0</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>31821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22836.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55902.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56731.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41474.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55896.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39873.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56497.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40017.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57265.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42361.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32388.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41427.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>34233.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22865.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41427.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56847.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41432.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56849.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41432.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41428.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32395.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54132.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32397.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45617.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32391.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57274.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42345.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32398.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57094.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48713.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57063.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57159.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57155.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56480.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57154.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57183.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32385.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57057.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57180.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43613.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57037.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57108.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56736.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26544.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22837.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42468.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40018.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>43561.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57221.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57164.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32405.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57055.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57153.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57189.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57045.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57145.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57083.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37901.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57097.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56868.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57141.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43589.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57115.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57153.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32123.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54111.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48747.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57147.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57152.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57169.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57112.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42316.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48746.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42350.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41447.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22873.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32158.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42321.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32402.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26565.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55893.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22827.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48105.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42319.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26547.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56479.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41440.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48792.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26591.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57241.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41499.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56849.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22830.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48798.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56545.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22881.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41434.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41447.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46634.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41483.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46649.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57118.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42329.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57076.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56849.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37882.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57190.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57185.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56817.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57131.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>56562.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>27049.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55875.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26569.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42351.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57207.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26576.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26967.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41427.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34241.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54318.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32386.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32384.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55134.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57271.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55900.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42478.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42335.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22829.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56849.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22833.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32380.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41493.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39356.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>45623.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56475.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57190.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57232.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41407.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22825.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57209.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42959.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42981.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>54339.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57143.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32397.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26550.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26548.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57085.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>42461.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55096.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56875.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56824.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57030.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57115.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57136.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57073.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57195.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32386.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57260.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57179.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56849.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56740.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57005.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55897.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57148.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57020.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>35576.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56441.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57081.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57077.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56503.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42327.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56468.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57141.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57105.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32096.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37891.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43623.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57219.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37884.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57049.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56651.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56576.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57210.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57131.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42339.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57247.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56978.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41490.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57196.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57044.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57181.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41407.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41407.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41433.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32367.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43598.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22834.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>41496.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56508.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48736.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57141.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57152.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22835.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57150.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35582.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32388.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56971.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57181.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57288.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42354.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41428.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22839.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57109.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57165.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57276.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32396.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32379.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57277.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54132.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48713.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22879.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37894.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42458.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57234.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22860.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55891.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22861.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41472.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32409.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57162.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57205.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48742.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56539.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57234.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34256.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41501.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56849.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>26512.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57290.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48783.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>39983.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37913.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42311.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42324.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56594.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36707.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>36708.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26996.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56946.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57054.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56817.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57104.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22847.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57143.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26528.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57119.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>55900.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22844.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56849.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41433.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41406.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32393.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32389.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42324.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45600.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37903.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32066.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41406.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57164.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56849.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55110.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22835.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41406.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57050.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57197.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39339.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32111.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57165.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39313.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54124.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26997.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55114.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56828.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55897.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57028.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41407.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26973.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57303.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32394.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42365.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41428.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57183.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57233.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32401.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32080.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42459.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55886.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26543.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32086.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34197.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57256.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34200.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46663.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45627.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55102.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39826.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35548.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57251.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56526.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56517.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57221.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48112.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46650.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>27017.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34273.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32380.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57063.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56475.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26579.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22859.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22861.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22837.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55903.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56732.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41475.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55897.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39874.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56498.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40018.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57266.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42362.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32389.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56858.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41428.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>34234.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22866.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41428.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56848.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41426.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41433.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41433.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41429.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32396.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54133.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32398.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45618.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34251.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57275.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42346.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32399.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57095.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48714.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57064.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57160.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57156.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56481.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57155.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57184.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32386.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57058.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57181.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43614.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57038.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57109.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56737.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26545.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22838.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42469.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>43562.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57222.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57165.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32406.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57056.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57154.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57190.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57046.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57146.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57084.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37902.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57098.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56869.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57142.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43590.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57116.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57154.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32124.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54112.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48748.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57148.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57153.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57170.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57258.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57113.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42317.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48747.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42351.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41448.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22874.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32159.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42322.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32403.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26566.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55894.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22828.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48106.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42320.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26548.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56480.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41441.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48793.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26592.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57242.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22831.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48799.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56546.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22882.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41435.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41448.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46635.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41484.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46650.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57119.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42330.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57077.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37883.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57191.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57186.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56818.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57132.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>56563.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>27050.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55876.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26570.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42352.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57208.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26577.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26968.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41428.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34242.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54319.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32401.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32387.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56858.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32385.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55135.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57272.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55901.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42479.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42336.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22830.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22834.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32381.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41494.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39357.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>45624.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56476.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57191.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57233.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22826.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57210.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42960.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42982.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>54340.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57144.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32398.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26551.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26549.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57086.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>42462.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55097.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41426.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56876.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56825.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57031.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57116.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57137.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57074.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57196.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32387.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57261.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57180.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56741.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57006.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55898.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57149.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57021.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>35577.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56442.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57082.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57078.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56504.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42328.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56469.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57142.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57106.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32097.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37892.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43624.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57220.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37885.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57050.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56652.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56577.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57211.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57132.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42340.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57248.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56979.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41491.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57197.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57045.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57182.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41434.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32368.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43599.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22835.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>41497.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56509.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48737.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57142.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57153.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22836.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57151.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35583.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32389.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56972.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57182.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57289.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42355.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41429.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22840.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57110.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57166.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57277.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32397.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32380.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57278.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54133.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48714.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22880.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37895.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42459.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57235.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22861.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55892.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22862.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41473.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32410.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57163.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57206.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48743.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56540.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57235.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41502.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>26513.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57291.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48784.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>39984.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37914.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42312.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42325.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56595.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36708.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>36709.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26997.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56947.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57055.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56818.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57105.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22848.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57144.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26529.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57120.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>55901.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22845.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41434.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41407.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32394.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32390.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42325.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45601.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37904.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41407.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57165.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55111.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22836.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41407.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57051.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57198.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39340.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32112.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57166.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39314.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54125.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26998.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55115.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56829.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55898.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57029.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26974.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57304.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32395.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42366.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41429.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57184.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57234.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32402.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32081.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42460.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55887.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26544.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32087.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34198.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34201.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46664.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45628.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55103.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39827.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35549.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57252.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56527.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56518.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57222.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48113.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46651.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>27018.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34274.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32381.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57064.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56476.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26580.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22860.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22862.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22838.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56858.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55904.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56733.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41476.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55898.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39875.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56499.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57267.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42363.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32390.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56859.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41429.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>34235.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22867.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41429.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56849.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41427.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41434.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41434.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41430.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32397.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41426.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41426.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54134.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32399.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45619.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34252.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32393.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57276.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42347.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57096.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48715.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57065.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57161.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57157.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56482.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57156.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57185.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32387.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57059.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57182.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43615.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57039.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57110.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56738.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26546.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22839.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42470.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40020.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>43563.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57223.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57166.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32407.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57057.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57155.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57191.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57047.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57147.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57085.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37903.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57099.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56870.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57143.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43591.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57117.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57155.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32125.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54113.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48749.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57149.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57154.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57171.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57259.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57114.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42318.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48748.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42352.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41449.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22875.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32160.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42323.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32404.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26567.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55895.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22829.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48107.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42321.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26549.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56481.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41442.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48794.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26593.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41501.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22832.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48800.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56547.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22883.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41436.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41449.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46636.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41485.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46651.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57120.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42331.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57078.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37884.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57192.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57187.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56819.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56858.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57133.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>56564.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>27051.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55877.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26571.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42353.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57209.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26578.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26969.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41429.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34243.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54320.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32402.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32388.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56859.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32386.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55136.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57273.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41426.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55902.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42480.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42337.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22831.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22835.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32382.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41495.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39358.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>45625.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56477.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57192.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57234.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22827.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57211.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42961.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42983.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>54341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57145.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32399.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26552.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26550.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57087.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>42463.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55098.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41427.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56877.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56826.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57032.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57117.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57138.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57075.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57197.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32388.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57262.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57181.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56742.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57007.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55899.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57150.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57022.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>35578.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56443.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57083.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57079.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56505.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42329.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56470.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57143.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57107.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32098.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37893.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43625.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57221.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37886.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57051.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56653.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56578.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57212.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57133.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57249.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56980.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41492.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57198.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57046.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57183.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41435.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32369.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43600.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22836.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>41498.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56510.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48738.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57143.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57154.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22837.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57152.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35584.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32390.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56973.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57183.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57290.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42356.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41430.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56858.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22841.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57111.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57167.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57278.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32398.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32381.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57279.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54134.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48715.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22881.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37896.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42460.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57236.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22862.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55893.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22863.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41474.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32411.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57164.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57207.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48744.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56541.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57236.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34258.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41503.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>26514.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57292.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48785.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>39985.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37915.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42313.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42326.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56596.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36709.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>36710.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26998.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56948.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57056.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56819.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57106.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22849.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57145.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26530.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57121.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>55902.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22846.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41435.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32395.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32391.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42326.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45602.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37905.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32068.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57166.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56851.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55112.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22837.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57052.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57199.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39341.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32113.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57167.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39315.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54126.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26999.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55116.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56830.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55899.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57030.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26975.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57305.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32396.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42367.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56858.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41430.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57185.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57235.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32403.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32082.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42461.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55888.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26545.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32088.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34199.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57258.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34202.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46665.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45629.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55104.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39828.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35550.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57253.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56528.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56519.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57223.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48114.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46652.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>27019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34275.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32382.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57065.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56477.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26581.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22861.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22863.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22839.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56859.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55905.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56734.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41477.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55899.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39876.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56500.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40020.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57268.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42364.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32391.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56860.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41426.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41430.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>34236.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22868.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41430.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41426.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41428.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41435.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41435.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41431.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32398.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41427.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41427.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54135.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45620.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34253.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32394.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57277.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22858.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42348.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32401.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57097.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48716.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57066.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57162.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57158.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56483.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57157.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57186.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32388.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57060.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57183.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43616.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57040.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57111.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56739.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26547.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22840.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42471.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40021.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>43564.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57224.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57167.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32408.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57058.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57156.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57192.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57048.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57148.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57086.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37904.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56871.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57144.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43592.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57118.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57156.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32126.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54114.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48750.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57150.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57155.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57172.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57260.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57115.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42319.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41425.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48749.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42353.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41450.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22876.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32161.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42324.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32405.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26568.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55896.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22830.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48108.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42322.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26550.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56482.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41443.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48795.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26594.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57244.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41502.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22833.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48801.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56548.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22884.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41437.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41450.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46637.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41486.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46652.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57121.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42332.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57079.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37885.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57193.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57188.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56820.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56859.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57134.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>56565.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>27052.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55878.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26572.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42354.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57210.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26579.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26970.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41430.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34244.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54321.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32403.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32389.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56860.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32387.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55137.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57274.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41419.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41427.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55903.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42481.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42338.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22832.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22836.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32383.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41496.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39359.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>45626.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56478.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57193.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57235.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22828.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57212.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42962.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42984.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>54342.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57146.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26553.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26551.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57088.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>42464.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55099.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41428.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56878.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56827.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57033.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57118.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57139.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57076.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57198.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32389.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57263.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57182.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56743.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57008.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55900.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57151.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57023.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>35579.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56444.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57084.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57080.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56506.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42330.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56471.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57144.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57108.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32099.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37894.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43626.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57222.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37887.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57052.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56654.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56579.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57213.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57134.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42342.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56981.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41493.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57199.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57047.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57184.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41436.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32370.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43601.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22837.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>41499.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56511.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48739.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57144.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57155.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22838.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57153.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35585.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32391.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56974.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57184.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41426.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57291.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42357.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41431.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56859.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22842.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57112.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57168.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57279.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32399.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32382.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57280.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54135.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48716.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22882.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37897.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42461.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57237.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22863.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55894.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22864.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41475.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32412.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57165.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57208.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48745.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56542.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>57237.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34259.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41504.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>26515.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57293.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48786.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>39986.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37916.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42314.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42327.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56597.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36710.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>36711.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26999.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56949.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57057.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56820.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57107.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56857.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22850.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57146.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26531.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57122.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41414.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>55903.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22847.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41420.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41436.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41422.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32396.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32392.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42327.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45603.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41417.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37906.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32069.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57167.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56852.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55113.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22838.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41409.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56855.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57053.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57200.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39342.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32114.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57168.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39316.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54127.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55117.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56831.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55900.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41423.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57031.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41410.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26976.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>57306.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32397.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42368.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41413.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41411.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56853.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56859.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56858.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41431.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57186.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57236.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32404.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32083.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42462.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55889.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26546.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32089.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34200.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57259.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34203.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46666.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45630.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55105.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39829.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35551.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57254.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56529.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56520.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57224.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48115.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46653.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>27020.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34276.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56856.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41412.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32383.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57066.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41418.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56478.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41421.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26582.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22862.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41416.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41424.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22864.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41426.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41415.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>32388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17844 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label        0                    1                    2              \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022    866.0    0.000011   1022.0    0.000022   1156.0   \n",
       "1        0.000000  56854.0    0.000000  41418.0    0.000000  56853.0   \n",
       "2        0.000000  56855.0    0.000000  41419.0    0.000000  56854.0   \n",
       "3        0.000000  56856.0    0.000000  41420.0    0.000000  56855.0   \n",
       "4        0.000000  56857.0    0.000000  41421.0    0.000000  56856.0   \n",
       "\n",
       "label        3                    4                    5              \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    823.0    0.000033    984.0    0.000011    643.0   \n",
       "1        0.000000  41410.0    0.000000  22836.0    0.000000  41413.0   \n",
       "2        0.000000  41411.0    0.000000  22837.0    0.000000  41414.0   \n",
       "3        0.000000  41412.0    0.000000  22838.0    0.000000  41415.0   \n",
       "4        0.000000  41413.0    0.000000  22839.0    0.000000  41416.0   \n",
       "\n",
       "label        6                    7                    8              \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    779.0    0.000011    793.0    0.000022   1005.0   \n",
       "1        0.000000  41417.0    0.000000  41416.0    0.000000  56856.0   \n",
       "2        0.000000  41418.0    0.000000  41417.0    0.000000  56857.0   \n",
       "3        0.000000  41419.0    0.000000  41418.0    0.000000  56858.0   \n",
       "4        0.000000  41420.0    0.000000  41419.0    0.000000  56859.0   \n",
       "\n",
       "label        9                    10                   11             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    819.0    0.000011    850.0    0.000065   1432.0   \n",
       "1        0.000000  41417.0    0.000000  41422.0    0.000000  55902.0   \n",
       "2        0.000000  41418.0    0.000000  41423.0    0.000000  55903.0   \n",
       "3        0.000000  41419.0    0.000000  41424.0    0.000000  55904.0   \n",
       "4        0.000000  41420.0    0.000000  41425.0    0.000000  55905.0   \n",
       "\n",
       "label        12                   13                   14             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    665.0    0.000011    634.0    0.000011    761.0   \n",
       "1        0.000000  41409.0    0.000000  41409.0    0.000000  41409.0   \n",
       "2        0.000000  41410.0    0.000000  41410.0    0.000000  41410.0   \n",
       "3        0.000000  41411.0    0.000000  41411.0    0.000000  41411.0   \n",
       "4        0.000000  41412.0    0.000000  41412.0    0.000000  41412.0   \n",
       "\n",
       "label        15                   16                     17             \\\n",
       "key2  mutual_info     rank mutual_info     rank   mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.001175   1270.0    0.000011   1595.0  6.888287e-07  31864.0   \n",
       "1        0.000000  56731.0    0.000000  41474.0  0.000000e+00  32418.0   \n",
       "2        0.000000  56732.0    0.000000  41475.0  0.000000e+00  32419.0   \n",
       "3        0.000000  56733.0    0.000000  41476.0  0.000000e+00  32420.0   \n",
       "4        0.000000  56734.0    0.000000  41477.0  0.000000e+00  32421.0   \n",
       "\n",
       "label        18                   19                   20             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    979.0    0.000022    910.0    0.000065   1142.0   \n",
       "1        0.000000  41419.0    0.000000  56852.0    0.000000  55896.0   \n",
       "2        0.000000  41420.0    0.000000  56853.0    0.000000  55897.0   \n",
       "3        0.000000  41421.0    0.000000  56854.0    0.000000  55898.0   \n",
       "4        0.000000  41422.0    0.000000  56855.0    0.000000  55899.0   \n",
       "\n",
       "label        21                   22                   23             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000185   2533.0    0.000036  20655.0    0.000109   2654.0   \n",
       "1        0.000000  39873.0    0.000000  56497.0    0.000000  40017.0   \n",
       "2        0.000000  39874.0    0.000000  56498.0    0.000000  40018.0   \n",
       "3        0.000000  39875.0    0.000000  56499.0    0.000000  40019.0   \n",
       "4        0.000000  39876.0    0.000000  56500.0    0.000000  40020.0   \n",
       "\n",
       "label        24                   25                     26             \\\n",
       "key2  mutual_info     rank mutual_info     rank   mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000062   4403.0    0.000004  38786.0  6.888287e-07  31812.0   \n",
       "1        0.000000  57265.0    0.000000  42361.0  0.000000e+00  32388.0   \n",
       "2        0.000000  57266.0    0.000000  42362.0  0.000000e+00  32389.0   \n",
       "3        0.000000  57267.0    0.000000  42363.0  0.000000e+00  32390.0   \n",
       "4        0.000000  57268.0    0.000000  42364.0  0.000000e+00  32391.0   \n",
       "\n",
       "label        27                   28                   29             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022   1300.0    0.000011    993.0    0.000011    623.0   \n",
       "1        0.000000  56857.0    0.000000  41423.0    0.000000  41408.0   \n",
       "2        0.000000  56858.0    0.000000  41424.0    0.000000  41409.0   \n",
       "3        0.000000  56859.0    0.000000  41425.0    0.000000  41410.0   \n",
       "4        0.000000  56860.0    0.000000  41426.0    0.000000  41411.0   \n",
       "\n",
       "label        30                   31                   32             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011   1039.0    0.000011    691.0     0.00002   8325.0   \n",
       "1        0.000000  41427.0    0.000000  41415.0     0.00000  34233.0   \n",
       "2        0.000000  41428.0    0.000000  41416.0     0.00000  34234.0   \n",
       "3        0.000000  41429.0    0.000000  41417.0     0.00000  34235.0   \n",
       "4        0.000000  41430.0    0.000000  41418.0     0.00000  34236.0   \n",
       "\n",
       "label        33                   34                   35             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    861.0    0.000022   1068.0    0.000011   1063.0   \n",
       "1        0.000000  41412.0    0.000000  56853.0    0.000000  41415.0   \n",
       "2        0.000000  41413.0    0.000000  56854.0    0.000000  41416.0   \n",
       "3        0.000000  41414.0    0.000000  56855.0    0.000000  41417.0   \n",
       "4        0.000000  41415.0    0.000000  56856.0    0.000000  41418.0   \n",
       "\n",
       "label        36                   37                   38             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    962.0    0.000033   1250.0    0.000011   1039.0   \n",
       "1        0.000000  41419.0    0.000000  22865.0    0.000000  41427.0   \n",
       "2        0.000000  41420.0    0.000000  22866.0    0.000000  41428.0   \n",
       "3        0.000000  41421.0    0.000000  22867.0    0.000000  41429.0   \n",
       "4        0.000000  41422.0    0.000000  22868.0    0.000000  41430.0   \n",
       "\n",
       "label        39                   40                   41             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000006  27404.0    0.000011    881.0    0.000011    614.0   \n",
       "1        0.000000  56847.0    0.000000  41418.0    0.000000  41409.0   \n",
       "2        0.000000  56848.0    0.000000  41419.0    0.000000  41410.0   \n",
       "3        0.000000  56849.0    0.000000  41420.0    0.000000  41411.0   \n",
       "4        0.000000  56850.0    0.000000  41421.0    0.000000  41412.0   \n",
       "\n",
       "label        42                   43                   44             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    960.0    0.000011   1304.0    0.000011   1318.0   \n",
       "1        0.000000  41423.0    0.000000  41425.0    0.000000  41432.0   \n",
       "2        0.000000  41424.0    0.000000  41426.0    0.000000  41433.0   \n",
       "3        0.000000  41425.0    0.000000  41427.0    0.000000  41434.0   \n",
       "4        0.000000  41426.0    0.000000  41428.0    0.000000  41435.0   \n",
       "\n",
       "label        45                   46                   47             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022    645.0    0.000011    727.0    0.000022    631.0   \n",
       "1        0.000000  56850.0    0.000000  41418.0    0.000000  56849.0   \n",
       "2        0.000000  56851.0    0.000000  41419.0    0.000000  56850.0   \n",
       "3        0.000000  56852.0    0.000000  41420.0    0.000000  56851.0   \n",
       "4        0.000000  56853.0    0.000000  41421.0    0.000000  56852.0   \n",
       "\n",
       "label        48                   49                   50             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011   1340.0    0.000011    944.0    0.000011   1098.0   \n",
       "1        0.000000  41432.0    0.000000  41418.0    0.000000  41428.0   \n",
       "2        0.000000  41433.0    0.000000  41419.0    0.000000  41429.0   \n",
       "3        0.000000  41434.0    0.000000  41420.0    0.000000  41430.0   \n",
       "4        0.000000  41435.0    0.000000  41421.0    0.000000  41431.0   \n",
       "\n",
       "label        51                   52                   53             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000044    926.0    0.000011   1074.0    0.000011   1391.0   \n",
       "1        0.000000  32395.0    0.000000  41416.0    0.000000  41424.0   \n",
       "2        0.000000  32396.0    0.000000  41417.0    0.000000  41425.0   \n",
       "3        0.000000  32397.0    0.000000  41418.0    0.000000  41426.0   \n",
       "4        0.000000  32398.0    0.000000  41419.0    0.000000  41427.0   \n",
       "\n",
       "label        54                   55                   56             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    954.0    0.000011    921.0    0.000109   1642.0   \n",
       "1        0.000000  41424.0    0.000000  41416.0    0.000000  54132.0   \n",
       "2        0.000000  41425.0    0.000000  41417.0    0.000000  54133.0   \n",
       "3        0.000000  41426.0    0.000000  41418.0    0.000000  54134.0   \n",
       "4        0.000000  41427.0    0.000000  41419.0    0.000000  54135.0   \n",
       "\n",
       "label          57                   58                   59             \\\n",
       "key2    mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0      6.888287e-07  31825.0    0.000011    837.0    0.000011    768.0   \n",
       "1      0.000000e+00  32397.0    0.000000  41422.0    0.000000  41415.0   \n",
       "2      0.000000e+00  32398.0    0.000000  41423.0    0.000000  41416.0   \n",
       "3      0.000000e+00  32399.0    0.000000  41424.0    0.000000  41417.0   \n",
       "4      0.000000e+00  32400.0    0.000000  41425.0    0.000000  41418.0   \n",
       "\n",
       "label        60                   61                   62             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000067   2603.0    0.000022    957.0    0.000174   1894.0   \n",
       "1        0.000000  45617.0    0.000000  56852.0    0.000000  34250.0   \n",
       "2        0.000000  45618.0    0.000000  56853.0    0.000000  34251.0   \n",
       "3        0.000000  45619.0    0.000000  56854.0    0.000000  34252.0   \n",
       "4        0.000000  45620.0    0.000000  56855.0    0.000000  34253.0   \n",
       "\n",
       "label        63                   64                   65             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022    798.0    0.000044    762.0    0.000022   1003.0   \n",
       "1        0.000000  56850.0    0.000000  32391.0    0.000000  56850.0   \n",
       "2        0.000000  56851.0    0.000000  32392.0    0.000000  56851.0   \n",
       "3        0.000000  56852.0    0.000000  32393.0    0.000000  56852.0   \n",
       "4        0.000000  56853.0    0.000000  32394.0    0.000000  56853.0   \n",
       "\n",
       "label        66                   67                   68             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000038    543.0    0.000022    830.0    0.000011    919.0   \n",
       "1        0.000000  41415.0    0.000000  56850.0    0.000000  41412.0   \n",
       "2        0.000000  41416.0    0.000000  56851.0    0.000000  41413.0   \n",
       "3        0.000000  41417.0    0.000000  56852.0    0.000000  41414.0   \n",
       "4        0.000000  41418.0    0.000000  56853.0    0.000000  41415.0   \n",
       "\n",
       "label        69                     70                   71             \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000034   9881.0  3.375316e-07  22575.0    0.000004  38759.0   \n",
       "1        0.000000  57274.0  0.000000e+00  22855.0    0.000000  42345.0   \n",
       "2        0.000000  57275.0  0.000000e+00  22856.0    0.000000  42346.0   \n",
       "3        0.000000  57276.0  0.000000e+00  22857.0    0.000000  42347.0   \n",
       "4        0.000000  57277.0  0.000000e+00  22858.0    0.000000  42348.0   \n",
       "\n",
       "label        72                   73                   74             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000044   1226.0    0.000011    914.0    0.000841   3295.0   \n",
       "1        0.000000  32398.0    0.000000  41411.0    0.000000  57094.0   \n",
       "2        0.000000  32399.0    0.000000  41412.0    0.000000  57095.0   \n",
       "3        0.000000  32400.0    0.000000  41413.0    0.000000  57096.0   \n",
       "4        0.000000  32401.0    0.000000  41414.0    0.000000  57097.0   \n",
       "\n",
       "label        75                   76                   77             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000025  21827.0    0.000475   4784.0    0.000511   4135.0   \n",
       "1        0.000000  48713.0    0.000000  57063.0    0.000000  57159.0   \n",
       "2        0.000000  48714.0    0.000000  57064.0    0.000000  57160.0   \n",
       "3        0.000000  48715.0    0.000000  57065.0    0.000000  57161.0   \n",
       "4        0.000000  48716.0    0.000000  57066.0    0.000000  57162.0   \n",
       "\n",
       "label        78                   79                   80             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000099  11934.0    0.000119   9171.0    0.000087  12081.0   \n",
       "1        0.000000  57155.0    0.000000  56480.0    0.000000  57154.0   \n",
       "2        0.000000  57156.0    0.000000  56481.0    0.000000  57155.0   \n",
       "3        0.000000  57157.0    0.000000  56482.0    0.000000  57156.0   \n",
       "4        0.000000  57158.0    0.000000  56483.0    0.000000  57157.0   \n",
       "\n",
       "label        81                     82                   83             \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000018  27807.0  6.888287e-07  31817.0     0.00054   4253.0   \n",
       "1        0.000000  57183.0  0.000000e+00  32385.0     0.00000  57057.0   \n",
       "2        0.000000  57184.0  0.000000e+00  32386.0     0.00000  57058.0   \n",
       "3        0.000000  57185.0  0.000000e+00  32387.0     0.00000  57059.0   \n",
       "4        0.000000  57186.0  0.000000e+00  32388.0     0.00000  57060.0   \n",
       "\n",
       "label        84                   85                   86             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000423   3984.0    0.000044  11603.0    0.000408   5461.0   \n",
       "1        0.000000  57180.0    0.000000  43613.0    0.000000  57037.0   \n",
       "2        0.000000  57181.0    0.000000  43614.0    0.000000  57038.0   \n",
       "3        0.000000  57182.0    0.000000  43615.0    0.000000  57039.0   \n",
       "4        0.000000  57183.0    0.000000  43616.0    0.000000  57040.0   \n",
       "\n",
       "label        87                   88                   89             \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000105  13066.0    0.002299    946.0    0.000014  11112.0   \n",
       "1        0.000000  57108.0    0.000000  56736.0    0.000000  26544.0   \n",
       "2        0.000000  57109.0    0.000000  56737.0    0.000000  26545.0   \n",
       "3        0.000000  57110.0    0.000000  56738.0    0.000000  26546.0   \n",
       "4        0.000000  57111.0    0.000000  56739.0    0.000000  26547.0   \n",
       "\n",
       "label        90                     91                   92             \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000038    362.0  3.375316e-07  22557.0    0.000004  38844.0   \n",
       "1        0.000000  41409.0  0.000000e+00  22837.0    0.000000  42468.0   \n",
       "2        0.000000  41410.0  0.000000e+00  22838.0    0.000000  42469.0   \n",
       "3        0.000000  41411.0  0.000000e+00  22839.0    0.000000  42470.0   \n",
       "4        0.000000  41412.0  0.000000e+00  22840.0    0.000000  42471.0   \n",
       "\n",
       "label        93                   94                     95             \\\n",
       "key2  mutual_info     rank mutual_info     rank   mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000068   6105.0    0.000022    930.0  3.929606e-07  43349.0   \n",
       "1        0.000000  40018.0    0.000000  56851.0  0.000000e+00  43561.0   \n",
       "2        0.000000  40019.0    0.000000  56852.0  0.000000e+00  43562.0   \n",
       "3        0.000000  40020.0    0.000000  56853.0  0.000000e+00  43563.0   \n",
       "4        0.000000  40021.0    0.000000  56854.0  0.000000e+00  43564.0   \n",
       "\n",
       "label        96                   97                     98             \\\n",
       "key2  mutual_info     rank mutual_info     rank   mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000049  12844.0    0.000228   3630.0  6.888287e-07  31867.0   \n",
       "1        0.000000  57221.0    0.000000  57164.0  0.000000e+00  32405.0   \n",
       "2        0.000000  57222.0    0.000000  57165.0  0.000000e+00  32406.0   \n",
       "3        0.000000  57223.0    0.000000  57166.0  0.000000e+00  32407.0   \n",
       "4        0.000000  57224.0    0.000000  57167.0  0.000000e+00  32408.0   \n",
       "\n",
       "label        99                   100                  101            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.001934    341.0    0.000044   1252.0    0.000168   7976.0   \n",
       "1        0.000000  57055.0    0.000000  32410.0    0.000000  57153.0   \n",
       "2        0.000000  57056.0    0.000000  32411.0    0.000000  57154.0   \n",
       "3        0.000000  57057.0    0.000000  32412.0    0.000000  57155.0   \n",
       "4        0.000000  57058.0    0.000000  32413.0    0.000000  57156.0   \n",
       "\n",
       "label        102                  103                  104            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000067  12207.0    0.001052   1028.0    0.000813   3174.0   \n",
       "1        0.000000  57189.0    0.000000  57045.0    0.000000  57145.0   \n",
       "2        0.000000  57190.0    0.000000  57046.0    0.000000  57146.0   \n",
       "3        0.000000  57191.0    0.000000  57047.0    0.000000  57147.0   \n",
       "4        0.000000  57192.0    0.000000  57048.0    0.000000  57148.0   \n",
       "\n",
       "label        105                  106                  107            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000731   3219.0    0.000059   2519.0    0.000798   2563.0   \n",
       "1        0.000000  57083.0    0.000000  37901.0    0.000000  57097.0   \n",
       "2        0.000000  57084.0    0.000000  37902.0    0.000000  57098.0   \n",
       "3        0.000000  57085.0    0.000000  37903.0    0.000000  57099.0   \n",
       "4        0.000000  57086.0    0.000000  37904.0    0.000000  57100.0   \n",
       "\n",
       "label        108                  109                  110            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.001044    607.0    0.000593   4213.0    0.000025  21779.0   \n",
       "1        0.000000  56868.0    0.000000  57141.0    0.000000  43589.0   \n",
       "2        0.000000  56869.0    0.000000  57142.0    0.000000  43590.0   \n",
       "3        0.000000  56870.0    0.000000  57143.0    0.000000  43591.0   \n",
       "4        0.000000  56871.0    0.000000  57144.0    0.000000  43592.0   \n",
       "\n",
       "label        111                  112                  113            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000537   3961.0    0.001456   1087.0    0.000051   3151.0   \n",
       "1        0.000000  57115.0    0.000000  57153.0    0.000000  32123.0   \n",
       "2        0.000000  57116.0    0.000000  57154.0    0.000000  32124.0   \n",
       "3        0.000000  57117.0    0.000000  57155.0    0.000000  32125.0   \n",
       "4        0.000000  57118.0    0.000000  57156.0    0.000000  32126.0   \n",
       "\n",
       "label        114                  115                  116            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000109   1348.0    0.000044  16202.0    0.000457   4947.0   \n",
       "1        0.000000  54111.0    0.000000  48747.0    0.000000  57147.0   \n",
       "2        0.000000  54112.0    0.000000  48748.0    0.000000  57148.0   \n",
       "3        0.000000  54113.0    0.000000  48749.0    0.000000  57149.0   \n",
       "4        0.000000  54114.0    0.000000  48750.0    0.000000  57150.0   \n",
       "\n",
       "label        117                  118                  119            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000101  12344.0    0.000059  14112.0    0.000062   4389.0   \n",
       "1        0.000000  57152.0    0.000000  57169.0    0.000000  57257.0   \n",
       "2        0.000000  57153.0    0.000000  57170.0    0.000000  57258.0   \n",
       "3        0.000000  57154.0    0.000000  57171.0    0.000000  57259.0   \n",
       "4        0.000000  57155.0    0.000000  57172.0    0.000000  57260.0   \n",
       "\n",
       "label        120                  121                  122            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000472   5125.0    0.000011    758.0    0.000004  38662.0   \n",
       "1        0.000000  57112.0    0.000000  41412.0    0.000000  42316.0   \n",
       "2        0.000000  57113.0    0.000000  41413.0    0.000000  42317.0   \n",
       "3        0.000000  57114.0    0.000000  41414.0    0.000000  42318.0   \n",
       "4        0.000000  57115.0    0.000000  41415.0    0.000000  42319.0   \n",
       "\n",
       "label        123                  124                    125            \\\n",
       "key2  mutual_info     rank mutual_info     rank   mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000011    691.0    0.000011    988.0  3.375316e-07  22590.0   \n",
       "1        0.000000  41413.0    0.000000  41422.0  0.000000e+00  22854.0   \n",
       "2        0.000000  41414.0    0.000000  41423.0  0.000000e+00  22855.0   \n",
       "3        0.000000  41415.0    0.000000  41424.0  0.000000e+00  22856.0   \n",
       "4        0.000000  41416.0    0.000000  41425.0  0.000000e+00  22857.0   \n",
       "\n",
       "label        126                  127                  128            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000026  18497.0    0.000054   1316.0    0.000038    205.0   \n",
       "1        0.000000  48746.0    0.000000  42350.0    0.000000  41411.0   \n",
       "2        0.000000  48747.0    0.000000  42351.0    0.000000  41412.0   \n",
       "3        0.000000  48748.0    0.000000  42352.0    0.000000  41413.0   \n",
       "4        0.000000  48749.0    0.000000  42353.0    0.000000  41414.0   \n",
       "\n",
       "label        129                  130                  131            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011   1759.0    0.000033   1132.0    0.000051   3409.0   \n",
       "1        0.000000  41447.0    0.000000  22873.0    0.000000  32158.0   \n",
       "2        0.000000  41448.0    0.000000  22874.0    0.000000  32159.0   \n",
       "3        0.000000  41449.0    0.000000  22875.0    0.000000  32160.0   \n",
       "4        0.000000  41450.0    0.000000  22876.0    0.000000  32161.0   \n",
       "\n",
       "label        132                  133                  134            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000033   1141.0    0.000004  38707.0    0.000044   1385.0   \n",
       "1        0.000000  22852.0    0.000000  42321.0    0.000000  32402.0   \n",
       "2        0.000000  22853.0    0.000000  42322.0    0.000000  32403.0   \n",
       "3        0.000000  22854.0    0.000000  42323.0    0.000000  32404.0   \n",
       "4        0.000000  22855.0    0.000000  42324.0    0.000000  32405.0   \n",
       "\n",
       "label        135                  136                  137            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000076   1162.0    0.000065   1308.0    0.000022    868.0   \n",
       "1        0.000000  26565.0    0.000000  55893.0    0.000000  56851.0   \n",
       "2        0.000000  26566.0    0.000000  55894.0    0.000000  56852.0   \n",
       "3        0.000000  26567.0    0.000000  55895.0    0.000000  56853.0   \n",
       "4        0.000000  26568.0    0.000000  55896.0    0.000000  56854.0   \n",
       "\n",
       "label        138                    139                  140            \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000022    922.0  3.375316e-07  22545.0    0.000011    847.0   \n",
       "1        0.000000  56851.0  0.000000e+00  22827.0    0.000000  41415.0   \n",
       "2        0.000000  56852.0  0.000000e+00  22828.0    0.000000  41416.0   \n",
       "3        0.000000  56853.0  0.000000e+00  22829.0    0.000000  41417.0   \n",
       "4        0.000000  56854.0  0.000000e+00  22830.0    0.000000  41418.0   \n",
       "\n",
       "label        141                  142                  143            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000143   4104.0    0.000022    736.0    0.000054    798.0   \n",
       "1        0.000000  48105.0    0.000000  56852.0    0.000000  42319.0   \n",
       "2        0.000000  48106.0    0.000000  56853.0    0.000000  42320.0   \n",
       "3        0.000000  48107.0    0.000000  56854.0    0.000000  42321.0   \n",
       "4        0.000000  48108.0    0.000000  56855.0    0.000000  42322.0   \n",
       "\n",
       "label        144                  145                  146            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022    694.0    0.000076   1255.0    0.000181   5143.0   \n",
       "1        0.000000  56851.0    0.000000  26547.0    0.000000  56479.0   \n",
       "2        0.000000  56852.0    0.000000  26548.0    0.000000  56480.0   \n",
       "3        0.000000  56853.0    0.000000  26549.0    0.000000  56481.0   \n",
       "4        0.000000  56854.0    0.000000  26550.0    0.000000  56482.0   \n",
       "\n",
       "label        147                  148                  149            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011   1493.0    0.000082   5058.0    0.000022   1198.0   \n",
       "1        0.000000  41440.0    0.000000  48792.0    0.000000  56853.0   \n",
       "2        0.000000  41441.0    0.000000  48793.0    0.000000  56854.0   \n",
       "3        0.000000  41442.0    0.000000  48794.0    0.000000  56855.0   \n",
       "4        0.000000  41443.0    0.000000  48795.0    0.000000  56856.0   \n",
       "\n",
       "label        150                  151                  152            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022   1205.0    0.000076   1750.0    0.000236   2788.0   \n",
       "1        0.000000  56854.0    0.000000  26591.0    0.000000  57241.0   \n",
       "2        0.000000  56855.0    0.000000  26592.0    0.000000  57242.0   \n",
       "3        0.000000  56856.0    0.000000  26593.0    0.000000  57243.0   \n",
       "4        0.000000  56857.0    0.000000  26594.0    0.000000  57244.0   \n",
       "\n",
       "label        153                  154                  155            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000077   3777.0    0.000011    752.0    0.000011    859.0   \n",
       "1        0.000000  41499.0    0.000000  41411.0    0.000000  41418.0   \n",
       "2        0.000000  41500.0    0.000000  41412.0    0.000000  41419.0   \n",
       "3        0.000000  41501.0    0.000000  41413.0    0.000000  41420.0   \n",
       "4        0.000000  41502.0    0.000000  41414.0    0.000000  41421.0   \n",
       "\n",
       "label        156                  157                    158            \\\n",
       "key2  mutual_info     rank mutual_info     rank   mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000022   1002.0    0.000011    861.0  3.375316e-07  22552.0   \n",
       "1        0.000000  56849.0    0.000000  41412.0  0.000000e+00  22830.0   \n",
       "2        0.000000  56850.0    0.000000  41413.0  0.000000e+00  22831.0   \n",
       "3        0.000000  56851.0    0.000000  41414.0  0.000000e+00  22832.0   \n",
       "4        0.000000  56852.0    0.000000  41415.0  0.000000e+00  22833.0   \n",
       "\n",
       "label        159                  160                  161            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000187   2763.0    0.000327   5254.0    0.000011    667.0   \n",
       "1        0.000000  48798.0    0.000000  56545.0    0.000000  41410.0   \n",
       "2        0.000000  48799.0    0.000000  56546.0    0.000000  41411.0   \n",
       "3        0.000000  48800.0    0.000000  56547.0    0.000000  41412.0   \n",
       "4        0.000000  48801.0    0.000000  56548.0    0.000000  41413.0   \n",
       "\n",
       "label        162                  163                  164            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000033   1238.0    0.000011   1074.0    0.000011    847.0   \n",
       "1        0.000000  22881.0    0.000000  41434.0    0.000000  41415.0   \n",
       "2        0.000000  22882.0    0.000000  41435.0    0.000000  41416.0   \n",
       "3        0.000000  22883.0    0.000000  41436.0    0.000000  41417.0   \n",
       "4        0.000000  22884.0    0.000000  41437.0    0.000000  41418.0   \n",
       "\n",
       "label        165                  166                  167            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011   1759.0    0.000011    960.0    0.000011    769.0   \n",
       "1        0.000000  41447.0    0.000000  41419.0    0.000000  41416.0   \n",
       "2        0.000000  41448.0    0.000000  41420.0    0.000000  41417.0   \n",
       "3        0.000000  41449.0    0.000000  41421.0    0.000000  41418.0   \n",
       "4        0.000000  41450.0    0.000000  41422.0    0.000000  41419.0   \n",
       "\n",
       "label        168                  169                  170            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011   1024.0    0.000011   1024.0    0.000038    225.0   \n",
       "1        0.000000  41420.0    0.000000  41420.0    0.000000  41408.0   \n",
       "2        0.000000  41421.0    0.000000  41421.0    0.000000  41409.0   \n",
       "3        0.000000  41422.0    0.000000  41422.0    0.000000  41410.0   \n",
       "4        0.000000  41423.0    0.000000  41423.0    0.000000  41411.0   \n",
       "\n",
       "label        171                  172                  173            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000007  33918.0    0.000019  19308.0    0.000025  16688.0   \n",
       "1        0.000000  46634.0    0.000000  41483.0    0.000000  46649.0   \n",
       "2        0.000000  46635.0    0.000000  41484.0    0.000000  46650.0   \n",
       "3        0.000000  46636.0    0.000000  41485.0    0.000000  46651.0   \n",
       "4        0.000000  46637.0    0.000000  41486.0    0.000000  46652.0   \n",
       "\n",
       "label        174                  175                  176            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0         0.00012  10352.0    0.000031   1613.0    0.000105  11958.0   \n",
       "1         0.00000  57118.0    0.000000  42329.0    0.000000  57076.0   \n",
       "2         0.00000  57119.0    0.000000  42330.0    0.000000  57077.0   \n",
       "3         0.00000  57120.0    0.000000  42331.0    0.000000  57078.0   \n",
       "4         0.00000  57121.0    0.000000  42332.0    0.000000  57079.0   \n",
       "\n",
       "label        177                  178                  179            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022    558.0    0.000004  35857.0    0.000283   5834.0   \n",
       "1        0.000000  56849.0    0.000000  37882.0    0.000000  57190.0   \n",
       "2        0.000000  56850.0    0.000000  37883.0    0.000000  57191.0   \n",
       "3        0.000000  56851.0    0.000000  37884.0    0.000000  57192.0   \n",
       "4        0.000000  56852.0    0.000000  37885.0    0.000000  57193.0   \n",
       "\n",
       "label        180                  181                  182            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    940.0    0.000204   4599.0    0.000011    661.0   \n",
       "1        0.000000  41419.0    0.000000  57185.0    0.000000  41410.0   \n",
       "2        0.000000  41420.0    0.000000  57186.0    0.000000  41411.0   \n",
       "3        0.000000  41421.0    0.000000  57187.0    0.000000  41412.0   \n",
       "4        0.000000  41422.0    0.000000  57188.0    0.000000  41413.0   \n",
       "\n",
       "label        183                  184                  185            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000038    607.0    0.000306   5082.0    0.000022    995.0   \n",
       "1        0.000000  41414.0    0.000000  56817.0    0.000000  56856.0   \n",
       "2        0.000000  41415.0    0.000000  56818.0    0.000000  56857.0   \n",
       "3        0.000000  41416.0    0.000000  56819.0    0.000000  56858.0   \n",
       "4        0.000000  41417.0    0.000000  56820.0    0.000000  56859.0   \n",
       "\n",
       "label        186                  187                  188            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000745   1822.0     0.00012   8192.0    0.000011    768.0   \n",
       "1        0.000000  57131.0     0.00000  56562.0    0.000000  41408.0   \n",
       "2        0.000000  57132.0     0.00000  56563.0    0.000000  41409.0   \n",
       "3        0.000000  57133.0     0.00000  56564.0    0.000000  41410.0   \n",
       "4        0.000000  57134.0     0.00000  56565.0    0.000000  41411.0   \n",
       "\n",
       "label        189                  190                  191            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0         0.00012   2068.0    0.000022    917.0    0.000006  27433.0   \n",
       "1         0.00000  27049.0    0.000000  56853.0    0.000000  56853.0   \n",
       "2         0.00000  27050.0    0.000000  56854.0    0.000000  56854.0   \n",
       "3         0.00000  27051.0    0.000000  56855.0    0.000000  56855.0   \n",
       "4         0.00000  27052.0    0.000000  56856.0    0.000000  56856.0   \n",
       "\n",
       "label        192                  193                  194            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    616.0    0.000065    752.0    0.000076   1154.0   \n",
       "1        0.000000  41412.0    0.000000  55875.0    0.000000  26569.0   \n",
       "2        0.000000  41413.0    0.000000  55876.0    0.000000  26570.0   \n",
       "3        0.000000  41414.0    0.000000  55877.0    0.000000  26571.0   \n",
       "4        0.000000  41415.0    0.000000  55878.0    0.000000  26572.0   \n",
       "\n",
       "label        195                  196                  197            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000004  38744.0    0.000457   4912.0    0.000022    923.0   \n",
       "1        0.000000  42351.0    0.000000  57207.0    0.000000  56852.0   \n",
       "2        0.000000  42352.0    0.000000  57208.0    0.000000  56853.0   \n",
       "3        0.000000  42353.0    0.000000  57209.0    0.000000  56854.0   \n",
       "4        0.000000  42354.0    0.000000  57210.0    0.000000  56855.0   \n",
       "\n",
       "label          198                  199                  200            \\\n",
       "key2    mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0      3.375316e-07  22557.0    0.000022   1148.0    0.000022    815.0   \n",
       "1      0.000000e+00  22850.0    0.000000  56853.0    0.000000  56852.0   \n",
       "2      0.000000e+00  22851.0    0.000000  56854.0    0.000000  56853.0   \n",
       "3      0.000000e+00  22852.0    0.000000  56855.0    0.000000  56854.0   \n",
       "4      0.000000e+00  22853.0    0.000000  56856.0    0.000000  56855.0   \n",
       "\n",
       "label        201                  202                  203            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000014  11246.0    0.000011   1057.0    0.000012  16674.0   \n",
       "1        0.000000  26576.0    0.000000  41416.0    0.000000  26967.0   \n",
       "2        0.000000  26577.0    0.000000  41417.0    0.000000  26968.0   \n",
       "3        0.000000  26578.0    0.000000  41418.0    0.000000  26969.0   \n",
       "4        0.000000  26579.0    0.000000  41419.0    0.000000  26970.0   \n",
       "\n",
       "label        204                  205                  206            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011   1028.0    0.000015  19079.0    0.000011    855.0   \n",
       "1        0.000000  41427.0    0.000000  34241.0    0.000000  41421.0   \n",
       "2        0.000000  41428.0    0.000000  34242.0    0.000000  41422.0   \n",
       "3        0.000000  41429.0    0.000000  34243.0    0.000000  41423.0   \n",
       "4        0.000000  41430.0    0.000000  34244.0    0.000000  41424.0   \n",
       "\n",
       "label        207                    208                  209            \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000054  14786.0  6.888287e-07  31824.0    0.000022    871.0   \n",
       "1        0.000000  54318.0  0.000000e+00  32400.0    0.000000  56851.0   \n",
       "2        0.000000  54319.0  0.000000e+00  32401.0    0.000000  56852.0   \n",
       "3        0.000000  54320.0  0.000000e+00  32402.0    0.000000  56853.0   \n",
       "4        0.000000  54321.0  0.000000e+00  32403.0    0.000000  56854.0   \n",
       "\n",
       "label        210                    211                  212            \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000011    689.0  6.888287e-07  31836.0    0.000022    770.0   \n",
       "1        0.000000  41408.0  0.000000e+00  32386.0    0.000000  56857.0   \n",
       "2        0.000000  41409.0  0.000000e+00  32387.0    0.000000  56858.0   \n",
       "3        0.000000  41410.0  0.000000e+00  32388.0    0.000000  56859.0   \n",
       "4        0.000000  41411.0  0.000000e+00  32389.0    0.000000  56860.0   \n",
       "\n",
       "label        213                  214                  215            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    781.0    0.000011    850.0    0.000038    289.0   \n",
       "1        0.000000  41412.0    0.000000  41418.0    0.000000  41411.0   \n",
       "2        0.000000  41413.0    0.000000  41419.0    0.000000  41412.0   \n",
       "3        0.000000  41414.0    0.000000  41420.0    0.000000  41413.0   \n",
       "4        0.000000  41415.0    0.000000  41421.0    0.000000  41414.0   \n",
       "\n",
       "label          216                  217                  218            \\\n",
       "key2    mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0      6.888287e-07  31854.0    0.000011    718.0    0.000011  38799.0   \n",
       "1      0.000000e+00  32384.0    0.000000  41410.0    0.000000  55134.0   \n",
       "2      0.000000e+00  32385.0    0.000000  41411.0    0.000000  55135.0   \n",
       "3      0.000000e+00  32386.0    0.000000  41412.0    0.000000  55136.0   \n",
       "4      0.000000e+00  32387.0    0.000000  41413.0    0.000000  55137.0   \n",
       "\n",
       "label        219                  220                  221            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000034   9967.0    0.000011    602.0    0.000011    686.0   \n",
       "1        0.000000  57271.0    0.000000  41408.0    0.000000  41419.0   \n",
       "2        0.000000  57272.0    0.000000  41409.0    0.000000  41420.0   \n",
       "3        0.000000  57273.0    0.000000  41410.0    0.000000  41421.0   \n",
       "4        0.000000  57274.0    0.000000  41411.0    0.000000  41422.0   \n",
       "\n",
       "label        222                  223                  224            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    720.0    0.000011    767.0    0.000038    166.0   \n",
       "1        0.000000  41416.0    0.000000  41424.0    0.000000  41410.0   \n",
       "2        0.000000  41417.0    0.000000  41425.0    0.000000  41411.0   \n",
       "3        0.000000  41418.0    0.000000  41426.0    0.000000  41412.0   \n",
       "4        0.000000  41419.0    0.000000  41427.0    0.000000  41413.0   \n",
       "\n",
       "label        225                  226                  227            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022    820.0    0.000065   1284.0    0.000004  38864.0   \n",
       "1        0.000000  56850.0    0.000000  55900.0    0.000000  42478.0   \n",
       "2        0.000000  56851.0    0.000000  55901.0    0.000000  42479.0   \n",
       "3        0.000000  56852.0    0.000000  55902.0    0.000000  42480.0   \n",
       "4        0.000000  56853.0    0.000000  55903.0    0.000000  42481.0   \n",
       "\n",
       "label        228                  229                  230            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000006  27462.0    0.000011    743.0    0.000054   1089.0   \n",
       "1        0.000000  56852.0    0.000000  41420.0    0.000000  42335.0   \n",
       "2        0.000000  56853.0    0.000000  41421.0    0.000000  42336.0   \n",
       "3        0.000000  56854.0    0.000000  41422.0    0.000000  42337.0   \n",
       "4        0.000000  56855.0    0.000000  41423.0    0.000000  42338.0   \n",
       "\n",
       "label        231                  232                  233            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000028    705.0    0.000038    245.0    0.000022    651.0   \n",
       "1        0.000000  22829.0    0.000000  41408.0    0.000000  56849.0   \n",
       "2        0.000000  22830.0    0.000000  41409.0    0.000000  56850.0   \n",
       "3        0.000000  22831.0    0.000000  41410.0    0.000000  56851.0   \n",
       "4        0.000000  22832.0    0.000000  41411.0    0.000000  56852.0   \n",
       "\n",
       "label        234                  235                  236            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000033    678.0    0.000044    996.0    0.000019  19290.0   \n",
       "1        0.000000  22833.0    0.000000  32380.0    0.000000  41493.0   \n",
       "2        0.000000  22834.0    0.000000  32381.0    0.000000  41494.0   \n",
       "3        0.000000  22835.0    0.000000  32382.0    0.000000  41495.0   \n",
       "4        0.000000  22836.0    0.000000  32383.0    0.000000  41496.0   \n",
       "\n",
       "label        237                  238                  239            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    844.0    0.000023  20403.0     0.00004   6418.0   \n",
       "1        0.000000  41418.0    0.000000  39356.0     0.00000  45623.0   \n",
       "2        0.000000  41419.0    0.000000  39357.0     0.00000  45624.0   \n",
       "3        0.000000  41420.0    0.000000  39358.0     0.00000  45625.0   \n",
       "4        0.000000  41421.0    0.000000  39359.0     0.00000  45626.0   \n",
       "\n",
       "label        240                  241                  242            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000138  10144.0    0.000158   7278.0    0.000005  47337.0   \n",
       "1        0.000000  56475.0    0.000000  57190.0    0.000000  57232.0   \n",
       "2        0.000000  56476.0    0.000000  57191.0    0.000000  57233.0   \n",
       "3        0.000000  56477.0    0.000000  57192.0    0.000000  57234.0   \n",
       "4        0.000000  56478.0    0.000000  57193.0    0.000000  57235.0   \n",
       "\n",
       "label        243                    244                    245            \\\n",
       "key2  mutual_info     rank   mutual_info     rank   mutual_info     rank   \n",
       "token                                                                      \n",
       "0        0.000011    559.0  3.375316e-07  22557.0 -1.107487e-07  57246.0   \n",
       "1        0.000000  41407.0  0.000000e+00  22825.0  0.000000e+00  57209.0   \n",
       "2        0.000000  41408.0  0.000000e+00  22826.0  0.000000e+00  57210.0   \n",
       "3        0.000000  41409.0  0.000000e+00  22827.0  0.000000e+00  57211.0   \n",
       "4        0.000000  41410.0  0.000000e+00  22828.0  0.000000e+00  57212.0   \n",
       "\n",
       "label        246                  247                  248            \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022   1119.0    0.000116   4175.0    0.000054  11307.0   \n",
       "1        0.000000  56851.0    0.000000  42959.0    0.000000  42981.0   \n",
       "2        0.000000  56852.0    0.000000  42960.0    0.000000  42982.0   \n",
       "3        0.000000  56853.0    0.000000  42961.0    0.000000  42983.0   \n",
       "4        0.000000  56854.0    0.000000  42962.0    0.000000  42984.0   \n",
       "\n",
       "label        249   ...     8672        8673                 8674           \\\n",
       "key2  mutual_info  ...     rank mutual_info     rank mutual_info     rank   \n",
       "token              ...                                                      \n",
       "0         0.00014  ...  12905.0    0.000065  13841.0    0.000011    769.0   \n",
       "1         0.00000  ...  54339.0    0.000000  57143.0    0.000000  41417.0   \n",
       "2         0.00000  ...  54340.0    0.000000  57144.0    0.000000  41418.0   \n",
       "3         0.00000  ...  54341.0    0.000000  57145.0    0.000000  41419.0   \n",
       "4         0.00000  ...  54342.0    0.000000  57146.0    0.000000  41420.0   \n",
       "\n",
       "label        8675                 8676                 8677           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000044   1234.0    0.000014  11067.0    0.000014  11085.0   \n",
       "1        0.000000  32397.0    0.000000  26550.0    0.000000  26548.0   \n",
       "2        0.000000  32398.0    0.000000  26551.0    0.000000  26549.0   \n",
       "3        0.000000  32399.0    0.000000  26552.0    0.000000  26550.0   \n",
       "4        0.000000  32400.0    0.000000  26553.0    0.000000  26551.0   \n",
       "\n",
       "label        8678                   8679                 8680           \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000159   9079.0  9.242802e-07  41954.0    0.000011    701.0   \n",
       "1        0.000000  57085.0  0.000000e+00  42461.0    0.000000  41412.0   \n",
       "2        0.000000  57086.0  0.000000e+00  42462.0    0.000000  41413.0   \n",
       "3        0.000000  57087.0  0.000000e+00  42463.0    0.000000  41414.0   \n",
       "4        0.000000  57088.0  0.000000e+00  42464.0    0.000000  41415.0   \n",
       "\n",
       "label        8681                 8682                 8683           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000093   2769.0    0.000011   1075.0    0.000484   2487.0   \n",
       "1        0.000000  55096.0    0.000000  41425.0    0.000000  56875.0   \n",
       "2        0.000000  55097.0    0.000000  41426.0    0.000000  56876.0   \n",
       "3        0.000000  55098.0    0.000000  41427.0    0.000000  56877.0   \n",
       "4        0.000000  55099.0    0.000000  41428.0    0.000000  56878.0   \n",
       "\n",
       "label        8684                 8685                 8686           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.001038    699.0    0.000022    738.0    0.000559   4254.0   \n",
       "1        0.000000  56824.0    0.000000  56852.0    0.000000  57030.0   \n",
       "2        0.000000  56825.0    0.000000  56853.0    0.000000  57031.0   \n",
       "3        0.000000  56826.0    0.000000  56854.0    0.000000  57032.0   \n",
       "4        0.000000  56827.0    0.000000  56855.0    0.000000  57033.0   \n",
       "\n",
       "label        8687                 8688                 8689           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000676   3243.0    0.000243   6530.0     0.00026   6160.0   \n",
       "1        0.000000  57115.0    0.000000  57136.0     0.00000  57073.0   \n",
       "2        0.000000  57116.0    0.000000  57137.0     0.00000  57074.0   \n",
       "3        0.000000  57117.0    0.000000  57138.0     0.00000  57075.0   \n",
       "4        0.000000  57118.0    0.000000  57139.0     0.00000  57076.0   \n",
       "\n",
       "label        8690                   8691                 8692           \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000135   7352.0  6.888287e-07  31811.0    0.000011    645.0   \n",
       "1        0.000000  57195.0  0.000000e+00  32386.0    0.000000  41413.0   \n",
       "2        0.000000  57196.0  0.000000e+00  32387.0    0.000000  41414.0   \n",
       "3        0.000000  57197.0  0.000000e+00  32388.0    0.000000  41415.0   \n",
       "4        0.000000  57198.0  0.000000e+00  32389.0    0.000000  41416.0   \n",
       "\n",
       "label        8693                 8694                 8695           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011  33701.0    0.000371   2551.0    0.000022    657.0   \n",
       "1        0.000000  57260.0    0.000000  57179.0    0.000000  56849.0   \n",
       "2        0.000000  57261.0    0.000000  57180.0    0.000000  56850.0   \n",
       "3        0.000000  57262.0    0.000000  57181.0    0.000000  56851.0   \n",
       "4        0.000000  57263.0    0.000000  57182.0    0.000000  56852.0   \n",
       "\n",
       "label        8696                 8697                 8698           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    554.0    0.000963    812.0    0.000899   1591.0   \n",
       "1        0.000000  41408.0    0.000000  56740.0    0.000000  57005.0   \n",
       "2        0.000000  41409.0    0.000000  56741.0    0.000000  57006.0   \n",
       "3        0.000000  41410.0    0.000000  56742.0    0.000000  57007.0   \n",
       "4        0.000000  41411.0    0.000000  56743.0    0.000000  57008.0   \n",
       "\n",
       "label        8699                 8700                 8701           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000065   1297.0    0.000046  19617.0    0.001333   1326.0   \n",
       "1        0.000000  55897.0    0.000000  57148.0    0.000000  57020.0   \n",
       "2        0.000000  55898.0    0.000000  57149.0    0.000000  57021.0   \n",
       "3        0.000000  55899.0    0.000000  57150.0    0.000000  57022.0   \n",
       "4        0.000000  55900.0    0.000000  57151.0    0.000000  57023.0   \n",
       "\n",
       "label          8702                 8703                 8704           \\\n",
       "key2    mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0     -7.447866e-08  35617.0    0.000085  12891.0    0.000064  14907.0   \n",
       "1      0.000000e+00  35576.0    0.000000  56441.0    0.000000  57081.0   \n",
       "2      0.000000e+00  35577.0    0.000000  56442.0    0.000000  57082.0   \n",
       "3      0.000000e+00  35578.0    0.000000  56443.0    0.000000  57083.0   \n",
       "4      0.000000e+00  35579.0    0.000000  56444.0    0.000000  57084.0   \n",
       "\n",
       "label        8705                 8706                 8707           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000166   8785.0    0.000016  27780.0    0.000004  38672.0   \n",
       "1        0.000000  57077.0    0.000000  56503.0    0.000000  42327.0   \n",
       "2        0.000000  57078.0    0.000000  56504.0    0.000000  42328.0   \n",
       "3        0.000000  57079.0    0.000000  56505.0    0.000000  42329.0   \n",
       "4        0.000000  57080.0    0.000000  56506.0    0.000000  42330.0   \n",
       "\n",
       "label        8708                 8709                 8710           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000112   9637.0    0.000264   5444.0    0.000209   6887.0   \n",
       "1        0.000000  56468.0    0.000000  57141.0    0.000000  57105.0   \n",
       "2        0.000000  56469.0    0.000000  57142.0    0.000000  57106.0   \n",
       "3        0.000000  56470.0    0.000000  57143.0    0.000000  57107.0   \n",
       "4        0.000000  56471.0    0.000000  57144.0    0.000000  57108.0   \n",
       "\n",
       "label        8711                 8712                 8713           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000016  15997.0    0.000004  35910.0    0.000021  22051.0   \n",
       "1        0.000000  32096.0    0.000000  37891.0    0.000000  43623.0   \n",
       "2        0.000000  32097.0    0.000000  37892.0    0.000000  43624.0   \n",
       "3        0.000000  32098.0    0.000000  37893.0    0.000000  43625.0   \n",
       "4        0.000000  32099.0    0.000000  37894.0    0.000000  43626.0   \n",
       "\n",
       "label        8714                 8715                 8716           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000101   6222.0    0.000022  14134.0    0.000163   8560.0   \n",
       "1        0.000000  57219.0    0.000000  37884.0    0.000000  57049.0   \n",
       "2        0.000000  57220.0    0.000000  37885.0    0.000000  57050.0   \n",
       "3        0.000000  57221.0    0.000000  37886.0    0.000000  57051.0   \n",
       "4        0.000000  57222.0    0.000000  37887.0    0.000000  57052.0   \n",
       "\n",
       "label        8717                 8718                 8719           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000932   1113.0    0.000727   1554.0    0.000071  11569.0   \n",
       "1        0.000000  56651.0    0.000000  56576.0    0.000000  57210.0   \n",
       "2        0.000000  56652.0    0.000000  56577.0    0.000000  57211.0   \n",
       "3        0.000000  56653.0    0.000000  56578.0    0.000000  57212.0   \n",
       "4        0.000000  56654.0    0.000000  56579.0    0.000000  57213.0   \n",
       "\n",
       "label        8720                 8721                 8722           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000226   7137.0    0.000054   1158.0    0.000148   5774.0   \n",
       "1        0.000000  57131.0    0.000000  42339.0    0.000000  57247.0   \n",
       "2        0.000000  57132.0    0.000000  42340.0    0.000000  57248.0   \n",
       "3        0.000000  57133.0    0.000000  42341.0    0.000000  57249.0   \n",
       "4        0.000000  57134.0    0.000000  42342.0    0.000000  57250.0   \n",
       "\n",
       "label        8723                 8724                 8725           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000601   2473.0    0.000011  24694.0     0.00063   3587.0   \n",
       "1        0.000000  56978.0    0.000000  41490.0     0.00000  57196.0   \n",
       "2        0.000000  56979.0    0.000000  41491.0     0.00000  57197.0   \n",
       "3        0.000000  56980.0    0.000000  41492.0     0.00000  57198.0   \n",
       "4        0.000000  56981.0    0.000000  41493.0     0.00000  57199.0   \n",
       "\n",
       "label        8726                 8727                 8728           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    693.0    0.000772   2853.0    0.000249   4148.0   \n",
       "1        0.000000  41417.0    0.000000  57044.0    0.000000  57181.0   \n",
       "2        0.000000  41418.0    0.000000  57045.0    0.000000  57182.0   \n",
       "3        0.000000  41419.0    0.000000  57046.0    0.000000  57183.0   \n",
       "4        0.000000  41420.0    0.000000  57047.0    0.000000  57184.0   \n",
       "\n",
       "label        8729                 8730                 8731           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000038    297.0    0.000011    561.0    0.000011   1407.0   \n",
       "1        0.000000  41407.0    0.000000  41407.0    0.000000  41433.0   \n",
       "2        0.000000  41408.0    0.000000  41408.0    0.000000  41434.0   \n",
       "3        0.000000  41409.0    0.000000  41409.0    0.000000  41435.0   \n",
       "4        0.000000  41410.0    0.000000  41410.0    0.000000  41436.0   \n",
       "\n",
       "label        8732                 8733                 8734           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    900.0    0.000011   9693.0    0.000006  27432.0   \n",
       "1        0.000000  41418.0    0.000000  32367.0    0.000000  56852.0   \n",
       "2        0.000000  41419.0    0.000000  32368.0    0.000000  56853.0   \n",
       "3        0.000000  41420.0    0.000000  32369.0    0.000000  56854.0   \n",
       "4        0.000000  41421.0    0.000000  32370.0    0.000000  56855.0   \n",
       "\n",
       "label        8735                 8736                 8737           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000008  30389.0    0.000011    911.0    0.000033    851.0   \n",
       "1        0.000000  43598.0    0.000000  41420.0    0.000000  22834.0   \n",
       "2        0.000000  43599.0    0.000000  41421.0    0.000000  22835.0   \n",
       "3        0.000000  43600.0    0.000000  41422.0    0.000000  22836.0   \n",
       "4        0.000000  43601.0    0.000000  41423.0    0.000000  22837.0   \n",
       "\n",
       "label        8738                 8739                 8740           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    767.0     0.00013   1934.0    0.000216   4730.0   \n",
       "1        0.000000  41414.0     0.00000  41496.0    0.000000  56508.0   \n",
       "2        0.000000  41415.0     0.00000  41497.0    0.000000  56509.0   \n",
       "3        0.000000  41416.0     0.00000  41498.0    0.000000  56510.0   \n",
       "4        0.000000  41417.0     0.00000  41499.0    0.000000  56511.0   \n",
       "\n",
       "label        8741                 8742                 8743           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000069   8399.0    0.000375   5219.0    0.000105  10857.0   \n",
       "1        0.000000  48736.0    0.000000  57141.0    0.000000  57152.0   \n",
       "2        0.000000  48737.0    0.000000  57142.0    0.000000  57153.0   \n",
       "3        0.000000  48738.0    0.000000  57143.0    0.000000  57154.0   \n",
       "4        0.000000  48739.0    0.000000  57144.0    0.000000  57155.0   \n",
       "\n",
       "label        8744                 8745                 8746           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000033    669.0    0.000247   6527.0    0.000121   1893.0   \n",
       "1        0.000000  22835.0    0.000000  57150.0    0.000000  35582.0   \n",
       "2        0.000000  22836.0    0.000000  57151.0    0.000000  35583.0   \n",
       "3        0.000000  22837.0    0.000000  57152.0    0.000000  35584.0   \n",
       "4        0.000000  22838.0    0.000000  57153.0    0.000000  35585.0   \n",
       "\n",
       "label        8747                 8748                 8749           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000044    878.0    0.002699    560.0    0.000792   3230.0   \n",
       "1        0.000000  32388.0    0.000000  56971.0    0.000000  57181.0   \n",
       "2        0.000000  32389.0    0.000000  56972.0    0.000000  57182.0   \n",
       "3        0.000000  32390.0    0.000000  56973.0    0.000000  57183.0   \n",
       "4        0.000000  32391.0    0.000000  56974.0    0.000000  57184.0   \n",
       "\n",
       "label        8750                 8751                 8752           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011   1105.0    0.003815   1022.0    0.000038    310.0   \n",
       "1        0.000000  41423.0    0.000000  57288.0    0.000000  41410.0   \n",
       "2        0.000000  41424.0    0.000000  57289.0    0.000000  41411.0   \n",
       "3        0.000000  41425.0    0.000000  57290.0    0.000000  41412.0   \n",
       "4        0.000000  41426.0    0.000000  57291.0    0.000000  41413.0   \n",
       "\n",
       "label        8753                 8754                 8755           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000085    252.0    0.000038    721.0    0.000076    104.0   \n",
       "1        0.000000  42354.0    0.000000  41428.0    0.000000  56856.0   \n",
       "2        0.000000  42355.0    0.000000  41429.0    0.000000  56857.0   \n",
       "3        0.000000  42356.0    0.000000  41430.0    0.000000  56858.0   \n",
       "4        0.000000  42357.0    0.000000  41431.0    0.000000  56859.0   \n",
       "\n",
       "label        8756                 8757                 8758           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    674.0    0.000011    724.0    0.000011    716.0   \n",
       "1        0.000000  41417.0    0.000000  41412.0    0.000000  41417.0   \n",
       "2        0.000000  41418.0    0.000000  41413.0    0.000000  41418.0   \n",
       "3        0.000000  41419.0    0.000000  41414.0    0.000000  41419.0   \n",
       "4        0.000000  41420.0    0.000000  41415.0    0.000000  41420.0   \n",
       "\n",
       "label        8759                 8760                 8761           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000033    735.0    0.000064  15372.0    0.000104   9957.0   \n",
       "1        0.000000  22839.0    0.000000  57109.0    0.000000  57165.0   \n",
       "2        0.000000  22840.0    0.000000  57110.0    0.000000  57166.0   \n",
       "3        0.000000  22841.0    0.000000  57111.0    0.000000  57167.0   \n",
       "4        0.000000  22842.0    0.000000  57112.0    0.000000  57168.0   \n",
       "\n",
       "label        8762                 8763                 8764           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000076   1820.0    0.000022   1061.0    0.000011    876.0   \n",
       "1        0.000000  57276.0    0.000000  56854.0    0.000000  41413.0   \n",
       "2        0.000000  57277.0    0.000000  56855.0    0.000000  41414.0   \n",
       "3        0.000000  57278.0    0.000000  56856.0    0.000000  41415.0   \n",
       "4        0.000000  57279.0    0.000000  56857.0    0.000000  41416.0   \n",
       "\n",
       "label          8765                 8766                 8767           \\\n",
       "key2    mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0      6.888287e-07  31834.0    0.000022    935.0    0.000044    591.0   \n",
       "1      0.000000e+00  32396.0    0.000000  56850.0    0.000000  32379.0   \n",
       "2      0.000000e+00  32397.0    0.000000  56851.0    0.000000  32380.0   \n",
       "3      0.000000e+00  32398.0    0.000000  56852.0    0.000000  32381.0   \n",
       "4      0.000000e+00  32399.0    0.000000  56853.0    0.000000  32382.0   \n",
       "\n",
       "label        8768                 8769                 8770           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    841.0    0.000076   2075.0    0.000109   1075.0   \n",
       "1        0.000000  41414.0    0.000000  57277.0    0.000000  54132.0   \n",
       "2        0.000000  41415.0    0.000000  57278.0    0.000000  54133.0   \n",
       "3        0.000000  41416.0    0.000000  57279.0    0.000000  54134.0   \n",
       "4        0.000000  41417.0    0.000000  57280.0    0.000000  54135.0   \n",
       "\n",
       "label        8771                 8772                 8773           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000046  12144.0    0.000033   1543.0    0.000004  35900.0   \n",
       "1        0.000000  48713.0    0.000000  22879.0    0.000000  37894.0   \n",
       "2        0.000000  48714.0    0.000000  22880.0    0.000000  37895.0   \n",
       "3        0.000000  48715.0    0.000000  22881.0    0.000000  37896.0   \n",
       "4        0.000000  48716.0    0.000000  22882.0    0.000000  37897.0   \n",
       "\n",
       "label        8774                   8775                 8776           \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000098    859.0  7.732244e-07  54820.0    0.000011    746.0   \n",
       "1        0.000000  42458.0  0.000000e+00  57234.0    0.000000  41410.0   \n",
       "2        0.000000  42459.0  0.000000e+00  57235.0    0.000000  41411.0   \n",
       "3        0.000000  42460.0  0.000000e+00  57236.0    0.000000  41412.0   \n",
       "4        0.000000  42461.0  0.000000e+00  57237.0    0.000000  41413.0   \n",
       "\n",
       "label        8777                 8778                 8779           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000038    352.0    0.000011    814.0    0.000033   1362.0   \n",
       "1        0.000000  41409.0    0.000000  41415.0    0.000000  22860.0   \n",
       "2        0.000000  41410.0    0.000000  41416.0    0.000000  22861.0   \n",
       "3        0.000000  41411.0    0.000000  41417.0    0.000000  22862.0   \n",
       "4        0.000000  41412.0    0.000000  41418.0    0.000000  22863.0   \n",
       "\n",
       "label        8780                   8781                 8782           \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000008  38120.0  3.375316e-07  22587.0    0.000042   9907.0   \n",
       "1        0.000000  55891.0  0.000000e+00  22861.0    0.000000  41472.0   \n",
       "2        0.000000  55892.0  0.000000e+00  22862.0    0.000000  41473.0   \n",
       "3        0.000000  55893.0  0.000000e+00  22863.0    0.000000  41474.0   \n",
       "4        0.000000  55894.0  0.000000e+00  22864.0    0.000000  41475.0   \n",
       "\n",
       "label          8783                 8784                 8785           \\\n",
       "key2    mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0      6.888287e-07  31858.0     0.00028   4500.0    0.000175   4318.0   \n",
       "1      0.000000e+00  32409.0     0.00000  57162.0    0.000000  57205.0   \n",
       "2      0.000000e+00  32410.0     0.00000  57163.0    0.000000  57206.0   \n",
       "3      0.000000e+00  32411.0     0.00000  57164.0    0.000000  57207.0   \n",
       "4      0.000000e+00  32412.0     0.00000  57165.0    0.000000  57208.0   \n",
       "\n",
       "label        8786                 8787                   8788           \\\n",
       "key2  mutual_info     rank mutual_info     rank   mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000017  28358.0    0.000026  21911.0  7.732244e-07  54855.0   \n",
       "1        0.000000  48742.0    0.000000  56539.0  0.000000e+00  57234.0   \n",
       "2        0.000000  48743.0    0.000000  56540.0  0.000000e+00  57235.0   \n",
       "3        0.000000  48744.0    0.000000  56541.0  0.000000e+00  57236.0   \n",
       "4        0.000000  48745.0    0.000000  56542.0  0.000000e+00  57237.0   \n",
       "\n",
       "label        8789                 8790                 8791           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000087    928.0    0.000077   3362.0    0.000006  27411.0   \n",
       "1        0.000000  34256.0    0.000000  41501.0    0.000000  56849.0   \n",
       "2        0.000000  34257.0    0.000000  41502.0    0.000000  56850.0   \n",
       "3        0.000000  34258.0    0.000000  41503.0    0.000000  56851.0   \n",
       "4        0.000000  34259.0    0.000000  41504.0    0.000000  56852.0   \n",
       "\n",
       "label          8792                 8793                 8794           \\\n",
       "key2    mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0     -6.477539e-08  26549.0    0.000006  27461.0    0.000022    947.0   \n",
       "1      0.000000e+00  26512.0    0.000000  56852.0    0.000000  56852.0   \n",
       "2      0.000000e+00  26513.0    0.000000  56853.0    0.000000  56853.0   \n",
       "3      0.000000e+00  26514.0    0.000000  56854.0    0.000000  56854.0   \n",
       "4      0.000000e+00  26515.0    0.000000  56855.0    0.000000  56855.0   \n",
       "\n",
       "label        8795                 8796                 8797           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022   1107.0    0.000034  10011.0    0.000046  15277.0   \n",
       "1        0.000000  56852.0    0.000000  57290.0    0.000000  48783.0   \n",
       "2        0.000000  56853.0    0.000000  57291.0    0.000000  48784.0   \n",
       "3        0.000000  56854.0    0.000000  57292.0    0.000000  48785.0   \n",
       "4        0.000000  56855.0    0.000000  57293.0    0.000000  48786.0   \n",
       "\n",
       "label        8798                 8799                 8800           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0         0.00002  21063.0    0.000006  27414.0    0.000142   1576.0   \n",
       "1         0.00000  39983.0    0.000000  56852.0    0.000000  37913.0   \n",
       "2         0.00000  39984.0    0.000000  56853.0    0.000000  37914.0   \n",
       "3         0.00000  39985.0    0.000000  56854.0    0.000000  37915.0   \n",
       "4         0.00000  39986.0    0.000000  56855.0    0.000000  37916.0   \n",
       "\n",
       "label        8801                 8802                 8803           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000004  38662.0    0.000038    147.0    0.000006  27419.0   \n",
       "1        0.000000  42311.0    0.000000  41408.0    0.000000  56850.0   \n",
       "2        0.000000  42312.0    0.000000  41409.0    0.000000  56851.0   \n",
       "3        0.000000  42313.0    0.000000  41410.0    0.000000  56852.0   \n",
       "4        0.000000  42314.0    0.000000  41411.0    0.000000  56853.0   \n",
       "\n",
       "label        8804                 8805                 8806           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022   1280.0    0.000031   1203.0    0.003367    368.0   \n",
       "1        0.000000  56850.0    0.000000  42324.0    0.000000  56594.0   \n",
       "2        0.000000  56851.0    0.000000  42325.0    0.000000  56595.0   \n",
       "3        0.000000  56852.0    0.000000  42326.0    0.000000  56596.0   \n",
       "4        0.000000  56853.0    0.000000  42327.0    0.000000  56597.0   \n",
       "\n",
       "label        8807                   8808                 8809           \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000101   2710.0 -3.151087e-08  36727.0    0.000042   3267.0   \n",
       "1        0.000000  36707.0  0.000000e+00  36708.0    0.000000  26996.0   \n",
       "2        0.000000  36708.0  0.000000e+00  36709.0    0.000000  26997.0   \n",
       "3        0.000000  36709.0  0.000000e+00  36710.0    0.000000  26998.0   \n",
       "4        0.000000  36710.0  0.000000e+00  36711.0    0.000000  26999.0   \n",
       "\n",
       "label        8810                 8811                 8812           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.002355    362.0     0.00018   8279.0    0.003803    363.0   \n",
       "1        0.000000  56946.0     0.00000  57054.0    0.000000  56817.0   \n",
       "2        0.000000  56947.0     0.00000  57055.0    0.000000  56818.0   \n",
       "3        0.000000  56948.0     0.00000  57056.0    0.000000  56819.0   \n",
       "4        0.000000  56949.0     0.00000  57057.0    0.000000  56820.0   \n",
       "\n",
       "label        8813                 8814                 8815           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0         0.00039   4262.0    0.000006  27422.0    0.000033    825.0   \n",
       "1         0.00000  57104.0    0.000000  56854.0    0.000000  22847.0   \n",
       "2         0.00000  57105.0    0.000000  56855.0    0.000000  22848.0   \n",
       "3         0.00000  57106.0    0.000000  56856.0    0.000000  22849.0   \n",
       "4         0.00000  57107.0    0.000000  56857.0    0.000000  22850.0   \n",
       "\n",
       "label        8816                 8817                 8818           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000026  23976.0    0.000267    152.0    0.000077  15830.0   \n",
       "1        0.000000  57143.0    0.000000  26528.0    0.000000  57119.0   \n",
       "2        0.000000  57144.0    0.000000  26529.0    0.000000  57120.0   \n",
       "3        0.000000  57145.0    0.000000  26530.0    0.000000  57121.0   \n",
       "4        0.000000  57146.0    0.000000  26531.0    0.000000  57122.0   \n",
       "\n",
       "label        8819                   8820                   8821           \\\n",
       "key2  mutual_info     rank   mutual_info     rank   mutual_info     rank   \n",
       "token                                                                      \n",
       "0        0.000011    673.0  6.455791e-07  54799.0  3.375316e-07  22540.0   \n",
       "1        0.000000  41411.0  0.000000e+00  55900.0  0.000000e+00  22844.0   \n",
       "2        0.000000  41412.0  0.000000e+00  55901.0  0.000000e+00  22845.0   \n",
       "3        0.000000  41413.0  0.000000e+00  55902.0  0.000000e+00  22846.0   \n",
       "4        0.000000  41414.0  0.000000e+00  55903.0  0.000000e+00  22847.0   \n",
       "\n",
       "label        8822                 8823                 8824           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    806.0    0.000006  27442.0    0.000011    697.0   \n",
       "1        0.000000  41417.0    0.000000  56849.0    0.000000  41412.0   \n",
       "2        0.000000  41418.0    0.000000  56850.0    0.000000  41413.0   \n",
       "3        0.000000  41419.0    0.000000  56851.0    0.000000  41414.0   \n",
       "4        0.000000  41420.0    0.000000  56852.0    0.000000  41415.0   \n",
       "\n",
       "label        8825                 8826                 8827           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    982.0    0.000038    374.0    0.000011    880.0   \n",
       "1        0.000000  41433.0    0.000000  41415.0    0.000000  41419.0   \n",
       "2        0.000000  41434.0    0.000000  41416.0    0.000000  41420.0   \n",
       "3        0.000000  41435.0    0.000000  41417.0    0.000000  41421.0   \n",
       "4        0.000000  41436.0    0.000000  41418.0    0.000000  41422.0   \n",
       "\n",
       "label        8828                 8829                 8830           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    596.0    0.000011    683.0    0.000038    230.0   \n",
       "1        0.000000  41410.0    0.000000  41408.0    0.000000  41406.0   \n",
       "2        0.000000  41411.0    0.000000  41409.0    0.000000  41407.0   \n",
       "3        0.000000  41412.0    0.000000  41410.0    0.000000  41408.0   \n",
       "4        0.000000  41413.0    0.000000  41411.0    0.000000  41409.0   \n",
       "\n",
       "label        8831                   8832                 8833           \\\n",
       "key2  mutual_info     rank   mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0        0.000044    982.0  6.888287e-07  31825.0    0.000011    685.0   \n",
       "1        0.000000  32393.0  0.000000e+00  32389.0    0.000000  41410.0   \n",
       "2        0.000000  32394.0  0.000000e+00  32390.0    0.000000  41411.0   \n",
       "3        0.000000  32395.0  0.000000e+00  32391.0    0.000000  41412.0   \n",
       "4        0.000000  32396.0  0.000000e+00  32392.0    0.000000  41413.0   \n",
       "\n",
       "label        8834                 8835                 8836           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000054    685.0    0.000067   1759.0    0.000038    285.0   \n",
       "1        0.000000  42324.0    0.000000  45600.0    0.000000  41414.0   \n",
       "2        0.000000  42325.0    0.000000  45601.0    0.000000  41415.0   \n",
       "3        0.000000  42326.0    0.000000  45602.0    0.000000  41416.0   \n",
       "4        0.000000  42327.0    0.000000  45603.0    0.000000  41417.0   \n",
       "\n",
       "label        8837                 8838                 8839           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000004  35938.0    0.000016  15933.0    0.000011    655.0   \n",
       "1        0.000000  37903.0    0.000000  32066.0    0.000000  41406.0   \n",
       "2        0.000000  37904.0    0.000000  32067.0    0.000000  41407.0   \n",
       "3        0.000000  37905.0    0.000000  32068.0    0.000000  41408.0   \n",
       "4        0.000000  37906.0    0.000000  32069.0    0.000000  41409.0   \n",
       "\n",
       "label        8840                 8841                 8842           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000509   3340.0    0.000011    762.0    0.000006  27439.0   \n",
       "1        0.000000  57164.0    0.000000  41418.0    0.000000  56849.0   \n",
       "2        0.000000  57165.0    0.000000  41419.0    0.000000  56850.0   \n",
       "3        0.000000  57166.0    0.000000  41420.0    0.000000  56851.0   \n",
       "4        0.000000  57167.0    0.000000  41421.0    0.000000  56852.0   \n",
       "\n",
       "label        8843                 8844                 8845           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000028  17061.0    0.000033    789.0    0.000011    612.0   \n",
       "1        0.000000  55110.0    0.000000  22835.0    0.000000  41408.0   \n",
       "2        0.000000  55111.0    0.000000  22836.0    0.000000  41409.0   \n",
       "3        0.000000  55112.0    0.000000  22837.0    0.000000  41410.0   \n",
       "4        0.000000  55113.0    0.000000  22838.0    0.000000  41411.0   \n",
       "\n",
       "label        8846                 8847                 8848           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000038    223.0    0.000022    816.0    0.000028  24146.0   \n",
       "1        0.000000  41406.0    0.000000  56852.0    0.000000  57050.0   \n",
       "2        0.000000  41407.0    0.000000  56853.0    0.000000  57051.0   \n",
       "3        0.000000  41408.0    0.000000  56854.0    0.000000  57052.0   \n",
       "4        0.000000  41409.0    0.000000  56855.0    0.000000  57053.0   \n",
       "\n",
       "label        8849                 8850                 8851           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000432   2584.0    0.000018  21887.0    0.000067   1274.0   \n",
       "1        0.000000  57197.0    0.000000  39339.0    0.000000  32111.0   \n",
       "2        0.000000  57198.0    0.000000  39340.0    0.000000  32112.0   \n",
       "3        0.000000  57199.0    0.000000  39341.0    0.000000  32113.0   \n",
       "4        0.000000  57200.0    0.000000  39342.0    0.000000  32114.0   \n",
       "\n",
       "label        8852                 8853                 8854           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000071  14923.0    0.000006  34985.0    0.000038     80.0   \n",
       "1        0.000000  57165.0    0.000000  39313.0    0.000000  41410.0   \n",
       "2        0.000000  57166.0    0.000000  39314.0    0.000000  41411.0   \n",
       "3        0.000000  57167.0    0.000000  39315.0    0.000000  41412.0   \n",
       "4        0.000000  57168.0    0.000000  39316.0    0.000000  41413.0   \n",
       "\n",
       "label        8855                 8856                 8857           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000109   1028.0    0.000012  16859.0    0.000011    739.0   \n",
       "1        0.000000  54124.0    0.000000  26997.0    0.000000  41418.0   \n",
       "2        0.000000  54125.0    0.000000  26998.0    0.000000  41419.0   \n",
       "3        0.000000  54126.0    0.000000  26999.0    0.000000  41420.0   \n",
       "4        0.000000  54127.0    0.000000  27000.0    0.000000  41421.0   \n",
       "\n",
       "label        8858                 8859                 8860           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000002  48540.0    0.000011    717.0    0.000038    335.0   \n",
       "1        0.000000  55114.0    0.000000  41410.0    0.000000  41410.0   \n",
       "2        0.000000  55115.0    0.000000  41411.0    0.000000  41411.0   \n",
       "3        0.000000  55116.0    0.000000  41412.0    0.000000  41412.0   \n",
       "4        0.000000  55117.0    0.000000  41413.0    0.000000  41413.0   \n",
       "\n",
       "label        8861                 8862                 8863           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000956   1393.0    0.000011    949.0    0.000011    949.0   \n",
       "1        0.000000  56828.0    0.000000  41413.0    0.000000  41413.0   \n",
       "2        0.000000  56829.0    0.000000  41414.0    0.000000  41414.0   \n",
       "3        0.000000  56830.0    0.000000  41415.0    0.000000  41415.0   \n",
       "4        0.000000  56831.0    0.000000  41416.0    0.000000  41416.0   \n",
       "\n",
       "label        8864                 8865                 8866           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000008  38164.0    0.000038    244.0    0.000011   1063.0   \n",
       "1        0.000000  55897.0    0.000000  41409.0    0.000000  41420.0   \n",
       "2        0.000000  55898.0    0.000000  41410.0    0.000000  41421.0   \n",
       "3        0.000000  55899.0    0.000000  41411.0    0.000000  41422.0   \n",
       "4        0.000000  55900.0    0.000000  41412.0    0.000000  41423.0   \n",
       "\n",
       "label        8867                 8868                 8869           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000191   8733.0    0.000011    527.0    0.000019  12250.0   \n",
       "1        0.000000  57028.0    0.000000  41407.0    0.000000  26973.0   \n",
       "2        0.000000  57029.0    0.000000  41408.0    0.000000  26974.0   \n",
       "3        0.000000  57030.0    0.000000  41409.0    0.000000  26975.0   \n",
       "4        0.000000  57031.0    0.000000  41410.0    0.000000  26976.0   \n",
       "\n",
       "label        8870                 8871                 8872           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    533.0     0.00123    884.0    0.000011    634.0   \n",
       "1        0.000000  41409.0     0.00000  57303.0    0.000000  41409.0   \n",
       "2        0.000000  41410.0     0.00000  57304.0    0.000000  41410.0   \n",
       "3        0.000000  41411.0     0.00000  57305.0    0.000000  41411.0   \n",
       "4        0.000000  41412.0     0.00000  57306.0    0.000000  41412.0   \n",
       "\n",
       "label          8873                 8874                 8875           \\\n",
       "key2    mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0      6.888287e-07  31833.0    0.000054   1431.0    0.000011    764.0   \n",
       "1      0.000000e+00  32394.0    0.000000  42365.0    0.000000  41412.0   \n",
       "2      0.000000e+00  32395.0    0.000000  42366.0    0.000000  41413.0   \n",
       "3      0.000000e+00  32396.0    0.000000  42367.0    0.000000  41414.0   \n",
       "4      0.000000e+00  32397.0    0.000000  42368.0    0.000000  41415.0   \n",
       "\n",
       "label        8876                 8877                 8878           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    688.0    0.000011    810.0    0.000022    865.0   \n",
       "1        0.000000  41410.0    0.000000  41408.0    0.000000  56850.0   \n",
       "2        0.000000  41411.0    0.000000  41409.0    0.000000  56851.0   \n",
       "3        0.000000  41412.0    0.000000  41410.0    0.000000  56852.0   \n",
       "4        0.000000  41413.0    0.000000  41411.0    0.000000  56853.0   \n",
       "\n",
       "label        8879                 8880                 8881           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000022    843.0    0.000022    893.0    0.000038    721.0   \n",
       "1        0.000000  56856.0    0.000000  56855.0    0.000000  41428.0   \n",
       "2        0.000000  56857.0    0.000000  56856.0    0.000000  41429.0   \n",
       "3        0.000000  56858.0    0.000000  56857.0    0.000000  41430.0   \n",
       "4        0.000000  56859.0    0.000000  56858.0    0.000000  41431.0   \n",
       "\n",
       "label        8882                 8883                 8884           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011    851.0    0.000552   3322.0    0.000163   6802.0   \n",
       "1        0.000000  41415.0    0.000000  57183.0    0.000000  57233.0   \n",
       "2        0.000000  41416.0    0.000000  57184.0    0.000000  57234.0   \n",
       "3        0.000000  41417.0    0.000000  57185.0    0.000000  57235.0   \n",
       "4        0.000000  41418.0    0.000000  57186.0    0.000000  57236.0   \n",
       "\n",
       "label        8885                 8886                 8887           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000044   1135.0    0.000002  31362.0    0.000027   5943.0   \n",
       "1        0.000000  32401.0    0.000000  32080.0    0.000000  42459.0   \n",
       "2        0.000000  32402.0    0.000000  32081.0    0.000000  42460.0   \n",
       "3        0.000000  32403.0    0.000000  32082.0    0.000000  42461.0   \n",
       "4        0.000000  32404.0    0.000000  32083.0    0.000000  42462.0   \n",
       "\n",
       "label        8888                 8889                 8890           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000008  38083.0    0.000076    938.0    0.000051   2675.0   \n",
       "1        0.000000  55886.0    0.000000  26543.0    0.000000  32086.0   \n",
       "2        0.000000  55887.0    0.000000  26544.0    0.000000  32087.0   \n",
       "3        0.000000  55888.0    0.000000  26545.0    0.000000  32088.0   \n",
       "4        0.000000  55889.0    0.000000  26546.0    0.000000  32089.0   \n",
       "\n",
       "label        8891                 8892                 8893           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000015  18955.0    0.000011  33750.0    0.000085   1944.0   \n",
       "1        0.000000  34197.0    0.000000  57256.0    0.000000  34200.0   \n",
       "2        0.000000  34198.0    0.000000  57257.0    0.000000  34201.0   \n",
       "3        0.000000  34199.0    0.000000  57258.0    0.000000  34202.0   \n",
       "4        0.000000  34200.0    0.000000  57259.0    0.000000  34203.0   \n",
       "\n",
       "label        8894                 8895                 8896           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000007  34174.0    0.000067   2153.0    0.000011  38636.0   \n",
       "1        0.000000  46663.0    0.000000  45627.0    0.000000  55102.0   \n",
       "2        0.000000  46664.0    0.000000  45628.0    0.000000  55103.0   \n",
       "3        0.000000  46665.0    0.000000  45629.0    0.000000  55104.0   \n",
       "4        0.000000  46666.0    0.000000  45630.0    0.000000  55105.0   \n",
       "\n",
       "label        8897                 8898                 8899           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000094   1852.0    0.000036  11357.0    0.000112   1917.0   \n",
       "1        0.000000  39826.0    0.000000  35548.0    0.000000  57251.0   \n",
       "2        0.000000  39827.0    0.000000  35549.0    0.000000  57252.0   \n",
       "3        0.000000  39828.0    0.000000  35550.0    0.000000  57253.0   \n",
       "4        0.000000  39829.0    0.000000  35551.0    0.000000  57254.0   \n",
       "\n",
       "label        8900                 8901                 8902           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000046  17134.0    0.000114   9263.0    0.000136   4159.0   \n",
       "1        0.000000  56526.0    0.000000  56517.0    0.000000  57221.0   \n",
       "2        0.000000  56527.0    0.000000  56518.0    0.000000  57222.0   \n",
       "3        0.000000  56528.0    0.000000  56519.0    0.000000  57223.0   \n",
       "4        0.000000  56529.0    0.000000  56520.0    0.000000  57224.0   \n",
       "\n",
       "label        8903                 8904                 8905           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000135   5236.0    0.000025  16826.0     0.00012   1556.0   \n",
       "1        0.000000  48112.0    0.000000  46650.0     0.00000  27017.0   \n",
       "2        0.000000  48113.0    0.000000  46651.0     0.00000  27018.0   \n",
       "3        0.000000  48114.0    0.000000  46652.0     0.00000  27019.0   \n",
       "4        0.000000  48115.0    0.000000  46653.0     0.00000  27020.0   \n",
       "\n",
       "label        8906                 8907                 8908           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000001  33705.0    0.000022    924.0    0.000011    740.0   \n",
       "1        0.000000  34273.0    0.000000  56853.0    0.000000  41409.0   \n",
       "2        0.000000  34274.0    0.000000  56854.0    0.000000  41410.0   \n",
       "3        0.000000  34275.0    0.000000  56855.0    0.000000  41411.0   \n",
       "4        0.000000  34276.0    0.000000  56856.0    0.000000  41412.0   \n",
       "\n",
       "label        8909                 8910                 8911           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000011   9752.0    0.000896   2377.0    0.000011    819.0   \n",
       "1        0.000000  32380.0    0.000000  57063.0    0.000000  41415.0   \n",
       "2        0.000000  32381.0    0.000000  57064.0    0.000000  41416.0   \n",
       "3        0.000000  32382.0    0.000000  57065.0    0.000000  41417.0   \n",
       "4        0.000000  32383.0    0.000000  57066.0    0.000000  41418.0   \n",
       "\n",
       "label        8912                 8913                 8914           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000265   5414.0    0.000011    995.0    0.000014  11115.0   \n",
       "1        0.000000  56475.0    0.000000  41418.0    0.000000  26579.0   \n",
       "2        0.000000  56476.0    0.000000  41419.0    0.000000  26580.0   \n",
       "3        0.000000  56477.0    0.000000  41420.0    0.000000  26581.0   \n",
       "4        0.000000  56478.0    0.000000  41421.0    0.000000  26582.0   \n",
       "\n",
       "label          8915                 8916                 8917           \\\n",
       "key2    mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                    \n",
       "0      3.375316e-07  22588.0    0.000011    803.0    0.000011    850.0   \n",
       "1      0.000000e+00  22859.0    0.000000  41413.0    0.000000  41421.0   \n",
       "2      0.000000e+00  22860.0    0.000000  41414.0    0.000000  41422.0   \n",
       "3      0.000000e+00  22861.0    0.000000  41415.0    0.000000  41423.0   \n",
       "4      0.000000e+00  22862.0    0.000000  41416.0    0.000000  41424.0   \n",
       "\n",
       "label        8918                 8919                 8920           \\\n",
       "key2  mutual_info     rank mutual_info     rank mutual_info     rank   \n",
       "token                                                                  \n",
       "0        0.000033    944.0    0.000011    960.0    0.000011    771.0   \n",
       "1        0.000000  22861.0    0.000000  41423.0    0.000000  41412.0   \n",
       "2        0.000000  22862.0    0.000000  41424.0    0.000000  41413.0   \n",
       "3        0.000000  22863.0    0.000000  41425.0    0.000000  41414.0   \n",
       "4        0.000000  22864.0    0.000000  41426.0    0.000000  41415.0   \n",
       "\n",
       "label          8921           \n",
       "key2    mutual_info     rank  \n",
       "token                         \n",
       "0      6.888287e-07  31821.0  \n",
       "1      0.000000e+00  32385.0  \n",
       "2      0.000000e+00  32386.0  \n",
       "3      0.000000e+00  32387.0  \n",
       "4      0.000000e+00  32388.0  \n",
       "\n",
       "[5 rows x 17844 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c821b97-a7be-4a8b-ac94-78a03c6e491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_collab.loc[:, ( slice(0, len(lbs)), ['mutual_info'])] = info.cpu()\n",
    "# df_collab.loc[:, ( slice(0, len(lbs)), ['rank'])] = info_ranked.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f0274-a18d-4046-bf47-baa6d5cf74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collab = df_collab.stack(level=0).reset_index().rename_axis(None, axis=1)\n",
    "df_collab[['token', 'label']] = df_collab[['token', 'label']].astype(np.int32) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00d5764-ebab-4d0c-9e52-7a45a10b791a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b95b64-7168-45b1-a246-f5fa740be5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collab = pd.DataFrame(info, columns=range(len(lbs)), index=range(len(toks)))\n",
    "test_eq(len(df_collab), len(toks))\n",
    "test_eq(len(df_collab.columns), len(lbs))\n",
    "df_collab.index.name = 'token'\n",
    "df_collab.columns.name = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91de7c-94dd-47d3-8eea-616c4fda96ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>...</th>\n",
       "      <th>8897</th>\n",
       "      <th>8898</th>\n",
       "      <th>8899</th>\n",
       "      <th>8900</th>\n",
       "      <th>8901</th>\n",
       "      <th>8902</th>\n",
       "      <th>8903</th>\n",
       "      <th>8904</th>\n",
       "      <th>8905</th>\n",
       "      <th>8906</th>\n",
       "      <th>8907</th>\n",
       "      <th>8908</th>\n",
       "      <th>8909</th>\n",
       "      <th>8910</th>\n",
       "      <th>8911</th>\n",
       "      <th>8912</th>\n",
       "      <th>8913</th>\n",
       "      <th>8914</th>\n",
       "      <th>8915</th>\n",
       "      <th>8916</th>\n",
       "      <th>8917</th>\n",
       "      <th>8918</th>\n",
       "      <th>8919</th>\n",
       "      <th>8920</th>\n",
       "      <th>8921</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>6.888287e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>3.375316e-07</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>6.888287e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8922 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label      0         1         2         3         4         5         6     \\\n",
       "token                                                                         \n",
       "0      0.000022  0.000011  0.000022  0.000011  0.000033  0.000011  0.000011   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "label      7         8         9         10        11        12        13    \\\n",
       "token                                                                         \n",
       "0      0.000011  0.000022  0.000011  0.000011  0.000065  0.000011  0.000011   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "label      14        15        16            17        18        19    \\\n",
       "token                                                                   \n",
       "0      0.000011  0.001175  0.000011  6.888287e-07  0.000011  0.000022   \n",
       "1      0.000000  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
       "\n",
       "label      20        21        22        23        24    ...      8897  \\\n",
       "token                                                    ...             \n",
       "0      0.000065  0.000185  0.000036  0.000109  0.000062  ...  0.000094   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "\n",
       "label      8898      8899      8900      8901      8902      8903      8904  \\\n",
       "token                                                                         \n",
       "0      0.000036  0.000112  0.000046  0.000114  0.000136  0.000135  0.000025   \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "label     8905      8906      8907      8908      8909      8910      8911  \\\n",
       "token                                                                        \n",
       "0      0.00012  0.000001  0.000022  0.000011  0.000011  0.000896  0.000011   \n",
       "1      0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3      0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "label      8912      8913      8914          8915      8916      8917  \\\n",
       "token                                                                   \n",
       "0      0.000265  0.000011  0.000014  3.375316e-07  0.000011  0.000011   \n",
       "1      0.000000  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  0.000000e+00  0.000000  0.000000   \n",
       "\n",
       "label      8918      8919      8920          8921  \n",
       "token                                              \n",
       "0      0.000033  0.000011  0.000011  6.888287e-07  \n",
       "1      0.000000  0.000000  0.000000  0.000000e+00  \n",
       "2      0.000000  0.000000  0.000000  0.000000e+00  \n",
       "3      0.000000  0.000000  0.000000  0.000000e+00  \n",
       "4      0.000000  0.000000  0.000000  0.000000e+00  \n",
       "\n",
       "[5 rows x 8922 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with pd.option_context('display.max_columns', 50):\n",
    "pd.set_option('display.max_columns', 50)\n",
    "df_collab.head()\n",
    "# pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e6166d-d2ea-4819-8761-05a4049b9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collab = df_collab.stack().reset_index(name='mutual_info')\n",
    "test_eq(len(df_collab), len(toks)*len(lbs))\n",
    "df_collab[['token', 'label']] = df_collab[['token', 'label']].astype(np.int32) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a770be3-3a2c-4313-8c3d-056691a8e477",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf93bf9-dd9c-42fd-ab0b-4e8ea0ae2f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1156.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  label  mutual_info    rank\n",
       "0      0      0     0.000022   866.0\n",
       "1      0      1     0.000011  1022.0\n",
       "2      0      2     0.000022  1156.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a3bc4-159b-4cf4-a43b-dd5d7cf8d133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index          1.192093e-07\n",
       "token          1.906211e+00\n",
       "label          1.906211e+00\n",
       "mutual_info    1.906211e+00\n",
       "rank           1.906211e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab.memory_usage()/1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49baf2b-ada3-4638-ade9-e9e3ba9fbb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toks = pd.DataFrame([(i, w) for i,w in enumerate(toks)], columns=['token', 'tok_val'])\n",
    "df_lbs = pd.DataFrame([(i,w) for i, w in enumerate(lbs)], columns=['lbl', 'lbl_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb455422-8e1e-4921-b1d1-e998b6bed63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>tok_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>xxbos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token tok_val\n",
       "0      0   xxunk\n",
       "1      1   xxpad\n",
       "2      2   xxbos"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toks.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991db1e5-20ce-4593-8766-11acd6450db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbl</th>\n",
       "      <th>lbl_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>003.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>003.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lbl lbl_val\n",
       "0    0   003.0\n",
       "1    1   003.1\n",
       "2    2   003.8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lbs.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d03d0e-7844-428c-b1f1-298c437a5ade",
   "metadata": {},
   "source": [
    "Let us save this format, as this is what we will use to train our Collab Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5890282-e964-4763-81fc-fa5d5aee6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collab.to_feather(collab_data_path)\n",
    "df_toks.to_feather(collab_tok_path)\n",
    "df_lbs.to_feather(collab_lbl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6f5be-1174-4171-b7bb-2081fd451c97",
   "metadata": {},
   "source": [
    "#### Statistical Analysis of that `mutual_info` column before we build the collab `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de863d-c9a1-48f8-898d-54721aaa1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with concurrent.futures.ProcessPoolExecutor(max_workers=1) as executor:\n",
    "#     args = (collab_data_path,)\n",
    "#     kwargs = {}\n",
    "#     df_collab = executor.submit(_read_collab, *args, **kwargs).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851bd31-4a56-4e36-a537-31399294c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert collab_data_path.exists()\n",
    "df_collab = pd.read_feather(collab_data_path)\n",
    "test_eq(df_collab.dtypes.mutual_info, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d2d6b-4113-49ec-bb34-a98022468b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc; gc.collect()\n",
    "# df_collab.info()\n",
    "# ic(df_collab.memory_usage().sum()/1024**3)\n",
    "# ic(sys.getsizeof(df_collab)/1024**3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970a782-d80e-42d2-bbd9-6ac4ece76ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>bcx_mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>866.0</td>\n",
       "      <td>-6.530356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>-6.753679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>-6.530356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  label  mutual_info    rank  bcx_mutual_info\n",
       "0      0      0     0.000022   866.0        -6.530356\n",
       "1      0      1     0.000011  1022.0        -6.753679\n",
       "2      0      2     0.000022  1156.0        -6.530356"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af708cf-5878-45db-af27-06ae08def0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_collab.token.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1e6d3-1d9e-4ba6-a311-3a7fda646896",
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_infos = df_collab['mutual_info'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69637d68-eeeb-4976-aa0c-23bc5e09479f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.99999636, 7.697003e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mut_infos.min(), mut_infos.max(), mut_infos.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b9869-841f-4b84-ad3b-2d4dbec36f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.74 s, sys: 1.01 s, total: 2.75 s\n",
      "Wall time: 2.75 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "142.75660007849734"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "skew(mut_infos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa2eea-8e3f-4bf9-96ec-c19ca6761405",
   "metadata": {},
   "source": [
    "Before we attempt to transform `mut_infos` we need to convert any non-zeros in it to eps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14c946-14c8-46c1-88f4-91824f2f5664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.sum(where_negs): 111226814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111226814"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.where(mut_infos<0, 1, 0).sum() # or, better yet\n",
    "where_negs = mut_infos < 0\n",
    "ic(np.sum(where_negs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd925c-86f0-4ed6-bcb9-e866702f3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.float32(1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4df7e75-4b72-4a04-9717-2abac0619bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_infos[where_negs] = eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1e77f-4f23-4de0-8729-1bd47a03174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(np.sum(mut_infos<0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9415f83-e5a9-46c0-8adf-eba17535d50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.99999636, 7.697003e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(mut_infos), np.max(mut_infos), np.mean(mut_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79078145-b16f-4ebe-8cc4-3f2661e6e3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins, _ = plt.hist(mut_infos, bins=50)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6faa68-092f-43f5-9ef5-789f89f3812f",
   "metadata": {},
   "source": [
    "**Applying log transform:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57c44a-86a5-47e5-8fe5-604f66ded5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mut_infos = np.log(mut_infos + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353df9c8-f6dd-4dcf-a6a0-d00887d25eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(log_mut_infos).sum(), np.isneginf(log_mut_infos).sum(), np.isinf(log_mut_infos).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd795e-95ae-42e1-a995-c16ffd1b5d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 s, sys: 462 ms, total: 2.49 s\n",
      "Wall time: 2.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.3383214188674972"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time skew(log_mut_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f112b0-3eb5-45ae-8590-bb8a7ff6d8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins, _ = plt.hist(log_mut_infos, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c711dfb-a826-4128-82c8-38f9a4fc63e1",
   "metadata": {},
   "source": [
    "**Applying sqrt transform:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a3976b-bcc4-4428-84ba-ea8f17e48318",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_mut_infos = np.sqrt(mut_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace595e8-365c-451e-8590-f367a87b5c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(sqrt_mut_infos).sum(), np.isinf(sqrt_mut_infos).sum(), np.isneginf(sqrt_mut_infos).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d6551-876b-4846-bedf-a34d41e09660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 s, sys: 1.04 s, total: 2.63 s\n",
      "Wall time: 2.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.40865608826817"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time skew(sqrt_mut_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f977fa6-d197-4838-b135-5cd45bb9c6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins, _ = plt.hist(sqrt_mut_infos, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170762c1-7839-45ac-8e39-573ff29efd05",
   "metadata": {},
   "source": [
    "**Apply box-cox transfrom:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a39ff-7560-445d-8fb8-47f59ea3510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcx_mut_infos, *_ = boxcox(mut_infos+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2154ec-607f-4ae6-b66a-f1464cc0aab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(bcx_mut_infos).sum(), np.isinf(bcx_mut_infos).sum(), np.isneginf(bcx_mut_infos).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514afd2e-baa1-4b7f-9b2a-245724e00924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.7 s, sys: 921 ms, total: 2.62 s\n",
      "Wall time: 2.62 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.885981418331696"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time skew(bcx_mut_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efcffe-dde6-44db-a9fc-420bbe909b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collab['bcx_mutual_info'] = bcx_mut_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd640f46-f7d4-41e2-867f-3dbd89d4a7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins, _ = plt.hist(bcx_mut_infos, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6696f8e-f7d9-4f1f-89a1-5497e2f09559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9.734209, -3.6358892e-06, -7.381837, -6.9605794)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(bcx_mut_infos), np.max(bcx_mut_infos), np.mean(bcx_mut_infos), np.median(bcx_mut_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a43b48-ae08-45ce-bc4b-85549bb3ad1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>bcx_mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>866.0</td>\n",
       "      <td>-6.530356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>-6.753679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>-6.530356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  label  mutual_info    rank  bcx_mutual_info\n",
       "0      0      0     0.000022   866.0        -6.530356\n",
       "1      0      1     0.000011  1022.0        -6.753679\n",
       "2      0      2     0.000022  1156.0        -6.530356"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcd759-fb60-4c38-9686-069e52be07f8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f24001-d7ba-4444-93d5-ec49da89f8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.cpu_percent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d6b83f-9ec4-47f8-b4b8-45fa357502a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=63205289984, available=51459112960, percent=18.6, used=11144814592, free=45459292160, active=145227776, inactive=17213775872, buffers=49983488, cached=6551199744, shared=57344, slab=101920768)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29318553-16a8-43be-9565-378246b44109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 63205289984,\n",
       " 'available': 51458928640,\n",
       " 'percent': 18.6,\n",
       " 'used': 11144998912,\n",
       " 'free': 45459050496,\n",
       " 'active': 145195008,\n",
       " 'inactive': 17213902848,\n",
       " 'buffers': 50032640,\n",
       " 'cached': 6551207936,\n",
       " 'shared': 57344,\n",
       " 'slab': 101941248}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(psutil.virtual_memory()._asdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19796b3-4e1c-477f-9e7c-f3c83d6a02a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory().percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918e4f3-18a9-442b-a9f2-3e44822c6730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.41651284730541"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory().available * 100 / psutil.virtual_memory().total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a1637-447c-4df4-adc1-0d3b14ba1593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory use: 19.49184799194336\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psutil\n",
    "pid = os.getpid()\n",
    "python_process = psutil.Process(pid)\n",
    "memoryUse = python_process.memory_info()[0]/2.**30  # memory use in GB...I think\n",
    "print('memory use:', memoryUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb5221-cd7e-4926-a029-98b00ff2c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import psutil\n",
    "\n",
    "with tqdm(total=100, desc='cpu%', position=1) as cpubar, tqdm(total=100, desc='ram%', position=0) as rambar:\n",
    "    while True:\n",
    "        rambar.n=psutil.virtual_memory().percent\n",
    "        cpubar.n=psutil.cpu_percent()\n",
    "        rambar.refresh()\n",
    "        cpubar.refresh()\n",
    "        sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f396d0-c721-4cff-ad45-b44d2b0c2f6e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c11ba-8a2b-4985-9eaa-3b607c51eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collab_high_ranked = df_collab[df_collab['rank'] <= 10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa58258-df82-46bd-b9ed-95c73fa48937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>6109</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>6111</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>6461</td>\n",
       "      <td>0.027056</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>8030</td>\n",
       "      <td>0.034794</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>8696</td>\n",
       "      <td>0.034794</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  label  mutual_info  rank\n",
       "0      9   6109     0.008734   7.0\n",
       "1      9   6111     0.008734   5.0\n",
       "2     10   6461     0.027056   1.0\n",
       "3     10   8030     0.034794   4.0\n",
       "4     10   8696     0.034794   1.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab_high_ranked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccac6a2-74d6-4cbd-b9b5-55d44ded754f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8922, 36909)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab_high_ranked['label'].nunique(), df_collab_high_ranked['token'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ede15bd-422e-4e92-a8f7-45a9480832f6",
   "metadata": {},
   "source": [
    "Box plots using matplotlib and seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663d859-53c1-4d60-9a53-fe57fda8ffe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "ax1.boxplot(df_collab.mutual_info, vert=0, notch=True, patch_artist=True)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Mutual Information')\n",
    "\n",
    "ax2.boxplot(df_collab.bcx_mutual_info, vert=0, notch=True, patch_artist=True)\n",
    "# ax2.set_xscale('symlog')\n",
    "ax2.set_xlabel('Box-Cox Mutual Information')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930de28-c9ff-4fd8-8545-11714059bf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xscale('log')\n",
    "sns.boxplot(x=df_collab_high_ranked['mutual_info'], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa4e24-53b1-43c4-ac33-80baadb270ec",
   "metadata": {},
   "source": [
    "Histograms and kde using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5237212a-21ff-40ff-a0f9-5fc3270420ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "# ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "hist, bins, pathches = ax1.hist(df_collab_high_ranked['mutual_info'])\n",
    "ax1.set_xlabel('mutual_info')\n",
    "ax1.set_ylabel('frequency')\n",
    "ax1.grid(axis='y', color='black')\n",
    "\n",
    "# ax2.hist(df_collab['mutual_info'])\n",
    "# ax2.set_xlabel('mutual_info')\n",
    "# ax2.set_ylabel('frequency')\n",
    "# ax2.grid(axis='y', color='black')\n",
    "# ax2.set_yscale('log')\n",
    "\n",
    "fig.suptitle('Histogram of Mutual Information')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591e9f2-56af-40b1-b659-119c28d80714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98142,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab_high_ranked['mutual_info'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15996a77-9376-4364-a7f7-22a858f8d423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(df_collab_high_ranked['mutual_info'], np.full_like(df_collab_high_ranked['mutual_info'], 0.01), 'b+', ms=20)\n",
    "ax.set_xlabel('mutual_info')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197837b6-6e3e-4bee-a92c-463e2c81e567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boundary</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-6.852321e-05, 0.09993797]</td>\n",
       "      <td>511675593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.09993797, 0.19994445]</td>\n",
       "      <td>14854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.19994445, 0.29995096]</td>\n",
       "      <td>3323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.29995096, 0.39995742]</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.39995742, 0.4999639]</td>\n",
       "      <td>454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.4999639, 0.5999704]</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.5999704, 0.6999769]</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.6999769, 0.7999834]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.7999834, 0.8999899]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.8999899, 0.99999636]</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      boundary       counts\n",
       "0  [-6.852321e-05, 0.09993797]  511675593.0\n",
       "1     [0.09993797, 0.19994445]      14854.0\n",
       "2     [0.19994445, 0.29995096]       3323.0\n",
       "3     [0.29995096, 0.39995742]        191.0\n",
       "4      [0.39995742, 0.4999639]        454.0\n",
       "5       [0.4999639, 0.5999704]         30.0\n",
       "6       [0.5999704, 0.6999769]          5.0\n",
       "7       [0.6999769, 0.7999834]          0.0\n",
       "8       [0.7999834, 0.8999899]          0.0\n",
       "9      [0.8999899, 0.99999636]         94.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdrs = [bins[i:i+2] for i in range(0, len(bins)-1)]\n",
    "pd.DataFrame({'boundary': bdrs, 'counts': hist})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76920535-91bd-4dac-8c5b-7878b640c227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "density = gaussian_kde(df_collab['mutual_info'])\n",
    "xs = np.linspace(0, 1, 200)\n",
    "density.covariance_factor = lambda : .25\n",
    "density._compute_covariance()\n",
    "plt.plot(xs, density(xs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0150da-6b25-44f0-b721-1cec16d5e031",
   "metadata": {},
   "source": [
    "Histograms and kde using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554def3-e1e1-4902-b873-da16ea1a0d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAFJCAYAAAC2DwjyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAU50lEQVR4nO3dfbBtZX0f8O9PwBx8xRa1ji+5alOVOoJ4SNKoiaJpFfJSW9NqUp06xlvHNmOmTSI6jtB2MsW0SUzGWoPWsdpEo/ElxnepIqYR9V5FQDHRKL4AU0QrqHFE4Nc/zqZcL/fes4Rn7X1ePp+ZPXfttddez2/OM/fs73metddT3R0AAMa43aoLAADYSYQrAICBhCsAgIGEKwCAgYQrAICBhCsAgIG2XLiqqldV1VVVdcmEY+9XVR+oqk9U1UVVddoyagQAOJwtF66SvDrJEyYe+8Ikb+juhyd5SpKXzVUUAMAUWy5cdff5Sb5+4L6qemBVvbuq9lfVh6rqwTcdnuQui+27JrliiaUCANzC0asuYKJzkjy7uz9bVT+WjRGqU5OcleS9VfUrSe6Y5PGrKxEAYBuEq6q6U5KfSPLGqrpp9w8t/n1qkld3929X1T9I8tqqemh337iCUgEAtn64ysbU5Te6+6RDvPbMLK7P6u4PV9VakuOTXLW88gAAbrblrrk6WHdfm+QLVfULSVIbTly8/KUkj1vsf0iStSRfXUmhAABJqrtXXcP3qarXJXlMNkag/k+SM5O8P8l/S3KvJMckeX13/4eqOiHJK5LcKRsXt/9Gd793FXUDACRbMFwBAGxnW35aEABgOxGuAAAG2lLfFjz++ON7z549qy4DAGBT+/fvv7q7737w/i0Vrvbs2ZN9+/atugwAgE1V1RcPtd+0IADAQMIVAMBAwhUAwEDCFQDAQMIVAMBAwhUAwEDCFQDAQMIVAMBAwhUAwEDCFQDAQMIVAMBAW2ptwWXYc8Y7Vl3CMJedffqqSwAADmLkCgBgoFlHrqrqsiTfTHJDkuu7e33O9gAAVm0Z04KP7e6rl9AOAMDKmRYEABho7nDVSd5bVfurau/MbQEArNzc04KP7O4rquoeSd5XVZ/p7vMPPGARuvYmydraWtbX570s68rLr5n1/Mu0fu6Zqy4BADhIdfdyGqo6K8m3uvu/HO6Y9fX13rdv36x1uBUDADBCVe0/1Jf1ZpsWrKo7VtWdb9pO8g+TXDJXewAAW8Gc04L3TPKWqrqpnT/q7nfP2B4AwMrNFq66+/NJTpzr/AAAW5FbMQAADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAw0e7iqqqOq6hNV9fa52wIAWLVljFw9N8mlS2gHAGDlZg1XVXWfJKcneeWc7QAAbBVzj1y9JMlvJLlx5nYAALaEo+c6cVX9TJKrunt/VT3mCMftTbI3SdbW1rK+vj5XSUmSKy+/ZtbzL9P6uWeuugQA4CDV3fOcuOo/JXlakuuTrCW5S5I3d/e/ONx71tfXe9++fbPUc5M9Z7xj1vMv02Vnn77qEgBg16qq/d19i1Gh2aYFu/v53X2f7t6T5ClJ3n+kYAUAsBO4zxUAwECzXXN1oO4+L8l5y2gLAGCVjFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAw0KVxV1UPnLgQAYCeYOnL18qr6aFU9p6qOm7MgAIDtbFK46u5HJfmlJPdNsq+q/qiqfnrWygAAtqHJ11x192eTvDDJ85L8VJLfr6rPVNU/mas4AIDtZuo1Vw+rqt9NcmmSU5P8bHc/ZLH9u4d5z9piKvGTVfWpqvr3w6oGANiijp543EuTvCLJC7r7Ozft7O4rquqFh3nPd5Oc2t3fqqpjkvx5Vb2ruy+4bSUDAGxdU8PVaUm+0903JElV3S7JWnf/TXe/9lBv6O5O8q3F02MWj76N9QIAbGlTr7k6N8mxBzy/w2LfEVXVUVV1YZKrkryvuz/yA1cIALCNTB25Wuvum0ahspjqu8Nmb1qMdJ20uH3DW6rqod19yYHHVNXeJHuTZG1tLevr65OLvzWuvPyaWc+/TOvnnrnqEgCAg0wNV9+uqpO7++NJUlWPSPKdTd7z/3X3N6rqvCRPSHLJQa+dk+ScJFlfX+99+/ZNPe2tsueMd8x6/mXad/bpqy4BAHatqjrk/qnh6leTvLGqrlg8v1eSf75Jg3dP8r1FsDo2yeOTvHhiewAA29KkcNXdH6uqByd5UJJK8pnu/t4mb7tXkv9RVUdl49quN3T3229TtQAAW9zUkaskOSXJnsV7Hl5V6e7XHO7g7r4oycNvW3kAANvLpHBVVa9N8sAkFya5YbG7kxw2XAEA7EZTR67Wk5ywuHcVAACHMfU+V5ck+TtzFgIAsBNMHbk6Psmnq+qj2VjWJknS3T83S1UAANvU1HB11pxFAADsFFNvxfDBqvrhJD/S3ecu7s5+1LylAQBsP5OuuaqqZyX5kyR/sNh17yRvnakmAIBta+oF7f86ySOTXJsk3f3ZJPeYqygAgO1qarj6bndfd9OTqjo6G/e5AgDgAFPD1Qer6gVJjq2qn07yxiR/Nl9ZAADb09RwdUaSrya5OMm/SvLOJC+cqygAgO1q6rcFb0zyisUDAIDDmLq24BdyiGusuvsBwysCANjGfpC1BW+yluQXkvyt8eUAAGxvk6656u6vHfC4vLtfkuTUeUsDANh+pk4LnnzA09tlYyTrzrNUBACwjU2dFvztA7avT3JZkn82vBoAgG1u6rcFHzt3IQAAO8HUacF/e6TXu/t3xpQDALC9/SDfFjwlydsWz382yflJvjxHUQAA29XUcHV8kpO7+5tJUlVnJXljd//yXIUBAGxHU5e/uV+S6w54fl2SPcOrAQDY5qaOXL02yUer6i3ZuFP7k5K8ZraqAAC2qanfFvzNqnpXkkcvdj2juz8xX1kAANvT1GnBJLlDkmu7+/eSfKWq7j9TTQAA29akcFVVZyZ5XpLnL3Ydk+R/zlUUAMB2NXXk6klJfi7Jt5Oku6+I5W8AAG5hari6rrs7Gxezp6ruOF9JAADb19Rw9Yaq+oMkx1XVs5Kcm+QV85UFALA9bfptwaqqJH+c5MFJrk3yoCQv6u73zVwbAMC2s2m46u6uqrd29yOSCFQAAEcwdVrwgqo6ZdZKAAB2gKl3aH9skmdX1WXZ+MZgZWNQ62FzFQYAsB0dMVxV1f26+0tJnrikegAAtrXNRq7emuTk7v5iVb2pu//pEmoCANi2Nrvmqg7YfsCchQAA7ASbhas+zDYAAIew2bTgiVV1bTZGsI5dbCc3X9B+l1mrAwDYZo4Yrrr7qGUVAgCwE0y9zxUAABMIVwAAAwlXAAADzRauquq+VfWBqrq0qj5VVc+dqy0AgK1i6vI3t8b1Sf5dd3+8qu6cZH9Vva+7Pz1jmwAAKzXbyFV3X9ndH19sfzPJpUnuPVd7AABbwVKuuaqqPUkenuQjy2gPAGBV5pwWTJJU1Z2SvCnJr3b3tYd4fW+SvUmytraW9fX1Weu58vJrZj3/Mq2fe+aqSwAADlLd861qU1XHJHl7kvd09+9sdvz6+nrv27dvtnqSZM8Z75j1/Mt02dmnr7oEANi1qmp/d99iVGjObwtWkv+e5NIpwQoAYCeY85qrRyZ5WpJTq+rCxeO0GdsDAFi52a656u4/z8YCzwAAu4Y7tAMADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMNFu4qqpXVdVVVXXJXG0AAGw1c45cvTrJE2Y8PwDAljNbuOru85N8fa7zAwBsRa65AgAY6OhVF1BVe5PsTZK1tbWsr6/P2t6Vl18z6/mXaf3cM1ddAgBwkJWHq+4+J8k5SbK+vt779u2btb09Z7xj1vMv076zT191CQCwa1XVIfebFgQAGGjOWzG8LsmHkzyoqr5SVc+cqy0AgK1itmnB7n7qXOcGANiqTAsCAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMJFwBAAwkXAEADCRcAQAMNGu4qqonVNVfVtXnquqMOdsCANgKZgtXVXVUkv+a5IlJTkjy1Ko6Ya72AAC2gjlHrn40yee6+/PdfV2S1yf5+RnbAwBYuTnD1b2TfPmA519Z7AMA2LGOnvHcdYh9fYuDqvYm2bt4+q2q+ssZa0qS45NcPXMbS1EvXnUFw+yYPtlh9MvWo0+2Jv2y9SyrT374UDvnDFdfSXLfA57fJ8kVBx/U3eckOWfGOr5PVe3r7vVltcfm9MnWpF+2Hn2yNemXrWfVfTLntODHkvxIVd2/qm6f5ClJ3jZjewAAKzfbyFV3X19V/ybJe5IcleRV3f2pudoDANgK5pwWTHe/M8k752zjVljaFCST6ZOtSb9sPfpka9IvW89K+6S6b3GNOQAAt5LlbwAABtqx4WqzpXdqw+8vXr+oqk5eRZ27yYQ++aVFX1xUVX9RVSeuos7dZOoSVVV1SlXdUFVPXmZ9u9WUfqmqx1TVhVX1qar64LJr3G0m/P66a1X9WVV9ctEnz1hFnbtJVb2qqq6qqksO8/rqPue7e8c9snEB/V8neUCS2yf5ZJITDjrmtCTvysb9uH48yUdWXfdOfkzsk59IcrfF9hP1yer75IDj3p+N6yefvOq6d/pj4v+V45J8Osn9Fs/vseq6d/JjYp+8IMmLF9t3T/L1JLdfde07+ZHkJ5OcnOSSw7y+ss/5nTpyNWXpnZ9P8precEGS46rqXssudBfZtE+6+y+6+/8unl6QjXujMZ+pS1T9SpI3JblqmcXtYlP65ReTvLm7v5Qk3a1v5jWlTzrJnauqktwpG+Hq+uWWubt09/nZ+Dkfzso+53dquJqy9I7leZbrB/15PzMbf3Ewn037pKruneRJSV6+xLp2uyn/V/5ekrtV1XlVtb+qnr606nanKX3y0iQPycbNsi9O8tzuvnE55XEYK/ucn/VWDCs0ZemdScvzMMzkn3dVPTYb4epRs1bElD55SZLndfcNG3+QswRT+uXoJI9I8rgkxyb5cFVd0N1/NXdxu9SUPvlHSS5McmqSByZ5X1V9qLuvnbk2Dm9ln/M7NVxNWXpn0vI8DDPp511VD0vyyiRP7O6vLam23WpKn6wnef0iWB2f5LSqur6737qUCnenqb+/ru7ubyf5dlWdn+TEJMLVPKb0yTOSnN0bF/t8rqq+kOTBST66nBI5hJV9zu/UacEpS++8LcnTF98m+PEk13T3lcsudBfZtE+q6n5J3pzkaf4CX4pN+6S779/de7p7T5I/SfIcwWp2U35//WmSR1fV0VV1hyQ/luTSJde5m0zpky9lYyQxVXXPJA9K8vmlVsnBVvY5vyNHrvowS+9U1bMXr788G998Oi3J55L8TTb+6mAmE/vkRUn+dpKXLUZKrm+Loc5mYp+wZFP6pbsvrap3J7koyY1JXtndh/w6OrfdxP8r/zHJq6vq4mxMRz2vu69eWdG7QFW9LsljkhxfVV9JcmaSY5LVf867QzsAwEA7dVoQAGAlhCsAgIGEKwCAgYQrAICBhCsAgIGEKwCAgYQrYNuoquOq6jm38RyvrqonH+H1V1bVCZuc4+5V9ZGq+kRVPfq21APsPMIVsJ0cl+Q2havNdPcvd/enNznscUk+090P7+4PzVkPsP0IV8BSVdWeqvrMYoTokqr6w6p6fFX976r6bFX9aFWdVVW/dsB7LqmqPUnOTvLAqrqwqv5zVT2mqt5+wHEvrap/udh+UVV9bPHec2riytNVdV5VrS+2v1VVv1lVn6yqC6rqnlV1UpLfysY6ixdW1bFV9dSqunjR1ouH/bCAbUm4Albh7yb5vSQPy8bitr+Y5FFJfi3JC47wvjOS/HV3n9Tdv75JGy/t7lO6+6FJjk3yM7eizjsmuaC7T0xyfpJndfeF2Viq6Y+7+6Qkd0vy4iSnJjkpySlV9Y9vRVvADiFcAavwhe6+uLtvTPKpJP+rN9biujjJnkFtPHZxXdTF2Qg+f/9WnOO6JDeNjO0/TG2nJDmvu7/a3dcn+cMkP3kr2gJ2iB25cDOw5X33gO0bD3h+YzZ+L12f7//jb+0w5znkcVW1luRlSda7+8tVddYRznEk3+ubF2C9IYf+nTlpuhHYPYxcAVvRZUlOTpKqOjnJ/Rf7v5nkzgcc98UkJ1TVD1XVXbNxoXlyc5C6uqrulOSw3w4c4CNJfqqqjq+qo5I8NckHZ2wP2OKMXAFb0ZuSPL2qLkzysSR/lSTd/bXFhe+XJHlXd/96Vb0hyUVJPpvkE4vjvlFVr8jGNONli3PMoruvrKrnJ/lANkax3tndfzpXe8DWVzePeAMAcFuZFgQAGMi0ILArVdVbcvO1XDd5Xne/ZxX1ADuHaUEAgIFMCwIADCRcAQAMJFwBAAwkXAEADCRcAQAM9P8AjlpMjoRkv90AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot()\n",
    "df_collab['mutual_info'].plot.hist(ax=ax)\n",
    "ax.set_xlabel('mutual_info')\n",
    "ax.grid(axis='y', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1664944-6802-49c7-b938-e0d1183845c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "df_collab['mutual_info'].plot.kde(ax=ax)\n",
    "ax.set_xlabel('mutual_info')\n",
    "ax.grid(axis='y', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e09ced-e726-4301-aa92-d988f28fbd35",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9301dd55-be1c-4532-9cc0-b46b42225acd",
   "metadata": {},
   "source": [
    "Close everything below this (it was a scratchpad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a83fd-07e1-4bb2-b51b-6817bf6a8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf\n",
    "SQRT_TWO_PI = math.sqrt(2*math.pi)\n",
    "\n",
    "def normal_pdf(x: float, mu: float = 0, sigma: float = 1) -> float:\n",
    "    return (np.exp(-(x-mu)**2/2/sigma**2))/(SQRT_TWO_PI*sigma)\n",
    "\n",
    "def normal_cdf(x: float, mu: float = 0, sigma: float = 1) -> float:\n",
    "    return (1 + erf((x-mu)/np.sqrt(2)/sigma))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f654d7-d2d0-418e-9511-6be914e3e76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "xs = np.arange(-5, 5, step=0.1)\n",
    "ax1.plot(xs, normal_pdf(xs, sigma=1), label='mu=0,sigma=1')\n",
    "ax1.plot(xs, normal_pdf(xs, sigma=2), label='mu=0,sigma=2')\n",
    "ax1.legend()\n",
    "ax1.set_title(\"various Normal pdfs\")\n",
    "\n",
    "ax2.plot(xs, normal_cdf(xs, sigma=1), label='mu=0,sigma=1')\n",
    "ax2.plot(xs, normal_cdf(xs, sigma=2), label='mu=0,sigma=2')\n",
    "ax2.legend()\n",
    "ax2.set_title(\"various Normal cdfs\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e310b0-20d4-45f7-a4f1-641d7a1e763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hist(data, y_scale=None, x_label=None, y_label=None, title=\"Histogram\"):\n",
    "    n, bins, pathches = plt.hist(data)\n",
    "    plt.grid(axis='y', color='b')\n",
    "    if y_scale is not None: plt.yscale(y_scale)\n",
    "    if x_label is not None: plt.xlabel(x_label)\n",
    "    if y_label is not None: plt.ylabel(y_label)\n",
    "    maxfreq = n.max()\n",
    "    plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\n",
    "    plt.title(title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b6fe2-51b9-4282-8b84-e71269fd7ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_hist(mut_infos, x_label=\"Mutual Information Gain\", y_label=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4da55-997b-4ac6-8276-a6cb7275b7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_hist(mut_infos, y_scale='log', x_label=\"Mutual Information Gain\", y_label=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d75c8e-f8c5-4c14-acd3-1d3181888ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.735371 , -11.4250345, -10.735371 , ...,        -inf,        -inf,        -inf], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(mut_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb45e52-dcd9-43be-aee6-026a33090b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.float32(1e-20)\n",
    "my_hist(np.log(mut_infos), x_label=\"Mutual Information Gain\", y_label=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e8788e-c113-4936-9ca9-5384ae65f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "density = gaussian_kde(-np.log(mut_infos+eps))\n",
    "xs = np.linspace(0, 1, 20)\n",
    "density.covariance_factor = lambda : .25\n",
    "density._compute_covariance()\n",
    "plt.plot(xs, density(xs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a016ca-3a15-4db3-b396-2e3385dfe4a4",
   "metadata": {},
   "source": [
    "Histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21bc55-0450-445e-9572-68140d1ddda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades = [83, 95, 91, 87, 70, 0, 85, 82, 100, 67, 73, 77, 0, 99]\n",
    "len(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce38b75-60e7-4643-9337-bd780df67ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hist(data, start, end, n_bins):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    bins, step = np.linspace(start, end, n_bins+1, retstep=True)\n",
    "    hist = Counter(np.minimum(data//step*step, bins[-2]))\n",
    "    xs = array(list(hist.keys())) + step/2\n",
    "    ys = array(list(hist.values()))\n",
    "    plt.bar(xs,\n",
    "           hist.values(),\n",
    "           step,\n",
    "           edgecolor=(0,0,0))\n",
    "    plt.axis([start, end, 0, max(hist.values())])\n",
    "\n",
    "    plt.grid(axis='y', color='black')\n",
    "    plt.xticks(ticks=bins, rotation=90)\n",
    "    plt.xlabel(f\"{int(step)}%-ile\")\n",
    "    plt.ylabel(\"# of Students\")\n",
    "    plt.title(\"Distribution of Exam 1 grades\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670efa3-c11c-45fd-b546-32bf35bc1b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 98)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades = np.random.randint(0, 100, 50)\n",
    "min(grades), max(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988745a-c550-44a5-ba17-aa2a1ef17d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "_hist(mut_infos, 0, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f9cb0-4704-4b4a-ad54-e6ece40f5acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD4CAYAAAAqw8chAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMm0lEQVR4nO3dX4yldX3H8ffHXdCCGERODWWZDqaE1poIZEKlNKYFtcAavOnFktDYxmRubAuNiVnilXfbpDF6YU03iDaVYlqEluymqFGJMWmxu0DNwrJVcSur6C5pWsQmRey3F/PQnV1m5jzz55mZ3znvVzKZOec858z3N2d45+xznodJVSFJ2t5es9UDSJLGM9aS1ABjLUkNMNaS1ABjLUkN2DnEg1588cU1Ozs7xENL0kQ6fPjw81U1Wu72QWI9OzvLoUOHhnhoSZpISf59pdvdDSJJDTDWktQAYy1JDTDWktQAYy1JDTDWktSAsbFOcmWSJxZ9vJDkzk2YTZLUGXucdVUdA64CSLID+AHw4LBjSZIWW+1ukBuB71bVigdvS5I21mrPYNwD3LfUDUnmgXmAmZmZdY7Vltm9B9d1/+P7dm/QJJImVe9X1knOBW4F/m6p26tqf1XNVdXcaLTs6e2SpDVYzW6Qm4HHqurHQw0jSVraamJ9G8vsApEkDatXrJOcB7wbeGDYcSRJS+n1BmNV/TfwpoFnkSQtwzMYJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGtD3r5tfmOT+JE8nOZrkuqEHkySd1uuvmwOfAB6uqt9Lci5w3oAzSZLOMjbWSd4AvBP4A4Cqegl4adixJEmL9dkN8hbgFPCZJI8nuTvJ+WdvlGQ+yaEkh06dOrXhg0rSNOsT653ANcCnqupq4KfA3rM3qqr9VTVXVXOj0WiDx5Sk6dYn1ieAE1X1aHf5fhbiLUnaJGNjXVU/Ap5NcmV31Y3AU4NOJUk6Q9+jQf4YuLc7EuQZ4A+HG0mSdLZesa6qJ4C5YUeRJC3HMxglqQHGWpIaYKwlqQHGWpIaYKwlqQHGWpIaYKwlqQHGWpIaYKwlqQHGWpIaYKwlqQHGWpIaYKwlqQHGWpIaYKwlqQHGWpIaYKwlqQHGWpIaYKwlqQHGWpIaYKwlqQG9/rp5kuPAT4CfAy9XlX/pXJI2Ua9Yd36nqp4fbBJJ0rLcDSJJDej7yrqALyUp4C+rav/ZGySZB+YBZmZmNm5CSVql2b0H13zf4/t2b+AkG6fvK+vrq+oa4Gbgg0neefYGVbW/quaqam40Gm3okJI07XrFuqp+2H0+CTwIXDvkUJKkM42NdZLzk1zwytfAe4AjQw8mSTqtzz7rNwMPJnll+7+pqocHnUqSdIaxsa6qZ4C3b8IskqRleOieJDXAWEtSA4y1JDXAWEtSA4y1JDXAWEtSA4y1JDXAWEtSA4y1JDXAWEtSA4y1JDXAWEtSA4y1JDXAWEtSA4y1JDXAWEtSA4y1JDXAWEtSA4y1JDXAWEtSA3rHOsmOJI8nOTDkQJKkV1vNK+s7gKNDDSJJWl6vWCfZBewG7h52HEnSUnb23O7jwIeBC5bbIMk8MA8wMzOz5oFm9x5c832P79u95vtqddbzPIHPlbav7dqgsa+sk7wXOFlVh1farqr2V9VcVc2NRqMNG1CS1G83yPXArUmOA58HbkjyuUGnkiSdYWysq+quqtpVVbPAHuCrVXX74JNJkv6fx1lLUgP6vsEIQFU9AjwyyCSSpGX5ylqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGmCsJakBxlqSGjA21klel+SbSf41yZNJProZg0mSTtvZY5v/AW6oqheTnAN8I8k/VtU/DzybJKkzNtZVVcCL3cVzuo8acihJ0pn6vLImyQ7gMPArwCer6tEltpkH5gFmZmY2csZNMbv34FaPsOmmcc3rsZ6f1/F9uzdwktVpdW6dqdcbjFX186q6CtgFXJvkbUtss7+q5qpqbjQabfCYkjTdVnU0SFX9J/AIcNMQw0iSltbnaJBRkgu7r38BeBfw9MBzSZIW6bPP+hLgr7r91q8B/raqDgw7liRpsT5Hg3wLuHoTZpEkLcMzGCWpAcZakhpgrCWpAcZakhpgrCWpAcZakhpgrCWpAcZakhpgrCWpAcZakhpgrCWpAcZakhpgrCWpAcZakhpgrCWpAcZakhpgrCWpAcZakhpgrCWpAcZakhowNtZJLkvytSRHkzyZ5I7NGEySdNrYv24OvAx8qKoeS3IBcDjJl6vqqYFnkyR1xr6yrqrnquqx7uufAEeBS4ceTJJ02qr2WSeZBa4GHh1kGknSkvrsBgEgyeuBLwB3VtULS9w+D8wDzMzMbNiAqzG79+CWfF9trml8nltc83pnPr5v9wZNMhl6vbJOcg4Lob63qh5Yapuq2l9Vc1U1NxqNNnJGSZp6fY4GCfBp4GhVfWz4kSRJZ+vzyvp64PeBG5I80X3cMvBckqRFxu6zrqpvANmEWSRJy/AMRklqgLGWpAYYa0lqgLGWpAYYa0lqgLGWpAYYa0lqgLGWpAYYa0lqgLGWpAYYa0lqgLGWpAYYa0lqgLGWpAYYa0lqgLGWpAYYa0lqgLGWpAYYa0lqgLGWpAYYa0lqwNhYJ7knyckkRzZjIEnSq/V5Zf1Z4KaB55AkrWBsrKvq68B/bMIskqRl7NyoB0oyD8wDzMzMbNTDToXZvQfXfN/j+3Zv4CSbZz1rbtG0rXcj+DM704a9wVhV+6tqrqrmRqPRRj2sJAmPBpGkJhhrSWpAn0P37gP+CbgyyYkkHxh+LEnSYmPfYKyq2zZjEEnS8twNIkkNMNaS1ABjLUkNMNaS1ABjLUkNMNaS1ABjLUkNMNaS1ABjLUkNMNaS1ABjLUkNMNaS1ABjLUkNMNaS1ABjLUkNMNaS1ABjLUkNMNaS1ABjLUkNMNaS1ABjLUkN6BXrJDclOZbkO0n2Dj2UJOlMY2OdZAfwSeBm4K3AbUneOvRgkqTT+ryyvhb4TlU9U1UvAZ8H3jfsWJKkxXb22OZS4NlFl08Av3H2Rknmgfnu4otJjq1xpouB59d435atad35swEm2Vw+39vYAL9fTax7rVb4efVZ9y+vdGOfWGeJ6+pVV1TtB/b3eLyVv1lyqKrm1vs4rXHd08V1T5eNWHef3SAngMsWXd4F/HA931SStDp9Yv0vwBVJLk9yLrAHeGjYsSRJi43dDVJVLyf5I+CLwA7gnqp6csCZ1r0rpVGue7q47umy/l3EVa/a/SxJ2mY8g1GSGmCsJakB2ybW03JKe5LLknwtydEkTya5o7v+oiRfTvLt7vMbt3rWISTZkeTxJAe6y9Oy7guT3J/k6e65v24a1p7kT7vf8yNJ7kvyuklcd5J7kpxMcmTRdcuuM8ldXeuOJfndPt9jW8R6yk5pfxn4UFX9GvAO4IPdWvcCX6mqK4CvdJcn0R3A0UWXp2XdnwAerqpfBd7Ows9gotee5FLgT4C5qnobCwco7GEy1/1Z4Kazrltynd1/73uAX+/u8xddA1dWVVv+AVwHfHHR5buAu7Z6rk1a+z8A7waOAZd0110CHNvq2QZY667ul/YG4EB33TSs+w3A9+je0F90/USvndNnP1/EwpFnB4D3TOq6gVngyLjn9+y+sXCk3XXjHn9bvLJm6VPaL92iWTZNklngauBR4M1V9RxA9/kXt3C0oXwc+DDwv4uum4Z1vwU4BXym2wV0d5LzmfC1V9UPgD8Hvg88B/xXVX2JCV/3Isutc0292y6x7nVK+yRJ8nrgC8CdVfXCVs8ztCTvBU5W1eGtnmUL7ASuAT5VVVcDP2Uy/um/om4f7fuAy4FfAs5PcvvWTrUtrKl32yXWU3VKe5JzWAj1vVX1QHf1j5Nc0t1+CXByq+YbyPXArUmOs/B/brwhyeeY/HXDwu/3iap6tLt8PwvxnvS1vwv4XlWdqqqfAQ8Av8nkr/sVy61zTb3bLrGemlPakwT4NHC0qj626KaHgPd3X7+fhX3ZE6Oq7qqqXVU1y8Lz+9Wqup0JXzdAVf0IeDbJld1VNwJPMflr/z7wjiTndb/3N7Lwxuqkr/sVy63zIWBPktcmuRy4Avjm2Efb6p3yi3ay3wL8G/Bd4CNbPc+A6/wtFv7J8y3gie7jFuBNLLz59u3u80VbPeuAP4Pf5vQbjFOxbuAq4FD3vP898MZpWDvwUeBp4Ajw18BrJ3HdwH0s7Jf/GQuvnD+w0jqBj3StOwbc3Od7eLq5JDVgu+wGkSStwFhLUgOMtSQ1wFhLUgOMtSQ1wFhLUgOMtSQ14P8AQeNDE91UF+0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins, _ = plt.hist(grades, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f97422d-2c1c-49c7-91b2-433262b26ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.logspace(2, 5, 5) == np.power(10.0, np.linspace(2,5,5))).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb9ee99-53e0-4b50-8f49-833faa5fc79c",
   "metadata": {},
   "source": [
    "Log scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac164d73-d061-4cc7-a71e-f83e1226aecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = sns.load_dataset('diamonds')\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1b9d1-b4c7-43eb-a22e-7e7d2384f797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat        273\n",
       "cut            5\n",
       "color          7\n",
       "clarity        8\n",
       "depth        184\n",
       "table        127\n",
       "price      11602\n",
       "x            554\n",
       "y            552\n",
       "z            375\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa89802-1ec4-4cf9-b2dd-8f4ccb924f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797940</td>\n",
       "      <td>61.749405</td>\n",
       "      <td>57.457184</td>\n",
       "      <td>3932.799722</td>\n",
       "      <td>5.731157</td>\n",
       "      <td>5.734526</td>\n",
       "      <td>3.538734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474011</td>\n",
       "      <td>1.432621</td>\n",
       "      <td>2.234491</td>\n",
       "      <td>3989.439738</td>\n",
       "      <td>1.121761</td>\n",
       "      <td>1.142135</td>\n",
       "      <td>0.705699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5324.250000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>18823.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table         price             x  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.797940     61.749405     57.457184   3932.799722      5.731157   \n",
       "std        0.474011      1.432621      2.234491   3989.439738      1.121761   \n",
       "min        0.200000     43.000000     43.000000    326.000000      0.000000   \n",
       "25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n",
       "50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n",
       "75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \n",
       "max        5.010000     79.000000     95.000000  18823.000000     10.740000   \n",
       "\n",
       "                  y             z  \n",
       "count  53940.000000  53940.000000  \n",
       "mean       5.734526      3.538734  \n",
       "std        1.142135      0.705699  \n",
       "min        0.000000      0.000000  \n",
       "25%        4.720000      2.910000  \n",
       "50%        5.710000      3.530000  \n",
       "75%        6.540000      4.040000  \n",
       "max       58.900000     31.800000  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612c9b8-90f7-4166-8ea2-bf10f0f887d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype   \n",
      "---  ------   --------------  -----   \n",
      " 0   carat    53940 non-null  float64 \n",
      " 1   cut      53940 non-null  category\n",
      " 2   color    53940 non-null  category\n",
      " 3   clarity  53940 non-null  category\n",
      " 4   depth    53940 non-null  float64 \n",
      " 5   table    53940 non-null  float64 \n",
      " 6   price    53940 non-null  int64   \n",
      " 7   x        53940 non-null  float64 \n",
      " 8   y        53940 non-null  float64 \n",
      " 9   z        53940 non-null  float64 \n",
      "dtypes: category(3), float64(6), int64(1)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "diamonds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e215a-8192-4b6b-9e7d-424d2027ccb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sns.scatterplot(x='price', y='carat', data=diamonds, ax=ax, alpha=.05)\n",
    "ax.set_xlabel('Price ($)')\n",
    "ax.set_ylabel('Carat')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7b8c2-9427-43db-b690-73a675980790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sns.scatterplot(x='price', y='carat', data=diamonds, ax=ax, alpha=.05)\n",
    "ax.set_xlabel('Price ($)')\n",
    "ax.set_ylabel('Carat')\n",
    "ax.set_xscale('log') # added\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415503dc-7e2d-4e7b-ae1d-853e615da1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sns.scatterplot(x='price', y='carat', data=diamonds, ax=ax, alpha=.05)\n",
    "ax.set_xlabel('Price ($)')\n",
    "ax.set_ylabel('Carat')\n",
    "ax.set_xscale('log') \n",
    "ax.set_xticks([300, 500, 700, 1000, 1500, 2000, 2500, 3000, 5000, 7000, 10000]) # added\n",
    "ax.set_xticklabels([300, 500, 700, 1000, 1500, 2000, 2500, 3000, 5000, 7000, 10000]) # added\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6814dab-edc2-43f1-84b0-5823b68a2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter\n",
    "formatter = ScalarFormatter()\n",
    "formatter.set_scientific(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d5d768-3416-4948-a163-34e1e5d42da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "sns.scatterplot(x='price', y='carat', data=diamonds, ax=ax, alpha=.05)\n",
    "ax.set_xlabel('Price ($)')\n",
    "ax.set_ylabel('Carat')\n",
    "ax.set_xscale('log') \n",
    "for axis in (ax.xaxis, ax.yaxis): axis.set_major_formatter(formatter)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c8e13-245e-4ca4-b703-641d36ca4832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Extremely far exoplanets\n",
    "extremes = [465413, 2231451, 897931, 931312, 1612312]\n",
    "radius_extreme = [7986, 13456, 23144, 13254, 8562]\n",
    "\n",
    "# Nearer exoplanets\n",
    "exo_distance = [5, 4, 4, 8, 9, 12, 31]\n",
    "exo_radius = [13165, 7985, 9847, 6654, 25647, 15644, 10312]\n",
    "\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "sns.scatterplot(x=exo_distance, y=exo_radius, s=80)\n",
    "sns.scatterplot(x=extremes, y=radius_extreme, s=80)\n",
    "\n",
    "ax.axis([1, 10000000, 0, 40000])\n",
    "\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "\n",
    "ax.tick_params(bottom=True, which='both', width=2, length=5, labelsize=10)\n",
    "\n",
    "ax.set_title('Distance vs. Radius of Exoplanets', fontsize=20)\n",
    "ax.set_xlabel('Distance (light years)', fontsize=20)\n",
    "ax.set_ylabel('Radius (km)', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e2f38-bbb6-4a17-a5f3-97e79bc68c2d",
   "metadata": {},
   "source": [
    "We can now build the `Dataloaders` object from this dataframe `df_collab`, by defaultit takes the first column as the user (in our case the token) and the second column as the item (in our case the label), and the third column as the ratings (in our case the frequency):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2b499-7ee9-4fd5-9070-0ce6a419507d",
   "metadata": {},
   "source": [
    "#### Make `Dataloaders` and load it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db27ec75-e9ea-410a-9b35-1959c9812903",
   "metadata": {},
   "source": [
    "##### Using Fastai's Mid-Level API:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b88f4-5aeb-4d28-9cc7-ae55d10a58ed",
   "metadata": {},
   "source": [
    "###### Loading DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdba7d6-3b0a-462e-a072-471dd3c0a765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>length</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86006</td>\n",
       "      <td>111912</td>\n",
       "      <td>admission date discharge date date of birth sex f service surgery allergies patient recorded as having no known allergies to drugs attending first name3 lf chief complaint 60f on coumadin was found slightly drowsy tonight then fell down stairs paramedic found her unconscious and she was intubated w o any medication head ct shows multiple iph transferred to hospital1 for further eval major surgical or invasive procedure none past medical history her medical history is significant for hypertension osteoarthritis involving bilateral knee joints with a dependence on cane for ambulation chronic...</td>\n",
       "      <td>801.35;348.4;805.06;807.01;998.30;707.24;E880.9;427.31;414.01;401.9;V58.61;V43.64;707.00;E878.1;96.71</td>\n",
       "      <td>230</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85950</td>\n",
       "      <td>189769</td>\n",
       "      <td>admission date discharge date service neurosurgery allergies sulfa sulfonamides attending first name3 lf chief complaint cc cc contact info major surgical or invasive procedure none history of present illness hpi 88m who lives with family had fall yesterday today had decline in mental status ems called pt was unresponsive on arrival went to osh head ct showed large r sdh pt was intubated at osh and transferred to hospital1 for further care past medical history cad s p mi in s p cabg in ventricular aneurysm at that time cath in with occluded rca unable to intervene chf reported ef 1st degre...</td>\n",
       "      <td>852.25;E888.9;403.90;585.9;250.00;414.00;V45.81;96.71</td>\n",
       "      <td>304</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id hadm_id  \\\n",
       "0      86006  111912   \n",
       "1      85950  189769   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  admission date discharge date date of birth sex f service surgery allergies patient recorded as having no known allergies to drugs attending first name3 lf chief complaint 60f on coumadin was found slightly drowsy tonight then fell down stairs paramedic found her unconscious and she was intubated w o any medication head ct shows multiple iph transferred to hospital1 for further eval major surgical or invasive procedure none past medical history her medical history is significant for hypertension osteoarthritis involving bilateral knee joints with a dependence on cane for ambulation chronic...   \n",
       "1  admission date discharge date service neurosurgery allergies sulfa sulfonamides attending first name3 lf chief complaint cc cc contact info major surgical or invasive procedure none history of present illness hpi 88m who lives with family had fall yesterday today had decline in mental status ems called pt was unresponsive on arrival went to osh head ct showed large r sdh pt was intubated at osh and transferred to hospital1 for further care past medical history cad s p mi in s p cabg in ventricular aneurysm at that time cath in with occluded rca unable to intervene chf reported ef 1st degre...   \n",
       "\n",
       "                                                                                                  labels  \\\n",
       "0  801.35;348.4;805.06;807.01;998.30;707.24;E880.9;427.31;414.01;401.9;V58.61;V43.64;707.00;E878.1;96.71   \n",
       "1                                                  852.25;E888.9;403.90;585.9;250.00;414.00;V45.81;96.71   \n",
       "\n",
       "   length  is_valid  \n",
       "0     230     False  \n",
       "1     304     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data,\n",
    "                 header=0,\n",
    "                 names=['subject_id', 'hadm_id', 'text', 'labels', 'length', 'is_valid'],\n",
    "                 dtype={'subject_id': str, 'hadm_id': str, 'text': str, 'labels': str, 'length': np.int64, 'is_valid': bool})\n",
    "df[['text', 'labels']] = df[['text', 'labels']].astype(str)\n",
    "len(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ce8b7-e15b-445a-b186-1ffc42c5408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ColReader('labels', label_delim=';')\n",
    "lbs_frqs = Counter()\n",
    "for o in df.itertuples(): lbs_frqs.update(f(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39dc53-6aa4-4b4c-b766-ebe425b541a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.parent/'data'/'code_desc.pkl', 'rb') as f: lbs_desc = pickle.load(f)\n",
    "df_toks = pd.read_feather(collab_tok_path)\n",
    "df_lbs = pd.read_feather(collab_lbl_path)\n",
    "df_lbs['description'] = df_lbs['lbl_val'].map(lbs_desc)\n",
    "df_lbs['freq'] = df_lbs['lbl_val'].map(lbs_frqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5951cf8-68d4-44d9-8996-5fbdc9d6b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collab = pd.read_feather(collab_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67a392-97dc-4878-b0fc-c5cc918e71f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>bcx_mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>866.0</td>\n",
       "      <td>-6.530356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>-6.753679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>-6.530356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>823.0</td>\n",
       "      <td>-6.753679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>984.0</td>\n",
       "      <td>-6.391284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  label  mutual_info    rank  bcx_mutual_info\n",
       "0      0      0     0.000022   866.0        -6.530356\n",
       "1      0      1     0.000011  1022.0        -6.753679\n",
       "2      0      2     0.000022  1156.0        -6.530356\n",
       "3      0      3     0.000011   823.0        -6.753679\n",
       "4      0      4     0.000033   984.0        -6.391284"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323874cd-cd58-4eaa-b038-22dcfd659404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57352, 8922)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab.token.nunique(), df_collab.label.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e45c1-def9-4823-9158-e2355e193f53",
   "metadata": {},
   "source": [
    "Let's sample a tiny df from `df_collab` for quick experimentaion with `DataLoaders` creation and Model building/analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e6b9f-cb74-42c9-9381-b0d1bba682e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 100\n",
    "mask = df_collab.token.isin(range(num)) & df_collab.label.isin(range(num))\n",
    "test_eq(mask.sum(), num**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bfe47e-2260-401e-84f3-9d9ba126810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>rank</th>\n",
       "      <th>bcx_mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>866.0</td>\n",
       "      <td>-6.530356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>-6.753679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>-6.530356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>823.0</td>\n",
       "      <td>-6.753679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>984.0</td>\n",
       "      <td>-6.391284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  label  mutual_info    rank  bcx_mutual_info\n",
       "0      0      0     0.000022   866.0        -6.530356\n",
       "1      0      1     0.000011  1022.0        -6.753679\n",
       "2      0      2     0.000022  1156.0        -6.530356\n",
       "3      0      3     0.000011   823.0        -6.753679\n",
       "4      0      4     0.000033   984.0        -6.391284"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiny = df_collab[mask].reset_index(drop=True)\n",
    "df_tiny.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b59299-3fcf-4f09-8dbb-b2b03f239c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(df_tiny.token.nunique(), num) \n",
    "test_eq(df_tiny.label.nunique(), num) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69212c3c-9be2-4084-b0fe-b2190e0815ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tiny = df_collab.sample(n=5000, random_state=88).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ca101-b573-43e0-b66f-39cfb4e3474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tiny.to_feather('df_tiny.ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9272148-c1f1-4653-ac1a-553d0c357496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tiny = pd.read_feather('df_tiny.ft')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d946375e-1cfb-4b6b-a26d-983e398b66dc",
   "metadata": {},
   "source": [
    "Let's just delete the `df_collab` to free up RAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed7e13c-0c14-45e3-aae8-7d8fa7bba6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab = pd.DataFrame()\n",
    "lst = [df_collab]\n",
    "del lst\n",
    "del df_collab\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729a153-2df1-4a58-9cde-6e89f2664893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(df_tiny): 10000\n"
     ]
    }
   ],
   "source": [
    "ic(len(df_tiny));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aaf3dd-e193-4ab0-b00c-06f4d39ebe52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token               100\n",
       "label               100\n",
       "mutual_info        3845\n",
       "rank               6221\n",
       "bcx_mutual_info    3742\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiny.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d39d53-434d-4382-aee7-325441aeabd5",
   "metadata": {},
   "source": [
    "###### `DataLoader` for Collab Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9169598-2613-460b-afd3-2d590f917cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.76 ms, sys: 0 ns, total: 9.76 ms\n",
      "Wall time: 9.37 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f_x = ColReader(['token', 'label'])\n",
    "f_y = ColReader('bcx_mutual_info')\n",
    "# L(f_x(o) for o in df_tiny.itertuples())\n",
    "# L(f_y(o) for o in df_tiny.itertuples())\n",
    "tfms_x = [f_x, ListToTensor()]\n",
    "tfms_y = [f_y]\n",
    "tfms = [tfms_x, tfms_y]\n",
    "splits = RandomSplitter(seed=42)(df_tiny)\n",
    "dsets = Datasets(df_tiny, tfms, splits=splits)\n",
    "# dsets = Datasets(df_collab, tfms=tfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982bd04b-3f71-4354-860f-1a5b28eb037b",
   "metadata": {},
   "source": [
    "We need to make sure that the training and validation set has all the tokens and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f2c4e-3304-4fd9-b763-9c5fce2e9289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, df_val = df_tiny.loc[splits[0]].reset_index(drop=True), df_tiny.loc[splits[1]].reset_index(drop=True)\n",
    "assert df_trn.token.nunique() == num & df_trn.label.nunique() == num\n",
    "assert df_val.token.nunique() == num & df_val.label.nunique() == num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a6a8db-38ce-4c91-a1d8-1dab7e56db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(dsets.train) + len(dsets.valid), len(df_tiny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e6f21-cd0c-4f71-8046-d918526fe079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0, 0]), -6.530355930328369),\n",
       " (tensor([0, 1]), -6.753678798675537),\n",
       " (tensor([0, 2]), -6.530355930328369),\n",
       " (tensor([0, 3]), -6.753678798675537),\n",
       " (tensor([0, 4]), -6.391283988952637)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76528474-f893-4cb8-b1e9-ef2b3f323fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, numpy.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsets[0][0]), type(dsets[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748bb3d-0b82-487a-9d85-e63f3b4abbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dsets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce70a3-0527-4b6f-b533-d721d8a2d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x: tensor([0, 0])\n",
      "ic| y: -6.530355930328369\n"
     ]
    }
   ],
   "source": [
    "ic(x)\n",
    "ic(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0cbf42-1008-4b7f-b830-ab08e82ce8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#2) [tensor(0),tensor(0)], -6.530355930328369)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets.decode((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb33c0c-a9b7-4b39-b71a-e187dadc94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataLoader(DataLoader):\n",
    "    def randomize(self):\n",
    "        seed = np.random.default_rng().integers(0, 2**32-1, 1).item()\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def shuffle_fn(self, idxs): return self.rng.permutation(idxs)\n",
    "\n",
    "    def get_idxs(self):\n",
    "        if self.n is not None: idxs = range(self.n)\n",
    "        if self.shuffle: idxs = (idx for idx in self.shuffle_fn(idxs))\n",
    "        return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2a0b9-da91-45ce-a6a9-7fbacd70ac79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.34 ms, sys: 7.58 ms, total: 9.92 ms\n",
      "Wall time: 8.85 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# bs = 1024 * 50\n",
    "bs = 128\n",
    "# dls_collab = dsets.dataloaders(bs=bs, shuffle=False, after_batch=partial(to_device, device=default_device()), num_workers=0).cuda()\n",
    "dls_collab0 = MyDataLoader(dsets.train, bs=bs, shuffle=True, after_batch=partial(to_device, device=default_device()), num_workers=num_cpus())\n",
    "dls_collab1 = MyDataLoader(dsets.valid, bs=bs, shuffle=False, after_batch=partial(to_device, device=default_device()), num_workers=num_cpus())\n",
    "test_eq(len(dls_collab0), np.ceil(len(dsets.train)/128)) \n",
    "test_eq(len(dls_collab1), np.ceil(len(dsets.valid)/128))\n",
    "dls_collab = DataLoaders(dls_collab0, dls_collab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e6332-1332-48f0-bc75-e077ebaa4ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_collab.fake_l.num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15efbeb9-3013-413d-84a8-1daf13a77626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls_collab.train), len(dls_collab.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1079d883-93a7-42cd-bf4d-e6ccab55ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(dls_collab_path, 'wb') as f: pickle.dump(dls_collab, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cfe783-be09-4f40-a8be-13340167e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(dls_collab_path, 'rb') as f: dls_collab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a8fdf-6a0b-4511-8e77-3926aa6e180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 51.1 s, total: 1min 4s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.save(dls_collab, dls_collab_path, pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f52d22-5a70-4548-9c35-3ef054cbd290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 s, sys: 25.9 s, total: 28.2 s\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dls_collab = torch.load(dls_collab_path, map_location=lambda storage, loc: storage.cuda(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3e888-f740-47ef-b541-133654ea1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(dls_collab.device, default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba32e5c-334f-405d-91c4-56d73fb7e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs = 1024\n",
    "xb, yb = dls_collab.one_batch()\n",
    "test_eq(xb.dtype, torch.int64)\n",
    "test_eq(xb.shape, (bs, 2))\n",
    "test_eq(type(yb), Tensor)\n",
    "test_eq(yb.shape, [bs])\n",
    "test_eq(default_device().index, 0)\n",
    "test_eq(default_device().index, sum([o.device.index for o in (xb,yb)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aaa90e-f18f-47e0-ade6-ffe9c5c286c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_batch = torch.cat((xb, yb.unsqueeze(-1)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3325bdd-7bb1-4946-9362-8385d1172fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>bcx_mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-6.339581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.708092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-6.856811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-7.170342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-7.107794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-6.228233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-6.740957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-9.734209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-6.357643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.309844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  label  bcx_mutual_info\n",
       "0   58.0   86.0        -6.339581\n",
       "1    9.0   11.0        -6.708092\n",
       "2   68.0   53.0        -6.856811\n",
       "3   20.0   31.0        -7.170342\n",
       "4   73.0   91.0        -7.107794\n",
       "5   56.0   80.0        -6.228233\n",
       "6   43.0   63.0        -6.740957\n",
       "7   12.0   62.0        -9.734209\n",
       "8   73.0   72.0        -6.357643\n",
       "9   38.0    4.0        -7.309844"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_batch = pd.DataFrame(one_batch, columns=['token', 'label', 'bcx_mutual_info'])\n",
    "df_one_batch.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49d83f-c502-4c65-b0f1-90da620d7eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>bcx_mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-6.339581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.708092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-6.856811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-7.170342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-7.107794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-6.228233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-6.740957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-9.734209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-6.357643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.309844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  label  bcx_mutual_info\n",
       "0   58.0   86.0        -6.339581\n",
       "1    9.0   11.0        -6.708092\n",
       "2   68.0   53.0        -6.856811\n",
       "3   20.0   31.0        -7.170342\n",
       "4   73.0   91.0        -7.107794\n",
       "5   56.0   80.0        -6.228233\n",
       "6   43.0   63.0        -6.740957\n",
       "7   12.0   62.0        -9.734209\n",
       "8   73.0   72.0        -6.357643\n",
       "9   38.0    4.0        -7.309844"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab_one_batch = df_trn.loc[:bs-1, ['token','label', 'bcx_mutual_info']]\n",
    "df_collab_one_batch[['token', 'label', 'bcx_mutual_info']] = df_collab_one_batch[['token', 'label', 'bcx_mutual_info']].astype(np.float)\n",
    "df_collab_one_batch.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550c847-0838-4349-9efe-1ad607c7012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_one_batch.equals(df_collab_one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0a288-9d05-4fda-98ba-6dc71cd79e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(dls_collab.train), np.ceil(len(dls_collab.dataset)/bs))\n",
    "test_eq(len(dls_collab.valid), np.ceil(len(dls_collab.valid.dataset)/bs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de282097-09eb-4560-9d04-cb9c72aec90a",
   "metadata": {},
   "source": [
    "---\n",
    "Trying to solve the memory problem in `DataLoader` batching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433872a-b53a-4f4d-bf8c-c363d36f31c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataLoader.__iter__>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(dls_collab)\n",
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f670e1c-5b73-451b-b88f-0e21eba3b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "while True:\n",
    "    try:\n",
    "        pdb.set_trace()\n",
    "        xb, yb = next(it)\n",
    "        print(f\"{xb = }, {yb = }\")\n",
    "    except StopIteration as e: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72f0f8-2107-4b39-8e7e-ee6f03dceeb9",
   "metadata": {},
   "source": [
    "###### `DataLoader` for [Learning to Rank (L2R)](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d570c-96c7-405b-b8a7-5e14659e70ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>823.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>984.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  label    rank\n",
       "0      0      0   866.0\n",
       "1      0      1  1022.0\n",
       "2      0      2  1156.0\n",
       "3      0      3   823.0\n",
       "4      0      4   984.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab = pd.read_feather(collab_data_path)\n",
    "df_collab = df_collab.drop(['mutual_info', 'bcx_mutual_info'], axis=1)\n",
    "df_collab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea5a33-46e4-437e-ac40-a6ac7d442cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(df_collab.token.nunique(), 57352) \n",
    "test_eq(df_collab.label.nunique(), 8922)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839c71e-8e37-430d-91a3-2b5e0ee59bff",
   "metadata": {},
   "source": [
    "**`df_tiny`**: If we need to a smaller dataset for quick iteration\n",
    "\n",
    "Note: For technical reasons behind building a `dataloader` the number of tokens should be $x (mod 64) \\equiv 8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5fa08-64fc-4a40-b3cb-7b9a0d466ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_toks, num_lbs = 8 + 5*64, 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16f680-7fb2-48db-8880-0155e7e787e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might have to repeat this a few times until the follwoing cell asserst true\n",
    "rnd_toks = np.random.randint(0, len(df_collab.token.unique()), size=(num_toks,) )\n",
    "rnd_lbs = np.random.randint(0, len(df_collab.label.unique()), size=(num_lbs,) )\n",
    "mask = df_collab.token.isin(rnd_toks) & df_collab.label.isin(rnd_lbs)\n",
    "df_tiny = df_collab.loc[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508d640-1da6-4d5e-a5ad-5d63c3b8502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(df_tiny.token.nunique(), num_toks) \n",
    "test_eq(df_tiny.label.nunique(), num_lbs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd4c76-8b60-4739-a429-ea7d0f8f799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tiny.to_feather('df_tiny.ft')\n",
    "df_tiny = pd.read_feather('df_tiny.ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dab4c5-c2c7-4ed6-9e22-4912b0104ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tiny = df_tiny.drop(['mutual_info', 'bcx_mutual_info'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e492de0-8ddd-423a-aafb-301ba954b13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82</td>\n",
       "      <td>60</td>\n",
       "      <td>42717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>62</td>\n",
       "      <td>27548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>10617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>136</td>\n",
       "      <td>52177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>195</td>\n",
       "      <td>1359.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  label     rank\n",
       "0     82     60  42717.0\n",
       "1     82     62  27548.0\n",
       "2     82     86  10617.0\n",
       "3     82    136  52177.0\n",
       "4     82    195   1359.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiny.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28fe0a7-7c34-4f2c-bfc9-d6a8df861da8",
   "metadata": {},
   "source": [
    "**Only for `df_tiny`**:\n",
    "\n",
    "Due to random sampling the rankings are not uniform i.e., not from 0 to 99. A litte preprocessing to make sure that we have uniform rankings for all labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204ef0c-5417-4fce-a634-5e8eeeccad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_tiny.groupby('label', group_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef6dd9c-6748-40b2-9f44-aaa28301a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_rerank(df, column='rank'):\n",
    "    df = df.sort_values(by=column)\n",
    "    df['rank'] = range(len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c93c5ce-3c95-4518-8e33-cc6a514224a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiny = grouped.apply(sort_rerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e84793-2f67-46ee-9ea6-794c8f75cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_grouped = dict(list(df_tiny.groupby('label')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d0cdb-afee-4005-a6de-bd1561eb3012",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lbl = random.choice(list(dict_grouped.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566e771-9e4e-4f5d-81b0-8f421dcf4dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>1538</td>\n",
       "      <td>6972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>2600</td>\n",
       "      <td>6972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>2093</td>\n",
       "      <td>6972</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>4138</td>\n",
       "      <td>6972</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>1988</td>\n",
       "      <td>6972</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33361</th>\n",
       "      <td>56446</td>\n",
       "      <td>6972</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33465</th>\n",
       "      <td>56456</td>\n",
       "      <td>6972</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33673</th>\n",
       "      <td>56513</td>\n",
       "      <td>6972</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33985</th>\n",
       "      <td>56894</td>\n",
       "      <td>6972</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34089</th>\n",
       "      <td>57210</td>\n",
       "      <td>6972</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       token  label  rank\n",
       "1537    1538   6972     0\n",
       "2369    2600   6972     1\n",
       "2161    2093   6972     2\n",
       "3825    4138   6972     3\n",
       "2057    1988   6972     4\n",
       "...      ...    ...   ...\n",
       "33361  56446   6972   323\n",
       "33465  56456   6972   324\n",
       "33673  56513   6972   325\n",
       "33985  56894   6972   326\n",
       "34089  57210   6972   327\n",
       "\n",
       "[328 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_grouped[a_lbl]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48faa4c9-7182-4ca1-9435-f6d55089c79b",
   "metadata": {},
   "source": [
    "Using Pandas `groupby` to add *relevance scores* to each token-label pair based on the corresponding ranks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00071b3-00b1-4619-b53d-688f0727a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_collab.groupby('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f113934-8854-4d27-9280-61ec9413ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_grouped = dict(list(grouped))\n",
    "# _tmp = dict_grouped[16].copy()\n",
    "# _tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794f044-e72c-4c89-9fc2-dd5158a2bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(df, qnts, column='rank'):\n",
    "    num = df.to_numpy()\n",
    "    bins = np.quantile(num[:, -1], qnts)\n",
    "    num[:, -1] = len(bins) - np.digitize(num[:, -1], bins)\n",
    "    # bins = np.quantile(df['rank'], qnts)\n",
    "    # df[column] = len(bins) - np.digitize(df['rank'], bins)\n",
    "    # df[column] = pd.qcut(df[column], qnts, labels=labels)\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08133b4-0397-48ea-b604-6b1bc186090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 ms, sys: 0 ns, total: 15.2 ms\n",
      "Wall time: 13.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qnts = np.concatenate([array([0]), np.geomspace(1e-2, 1, 10)])\n",
    "scored = grouped.apply(cut, qnts) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdeba64-1ba7-45a9-90ea-80dcd00ccb43",
   "metadata": {},
   "source": [
    "**[Simulate Pandas `groupby` using `Numpy/PyTorch`](https://stackoverflow.com/questions/38013778/is-there-any-numpy-group-by-function/38015063#38015063):** (Why? `Pandas` are cute but speed thrills! More importantly: \"Memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aacef3-5482-41e1-83ec-9729cb7f08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(df, qnts):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    # from IPython import embed; embed()\n",
    "    data = qnts.new_tensor(df.to_numpy())\n",
    "    test_eq(data.shape, (len(df), 3)) # dim1 is a 3 tuple (token, label, rank)\n",
    "    # sort by the labels\n",
    "    data = data[data[:, 1].argsort()]\n",
    "    # indices of the unique labels\n",
    "    # import pdb; pdb.set_trace()\n",
    "        # splt_idxs = np.concatenate([torch.as_tensor(np.unique(data[:, 1].cpu().numpy(), return_index=True)[1], device=default_device(), dtype=torch.int).cpu().numpy(), array([len(data)])])\n",
    "        # splt_idxs = list(splt_idxs[1:] - splt_idxs[:-1])\n",
    "    splt_idxs = np.unique(data[:, 1].cpu().numpy(), return_index=True)[1][1:]\n",
    "    # split by the unique labels\n",
    "    data = np.split(data.cpu().numpy(), splt_idxs)\n",
    "    # stacking the 0th dim with label specific data\n",
    "    data = np.stack(data)\n",
    "    # data = torch.as_tensor(data, dtype=qnts.dtype)\n",
    "    data = qnts.new_tensor(data)\n",
    "    # test_eq(data.shape, (8922, 57352, 3))\n",
    "    # computing the bins based on qnts\n",
    "    bins = torch.quantile(data[:, :, -1], qnts, dim=1)\n",
    "    # test_eq(bins.shape, (101, 8922))\n",
    "    # replacing ranks with relevance scores\n",
    "    relv_scores = bins.shape[0] - torch.searchsorted(bins.T, data[:, :, -1], right=False) # shape (8922, 57352)\n",
    "    data = torch.cat((data, relv_scores.unsqueeze(-1)), dim=-1)\n",
    "    # data[:, :, -1] = relv_scores\n",
    "    return data # dim 0: labels, dim 1: 3 tuple (token, label, rank, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f918baf-3cf8-4530-8e08-4d586c750d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| qnts: tensor([0.0000e+00, 1.0000e-04, 1.0975e-04, 1.2045e-04, 1.3219e-04, 1.4508e-04, 1.5923e-04, 1.7475e-04, 1.9179e-04, 2.1049e-04, 2.3101e-04, 2.5354e-04, 2.7826e-04, 3.0539e-04, 3.3516e-04, 3.6784e-04,\n",
      "                  4.0370e-04, 4.4306e-04, 4.8626e-04, 5.3367e-04, 5.8570e-04, 6.4281e-04, 7.0548e-04, 7.7426e-04, 8.4975e-04, 9.3260e-04, 1.0235e-03, 1.1233e-03, 1.2328e-03, 1.3530e-03, 1.4850e-03, 1.6298e-03,\n",
      "                  1.7886e-03, 1.9630e-03, 2.1544e-03, 2.3645e-03, 2.5950e-03, 2.8480e-03, 3.1257e-03, 3.4305e-03, 3.7649e-03, 4.1320e-03, 4.5349e-03, 4.9770e-03, 5.4623e-03, 5.9948e-03, 6.5793e-03, 7.2208e-03,\n",
      "                  7.9248e-03, 8.6975e-03, 9.5455e-03, 1.0476e-02, 1.1498e-02, 1.2619e-02, 1.3849e-02, 1.5199e-02, 1.6681e-02, 1.8307e-02, 2.0092e-02, 2.2051e-02, 2.4201e-02, 2.6561e-02, 2.9151e-02, 3.1993e-02,\n",
      "                  3.5112e-02, 3.8535e-02, 4.2292e-02, 4.6416e-02, 5.0941e-02, 5.5908e-02, 6.1359e-02, 6.7342e-02, 7.3907e-02, 8.1113e-02, 8.9022e-02, 9.7701e-02, 1.0723e-01, 1.1768e-01, 1.2915e-01, 1.4175e-01,\n",
      "                  1.5557e-01, 1.7074e-01, 1.8738e-01, 2.0565e-01, 2.2570e-01, 2.4771e-01, 2.7186e-01, 2.9836e-01, 3.2745e-01, 3.5938e-01, 3.9442e-01, 4.3288e-01, 4.7508e-01, 5.2140e-01, 5.7224e-01, 6.2803e-01,\n",
      "                  6.8926e-01, 7.5646e-01, 8.3022e-01, 9.1116e-01, 1.0000e+00], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "qnts = to_device(torch.concat([tensor([0]), torch.logspace(torch.log10(tensor(1e-4)), torch.log10(tensor(1)), 100)]))\n",
    "ic(qnts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10807ec9-ec36-4548-8751-aad9027cac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 619 ms, sys: 9.86 ms, total: 629 ms\n",
      "Wall time: 86.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# scored_toks = score(df_collab, qnts)\n",
    "scored_toks = score(df_tiny, qnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4aa7a1-c621-4595-834e-9b3c2693a877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| scored_toks.shape: torch.Size([104, 328, 4])\n"
     ]
    }
   ],
   "source": [
    "ic(scored_toks.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0be51-5ee4-4895-b45c-c39981bbe386",
   "metadata": {},
   "source": [
    "Save!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b18bfbf-b10b-4181-8c6e-8daa651a652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(scored_toks, 'scored_tokens.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2da3a9-92a9-43e7-9a64-377dcb42f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tiny = df_tiny.pivot(index='token', columns='label', values=['rank', 'bcx_mutual_info'])\n",
    "# df_tiny_copy = df_tiny.pivot(index='token', columns='label', values='rank')\n",
    "# columns = [(p, o) for o in range(num) for p in ('rank', 'bcx_mutual_info')]\n",
    "# df_tiny = df_tiny[columns].swaplevel(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac7e45-0957-4904-9811-e7dcaa1cb53e",
   "metadata": {},
   "source": [
    "Create training and validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab4ebce-a1e9-4539-81ba-6759bd026461",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_toks = torch.load('scored_tokens.pth')\n",
    "test_eq(scored_toks.device, default_device())\n",
    "# test_eq(scored_toks.device, torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91675baf-433d-4211-a438-73975cd1f8ee",
   "metadata": {},
   "source": [
    "If you want to get it into the cpu RAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8be98-c42c-420f-baf5-42f6602ca514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| scored_toks.shape: torch.Size([104, 328, 4])\n"
     ]
    }
   ],
   "source": [
    "scored_toks = scored_toks.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "ic(scored_toks.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e07c50-c3e9-4f44-a147-5d68a443558c",
   "metadata": {},
   "source": [
    "**Remember**: In `scored_toks` dim 0: labels, dim 1: 4 tuple (token, label, rank, score). Below is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f72833-c73a-4c24-bc8d-1d02c174003c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11156.,  8326.,    32.,    25.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_toks[97, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984e8d3-852f-4935-92fa-15b4b3df4ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>11156</td>\n",
       "      <td>8326</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token  label  rank\n",
       "7065  11156   8326    32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiny[(df_tiny.token == 11156) & (df_tiny.label == 8326)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9d519-683f-45b9-b0d6-62e5e53de67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = scored_toks[:, :, 2].unique(dim=1).sort(-1)[0]\n",
    "ranks_shouldbe = torch.arange(scored_toks.shape[1], dtype=torch.float).expand(scored_toks.shape[0], -1)\n",
    "test_eq(ranks, ranks_shouldbe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52078c5b-d844-4c14-8149-2f2bfcdcf14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(scored_toks, n_lbs, n_toks):\n",
    "    test_eq(scored_toks.shape, (n_lbs, n_toks, 4))\n",
    "    qnts = (1 - torch.concat([tensor([0.]), torch.logspace(torch.log10(tensor(1e-4)), torch.log10(tensor(1.)), 10)])).flip(dims=(0,))\n",
    "    test_eq(qnts.shape, [11])\n",
    "    bins = torch.quantile(scored_toks[:, :, -1], qnts, dim=1)\n",
    "    test_eq(bins.shape, (11, n_lbs))\n",
    "    binned_toks = torch.searchsorted(bins.T, scored_toks[:, :, -1])\n",
    "    test_eq(binned_toks.shape, (n_lbs, n_toks))\n",
    "    # import pdb; pdb.set_trace()\n",
    "    bin_nums = binned_toks[0].unique() # all the labels have same binning because we are quantizing the scores\n",
    "    right_bds = bins[:, 0][bin_nums]\n",
    "    left_bds = torch.concat([tensor([-torch.inf]), bins[:, 0][bin_nums[1:]-1]])\n",
    "    bin_bds = torch.concat((left_bds[:,None], right_bds[:, None]), dim=1)\n",
    "    bin_size = torch.bincount(binned_toks[0])\n",
    "    probs = binned_toks.new_ones(binned_toks.shape).div(3.*bin_size[binned_toks])\n",
    "    # probs[bin_size[binned_toks] > 4] = 2.*probs[bin_size[binned_toks] > 4] \n",
    "    # probs[bin_size[binned_toks] <= 4] = 0.001*probs[bin_size[binned_toks] <= 4] \n",
    "    probs[binned_toks < bin_nums[-2]] = 2.*probs[binned_toks < bin_nums[-2]] \n",
    "    # probs[bin_size[binned_toks] <= 4] = 0.001*probs[bin_size[binned_toks] <= 4] \n",
    "    is_valid = torch.bernoulli(probs)\n",
    "    return scored_toks, binned_toks, probs, is_valid, bin_size, bin_bds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabb507-498b-4cdf-a9a5-0034c4058167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_split(binned_toks, is_valid):\n",
    "    \"pads the validation set for each label to the nearest multiple of 16\"\n",
    "    val_sizes = is_valid.sum(dim = -1)\n",
    "    sl = 16 * torch.floor(val_sizes.max()/16) + 16\n",
    "    deficit = (sl - val_sizes).int()\n",
    "    top3bins = binned_toks[0].unique().sort(descending=True)[0][:3]\n",
    "    for i,d in enumerate(deficit):\n",
    "        val_idxs = torch.where(is_valid[i]==True)[0]\n",
    "        trn_idxs = torch.where(is_valid[i]==False)[0]\n",
    "        top3idxs = torch.where(torch.isin(binned_toks[i], top3bins))[0].sort()[0]\n",
    "        trn_idxs = torch.as_tensor(np.setdiff1d(trn_idxs.cpu().numpy(), top3idxs.cpu().numpy()))\n",
    "        more_val_idxs = trn_idxs[torch.randperm(len(trn_idxs))[:d].long()]\n",
    "        is_valid[i][more_val_idxs] = 1\n",
    "    return sl.int().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c67f1-f803-47f6-b0a9-fa2abc01ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.6 ms, sys: 0 ns, total: 61.6 ms\n",
      "Wall time: 45.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# n_lbs, n_toks = 8922, 57352\n",
    "n_lbs, n_toks = num_lbs, num_toks\n",
    "scored_toks, binned_toks, probs, is_valid, bin_size, bin_bds = train_test_split(scored_toks, n_lbs, n_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0337e514-b221-4c8f-9095-0c85e2d97399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_sl=16\n",
      "CPU times: user 308 ms, sys: 0 ns, total: 308 ms\n",
      "Wall time: 41.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_sl = pad_split(binned_toks, is_valid)\n",
    "test_eq(is_valid.sum(dim=-1).unique().item(), val_sl)\n",
    "print(f\"{val_sl=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc53aa7-cbd3-4537-940d-567ccbe0bc51",
   "metadata": {},
   "source": [
    "Taking a look at the train/valid split for some labels (just to make sure we ticked all boxes!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e17d8d-64d8-4c0c-a28b-656311154cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7674.0</td>\n",
       "      <td>7697.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5755.0</td>\n",
       "      <td>7697.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5285.0</td>\n",
       "      <td>7697.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4173.0</td>\n",
       "      <td>7697.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1306.0</td>\n",
       "      <td>7697.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>51590.0</td>\n",
       "      <td>7697.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>51498.0</td>\n",
       "      <td>7697.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>51347.0</td>\n",
       "      <td>7697.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>50970.0</td>\n",
       "      <td>7697.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>57210.0</td>\n",
       "      <td>7697.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       token   label   rank  score\n",
       "0     7674.0  7697.0    0.0  101.0\n",
       "1     5755.0  7697.0    1.0   63.0\n",
       "2     5285.0  7697.0    2.0   55.0\n",
       "3     4173.0  7697.0    3.0   51.0\n",
       "4     1306.0  7697.0    4.0   48.0\n",
       "..       ...     ...    ...    ...\n",
       "301  51590.0  7697.0  301.0    1.0\n",
       "300  51498.0  7697.0  300.0    1.0\n",
       "299  51347.0  7697.0  299.0    1.0\n",
       "298  50970.0  7697.0  298.0    1.0\n",
       "327  57210.0  7697.0  327.0    1.0\n",
       "\n",
       "[328 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(scored_toks[89], columns=['token', 'label', 'rank', 'score']).sort_values(by='score', ascending=False)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7951e3-9197-46e3-85bd-36c5660b3cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scored_toks</th>\n",
       "      <td>(104, 328, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binned_toks</th>\n",
       "      <td>(104, 328)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probs</th>\n",
       "      <td>(104, 328)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_valid</th>\n",
       "      <td>(104, 328)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bin_size</th>\n",
       "      <td>(11,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bin_bds</th>\n",
       "      <td>(8, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     shape\n",
       "scored_toks  (104, 328, 4)\n",
       "binned_toks     (104, 328)\n",
       "probs           (104, 328)\n",
       "is_valid        (104, 328)\n",
       "bin_size             (11,)\n",
       "bin_bds             (8, 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = partial(namestr, namespace=globals())\n",
    "row_vals = apply(torch.Tensor.size, (scored_toks, binned_toks, probs, is_valid, bin_size, bin_bds))\n",
    "pd.DataFrame(index = list(itertools.chain.from_iterable(apply(name, [scored_toks, binned_toks, probs, is_valid, bin_size, bin_bds]))), columns=['shape'], data={'shape': row_vals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36a730-4635-45ef-8bc2-73c456f2b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'bin #': range(len(bin_size)), 'bin_bds': list(bin_bds.numpy()), 'bin_size': bin_size})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e41146-6169-4c36-be7f-32f68ecec683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbl</th>\n",
       "      <th>lbl_val</th>\n",
       "      <th>description</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>1834</td>\n",
       "      <td>340</td>\n",
       "      <td>Multiple sclerosis</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lbl lbl_val         description  freq\n",
       "1834  1834     340  Multiple sclerosis   297"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_lbl = 1834\n",
    "df_lbs.iloc[[a_lbl]]\n",
    "# df_lbs.loc[[a_lbl]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41768f8a-0052-4bc0-9fa9-92f77783c472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>tok_val</th>\n",
       "      <th>score</th>\n",
       "      <th>probs</th>\n",
       "      <th>binned_toks</th>\n",
       "      <th>bds</th>\n",
       "      <th>size</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>4005</td>\n",
       "      <td>sclerosis</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>10</td>\n",
       "      <td>[99.265625, 101.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19135</th>\n",
       "      <td>19135</td>\n",
       "      <td>avonex</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>10</td>\n",
       "      <td>[99.265625, 101.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216</th>\n",
       "      <td>20216</td>\n",
       "      <td>glatiramer</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>10</td>\n",
       "      <td>[99.265625, 101.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5892</th>\n",
       "      <td>5892</td>\n",
       "      <td>neurogenic</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>10</td>\n",
       "      <td>[99.265625, 101.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16410</th>\n",
       "      <td>16410</td>\n",
       "      <td>copaxone</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>10</td>\n",
       "      <td>[99.265625, 101.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>4006</td>\n",
       "      <td>baclofen</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>10</td>\n",
       "      <td>[99.265625, 101.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5515</th>\n",
       "      <td>5515</td>\n",
       "      <td>bound</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>[88.04297, 99.265625]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21429</th>\n",
       "      <td>21429</td>\n",
       "      <td>remitting</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>[88.04297, 99.265625]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25573</th>\n",
       "      <td>25573</td>\n",
       "      <td>betaseron</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>[88.04297, 99.265625]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651</th>\n",
       "      <td>9651</td>\n",
       "      <td>provigil</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>[88.04297, 99.265625]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9582</th>\n",
       "      <td>9582</td>\n",
       "      <td>modafinil</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>[88.04297, 99.265625]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14795</th>\n",
       "      <td>14795</td>\n",
       "      <td>neuritis</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>[88.04297, 99.265625]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12213</th>\n",
       "      <td>12213</td>\n",
       "      <td>relapsing</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>[88.04297, 99.265625]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10066</th>\n",
       "      <td>10066</td>\n",
       "      <td>spasticity</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>[88.04297, 99.265625]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>10005</td>\n",
       "      <td>cranberry</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>[88.04297, 99.265625]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5575</th>\n",
       "      <td>5575</td>\n",
       "      <td>oxybutynin</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>9</td>\n",
       "      <td>[88.04297, 99.265625]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17883</th>\n",
       "      <td>17883</td>\n",
       "      <td>hippurate</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>8</td>\n",
       "      <td>[77.59375, 88.04297]</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>4384</td>\n",
       "      <td>utis</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>8</td>\n",
       "      <td>[77.59375, 88.04297]</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8255</th>\n",
       "      <td>8255</td>\n",
       "      <td>demyelinating</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>8</td>\n",
       "      <td>[77.59375, 88.04297]</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14201</th>\n",
       "      <td>14201</td>\n",
       "      <td>methenamine</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>8</td>\n",
       "      <td>[77.59375, 88.04297]</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token        tok_val  score     probs  binned_toks  \\\n",
       "4005    4005      sclerosis  101.0  0.055556           10   \n",
       "19135  19135         avonex  100.0  0.055556           10   \n",
       "20216  20216     glatiramer  100.0  0.055556           10   \n",
       "5892    5892     neurogenic  100.0  0.055556           10   \n",
       "16410  16410       copaxone  100.0  0.055556           10   \n",
       "4006    4006       baclofen  100.0  0.055556           10   \n",
       "5515    5515          bound   99.0  0.033333            9   \n",
       "21429  21429      remitting   97.0  0.033333            9   \n",
       "25573  25573      betaseron   96.0  0.033333            9   \n",
       "9651    9651       provigil   95.0  0.033333            9   \n",
       "9582    9582      modafinil   94.0  0.033333            9   \n",
       "14795  14795       neuritis   92.0  0.033333            9   \n",
       "12213  12213      relapsing   92.0  0.033333            9   \n",
       "10066  10066     spasticity   91.0  0.033333            9   \n",
       "10005  10005      cranberry   90.0  0.033333            9   \n",
       "5575    5575     oxybutynin   89.0  0.033333            9   \n",
       "17883  17883      hippurate   88.0  0.022989            8   \n",
       "4384    4384           utis   88.0  0.022989            8   \n",
       "8255    8255  demyelinating   87.0  0.022989            8   \n",
       "14201  14201    methenamine   87.0  0.022989            8   \n",
       "\n",
       "                         bds  size  is_valid  \n",
       "4005      [99.265625, 101.0]     6       0.0  \n",
       "19135     [99.265625, 101.0]     6       1.0  \n",
       "20216     [99.265625, 101.0]     6       0.0  \n",
       "5892      [99.265625, 101.0]     6       0.0  \n",
       "16410     [99.265625, 101.0]     6       1.0  \n",
       "4006      [99.265625, 101.0]     6       1.0  \n",
       "5515   [88.04297, 99.265625]    10       0.0  \n",
       "21429  [88.04297, 99.265625]    10       0.0  \n",
       "25573  [88.04297, 99.265625]    10       0.0  \n",
       "9651   [88.04297, 99.265625]    10       0.0  \n",
       "9582   [88.04297, 99.265625]    10       0.0  \n",
       "14795  [88.04297, 99.265625]    10       0.0  \n",
       "12213  [88.04297, 99.265625]    10       0.0  \n",
       "10066  [88.04297, 99.265625]    10       0.0  \n",
       "10005  [88.04297, 99.265625]    10       0.0  \n",
       "5575   [88.04297, 99.265625]    10       0.0  \n",
       "17883   [77.59375, 88.04297]    29       0.0  \n",
       "4384    [77.59375, 88.04297]    29       0.0  \n",
       "8255    [77.59375, 88.04297]    29       0.0  \n",
       "14201   [77.59375, 88.04297]    29       0.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'token': scored_toks[a_lbl, :, 0] ,'score': scored_toks[a_lbl, :, -1], 'probs': probs[a_lbl], 'binned_toks': binned_toks[a_lbl], 'bds': list(bin_bds[binned_toks[a_lbl]].numpy()), 'size': bin_size[binned_toks[a_lbl]], 'is_valid': is_valid[a_lbl]})\n",
    "df3 = df_toks.merge(df3, on='token')\n",
    "df3.sort_values(by='score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f27a3-5b48-40d7-9f68-ce28234dc0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(32.), 32.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_valid[a_lbl].sum(), df3['is_valid'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62528572-38e2-426f-b7f4-aa048eac6705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>tok_val</th>\n",
       "      <th>score</th>\n",
       "      <th>probs</th>\n",
       "      <th>binned_toks</th>\n",
       "      <th>bds</th>\n",
       "      <th>size</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>4006</td>\n",
       "      <td>baclofen</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>10</td>\n",
       "      <td>[99.265625, 101.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16410</th>\n",
       "      <td>16410</td>\n",
       "      <td>copaxone</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>10</td>\n",
       "      <td>[99.265625, 101.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19135</th>\n",
       "      <td>19135</td>\n",
       "      <td>avonex</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>10</td>\n",
       "      <td>[99.265625, 101.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9655</th>\n",
       "      <td>9655</td>\n",
       "      <td>amantadine</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>8</td>\n",
       "      <td>[77.59375, 88.04297]</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>4227</td>\n",
       "      <td>proteus</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>7</td>\n",
       "      <td>[66.44141, 77.59375]</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20079</th>\n",
       "      <td>20079</td>\n",
       "      <td>dyskinesias</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.008439</td>\n",
       "      <td>7</td>\n",
       "      <td>[66.44141, 77.59375]</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20882</th>\n",
       "      <td>20882</td>\n",
       "      <td>7q</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>6</td>\n",
       "      <td>[55.1875, 66.44141]</td>\n",
       "      <td>220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41319</th>\n",
       "      <td>41319</td>\n",
       "      <td>retropancreatic</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>5</td>\n",
       "      <td>[44.328125, 55.1875]</td>\n",
       "      <td>613</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18465</th>\n",
       "      <td>18465</td>\n",
       "      <td>abulia</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>3</td>\n",
       "      <td>[22.832031, 33.003906]</td>\n",
       "      <td>4746</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20471</th>\n",
       "      <td>20471</td>\n",
       "      <td>eomis</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>3</td>\n",
       "      <td>[22.832031, 33.003906]</td>\n",
       "      <td>4746</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11243</th>\n",
       "      <td>11243</td>\n",
       "      <td>palms</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>3</td>\n",
       "      <td>[22.832031, 33.003906]</td>\n",
       "      <td>4746</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9901</th>\n",
       "      <td>9901</td>\n",
       "      <td>vc</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>3</td>\n",
       "      <td>[22.832031, 33.003906]</td>\n",
       "      <td>4746</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14108</th>\n",
       "      <td>14108</td>\n",
       "      <td>float</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.1171875, 22.832031]</td>\n",
       "      <td>13203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14577</th>\n",
       "      <td>14577</td>\n",
       "      <td>dehisced</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.1171875, 22.832031]</td>\n",
       "      <td>13203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19721</th>\n",
       "      <td>19721</td>\n",
       "      <td>cardiomediastinum</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.1171875, 22.832031]</td>\n",
       "      <td>13203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20742</th>\n",
       "      <td>20742</td>\n",
       "      <td>masectomy</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.1171875, 22.832031]</td>\n",
       "      <td>13203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21427</th>\n",
       "      <td>21427</td>\n",
       "      <td>paralysed</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.1171875, 22.832031]</td>\n",
       "      <td>13203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>2374</td>\n",
       "      <td>tibial</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.1171875, 22.832031]</td>\n",
       "      <td>13203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21104</th>\n",
       "      <td>21104</td>\n",
       "      <td>prefrontal</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>2</td>\n",
       "      <td>[11.1171875, 22.832031]</td>\n",
       "      <td>13203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27804</th>\n",
       "      <td>27804</td>\n",
       "      <td>r3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11011</th>\n",
       "      <td>11011</td>\n",
       "      <td>elder</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37255</th>\n",
       "      <td>37255</td>\n",
       "      <td>conrolled</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37286</th>\n",
       "      <td>37286</td>\n",
       "      <td>exported</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39002</th>\n",
       "      <td>39002</td>\n",
       "      <td>bloomgard</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39940</th>\n",
       "      <td>39940</td>\n",
       "      <td>phenothiazine</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43675</th>\n",
       "      <td>43675</td>\n",
       "      <td>slear</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45493</th>\n",
       "      <td>45493</td>\n",
       "      <td>leukotriene</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45788</th>\n",
       "      <td>45788</td>\n",
       "      <td>400bid</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46897</th>\n",
       "      <td>46897</td>\n",
       "      <td>oringinally</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46275</th>\n",
       "      <td>46275</td>\n",
       "      <td>cholecystoenterostomy</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51084</th>\n",
       "      <td>51084</td>\n",
       "      <td>9x13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>[1.0, 11.1171875]</td>\n",
       "      <td>31646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54394</th>\n",
       "      <td>54394</td>\n",
       "      <td>fibra</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0</td>\n",
       "      <td>[-inf, 1.0]</td>\n",
       "      <td>5095</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token                tok_val  score     probs  binned_toks  \\\n",
       "4006    4006               baclofen  100.0  0.055556           10   \n",
       "16410  16410               copaxone  100.0  0.055556           10   \n",
       "19135  19135                 avonex  100.0  0.055556           10   \n",
       "9655    9655             amantadine   80.0  0.022989            8   \n",
       "4227    4227                proteus   77.0  0.008439            7   \n",
       "20079  20079            dyskinesias   75.0  0.008439            7   \n",
       "20882  20882                     7q   58.0  0.003030            6   \n",
       "41319  41319        retropancreatic   52.0  0.001088            5   \n",
       "18465  18465                 abulia   30.0  0.000140            3   \n",
       "20471  20471                  eomis   30.0  0.000140            3   \n",
       "11243  11243                  palms   23.0  0.000140            3   \n",
       "9901    9901                     vc   23.0  0.000140            3   \n",
       "14108  14108                  float   19.0  0.000050            2   \n",
       "14577  14577               dehisced   19.0  0.000050            2   \n",
       "19721  19721      cardiomediastinum   15.0  0.000050            2   \n",
       "20742  20742              masectomy   14.0  0.000050            2   \n",
       "21427  21427              paralysed   12.0  0.000050            2   \n",
       "2374    2374                 tibial   12.0  0.000050            2   \n",
       "21104  21104             prefrontal   12.0  0.000050            2   \n",
       "27804  27804                     r3   10.0  0.000021            1   \n",
       "11011  11011                  elder    8.0  0.000021            1   \n",
       "37255  37255              conrolled    6.0  0.000021            1   \n",
       "37286  37286               exported    6.0  0.000021            1   \n",
       "39002  39002              bloomgard    5.0  0.000021            1   \n",
       "39940  39940          phenothiazine    5.0  0.000021            1   \n",
       "43675  43675                  slear    4.0  0.000021            1   \n",
       "45493  45493            leukotriene    4.0  0.000021            1   \n",
       "45788  45788                 400bid    4.0  0.000021            1   \n",
       "46897  46897            oringinally    4.0  0.000021            1   \n",
       "46275  46275  cholecystoenterostomy    3.0  0.000021            1   \n",
       "51084  51084                   9x13    2.0  0.000021            1   \n",
       "54394  54394                  fibra    1.0  0.000131            0   \n",
       "\n",
       "                           bds   size  is_valid  \n",
       "4006        [99.265625, 101.0]      6       1.0  \n",
       "16410       [99.265625, 101.0]      6       1.0  \n",
       "19135       [99.265625, 101.0]      6       1.0  \n",
       "9655      [77.59375, 88.04297]     29       1.0  \n",
       "4227      [66.44141, 77.59375]     79       1.0  \n",
       "20079     [66.44141, 77.59375]     79       1.0  \n",
       "20882      [55.1875, 66.44141]    220       1.0  \n",
       "41319     [44.328125, 55.1875]    613       1.0  \n",
       "18465   [22.832031, 33.003906]   4746       1.0  \n",
       "20471   [22.832031, 33.003906]   4746       1.0  \n",
       "11243   [22.832031, 33.003906]   4746       1.0  \n",
       "9901    [22.832031, 33.003906]   4746       1.0  \n",
       "14108  [11.1171875, 22.832031]  13203       1.0  \n",
       "14577  [11.1171875, 22.832031]  13203       1.0  \n",
       "19721  [11.1171875, 22.832031]  13203       1.0  \n",
       "20742  [11.1171875, 22.832031]  13203       1.0  \n",
       "21427  [11.1171875, 22.832031]  13203       1.0  \n",
       "2374   [11.1171875, 22.832031]  13203       1.0  \n",
       "21104  [11.1171875, 22.832031]  13203       1.0  \n",
       "27804        [1.0, 11.1171875]  31646       1.0  \n",
       "11011        [1.0, 11.1171875]  31646       1.0  \n",
       "37255        [1.0, 11.1171875]  31646       1.0  \n",
       "37286        [1.0, 11.1171875]  31646       1.0  \n",
       "39002        [1.0, 11.1171875]  31646       1.0  \n",
       "39940        [1.0, 11.1171875]  31646       1.0  \n",
       "43675        [1.0, 11.1171875]  31646       1.0  \n",
       "45493        [1.0, 11.1171875]  31646       1.0  \n",
       "45788        [1.0, 11.1171875]  31646       1.0  \n",
       "46897        [1.0, 11.1171875]  31646       1.0  \n",
       "46275        [1.0, 11.1171875]  31646       1.0  \n",
       "51084        [1.0, 11.1171875]  31646       1.0  \n",
       "54394              [-inf, 1.0]   5095       1.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[df3['is_valid'] == 1].sort_values(by='score', ascending=False)#.groupby('binned_toks').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49518d33-3708-4fb6-acd7-ed1fea2fd57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_topbins(binned_toks):\n",
    "    \"counts the number of top 2 bins for each label\"\n",
    "    top_lens = binned_toks.new_zeros(binned_toks.shape[0]) # for every label contains the number of top 2 bins (top bins are the ones which have most relevant tokens for that label) \n",
    "    top_bins = binned_toks[0].unique()[-2:]\n",
    "    for i, binned in enumerate(binned_toks):\n",
    "        topbin_idxs = torch.nonzero(torch.isin(binned, top_bins)).view(-1)\n",
    "        val_idxs = torch.where(is_valid[i] == 1)[0]\n",
    "        top = val_idxs[torch.where(torch.isin(val_idxs, topbin_idxs))[0]]\n",
    "        top_lens[i] = top.shape[0]\n",
    "    return top_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12def3f-23af-4a14-919b-dead1535383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| torch.where(top_lens >= 6)[0].shape: torch.Size([0])\n",
      "    top_lens.max(): tensor(5)\n",
      "    top_lens.min(): tensor(0)\n"
     ]
    }
   ],
   "source": [
    "top_lens = count_topbins(binned_toks)\n",
    "ic(torch.where(top_lens >= 6)[0].shape, top_lens.max(), top_lens.min());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33897661-b022-4031-97c7-6532c01783a1",
   "metadata": {},
   "source": [
    "Prepare the validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2fe07-20d2-4ea4-bb88-ca3758320980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| scored_toks.shape: torch.Size([104, 328, 4])\n",
      "    is_valid.shape: torch.Size([104, 328])\n"
     ]
    }
   ],
   "source": [
    "ic(scored_toks.shape, is_valid.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6912618-68dd-4f62-83f0-1a9c2aa3d33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| val_dset.shape: torch.Size([104, 16, 4])\n"
     ]
    }
   ],
   "source": [
    "val_dset = scored_toks[is_valid.bool()].view(scored_toks.shape[0], val_sl, -1)\n",
    "test_eq(val_dset.shape, (scored_toks.shape[0], val_sl, scored_toks.shape[2]))\n",
    "ic(val_dset.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd6d99-5042-4546-aa1c-d68585643b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_idxs_sorted = scored_toks[a_lbl, :, -1][valid_idxs.bool()].sort(descending=True, stable=True).indices\n",
    "# valid_idxs_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c761e96-c6ba-4fb5-88de-a55ec844c63d",
   "metadata": {},
   "source": [
    "Prepare the training dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b17d43-0f46-4d3f-bf1a-a6486c970e57",
   "metadata": {},
   "source": [
    "Don't remove the validation tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bec2c3-8978-48f4-8c62-49700b7347fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scored_toks[a_lbl][valid_idxs.bool()][valid_idxs_sorted]\n",
    "# scored_toks[a_lbl][valid_idxs.bool()]\n",
    "# trn = scored_toks[a_lbl][~valid_idxs.bool()]\n",
    "# trn = scored_toks[~is_valid.bool()].view(scored_toks.shape[0], scored_toks.shape[1]-val_sl, -1) # Use this if you want to remove validation tokens\n",
    "trn = scored_toks.clone() # Use this if you don't want to remove the validation tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1366221-cba3-48db-9e5c-e11559e23edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| trn.shape: torch.Size([104, 328, 4])\n",
      "    val_dset.shape: torch.Size([104, 16, 4])\n"
     ]
    }
   ],
   "source": [
    "# test_eq(trn.shape, (scored_toks.shape[0], scored_toks.shape[1]-val_sl, scored_toks.shape[2])) # Use this if you want to remove validation tokens\n",
    "test_eq(trn.shape, scored_toks.shape) # Use this if you don't want to remove the validation tokens\n",
    "ic(trn.shape, val_dset.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964660a-4bcb-476b-b81e-e95e76a5e595",
   "metadata": {},
   "source": [
    "Now that we have prepared the train/valid split we can delete `scored_toks` and `is_valid` to reclaim some memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38390c5a-1e0c-4844-8d55-de10ac05e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((trn, val_dset), 'trn_val_split_tiny.pkl')\n",
    "# torch.save((trn, val_dset), 'trn_val_split.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6945e1-7ab3-4e76-902d-1851ec99c3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_toks, is_valid  = None, None\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17620c93-3687-4fed-be47-cad5f1a234d1",
   "metadata": {},
   "source": [
    "This stuff goes inside the custom `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7278b-6ade-43fa-9137-fd278ea33cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 deb deb 8191681843 Dec  2 18:02 /home/deb/xcube/nbs/examples/mimic/sample/trn_val_split.pkl\n",
      "-rw-r--r-- 1 deb deb 573459 Dec  8 14:49 /home/deb/xcube/nbs/examples/mimic/sample/trn_val_split_tiny.pkl\n"
     ]
    }
   ],
   "source": [
    "# datetime.fromtimestamp((path/'trn_val_split.pkl').stat().st_ctime)\n",
    "!ls -la {path/'trn_val_split.pkl'}\n",
    "!ls -la {path/'trn_val_split_tiny.pkl'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb68d88-81a2-4523-a941-ec2d8a63f867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| trn.shape: torch.Size([104, 328, 4])\n",
      "    val_dset.shape: torch.Size([1, 104, 16, 4])\n"
     ]
    }
   ],
   "source": [
    "# trn, val_dset = torch.load('trn_val_split.pkl')\n",
    "trn, val_dset = torch.load('trn_val_split_tiny.pkl')\n",
    "val_dset = val_dset.unsqueeze(0)\n",
    "ic(trn.shape, val_dset.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f687f3-3383-4b04-a31c-fed459410d89",
   "metadata": {},
   "source": [
    "1. Shuffle the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e2438-2dca-405f-910e-b8ef2a37a8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| randperm.shape: torch.Size([57352])\n"
     ]
    }
   ],
   "source": [
    "randperm = torch.randint(low=0, high=trn.shape[1], size=(trn.shape[1],))\n",
    "ic(randperm.shape);\n",
    "trn = trn[:, randperm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adca3dc9-af0a-4c17-827a-2aea31fb679b",
   "metadata": {},
   "source": [
    "2. Split the training set into sqs that make the data and batching them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab3198-9e00-4647-9d46-e2b7409d3ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=500x250>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(path/'LRdataloader.png').resize((500,250))\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c2695a-63b3-4736-a8f7-24f24c8cec8c",
   "metadata": {},
   "source": [
    "Parameters you need to select: `lbs_chunks`, `tok_sl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eade6a-bc93-40c3-be49-e39826a2e4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| size_of_dim0: 2231.0, pad_len_dim0: 2\n",
      "ic| trn_pad.shape: torch.Size([8924, 57352, 4])\n"
     ]
    }
   ],
   "source": [
    "lbs_chunks = 4\n",
    "# lbs_chunks = 32 # for tiny\n",
    "size_of_dim0 = torch.ceil(trn.new_empty(1).fill_(trn.shape[0]/lbs_chunks)).item()\n",
    "pad_len_dim0 = int(lbs_chunks * np.floor(trn.shape[0]/lbs_chunks) + lbs_chunks - trn.shape[0]) # smallest number greater than `trn.shape[0]` divisible by `lbs_chunks`:\n",
    "ic(size_of_dim0, pad_len_dim0);\n",
    "trn_pad = F.pad(trn, (0,0,0,0,0,pad_len_dim0), value=-1)\n",
    "ic(trn_pad.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ffa3d-b894-4ee7-aeda-7a072a06df5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(trn_sqs): 897\n",
      "    trn_sqs[0].shape: torch.Size([8924, 64, 4])\n",
      "    trn_sqs[1].shape: torch.Size([8924, 64, 4])\n",
      "    trn_sqs[-1].shape: torch.Size([8924, 8, 4])\n",
      "ic| deficit: 56\n"
     ]
    }
   ],
   "source": [
    "trn_sl = 64\n",
    "trn_sqs = list(torch.split(trn_pad, split_size_or_sections=trn_sl, dim=1))\n",
    "ic(len(trn_sqs), trn_sqs[0].shape, trn_sqs[1].shape, trn_sqs[-1].shape);\n",
    "test_eq(len(trn_sqs), np.ceil(trn.shape[1]/trn_sl))\n",
    "test_eq(trn_sqs[-1].shape, (trn_pad.shape[0], trn_pad.shape[1]%trn_sl,4));\n",
    "deficit = trn_sl - trn_sqs[-1].shape[1]\n",
    "ic(deficit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e2ff7-3990-4531-99c8-05654e5e2acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(trn_sqs): 897\n",
      "    trn_sqs[0].shape: torch.Size([8924, 64, 4])\n",
      "    trn_sqs[1].shape: torch.Size([8924, 64, 4])\n",
      "    trn_sqs[-1].shape: torch.Size([8924, 64, 4])\n"
     ]
    }
   ],
   "source": [
    "if deficit: \n",
    "    test_eq(trn_sqs[-1].shape, (trn_pad.shape[0], trn_pad.shape[1]%trn_sl,4));\n",
    "    # trn_sqs[-1] = torch.concat((trn_sqs[-1],trn.new_empty((trn_sqs[-1].shape[0], deficit,3)).fill_(-1)), dim=1)\n",
    "    trn_sqs[-1] = trn_sqs[-1].repeat_interleave(trn_sl//trn_sqs[-1].shape[1], dim=1)\n",
    "test_eq(trn_sqs[-1].shape, (trn_pad.shape[0], trn_sl,4));\n",
    "ic(len(trn_sqs), trn_sqs[0].shape, trn_sqs[1].shape, trn_sqs[-1].shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b00c6-d60a-4ad2-a8c2-8d91ad7d44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sqs = map(partial(torch.chunk, chunks=lbs_chunks), trn_sqs)\n",
    "trn_sqs = itertools.chain.from_iterable(trn_sqs)\n",
    "trn_sqs, trn_sqs1, trn_sqs2, trn_sqs3 = itertools.tee(trn_sqs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e1854-eecb-4659-8fbf-105689fee879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1) [torch.Size([2231, 64, 4])], 3588)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(trn_sqs1).map(Tensor.size).unique(), len(L(trn_sqs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b77d689-fbce-46cb-acb3-7e81e37fe9d2",
   "metadata": {},
   "source": [
    "This is where the number 3588 is coming from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32cc8f-dba3-4aab-bbf2-925dd1e0f0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.125"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(328/64) # tok_sl 64 (#tok_chunks = #toks/trn_sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdefcc55-60fc-4b41-bf17-70ce9b5bb391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896.125"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "57352/64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b614710c-184b-408d-84ea-e7a4eafb161e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6694c62e-d292-4363-be98-068ff9e24b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(128/4) # labels chunk size is 4 (#lbs_chunk_sz = #lbs/lbs_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f5b70-88aa-4a6b-b3e0-b1fa90d6ff96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2231.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8924/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a904c79-d7a6-43d1-a877-1d46f4b4bb38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191a4b8-0ad9-4d42-88f4-7379df980860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6*32 #(tok_chunks * lbs_chunks) This is basically the # of datapoints, which gets batched. So #mini-batches in an epoch = #datapoints/bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c6254-a774-4f43-be55-7321e25c4ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3588"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "897*4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31d946-19af-47de-9b6f-d782517b1059",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ccb7b-7007-4e72-8407-4c4d7ff3def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = trn_sqs\n",
    "# dset_it = iter(dset)\n",
    "# n = next(dset_it)\n",
    "# ic(n.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0abae-0d79-42bb-8399-0ddc6ddb2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "bs_tiny = 8\n",
    "# btchs = chunked(dset, bs_tiny)\n",
    "# btch_it = iter(btchs)\n",
    "# xb = next(btch_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068b9b2-eb39-442a-b74e-8aed19d16841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ic(type(xb), len(xb), xb[0].shape)\n",
    "# btch = torch.stack(xb)\n",
    "# ic(btch.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde24e4-fbec-46b1-bff3-018781db7e6e",
   "metadata": {},
   "source": [
    "The number of mini-batches in an epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0ed4c-8c95-48a8-b704-c4455a327e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56.0625, 24.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3588/bs, 192/bs_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd55159-e347-4104-86a4-3ad22bd2cf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of mini-batches in an epoch\n",
    "int(np.ceil((np.ceil(trn.shape[1]/trn_sl) * lbs_chunks)/bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d52ae-4e4d-4e56-870e-7490ef42a23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([64, 2231, 64, 4]), lbs.shape = torch.Size([64, 2231, 1])\n",
      "xb.shape = torch.Size([4, 2231, 64, 4]), lbs.shape = torch.Size([4, 2231, 1])\n",
      "The number of minibatches = 57\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for btch in chunked(dset, bs):\n",
    "    xb = torch.stack(btch)\n",
    "    lbs = torch.unique(xb[:,:,:,1], dim=-1)\n",
    "    print(f\"{xb.shape = }, {lbs.shape = }\")\n",
    "    c += 1\n",
    "print(f\"The number of minibatches = {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e202570f-57bc-427d-af89-1365925a8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dset = torch.concat(trn_sqs)\n",
    "test_eq(trn_dset.shape, (trn.shape[0]*len(trn_sqs), trn_sl, 3))\n",
    "ic(trn_dset.shape, val_dset.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16792e-2f21-4bb1-a31e-d9fa7a111bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([4, 2231, 64, 4])\n",
      "    torch.unique(xb[:,:,:,1], dim=-1).shape: torch.Size([4, 2231, 1])\n"
     ]
    }
   ],
   "source": [
    "ic(xb.shape, torch.unique(xb[:,:,:,1], dim=-1).shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80280950-eb4a-4748-8e81-f4227e608b1d",
   "metadata": {},
   "source": [
    "Showtime: Writing our custom `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4184c-8843-4617-8c6f-d64b48809410",
   "metadata": {},
   "outputs": [],
   "source": [
    "%less {inspect.getsourcefile(DataLoader)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734e0bb-85b7-4930-ae1e-ab74faa17461",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrnDataLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.sl, self.lbs_chunks = kwargs.pop('sl', None), kwargs.pop('lbs_chunks', None)\n",
    "        if self.sl is None: self.sl = 64\n",
    "        if self.lbs_chunks is None: self.lbs_chunks = 4\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def randomize(self):\n",
    "        seed = np.random.default_rng().integers(0, 2**32-1, 1).item()\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def shuffle_fn(self, idxs): return self.rng.permutation(idxs)\n",
    "\n",
    "    def get_idxs(self):\n",
    "        if self.n is not None: idxs = range(self.n)\n",
    "        if self.shuffle: idxs = (idx for idx in self.shuffle_fn(idxs))\n",
    "        return idxs\n",
    "    \n",
    "    def create_batch(self, start_idx):\n",
    "        return self.dset[start_idx: min(start_idx+self.bs, self.dset.shape[0])]\n",
    "        # if self.device: to_device(btch, self.device)\n",
    "        # return btch\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil((np.ceil(self.dataset.shape[1]/self.sl) * self.lbs_chunks)/self.bs))\n",
    "    \n",
    "    def before_iter(self):\n",
    "        # shuffling\n",
    "        randperm = torch.randint(low=0, high=self.dataset.shape[1], size=(self.dataset.shape[1],))\n",
    "        self.dataset = self.dataset[:, randperm]\n",
    "        # self.lbs_chunks = 4\n",
    "        size_of_dim0 = torch.ceil(self.dataset.new_empty(1).fill_(self.dataset.shape[0]/self.lbs_chunks)).item()\n",
    "        pad_len_dim0 = int(self.lbs_chunks * np.floor(self.dataset.shape[0]/self.lbs_chunks) + self.lbs_chunks - self.dataset.shape[0])\n",
    "        self.dataset_pad = F.pad(self.dataset, (0,0,0,0,0,pad_len_dim0), value=-1)\n",
    "\n",
    "        trn_sqs = list(torch.split(self.dataset_pad, split_size_or_sections=self.sl, dim=1))\n",
    "        test_eq(len(trn_sqs), np.ceil(self.dataset_pad.shape[1]/self.sl))\n",
    "        test_eq(trn_sqs[-1].shape, (self.dataset_pad.shape[0], self.dataset_pad.shape[1]%self.sl,4))\n",
    "        deficit = self.sl - trn_sqs[-1].shape[1]\n",
    "        if deficit: \n",
    "            test_eq(trn_sqs[-1].shape, (self.dataset_pad.shape[0], self.dataset_pad.shape[1]%self.sl,4));\n",
    "            # trn_sqs[-1] = torch.concat((trn_sqs[-1], self.dataset_pad.new_empty((trn_sqs[-1].shape[0], deficit,3)).fill_(-1)), dim=1)\n",
    "            trn_sqs[-1] = trn_sqs[-1].repeat_interleave(self.sl//trn_sqs[-1].shape[1], dim=1)\n",
    "        test_eq(trn_sqs[-1].shape, (self.dataset_pad.shape[0], self.sl,4));\n",
    "        # self.dset = torch.concat(trn_sqs)\n",
    "        # self.dset = torch.stack(trn_sqs)\n",
    "        \n",
    "        trn_sqs = map(partial(torch.chunk, chunks=self.lbs_chunks), trn_sqs)\n",
    "        trn_sqs = itertools.chain.from_iterable(trn_sqs)\n",
    "        self.dset = trn_sqs\n",
    "        # test_eq(self.dset.shape, (self.dataset_pad.shape[0]*len(trn_sqs), self.sl, 3))\n",
    "        # test_eq(self.dset.shape, (len(trn_sqs), self.dataset_pad.shape[0], self.sl, 3))\n",
    "        # print(f\"{self.dset.shape=}\")\n",
    "        # yield from (btch for btch in dset.split(self.bs))\n",
    "    \n",
    "    def create_batches(self, samps):\n",
    "            # trn_sqs = list(torch.split(self.dataset, split_size_or_sections=self.sl, dim=1))\n",
    "            # test_eq(len(trn_sqs), np.ceil(self.dataset.shape[1]/self.sl))\n",
    "            # test_eq(trn_sqs[-1].shape, (self.dataset.shape[0], self.dataset.shape[1]%self.sl,3))\n",
    "            # deficit = self.sl - trn_sqs[-1].shape[1]\n",
    "            # if deficit: \n",
    "            #     test_eq(trn_sqs[-1].shape, (self.dataset.shape[0], self.dataset.shape[1]%self.sl,3));\n",
    "            #     trn_sqs[-1] = torch.concat((trn_sqs[-1], self.dataset.new_empty((trn_sqs[-1].shape[0], deficit,3)).fill_(-1)), dim=1)\n",
    "            # test_eq(trn_sqs[-1].shape, (self.dataset.shape[0], self.sl,3));\n",
    "            # # self.dset = torch.concat(trn_sqs)\n",
    "            # self.dset = torch.stack(trn_sqs)\n",
    "            # # test_eq(self.dset.shape, (self.dataset.shape[0]*len(trn_sqs), self.sl, 3))\n",
    "            # test_eq(self.dset.shape, (len(trn_sqs), self.dataset.shape[0], self.sl, 3))\n",
    "            # print(f\"{self.dset.shape=}\")\n",
    "            # # yield from (btch for btch in dset.split(self.bs))\n",
    "        # chunks = range(0, self.dset.shape[0], self.bs)\n",
    "        # with ProcessPoolExecutor(self.n_workers) as ex:\n",
    "        # with Pool(processes=self.num_workers) as pool:\n",
    "        # yield from pool.imap_unordered(self.create_batch, chunks, 16)\n",
    "        # yield from map(self.create_batch, chunks)\n",
    "        # yield from chunked(self.dset, chunk_sz=self.bs)\n",
    "        yield from (torch.stack(btch) for btch in self.chunkify(self.dset))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705b54a-e5fd-42b5-aa9e-c8be6d9a75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%save dataloader.py _i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459296f-32e5-41b4-b754-6fe8b1f478e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "class FDataLoader:\n",
    "    def __init__(self, dataset, sl=48, bs=128, n_workers=1, device=None):\n",
    "        store_attr('dataset,sl,bs,n_workers,device')\n",
    "        \n",
    "    def create_batch(self, start_idx):\n",
    "        btch = self.dset[start_idx: min(start_idx+self.bs, self.dset.shape[0])]\n",
    "        if self.device: to_device(btch, self.device)\n",
    "        return btch\n",
    "    \n",
    "    def __iter__(self):\n",
    "        trn_sqs = list(torch.split(self.dataset, split_size_or_sections=self.sl, dim=1))\n",
    "        test_eq(len(trn_sqs), np.ceil(self.dataset.shape[1]/self.sl))\n",
    "        test_eq(trn_sqs[-1].shape, (self.dataset.shape[0], self.dataset.shape[1]%self.sl,3))\n",
    "        deficit = self.sl - trn_sqs[-1].shape[1]\n",
    "        if deficit: \n",
    "            test_eq(trn_sqs[-1].shape, (self.dataset.shape[0], self.dataset.shape[1]%self.sl,3));\n",
    "            trn_sqs[-1] = torch.concat((trn_sqs[-1], self.dataset.new_empty((trn_sqs[-1].shape[0], deficit,3)).fill_(-1)), dim=1)\n",
    "        test_eq(trn_sqs[-1].shape, (self.dataset.shape[0], self.sl,3));\n",
    "        # self.dset = torch.concat(trn_sqs)\n",
    "        self.dset = torch.stack(trn_sqs)\n",
    "        # test_eq(self.dset.shape, (self.dataset.shape[0]*len(trn_sqs), self.sl, 3))\n",
    "        test_eq(self.dset.shape, (len(trn_sqs), self.dataset.shape[0], self.sl, 3))\n",
    "        print(f\"{self.dset.shape=}\")\n",
    "        # yield from (btch for btch in dset.split(self.bs))\n",
    "        chunks = np.arange(0, self.dset.shape[0], self.bs)\n",
    "        # with ProcessPoolExecutor(self.n_workers) as ex:\n",
    "        with Pool(processes=self.n_workers) as pool:\n",
    "            yield from pool.imap_unordered(self.create_batch, chunks, 16)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da52ccb-9d48-416f-94fe-f3ab17aaa024",
   "metadata": {},
   "source": [
    "Let's create the train/valid `DataLoaders`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5172ee3-b61e-4fff-91b6-06fb643714f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| trn.shape: torch.Size([8922, 57352, 4])\n",
      "    val_dset.shape: torch.Size([1, 8922, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "trn, val_dset = torch.load('trn_val_split.pkl')\n",
    "# trn, val_dset = torch.load('trn_val_split_tiny.pkl')\n",
    "val_dset = val_dset.unsqueeze(0)\n",
    "ic(trn.shape, val_dset.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d0367-1032-4184-bb26-4b97b503c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_full = 32\n",
    "bs_tiny = 8\n",
    "sl = 64\n",
    "lbs_chunks_full = 4\n",
    "lbs_chunks_tiny = 32\n",
    "trn_dl = L2RDataLoader(dataset=trn, sl=sl, bs=bs_full, lbs_chunks=lbs_chunks_full, shuffle=False, after_batch=partial(to_device, device=default_device()), num_workers=0)\n",
    "# trn_dl = TrnDataLoader(dataset=trn, sl=sl_tiny, lbs_chunks=lbs_chunks_tiny, bs=bs_tiny, shuffle=False, after_batch=partial(to_device, device=default_device()), num_workers=0)\n",
    "# trn_dl = L2RDataLoader(dataset=trn, sl=sl, lbs_chunks=lbs_chunks_tiny, bs=bs_tiny, shuffle=False, after_batch=partial(to_device, device=default_device()), num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172fbd5f-0e5e-4cbe-a963-d18a0d5c12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%less {inspect.getsourcefile(L2RDataLoader)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c69264-0018-4cbe-95f9-a88a026d68bc",
   "metadata": {},
   "source": [
    "Don't forget to check the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b6088-e120-4e47-a526-6559e8febc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85cc802-3456-4113-bb10-82a55a98f372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| trn_dl.device: None\n",
      "    trn_dl.num_workers: 1\n",
      "    trn_dl.fake_l.num_workers: 0\n"
     ]
    }
   ],
   "source": [
    "ic(trn_dl.device, trn_dl.num_workers, trn_dl.fake_l.num_workers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432f5d3-cf81-45a2-81ae-c96a4b0cf4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([32, 2231, 64, 4])\n",
      "    xb.device: device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "xb = trn_dl.one_batch()\n",
    "ic(xb.shape, xb.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30566a96-1115-41f8-a43b-d4c3c0759f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 1min 45s, total: 3min 31s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for xb in trn_dl:\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d897214c-2a42-4c5e-b986-ff21cb43729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| val_dl.device: None\n",
      "    val_dl.num_workers: 1\n",
      "    val_dl.fake_l.num_workers: 0\n"
     ]
    }
   ],
   "source": [
    "val_dl = DataLoader(val_dset, bs=1, shuffle=False, after_batch=partial(to_device, device=default_device()), num_workers=0)\n",
    "ic(val_dl.device, val_dl.num_workers, val_dl.fake_l.num_workers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e0a70-1925-4906-9ff9-589691b35fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([1, 8922, 32, 4])\n",
      "    xb.device: device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "xb = val_dl.one_batch()\n",
    "ic(xb.shape, xb.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def96b13-c243-4d2c-ad0a-160691e66bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 0 ns, total: 145 ms\n",
      "Wall time: 20.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for xb in val_dl:\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b7352-7fe2-4dad-8066-cc98af0518e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbd200-7581-4e45-a02e-59944297e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls_tiny = DataLoaders(trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882dd795-1b70-4c9f-8e98-755279555716",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dls, dls_learn_rank_path, pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb30f44-5c5a-47da-9f57-1d19239da817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/deb/xcube/nbs/examples/mimic/sample/models/mimic3-9k_dls_learn_rank_tiny2.pkl')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name, ext = dls_learn_rank_tiny_path.name.split('.')\n",
    "new_name = name + '2.' + ext\n",
    "new_name = dls_learn_rank_tiny_path.parent/new_name\n",
    "new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2dd3ec-21ae-4c98-915c-46bcc8b2d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dls_tiny, new_name, pickle_protocol=4)\n",
    "# torch.save(dls_tiny, dls_learn_rank_tiny_path, pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e905a-0ba0-40a8-bb1c-f61e558065ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls_learn_rank_path = dls_collab_path.parent/'mimic3-9k_dls_learn_rank.pkl'\n",
    "# dls_learn_rank_path\n",
    "\n",
    "# %%time\n",
    "# torch.save(dls_learn_rank, dls_learn_rank_path , pickle_protocol=4)\n",
    "\n",
    "# %%time\n",
    "# dls_learn_rank = torch.load(dls_learn_rank_path, map_location=lambda storage, loc: storage.cuda(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d5ac43-8c22-4722-a68b-630d089ffd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vals, cnts = torch.unique(xb[:, :, 1][:, 0].int(), return_counts=True)\n",
    "# pair = torch.concat((vals[...,None], cnts[...,None]), dim =-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0a822-d6a1-48c8-adc2-2d83ed47619c",
   "metadata": {},
   "source": [
    "##### Using Fastai's Factory Method for `CollabDataLoaders`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b473d7b-aa97-4285-afd4-6699bf07c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 1min 51s, total: 5min 26s\n",
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# %%prun\n",
    "bs = 1024\n",
    "dls_collab = CollabDataLoaders.from_df(df_collab, user_name='token', item_name='label', rating_name='bcx_mutual_info', valid_pct=0.0, bs=bs, device=default_device()).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87293ae8-1c0d-40b6-8327-0ddb63854c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dls_collab, dls_collab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfe3f0e-fe55-403c-806d-8ade88fdbab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(dls_collab.classes['token']) - 1 , df_collab.token.nunique()) # -1 because collab dataloaders added an '#na#' token\n",
    "test_eq(len(dls_collab.classes['label']) -1, df_collab.label.nunique()) # -1 because collab dataloaders added an '#na#' label\n",
    "test_eq(len(df_collab) // bs, len(dls_collab.train))\n",
    "test_eq(len(dls_collab.valid), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b4853-f40c-4585-9eae-fcc395646035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>bcx_mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18258</td>\n",
       "      <td>7976</td>\n",
       "      <td>-9.727593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54862</td>\n",
       "      <td>6950</td>\n",
       "      <td>-9.727593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33625</td>\n",
       "      <td>8124</td>\n",
       "      <td>-6.934011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9968</td>\n",
       "      <td>3236</td>\n",
       "      <td>-6.956002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22250</td>\n",
       "      <td>2212</td>\n",
       "      <td>-7.047239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9969</td>\n",
       "      <td>6222</td>\n",
       "      <td>-6.225886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33620</td>\n",
       "      <td>2492</td>\n",
       "      <td>-6.688501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50429</td>\n",
       "      <td>5467</td>\n",
       "      <td>-7.213950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17998</td>\n",
       "      <td>3071</td>\n",
       "      <td>-7.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38174</td>\n",
       "      <td>2719</td>\n",
       "      <td>-9.727593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls_collab.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb650299-cecf-4d9a-8137-33ad8d62bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time torch.save(dls_collab.train, dls_collab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cfda21-1111-4d28-8a4b-6d92eae32c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time torch.save(dls_collab.valid, dls_collab_path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3c4ce-a58b-41b1-bdc6-ce6a6bbbb46c",
   "metadata": {},
   "source": [
    "Load back the created collab `DataLoaders`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f401b7-6a1c-4b88-928f-5f08eb2ac9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls_collab_path1 = dls_collab_path.parent/(dls_collab_path.stem+'1'+dls_collab_path.suffix)\n",
    "# for o in (dls_collab_path, dls_collab_path1): o.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068404c-409a-490a-95f8-9837592bc5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls_collab_0 = torch.load(dls_collab_path)\n",
    "# dls_collab_1 = torch.load(dls_collab_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c081c0-3356-4c5a-b3c4-95b098caaf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_collab = DataLoaders(dls_collab_0, dls_collab_1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468fc14-2553-46b5-a577-38528e66d957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>mutual_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37065</td>\n",
       "      <td>4971</td>\n",
       "      <td>1.307339e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46450</td>\n",
       "      <td>5288</td>\n",
       "      <td>4.163884e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52554</td>\n",
       "      <td>5727</td>\n",
       "      <td>-2.303921e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57124</td>\n",
       "      <td>2590</td>\n",
       "      <td>2.214923e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>528</td>\n",
       "      <td>1255</td>\n",
       "      <td>3.363439e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4958</td>\n",
       "      <td>3030</td>\n",
       "      <td>8.705797e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31506</td>\n",
       "      <td>2068</td>\n",
       "      <td>3.449003e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33309</td>\n",
       "      <td>3896</td>\n",
       "      <td>-4.140208e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36785</td>\n",
       "      <td>5511</td>\n",
       "      <td>2.333709e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9630</td>\n",
       "      <td>8639</td>\n",
       "      <td>6.145393e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         1417386975 function calls (1417386305 primitive calls) in 553.467 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "        1  341.247  341.247  481.138  481.138 random.py:374(sample)\n",
       "409355637   97.723    0.000  139.891    0.000 random.py:237(_randbelow_with_getrandbits)\n",
       "   231/42   50.317    0.218   50.318    1.198 {built-in method _abc._abc_subclasscheck}\n",
       "598658458   25.864    0.000   25.864    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
       "409355637   16.303    0.000   16.303    0.000 {method 'bit_length' of 'int' objects}\n",
       "        1   11.182   11.182  503.027  503.027 load.py:112(get_idxs)\n",
       "        1   10.707   10.707  491.845  491.845 load.py:154(shuffle_fn)\n",
       "        2    0.011    0.006    0.026    0.013 core.py:234(_decode_cats)\n",
       "       23    0.006    0.000    0.006    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
       "        1    0.005    0.005    0.005    0.005 {pandas._libs.algos.take_2d_axis0_int32_int32}\n",
       "       15    0.004    0.000    0.004    0.000 {method 'acquire' of '_thread.lock' objects}\n",
       "        1    0.004    0.004    0.004    0.004 {built-in method empty}\n",
       "        1    0.004    0.004    0.004    0.004 {pandas._libs.algos.take_2d_axis0_float32_float32}\n",
       "        1    0.004    0.004    0.004    0.004 {method 'random_' of 'torch._C._TensorBase' objects}\n",
       "        9    0.003    0.000    0.003    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
       "        1    0.003    0.003    0.003    0.003 {pandas._libs.algos.take_2d_axis0_int16_int16}\n",
       "        8    0.002    0.000    0.002    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
       "        1    0.002    0.002    0.010    0.010 dataloader.py:494(__init__)\n",
       "       31    0.002    0.000    0.002    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
       "        6    0.002    0.000    0.002    0.000 base.py:2232(is_unique)\n",
       "        4    0.001    0.000    0.001    0.000 cast.py:1960(construct_1d_object_array_from_listlike)\n",
       "  135/133    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\n",
       "2932/2858    0.001    0.000   50.320    0.018 {built-in method builtins.isinstance}\n",
       "        2    0.001    0.001  503.103  251.552 load.py:121(__iter__)\n",
       "  861/805    0.001    0.000    0.002    0.000 {built-in method builtins.getattr}\n",
       "        9    0.001    0.000    0.005    0.001 base.py:1098(take)\n",
       "        5    0.001    0.000    0.001    0.000 socket.py:543(send)\n",
       "    20/16    0.001    0.000    0.010    0.001 base.py:397(__new__)\n",
       "        3    0.001    0.000    0.001    0.000 managers.py:1679(<listcomp>)\n",
       "        1    0.001    0.001    0.001    0.001 {built-in method torch._ops.profiler._record_function_enter}\n",
       "        1    0.001    0.001    0.001    0.001 {method 'long' of 'torch._C._TensorBase' objects}\n",
       "       11    0.001    0.000    0.001    0.000 {built-in method numpy.array}\n",
       "        2    0.001    0.000    0.010    0.005 series.py:463(_init_dict)\n",
       "        5    0.001    0.000    0.001    0.000 utils.py:249(maybe_convert_indices)\n",
       "        1    0.001    0.001    0.047    0.047 core.py:133(__getitem__)\n",
       "        1    0.001    0.001    0.001    0.001 profiler.py:435(__enter__)\n",
       "       18    0.001    0.000    0.014    0.001 take.py:120(_take_nd_ndarray)\n",
       "       12    0.001    0.000    0.001    0.000 indexing.py:958(<genexpr>)\n",
       "        5    0.001    0.000    0.026    0.005 generic.py:3609(take)\n",
       "        4    0.001    0.000    0.001    0.000 managers.py:713(_slice_take_blocks_ax0)\n",
       "        4    0.001    0.000    0.001    0.000 base.py:744(__iter__)\n",
       "       37    0.000    0.000   50.318    1.360 typing.py:719(__instancecheck__)\n",
       "        1    0.000    0.000    0.054    0.054 dataloader.py:526(__next__)\n",
       "    15/13    0.000    0.000    0.010    0.001 series.py:323(__init__)\n",
       "        4    0.000    0.000    0.031    0.008 indexing.py:1456(_getitem_tuple)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method zeros}\n",
       "      432    0.000    0.000    0.001    0.000 {built-in method builtins.hasattr}\n",
       "        2    0.000    0.000    0.006    0.003 iostream.py:470(flush)\n",
       "        1    0.000    0.000    0.012    0.012 display_functions.py:105(display)\n",
       "        2    0.000    0.000    0.002    0.001 inspect.py:2246(_signature_from_callable)\n",
       "       10    0.000    0.000    0.003    0.000 construction.py:470(sanitize_array)\n",
       "      340    0.000    0.000   50.318    0.148 {built-in method builtins.issubclass}\n",
       "       15    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\n",
       "       17    0.000    0.000    0.001    0.000 common.py:105(is_bool_indexer)\n",
       "        5    0.000    0.000    0.023    0.005 managers.py:875(take)\n",
       "        8    0.000    0.000    0.001    0.000 take.py:288(_get_take_nd_function_cached)\n",
       "       29    0.000    0.000    0.000    0.000 base.py:654(_simple_new)\n",
       "       61    0.000    0.000    0.000    0.000 re.py:289(_compile)\n",
       "        9    0.000    0.000    0.000    0.000 base.py:845(_engine)\n",
       "        8    0.000    0.000    0.004    0.001 indexing.py:1343(_validate_key)\n",
       "      156    0.000    0.000    0.001    0.000 traitlets.py:643(get)\n",
       "  211/209    0.000    0.000    0.002    0.000 {built-in method builtins.iter}\n",
       "  787/658    0.000    0.000    0.001    0.000 {built-in method builtins.len}\n",
       "       13    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_dtype}\n",
       "        3    0.000    0.000    0.014    0.005 core.py:168(new)\n",
       "        1    0.000    0.000    0.018    0.018 torch_core.py:537(display_df)\n",
       "       27    0.000    0.000    0.001    0.000 _dtype.py:328(_name_get)\n",
       "        3    0.000    0.000    0.005    0.002 core.py:145(__init__)\n",
       "       13    0.000    0.000    0.000    0.000 inspect.py:2498(__init__)\n",
       "       11    0.000    0.000    0.003    0.000 frame.py:587(__init__)\n",
       "        2    0.000    0.000    0.001    0.001 torch_core.py:125(tensor)\n",
       "        2    0.000    0.000    0.000    0.000 sre_parse.py:971(parse_template)\n",
       "        1    0.000    0.000    0.001    0.001 inspect.py:2152(_signature_from_function)\n",
       "       46    0.000    0.000   50.318    1.094 foundation.py:103(__init__)\n",
       "        1    0.000    0.000    0.010    0.010 zmqshell.py:80(publish)\n",
       "        1    0.000    0.000    0.011    0.011 dataloader.py:560(__init__)\n",
       "       13    0.000    0.000    0.011    0.001 base.py:672(_with_infer)\n",
       "        4    0.000    0.000    0.032    0.008 indexing.py:954(__getitem__)\n",
       "       25    0.000    0.000    0.001    0.000 numeric.py:289(full)\n",
       "        3    0.000    0.000    0.002    0.001 meta.py:111(_f)\n",
       "        9    0.000    0.000    0.009    0.001 base.py:3706(get_indexer)\n",
       "        3    0.000    0.000    0.009    0.003 block.py:15(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method as_tensor}\n",
       "       21    0.000    0.000    0.000    0.000 generic.py:5517(__finalize__)\n",
       "        5    0.000    0.000    0.026    0.005 generic.py:3708(_take_with_is_copy)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
       "       13    0.000    0.000    0.001    0.000 warnings.py:130(filterwarnings)\n",
       "        3    0.000    0.000    0.001    0.000 common.py:1198(is_numeric_dtype)\n",
       "       29    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(copyto)\n",
       "   231/42    0.000    0.000   50.318    1.198 abc.py:121(__subclasscheck__)\n",
       "        1    0.000    0.000    0.002    0.002 foundation.py:91(__iter__)\n",
       "  160/156    0.000    0.000    0.001    0.000 traitlets.py:675(__get__)\n",
       "        1    0.000    0.000    0.001    0.001 format.py:1494(get_result_as_array)\n",
       "        4    0.000    0.000    0.001    0.000 encoder.py:204(iterencode)\n",
       "       12    0.000    0.000    0.006    0.001 base.py:7106(_maybe_cast_data_without_dtype)\n",
       "       26    0.000    0.000    0.000    0.000 generic.py:239(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 managers.py:1601(_interleave)\n",
       "       55    0.000    0.000   50.318    0.915 basics.py:52(listify)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:2781(__init__)\n",
       "       18    0.000    0.000    0.001    0.000 take.py:554(_take_preprocess_indexer_and_fill_value)\n",
       "    41/37    0.000    0.000    0.001    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
       "        5    0.000    0.000    0.017    0.003 managers.py:634(reindex_indexer)\n",
       "        8    0.000    0.000    0.001    0.000 managers.py:1673(_consolidate_check)\n",
       "       55    0.000    0.000   50.318    0.915 foundation.py:95(__call__)\n",
       "        1    0.000    0.000    0.047    0.047 load.py:166(do_batch)\n",
       "       43    0.000    0.000    0.001    0.000 config.py:109(_get_single_key)\n",
       "        1    0.000    0.000    0.001    0.001 generic.py:1945(__iter__)\n",
       "        1    0.000    0.000    0.001    0.001 profiler.py:426(__init__)\n",
       "       30    0.000    0.000    0.000    0.000 generic.py:5577(__setattr__)\n",
       "        5    0.000    0.000    0.001    0.000 managers.py:578(copy)\n",
       "        6    0.000    0.000    0.001    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
       "      129    0.000    0.000    0.000    0.000 load.py:119(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
       "       24    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
       "       49    0.000    0.000    0.000    0.000 missing.py:149(_isna)\n",
       "        5    0.000    0.000    0.001    0.000 iostream.py:209(schedule)\n",
       "        1    0.000    0.000    0.006    0.006 zmqshell.py:63(_flush_streams)\n",
       "        5    0.000    0.000    0.000    0.000 managers.py:253(apply)\n",
       "        7    0.000    0.000    0.010    0.001 frame.py:3463(__getitem__)\n",
       "        2    0.000    0.000    0.002    0.001 basics.py:213(chunked)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:2008(_form_blocks)\n",
       "       26    0.000    0.000    0.000    0.000 flags.py:47(__init__)\n",
       "       72    0.000    0.000    0.000    0.000 html.py:126(write)\n",
       "        1    0.000    0.000    0.000    0.000 meta.py:120(<dictcomp>)\n",
       "        5    0.000    0.000    0.000    0.000 indexing.py:130(iloc)\n",
       "       77    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'isoformat' of 'datetime.datetime' objects}\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:494(unwrap)\n",
       "       45    0.000    0.000    0.000    0.000 common.py:1240(is_float_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:201(utcnow)\n",
       "        7    0.000    0.000    0.001    0.000 generic.py:5650(f)\n",
       "       11    0.000    0.000    0.000    0.000 indexing.py:2481(check_deprecated_indexers)\n",
       "      136    0.000    0.000    0.000    0.000 printing.py:164(pprint_thing)\n",
       "        2    0.000    0.000    0.051    0.026 load.py:133(create_batches)\n",
       "        1    0.000    0.000    0.005    0.005 frame.py:2846(to_html)\n",
       "       18    0.000    0.000    0.015    0.001 take.py:57(take_nd)\n",
       "       11    0.000    0.000    0.000    0.000 dir2.py:54(get_real_method)\n",
       "        2    0.000    0.000    0.015    0.007 base.py:796(_map_values)\n",
       "        2    0.000    0.000    0.015    0.007 series.py:4162(map)\n",
       "        1    0.000    0.000    0.029    0.029 apply.py:694(apply)\n",
       "        8    0.000    0.000    0.015    0.002 blocks.py:1114(take_nd)\n",
       "        4    0.000    0.000    0.000    0.000 indexing.py:1419(_is_scalar_access)\n",
       "        1    0.000    0.000    0.000    0.000 html.py:43(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 basics.py:302(type_hints)\n",
       "        7    0.000    0.000    0.000    0.000 frame.py:3906(_box_col_values)\n",
       "       23    0.000    0.000    0.000    0.000 generic.py:560(_get_axis)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:2642(_na_value)\n",
       "       37    0.000    0.000   50.318    1.360 typing.py:848(__subclasscheck__)\n",
       "        5    0.000    0.000    0.000    0.000 contextlib.py:123(__exit__)\n",
       "        4    0.000    0.000    0.001    0.000 encoder.py:182(encode)\n",
       "      390    0.000    0.000    0.000    0.000 generic.py:43(_check)\n",
       "        4    0.000    0.000    0.000    0.000 config.py:135(_set_option)\n",
       "        4    0.000    0.000    0.001    0.000 session.py:97(json_packer)\n",
       "        1    0.000    0.000    0.010    0.010 core.py:323(encodes)\n",
       "      148    0.000    0.000    0.001    0.000 common.py:1587(_is_dtype_type)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:1740(trait_defaults)\n",
       "        7    0.000    0.000   50.310    7.187 dispatch.py:130(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:560(__init__)\n",
       "      136    0.000    0.000    0.000    0.000 printing.py:195(as_escaped_string)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
       "        4    0.000    0.000    0.000    0.000 cast.py:1466(maybe_infer_to_datetimelike)\n",
       "       53    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
       "        1    0.000    0.000    0.004    0.004 format.py:1054(to_html)\n",
       "        4    0.000    0.000    0.000    0.000 range.py:167(_simple_new)\n",
       "       37    0.000    0.000    0.000    0.000 config.py:642(_warn_if_deprecated)\n",
       "        2    0.000    0.000    0.001    0.000 format.py:1350(_format_strings)\n",
       "        4    0.000    0.000    0.000    0.000 function_base.py:4958(delete)\n",
       "        3    0.000    0.000    0.001    0.000 basics.py:394(camel2snake)\n",
       "        6    0.000    0.000    0.001    0.000 _methods.py:38(_amax)\n",
       "        2    0.000    0.000    0.000    0.000 apply.py:108(__init__)\n",
       "        1    0.000    0.000    0.027    0.027 apply.py:856(apply_series_generator)\n",
       "       16    0.000    0.000    0.000    0.000 base.py:554(_dtype_to_subclass)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
       "        6    0.000    0.000    0.001    0.000 re.py:203(sub)\n",
       "       50    0.000    0.000    0.000    0.000 common.py:155(<lambda>)\n",
       "        2    0.000    0.000    0.001    0.000 managers.py:1061(iset)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {method '_rebuild_blknos_and_blklocs' of 'pandas._libs.internals.BlockManager' objects}\n",
       "      4/2    0.000    0.000    0.010    0.005 construction.py:822(create_series_with_explicit_dtype)\n",
       "        7    0.000    0.000    0.001    0.000 managers.py:618(consolidate)\n",
       "       11    0.000    0.000    0.004    0.000 torch_core.py:525(__init__)\n",
       "        1    0.000    0.000    0.029    0.029 frame.py:8667(transform)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:51(create_fetcher)\n",
       "       20    0.000    0.000    0.000    0.000 format.py:1456(base_formatter)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:273(msg_header)\n",
       "        4    0.000    0.000    0.000    0.000 indexing.py:777(_is_nested_tuple_indexer)\n",
       "        8    0.000    0.000    0.002    0.000 base.py:3786(_get_indexer)\n",
       "        1    0.000    0.000    0.010    0.010 display_functions.py:45(publish_display_data)\n",
       "       77    0.000    0.000    0.000    0.000 base.py:884(__len__)\n",
       "        1    0.000    0.000    0.002    0.002 formatters.py:89(format)\n",
       "        2    0.000    0.000    0.000    0.000 torch_core.py:251(to_device)\n",
       "        2    0.000    0.000    0.001    0.000 re.py:315(_compile_repl)\n",
       "        1    0.000    0.000    0.015    0.015 managers.py:692(<listcomp>)\n",
       "       12    0.000    0.000    0.001    0.000 managers.py:1665(is_consolidated)\n",
       "        6    0.000    0.000    0.000    0.000 generic.py:660(ndim)\n",
       "        3    0.000    0.000    0.000    0.000 cast.py:1985(maybe_cast_to_integer_array)\n",
       "        1    0.000    0.000    0.001    0.001 construction.py:274(ndarray_to_mgr)\n",
       "        8    0.000    0.000    0.000    0.000 blocks.py:238(fill_value)\n",
       "       11    0.000    0.000    0.000    0.000 formatters.py:395(lookup_by_type)\n",
       "        1    0.000    0.000    0.000    0.000 _asarray.py:22(require)\n",
       "        9    0.000    0.000    0.000    0.000 missing.py:911(clean_reindex_fill_method)\n",
       "       24    0.000    0.000   50.317    2.097 imports.py:20(is_iter)\n",
       "      4/3    0.000    0.000    0.063    0.021 dispatch.py:116(__call__)\n",
       "       43    0.000    0.000    0.000    0.000 config.py:571(_select_options)\n",
       "        5    0.000    0.000    0.001    0.000 generic.py:5926(copy)\n",
       "        4    0.000    0.000    0.000    0.000 contextlib.py:376(__init__)\n",
       "        1    0.000    0.000    0.025    0.025 indexing.py:815(_getitem_tuple_same_dim)\n",
       "        1    0.000    0.000    0.001    0.001 session.py:751(send)\n",
       "       39    0.000    0.000    0.001    0.000 config.py:127(_get_option)\n",
       "        6    0.000    0.000    0.000    0.000 basics.py:242(get_annotations_ex)\n",
       "       20    0.000    0.000    0.002    0.000 base.py:5905(_index_as_unique)\n",
       "        1    0.000    0.000    0.000    0.000 pretty.py:372(pretty)\n",
       "        7    0.000    0.000    0.001    0.000 frame.py:3411(_ixs)\n",
       "       17    0.000    0.000    0.001    0.000 common.py:229(asarray_tuplesafe)\n",
       "        1    0.000    0.000    0.000    0.000 load.py:156(retain)\n",
       "        2    0.000    0.000    0.000    0.000 _ufunc_config.py:32(seterr)\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2404(all)\n",
       "       27    0.000    0.000    0.000    0.000 _dtype.py:314(_name_includes_bit_suffix)\n",
       "        3    0.000    0.000    0.002    0.001 format.py:1240(format_array)\n",
       "        4    0.000    0.000    0.000    0.000 missing.py:625(is_valid_na_for_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 load.py:118(sample)\n",
       "        7    0.000    0.000    0.000    0.000 managers.py:1016(iget)\n",
       "       15    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
       "       12    0.000    0.000    0.000    0.000 inspect.py:2909(_bind)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2388(array_equal)\n",
       "        1    0.000    0.000    0.000    0.000 formatters.py:906(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:221(send_multipart)\n",
       "       17    0.000    0.000    0.000    0.000 common.py:1148(needs_i8_conversion)\n",
       "       21    0.000    0.000    0.000    0.000 flags.py:83(allows_duplicate_labels)\n",
       "    44/42    0.000    0.000    0.000    0.000 basics.py:451(__getattr__)\n",
       "        7    0.000    0.000    0.000    0.000 numeric.py:139(_ensure_array)\n",
       "        8    0.000    0.000    0.000    0.000 blocks.py:267(make_block_same_class)\n",
       "        1    0.000    0.000  553.467  553.467 {built-in method builtins.exec}\n",
       "       16    0.000    0.000    0.000    0.000 missing.py:390(array_equivalent)\n",
       "       16    0.000    0.000    0.000    0.000 base.py:5178(equals)\n",
       "       18    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
       "        4    0.000    0.000    0.007    0.002 base.py:5768(_get_indexer_strict)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:4009(_convert_slice_indexer)\n",
       "       44    0.000    0.000    0.000    0.000 formatters.py:551(_in_deferred_types)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:692(_constructor)\n",
       "        1    0.000    0.000    0.001    0.001 construction.py:425(dict_to_mgr)\n",
       "        3    0.000    0.000    0.003    0.001 format.py:886(format_col)\n",
       "        4    0.000    0.000    0.001    0.000 __init__.py:183(dumps)\n",
       "        1    0.000    0.000    0.000    0.000 range.py:944(_getitem_slice)\n",
       "       15    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:322(default_index)\n",
       "       10    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
       "        8    0.000    0.000    0.000    0.000 indexing.py:2318(convert_to_index_sliceable)\n",
       "       38    0.000    0.000    0.000    0.000 common.py:581(is_dtype_equal)\n",
       "        9    0.000    0.000    0.004    0.000 algorithms.py:1352(take)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'copy' of '_hashlib.HASH' objects}\n",
       "        3    0.000    0.000    0.008    0.003 foundation.py:145(__radd__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
       "       37    0.000    0.000    0.001    0.000 config.py:255(__call__)\n",
       "        4    0.000    0.000    0.025    0.006 indexing.py:1487(_getitem_axis)\n",
       "        1    0.000    0.000    0.001    0.001 construction.py:747(_get_axes)\n",
       "        1    0.000    0.000    0.051    0.051 dataloader.py:568(_next_data)\n",
       "        8    0.000    0.000    0.000    0.000 managers.py:973(from_blocks)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
       "        1    0.000    0.000    0.000    0.000 formatters.py:694(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:115(copy)\n",
       "        2    0.000    0.000    0.000    0.000 threading.py:521(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 managers.py:596(copy_func)\n",
       "      112    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
       "        1    0.000    0.000    0.025    0.025 indexing.py:1464(_get_list_axis)\n",
       "        1    0.000    0.000  503.104  503.104 load.py:168(one_batch)\n",
       "        3    0.000    0.000    0.000    0.000 transform.py:160(gather_attrs)\n",
       "       43    0.000    0.000    0.000    0.000 config.py:589(_get_root)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:53(shape)\n",
       "       35    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
       "        1    0.000    0.000    0.000    0.000 session.py:672(sign)\n",
       "        2    0.000    0.000    0.000    0.000 {pandas._libs.lib.map_infer}\n",
       "        1    0.000    0.000    0.000    0.000 load.py:30(__iter__)\n",
       "       10    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
       "      137    0.000    0.000    0.000    0.000 inference.py:359(is_sequence)\n",
       "       12    0.000    0.000    0.000    0.000 decorator.py:199(fix)\n",
       "        1    0.000    0.000    0.029    0.029 apply.py:181(transform)\n",
       "        4    0.000    0.000    0.000    0.000 missing.py:226(_isna_array)\n",
       "    86/84    0.000    0.000  503.103    5.989 {built-in method builtins.next}\n",
       "        9    0.000    0.000    0.001    0.000 base.py:6004(_should_compare)\n",
       "        1    0.000    0.000    0.000    0.000 pretty.py:355(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
       "        7    0.000    0.000    0.002    0.000 generic.py:5646(_consolidate_inplace)\n",
       "        4    0.000    0.000   50.354   12.589 transform.py:145(compose_tfms)\n",
       "        1    0.000    0.000    0.004    0.004 html.py:220(_write_table)\n",
       "        2    0.000    0.000    0.000    0.000 torch_core.py:269(<lambda>)\n",
       "        3    0.000    0.000    0.000    0.000 pretty.py:482(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 base.py:974(view)\n",
       "       43    0.000    0.000    0.000    0.000 foundation.py:136(__iter__)\n",
       "       19    0.000    0.000    0.000    0.000 _collections_abc.py:78(_check_methods)\n",
       "       13    0.000    0.000    0.000    0.000 dtypes.py:1206(is_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 jsonutil.py:39(_ensure_tzinfo)\n",
       "        7    0.000    0.000    0.000    0.000 numeric.py:188(_validate_dtype)\n",
       "        1    0.000    0.000    0.001    0.001 apply.py:875(wrap_results)\n",
       "        1    0.000    0.000    0.000    0.000 genericpath.py:16(exists)\n",
       "        6    0.000    0.000    0.000    0.000 generic.py:566(_get_block_manager_axis)\n",
       "        1    0.000    0.000    0.000    0.000 torch_core.py:267(to_np)\n",
       "        1    0.000    0.000    0.000    0.000 zmqshell.py:73(_hooks)\n",
       "      136    0.000    0.000    0.000    0.000 base.py:4820(_values)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:57(_retain_dl)\n",
       "        2    0.000    0.000    0.002    0.001 inspect.py:3111(signature)\n",
       "        7    0.000    0.000    0.000    0.000 basics.py:773(map_ex)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'get_slice' of 'pandas._libs.internals.BlockManager' objects}\n",
       "        1    0.000    0.000    0.001    0.001 session.py:643(msg_header)\n",
       "        3    0.000    0.000    0.000    0.000 missing.py:494(_array_equivalent_object)\n",
       "        7    0.000    0.000    0.000    0.000 basics.py:755(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:168(union_indexes)\n",
       "        4    0.000    0.000    0.000    0.000 indexing.py:834(_getitem_lowerdim)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:1715(_get_trait_default_generator)\n",
       "       56    0.000    0.000    0.000    0.000 base.py:286(is_dtype)\n",
       "       11    0.000    0.000    0.000    0.000 formatters.py:372(lookup)\n",
       "       13    0.000    0.000    0.001    0.000 cast.py:468(maybe_promote)\n",
       "        4    0.000    0.000    0.000    0.000 numeric.py:235(astype)\n",
       "        1    0.000    0.000    0.000    0.000 display.py:281(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 jsonutil.py:77(json_clean)\n",
       "        1    0.000    0.000    0.000    0.000 load.py:153(chunkify)\n",
       "       18    0.000    0.000    0.001    0.000 take.py:326(_get_take_nd_function)\n",
       "        2    0.000    0.000    0.002    0.001 inspect.py:2859(from_callable)\n",
       "        3    0.000    0.000    0.000    0.000 cast.py:1789(find_common_type)\n",
       "        2    0.000    0.000    0.000    0.000 sre_parse.py:224(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:599(msg_id)\n",
       "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(all)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:3560(_convert_can_do_setop)\n",
       "       15    0.000    0.000    0.000    0.000 _collections_abc.py:283(__subclasshook__)\n",
       "    44/42    0.000    0.000    0.000    0.000 basics.py:446(_component_attr_filter)\n",
       "        1    0.000    0.000    0.000    0.000 display.py:57(_safe_exists)\n",
       "       21    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1033(_handle_fromlist)\n",
       "        8    0.000    0.000    0.000    0.000 construction.py:695(_try_cast)\n",
       "        3    0.000    0.000    0.000    0.000 format.py:1884(_make_fixed_width)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method math.log}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
       "        9    0.000    0.000    0.000    0.000 basics.py:759(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 display.py:405(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 fetch.py:19(__init__)\n",
       "        1    0.000    0.000  553.467  553.467 <string>:1(<module>)\n",
       "       13    0.000    0.000    0.000    0.000 missing.py:571(na_value_for_dtype)\n",
       "        5    0.000    0.000    0.000    0.000 contextlib.py:86(__init__)\n",
       "        3    0.000    0.000    0.002    0.001 format.py:1346(get_result)\n",
       "        7    0.000    0.000    0.002    0.000 generic.py:5632(_protect_consolidate)\n",
       "       21    0.000    0.000    0.011    0.001 base.py:6987(ensure_index)\n",
       "        1    0.000    0.000    0.000    0.000 load.py:155(randomize)\n",
       "        4    0.000    0.000    0.005    0.001 base.py:5744(get_indexer_for)\n",
       "        1    0.000    0.000    0.000    0.000 fetch.py:8(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 contextlib.py:261(helper)\n",
       "        8    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
       "        4    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(delete)\n",
       "        1    0.000    0.000    0.031    0.031 core.py:199(transform)\n",
       "        1    0.000    0.000    0.004    0.004 html.py:71(to_string)\n",
       "      116    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
       "        8    0.000    0.000    0.000    0.000 managers.py:1837(dtype)\n",
       "        5    0.000    0.000    0.000    0.000 iostream.py:97(_event_pipe)\n",
       "       12    0.000    0.000    0.000    0.000 series.py:640(name)\n",
       "        7    0.000    0.000    0.000    0.000 threading.py:1126(is_alive)\n",
       "       39    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\n",
       "        2    0.000    0.000    0.000    0.000 frame.py:3923(_get_item_cache)\n",
       "        4    0.000    0.000    0.004    0.001 indexing.py:761(_validate_tuple_indexer)\n",
       "       44    0.000    0.000    0.000    0.000 html.py:166(_write_cell)\n",
       "       21    0.000    0.000    0.008    0.000 foundation.py:110(_new)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:1996(empty)\n",
       "        1    0.000    0.000    0.000    0.000 pretty.py:201(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 generic.py:546(_get_axis_number)\n",
       "       11    0.000    0.000    0.000    0.000 xtras.py:54(is_listy)\n",
       "       38    0.000    0.000    0.000    0.000 common.py:497(is_categorical_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 contextlib.py:382(__exit__)\n",
       "       80    0.000    0.000    0.000    0.000 config.py:603(_get_deprecated_option)\n",
       "       40    0.000    0.000    0.000    0.000 re.py:188(match)\n",
       "       14    0.000    0.000    0.000    0.000 inspect.py:2830(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 format.py:1320(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 blocks.py:1989(get_block_type)\n",
       "       28    0.000    0.000    0.000    0.000 numerictypes.py:282(issubclass_)\n",
       "       14    0.000    0.000    0.000    0.000 series.py:590(name)\n",
       "        2    0.000    0.000    0.001    0.000 frame.py:3822(_set_item)\n",
       "        1    0.000    0.000    0.010    0.010 transform.py:73(__call__)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:1005(astype)\n",
       "        2    0.000    0.000    0.000    0.000 frame.py:4515(_sanitize_column)\n",
       "        9    0.000    0.000    0.000    0.000 common.py:1274(is_bool_dtype)\n",
       "        2    0.000    0.000    0.008    0.004 core.py:205(f)\n",
       "        7    0.000    0.000    0.000    0.000 foundation.py:155(map)\n",
       "       15    0.000    0.000    0.000    0.000 re.py:250(compile)\n",
       "        1    0.000    0.000    0.029    0.029 apply.py:293(transform_str_or_callable)\n",
       "        2    0.000    0.000    0.000    0.000 jsonutil.py:108(json_default)\n",
       "        9    0.000    0.000    0.003    0.000 base.py:6293(_maybe_cast_listlike_indexer)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:5963(_find_common_type_compat)\n",
       "        3    0.000    0.000    0.000    0.000 cast.py:454(ensure_dtype_can_hold_na)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:407(_check_values_indices_shape_match)\n",
       "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:429(__enter__)\n",
       "        7    0.000    0.000    0.000    0.000 blocks.py:2119(extend_blocks)\n",
       "        2    0.000    0.000    0.000    0.000 config_init.py:380(_deprecate_negative_int_max_colwidth)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
       "       12    0.000    0.000    0.000    0.000 base.py:4973(__contains__)\n",
       "       12    0.000    0.000    0.000    0.000 indexing.py:957(<genexpr>)\n",
       "        7    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\n",
       "       49    0.000    0.000    0.000    0.000 common.py:161(is_object_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 threading.py:1351(current_thread)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:280(extract_header)\n",
       "       13    0.000    0.000    0.000    0.000 enum.py:670(__new__)\n",
       "       14    0.000    0.000    0.000    0.000 managers.py:1848(internal_values)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.delattr}\n",
       "        4    0.000    0.000    0.000    0.000 base.py:5799(_raise_if_missing)\n",
       "       12    0.000    0.000    0.001    0.000 formatters.py:218(catch_format_error)\n",
       "       15    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\n",
       "        3    0.000    0.000    0.008    0.003 foundation.py:87(__getitem__)\n",
       "        2    0.000    0.000    0.000    0.000 configurable.py:521(instance)\n",
       "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:425(__init__)\n",
       "       16    0.000    0.000    0.000    0.000 managers.py:156(blknos)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._ops.profiler._record_function_exit}\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:717(_validate)\n",
       "       51    0.000    0.000    0.000    0.000 basics.py:47(is_array)\n",
       "        9    0.000    0.000    0.000    0.000 base.py:3823(_check_indexing_method)\n",
       "        3    0.000    0.000    0.002    0.001 transform.py:176(__init__)\n",
       "        1    0.000    0.000    0.003    0.003 core.py:331(decodes)\n",
       "        1    0.000    0.000    0.001    0.001 html.py:405(_write_regular_rows)\n",
       "        6    0.000    0.000    0.001    0.000 {method 'sub' of 're.Pattern' objects}\n",
       "       20    0.000    0.000    0.000    0.000 base.py:5023(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 profiler.py:439(__exit__)\n",
       "       11    0.000    0.000    0.000    0.000 html.py:191(write_tr)\n",
       "        2    0.000    0.000    0.011    0.005 transform.py:200(__call__)\n",
       "        1    0.000    0.000   50.313   50.313 core.py:90(_pre_show_batch)\n",
       "        1    0.000    0.000    0.000    0.000 jsonutil.py:52(encode_images)\n",
       "       14    0.000    0.000    0.000    0.000 dispatch.py:67(all_matches)\n",
       "       20    0.000    0.000    0.000    0.000 format.py:1371(_format)\n",
       "        2    0.000    0.000    0.000    0.000 apply.py:78(frame_apply)\n",
       "       33    0.000    0.000    0.000    0.000 base.py:834(_reset_identity)\n",
       "       26    0.000    0.000    0.000    0.000 base.py:7082(maybe_extract_name)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:1191(save_to_buffer)\n",
       "       14    0.000    0.000    0.000    0.000 numerictypes.py:356(issubdtype)\n",
       "        2    0.000    0.000    0.000    0.000 _ufunc_config.py:131(geterr)\n",
       "        4    0.000    0.000    0.000    0.000 sre_parse.py:980(addgroup)\n",
       "        4    0.000    0.000    0.000    0.000 range.py:522(equals)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "       12    0.000    0.000    0.002    0.000 decorator.py:229(fun)\n",
       "        4    0.000    0.000    0.000    0.000 cast.py:515(_maybe_promote)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:475(get_adjustment)\n",
       "        9    0.000    0.000    0.000    0.000 base.py:1124(_maybe_disallow_fill)\n",
       "       14    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
       "        4    0.000    0.000    0.000    0.000 managers.py:2137(_preprocess_slice_or_indexer)\n",
       "       49    0.000    0.000    0.000    0.000 missing.py:66(isna)\n",
       "       13    0.000    0.000    0.000    0.000 common.py:459(is_interval_dtype)\n",
       "       57    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
       "       13    0.000    0.000    0.000    0.000 enum.py:358(__call__)\n",
       "        4    0.000    0.000    0.000    0.000 managers.py:1731(from_array)\n",
       "        7    0.000    0.000    0.000    0.000 inference.py:262(is_dict_like)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:767(_set_axis)\n",
       "       17    0.000    0.000    0.000    0.000 base.py:4846(_get_engine_target)\n",
       "       12    0.000    0.000    0.000    0.000 pretty.py:321(_get_mro)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method numpy.geterrobj}\n",
       "        2    0.000    0.000    0.001    0.000 frame.py:10808(values)\n",
       "        3    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(array_equal)\n",
       "       30    0.000    0.000    0.000    0.000 html.py:163(write_td)\n",
       "       12    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
       "       37    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
       "        3    0.000    0.000    0.001    0.000 generic.py:636(_info_axis)\n",
       "       40    0.000    0.000    0.000    0.000 format.py:1967(is_number_with_decimal)\n",
       "        7    0.000    0.000    0.000    0.000 blocks.py:1960(maybe_coerce_values)\n",
       "       13    0.000    0.000    0.000    0.000 managers.py:1700(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:266(_sanitize_and_check)\n",
       "       27    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\n",
       "        2    0.000    0.000    0.000    0.000 blocks.py:378(delete)\n",
       "        9    0.000    0.000    0.000    0.000 missing.py:107(clean_fill_method)\n",
       "        6    0.000    0.000    0.000    0.000 numerictypes.py:573(_can_coerce_all)\n",
       "       11    0.000    0.000    0.000    0.000 base.py:2596(inferred_type)\n",
       "        1    0.000    0.000  553.467  553.467 core.py:98(show_batch)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:190(all_col_names)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:1361(format)\n",
       "        1    0.000    0.000    0.000    0.000 pretty.py:490(__init__)\n",
       "        1    0.000    0.000    0.050    0.050 core.py:176(show)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:641(has_index_names)\n",
       "        4    0.000    0.000    0.001    0.000 base.py:4109(reindex)\n",
       "        1    0.000    0.000    0.001    0.001 frame.py:3664(_setitem_array)\n",
       "        2    0.000    0.000    0.000    0.000 config.py:837(inner)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:3058(union)\n",
       "       13    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\n",
       "       11    0.000    0.000    0.000    0.000 dispatch.py:187(retain_type)\n",
       "      132    0.000    0.000    0.000    0.000 _collections_abc.py:409(__subclasshook__)\n",
       "       45    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.checknull}\n",
       "        6    0.000    0.000    0.000    0.000 series.py:542(_set_axis)\n",
       "       18    0.000    0.000    0.000    0.000 common.py:346(apply_if_callable)\n",
       "        2    0.000    0.000    0.001    0.000 managers.py:1541(as_array)\n",
       "       22    0.000    0.000    0.000    0.000 missing.py:287(notna)\n",
       "        1    0.000    0.000    0.000    0.000 html.py:252(_write_col_header)\n",
       "       98    0.000    0.000    0.000    0.000 common.py:147(<lambda>)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2358(validate)\n",
       "        7    0.000    0.000    0.000    0.000 series.py:1238(_set_as_cached)\n",
       "       12    0.000    0.000    0.000    0.000 inspect.py:2648(args)\n",
       "        3    0.000    0.000    0.000    0.000 numerictypes.py:597(find_common_type)\n",
       "        4    0.000    0.000    0.000    0.000 frame.py:804(axes)\n",
       "        8    0.000    0.000    0.000    0.000 series.py:575(dtype)\n",
       "      221    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
       "       14    0.000    0.000    0.000    0.000 blocks.py:354(dtype)\n",
       "        7    0.000    0.000    0.000    0.000 blocks.py:638(copy)\n",
       "        2    0.000    0.000    0.001    0.001 cast.py:115(maybe_convert_platform)\n",
       "        1    0.000    0.000    0.029    0.029 apply.py:850(apply_standard)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:1956(_trim_zeros_float)\n",
       "        1    0.000    0.000    0.003    0.003 html.py:388(_get_formatted_values)\n",
       "        6    0.000    0.000    0.000    0.000 frame.py:1413(__len__)\n",
       "        9    0.000    0.000    0.000    0.000 utils.py:69(is_list_like_indexer)\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:1388(_notify_observers)\n",
       "      5/3    0.000    0.000    0.000    0.000 torch_core.py:202(apply)\n",
       "        6    0.000    0.000    0.000    0.000 {pandas._libs.internals.get_blkno_placements}\n",
       "       40    0.000    0.000    0.000    0.000 common.py:1483(is_ea_or_datetimelike_dtype)\n",
       "        8    0.000    0.000    0.000    0.000 indexing.py:1432(<genexpr>)\n",
       "        1    0.000    0.000    0.003    0.003 html.py:393(_write_body)\n",
       "        7    0.000    0.000    0.000    0.000 threading.py:1059(_wait_for_tstate_lock)\n",
       "       30    0.000    0.000    0.000    0.000 {method 'rjust' of 'str' objects}\n",
       "        4    0.000    0.000    0.000    0.000 blocks.py:2041(new_block)\n",
       "        3    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(concatenate)\n",
       "        3    0.000    0.000    0.000    0.000 {pandas._libs.lib.array_equivalent_object}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:596(_homogenize)\n",
       "       26    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
       "        3    0.000    0.000    0.000    0.000 meta.py:108(delegates)\n",
       "       85    0.000    0.000    0.000    0.000 common.py:1552(get_dtype)\n",
       "       45    0.000    0.000    0.000    0.000 inference.py:321(is_hashable)\n",
       "        1    0.000    0.000    0.000    0.000 basics.py:158(count)\n",
       "        4    0.000    0.000    0.000    0.000 indexing.py:740(_expand_ellipsis)\n",
       "       49    0.000    0.000    0.000    0.000 foundation.py:85(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 zmqshell.py:68(_default_thread_local)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:423(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:270(_convert_slice_indexer)\n",
       "        1    0.000    0.000    0.000    0.000 range.py:224(_format_with_header)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:75(get_op_result_name)\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:1102(ident)\n",
       "        1    0.000    0.000    0.000    0.000 _asarray.py:111(<setcomp>)\n",
       "        1    0.000    0.000    0.029    0.029 frame.py:8682(apply)\n",
       "        4    0.000    0.000    0.001    0.000 cast.py:507(_maybe_promote_cached)\n",
       "        3    0.000    0.000    0.000    0.000 dispatch.py:125(__get__)\n",
       "        1    0.000    0.000    0.000    0.000 load.py:148(prebatched)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:180(iloc)\n",
       "        2    0.000    0.000   50.323   25.162 transform.py:115(_call1)\n",
       "       12    0.000    0.000    0.000    0.000 inspect.py:2701(apply_defaults)\n",
       "        2    0.000    0.000    0.000    0.000 range.py:439(_view)\n",
       "        2    0.000    0.000    0.000    0.000 common.py:97(_maybe_match_name)\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:915(series_generator)\n",
       "       14    0.000    0.000    0.000    0.000 html.py:130(write_th)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:1992(_has_names)\n",
       "       10    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\n",
       "        7    0.000    0.000    0.000    0.000 foundation.py:144(__add__)\n",
       "       14    0.000    0.000    0.000    0.000 series.py:687(_values)\n",
       "      4/2    0.000    0.000    0.000    0.000 dispatch.py:200(retain_types)\n",
       "        1    0.000    0.000    0.000    0.000 display.py:349(reload)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method utcnow}\n",
       "       14    0.000    0.000    0.000    0.000 _methods.py:54(_any)\n",
       "        2    0.000    0.000    0.000    0.000 construction.py:233(mgr_to_mgr)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
       "       98    0.000    0.000    0.000    0.000 common.py:145(classes)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:6299(_validate_indexer)\n",
       "        2    0.000    0.000    0.001    0.000 frame.py:3797(_set_item_mgr)\n",
       "       12    0.000    0.000    0.000    0.000 common.py:786(is_unsigned_integer_dtype)\n",
       "       40    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
       "       26    0.000    0.000    0.000    0.000 range.py:909(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 display.py:406(warn)\n",
       "        3    0.000    0.000    0.000    0.000 basics.py:309(annotations)\n",
       "       18    0.000    0.000    0.000    0.000 foundation.py:111(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:2060(_stack_arrays)\n",
       "        3    0.000    0.000   50.354   16.785 transform.py:85(_do_call)\n",
       "        9    0.000    0.000    0.000    0.000 formatters.py:329(__call__)\n",
       "       24    0.000    0.000    0.000    0.000 common.py:1740(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:287(maybe_iterable_to_list)\n",
       "        3    0.000    0.000   50.354   16.785 transform.py:81(_call)\n",
       "        8    0.000    0.000    0.000    0.000 dispatch.py:70(<listcomp>)\n",
       "       24    0.000    0.000    0.000    0.000 inference.py:288(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 foundation.py:174(attrgot)\n",
       "       29    0.000    0.000    0.000    0.000 multiarray.py:1071(copyto)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:635(_extract_index)\n",
       "        1    0.000    0.000    0.000    0.000 pretty.py:775(_repr_pprint)\n",
       "       12    0.000    0.000    0.000    0.000 inspect.py:2671(kwargs)\n",
       "       13    0.000    0.000    0.000    0.000 types.py:171(__get__)\n",
       "      194    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 config.py:425(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 base.py:5917(_maybe_promote)\n",
       "       50    0.000    0.000    0.000    0.000 foundation.py:86(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 range.py:232(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 config.py:433(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 generic.py:3908(_slice)\n",
       "        2    0.000    0.000    0.001    0.000 frame.py:3790(_iset_item_mgr)\n",
       "        6    0.000    0.000    0.000    0.000 frame.py:3920(_clear_item_cache)\n",
       "       20    0.000    0.000    0.000    0.000 common.py:680(is_integer_dtype)\n",
       "       24    0.000    0.000    0.000    0.000 common.py:1429(is_extension_array_dtype)\n",
       "        1    0.000    0.000    0.001    0.001 construction.py:102(arrays_to_mgr)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:533(is_string_or_object_np_dtype)\n",
       "       14    0.000    0.000    0.000    0.000 managers.py:172(blklocs)\n",
       "        1    0.000    0.000    0.003    0.003 html.py:390(<dictcomp>)\n",
       "       18    0.000    0.000    0.000    0.000 base.py:2272(is_boolean)\n",
       "       54    0.000    0.000    0.000    0.000 base.py:55(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:1503(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 iostream.py:290(send_multipart)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:549(_prep_ndarray)\n",
       "        2    0.000    0.000    0.000    0.000 blocks.py:2135(ensure_block_shape)\n",
       "       25    0.000    0.000    0.000    0.000 inference.py:184(is_array_like)\n",
       "       12    0.000    0.000    0.000    0.000 indexing.py:783(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 basics.py:374(attrdict)\n",
       "        3    0.000    0.000    0.000    0.000 blocks.py:222(get_values)\n",
       "        3    0.000    0.000    0.000    0.000 format.py:429(justify)\n",
       "        3    0.000    0.000    0.001    0.000 apply.py:917(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:1978(<listcomp>)\n",
       "       46    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
       "        4    0.000    0.000    0.000    0.000 encoder.py:104(__init__)\n",
       "        9    0.000    0.000    0.000    0.000 cast.py:1819(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 indexing.py:2486(<genexpr>)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
       "        5    0.000    0.000    0.000    0.000 managers.py:1683(_consolidate_inplace)\n",
       "      3/1    0.000    0.000    0.001    0.001 frame.py:3630(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 utils.py:409(check_key_length)\n",
       "      168    0.000    0.000    0.000    0.000 inspect.py:2560(kind)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:290(randrange)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:1206(get_buffer)\n",
       "        3    0.000    0.000    0.000    0.000 transform.py:204(__getattr__)\n",
       "        2    0.000    0.000  503.103  251.552 basics.py:617(first)\n",
       "        2    0.000    0.000    0.000    0.000 pretty.py:280(begin_group)\n",
       "       21    0.000    0.000    0.000    0.000 common.py:1747(pandas_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:1985(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:153(<lambda>)\n",
       "       49    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
       "        3    0.000    0.000    0.000    0.000 foundation.py:175(<lambda>)\n",
       "        5    0.000    0.000    0.000    0.000 function.py:49(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:483(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'delete' of 'pandas._libs.internals.BlockPlacement' objects}\n",
       "        1    0.000    0.000    0.000    0.000 load.py:107(__len__)\n",
       "        3    0.000    0.000    0.000    0.000 {pandas._libs.lib.dtypes_all_equal}\n",
       "        5    0.000    0.000    0.000    0.000 transform.py:51(_is_tuple)\n",
       "       17    0.000    0.000    0.000    0.000 construction.py:438(ensure_wrapped_if_datetimelike)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:1979(<genexpr>)\n",
       "       11    0.000    0.000    0.000    0.000 managers.py:919(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 displaypub.py:43(_validate_data)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:128(_current)\n",
       "       24    0.000    0.000    0.000    0.000 common.py:160(cast_scalar_indexer)\n",
       "        3    0.000    0.000    0.000    0.000 generic.py:2054(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 display.py:393(_check_data)\n",
       "       43    0.000    0.000    0.000    0.000 config.py:630(_translate_key)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
       "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:434(__exit__)\n",
       "       34    0.000    0.000    0.000    0.000 numerictypes.py:582(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:1019(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 generic.py:3948(_check_setitem_copy)\n",
       "        2    0.000    0.000    0.000    0.000 series.py:1245(_clear_item_cache)\n",
       "       34    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x558752d71300}\n",
       "       18    0.000    0.000    0.000    0.000 foundation.py:114(_get)\n",
       "        1    0.000    0.000    0.000    0.000 configurable.py:565(initialized)\n",
       "        1    0.000    0.000    0.001    0.001 session.py:687(serialize)\n",
       "       21    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
       "        4    0.000    0.000    0.000    0.000 traitlets.py:1288(cross_validation_lock)\n",
       "        5    0.000    0.000    0.000    0.000 managers.py:282(<dictcomp>)\n",
       "       10    0.000    0.000    0.000    0.000 sre_parse.py:233(__next)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.repr}\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2399(_all_dispatcher)\n",
       "        4    0.000    0.000    0.000    0.000 format.py:899(_get_formatter)\n",
       "        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_object_object}\n",
       "        1    0.000    0.000    0.000    0.000 random.py:126(seed)\n",
       "       36    0.000    0.000    0.000    0.000 foundation.py:78(is_indexer)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:666(_initialize_formatters)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:605(default)\n",
       "       10    0.000    0.000    0.000    0.000 construction.py:627(_sanitize_ndim)\n",
       "        2    0.000    0.000    0.000    0.000 threading.py:228(__init__)\n",
       "        6    0.000    0.000    0.001    0.000 re.py:325(_subx)\n",
       "        8    0.000    0.000    0.000    0.000 generic.py:5561(__getattr__)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:191(<listcomp>)\n",
       "       50    0.000    0.000    0.000    0.000 common.py:150(classes_and_not_datetimelike)\n",
       "       15    0.000    0.000    0.000    0.000 common.py:732(is_signed_integer_dtype)\n",
       "        1    0.000    0.000    0.001    0.001 apply.py:927(wrap_results_for_axis)\n",
       "       16    0.000    0.000    0.000    0.000 base.py:803(is_)\n",
       "       36    0.000    0.000    0.000    0.000 _collections_abc.py:315(__subclasshook__)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
       "        2    0.000    0.000    0.005    0.002 threading.py:280(wait)\n",
       "       12    0.000    0.000    0.000    0.000 construction.py:379(extract_array)\n",
       "       12    0.000    0.000    0.000    0.000 common.py:1721(validate_all_hashable)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:1500(format_with_na_rep)\n",
       "       10    0.000    0.000    0.000    0.000 construction.py:802(is_empty_data)\n",
       "        2    0.000    0.000    0.001    0.000 format.py:1519(format_values_with)\n",
       "      128    0.000    0.000    0.000    0.000 core.py:353(do_item)\n",
       "       98    0.000    0.000    0.000    0.000 inspect.py:2548(name)\n",
       "       43    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
       "      128    0.000    0.000    0.000    0.000 load.py:135(<lambda>)\n",
       "       33    0.000    0.000    0.000    0.000 format.py:1899(<genexpr>)\n",
       "        3    0.000    0.000    0.000    0.000 printing.py:71(<listcomp>)\n",
       "       55    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
       "       12    0.000    0.000    0.000    0.000 inspect.py:3040(bind)\n",
       "        3    0.000    0.000    0.000    0.000 basics.py:624(nested_attr)\n",
       "        3    0.000    0.000    0.000    0.000 blocks.py:2030(new_block_2d)\n",
       "        7    0.000    0.000    0.000    0.000 blocks.py:358(iget)\n",
       "       24    0.000    0.000    0.000    0.000 base.py:937(dtype)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
       "       11    0.000    0.000    0.000    0.000 html.py:100(row_levels)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:3577(get_loc)\n",
       "       21    0.000    0.000    0.000    0.000 generic.py:328(attrs)\n",
       "        7    0.000    0.000    0.000    0.000 numeric.py:199(_ensure_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:785(_view)\n",
       "        2    0.000    0.000    0.000    0.000 cast.py:674(infer_dtype_from)\n",
       "       50    0.000    0.000    0.000    0.000 inspect.py:2865(parameters)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:4230(_maybe_preserve_names)\n",
       "        2    0.000    0.000    0.005    0.002 threading.py:556(wait)\n",
       "        1    0.000    0.000    0.001    0.001 session.py:646(msg)\n",
       "       51    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
       "        9    0.000    0.000    0.000    0.000 base.py:7168(unpack_nested_dtype)\n",
       "        4    0.000    0.000    0.000    0.000 blocks.py:2055(check_ndim)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "       15    0.000    0.000    0.000    0.000 base.py:2624(_is_multi)\n",
       "       42    0.000    0.000    0.000    0.000 generic.py:349(flags)\n",
       "       40    0.000    0.000    0.000    0.000 html.py:442(<genexpr>)\n",
       "        5    0.000    0.000    0.000    0.000 generic.py:3925(_set_is_copy)\n",
       "        2    0.000    0.000    0.000    0.000 cast.py:798(infer_dtype_from_array)\n",
       "       37    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
       "        1    0.000    0.000    0.000    0.000 foundation.py:178(zip)\n",
       "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x7fc7358bb9d0}\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1937(create_block_manager_from_column_arrays)\n",
       "       32    0.000    0.000    0.000    0.000 base.py:1650(name)\n",
       "        6    0.000    0.000    0.000    0.000 _collections_abc.py:262(__subclasshook__)\n",
       "       11    0.000    0.000    0.000    0.000 html.py:122(ncols)\n",
       "        3    0.000    0.000   50.310   16.770 dispatch.py:105(returns)\n",
       "       39    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
       "        6    0.000    0.000    0.000    0.000 indexing.py:1434(_validate_integer)\n",
       "        5    0.000    0.000    0.000    0.000 contextlib.py:114(__enter__)\n",
       "        4    0.000    0.000    0.000    0.000 numeric.py:149(ones)\n",
       "        2    0.000    0.000    0.000    0.000 missing.py:267(_isna_string_dtype)\n",
       "        8    0.000    0.000    0.000    0.000 indexing.py:2454(is_label_like)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:74(before_iter)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:348(is_datetime64tz_dtype)\n",
       "       12    0.000    0.000    0.000    0.000 dispatch.py:19(lenient_issubclass)\n",
       "        1    0.000    0.000    0.001    0.001 foundation.py:88(__setitem__)\n",
       "        3    0.000    0.000    0.000    0.000 format.py:1914(<listcomp>)\n",
       "        1    0.000    0.000   50.313   50.313 core.py:81(decode)\n",
       "        1    0.000    0.000    0.000    0.000 html.py:74(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 common.py:315(is_datetime64_dtype)\n",
       "        1    0.000    0.000    0.047    0.047 core.py:352(create_batch)\n",
       "       12    0.000    0.000    0.000    0.000 common.py:1416(is_1d_only_ea_dtype)\n",
       "       11    0.000    0.000    0.000    0.000 managers.py:1792(_block)\n",
       "       26    0.000    0.000    0.000    0.000 typing.py:1375(cast)\n",
       "       30    0.000    0.000    0.000    0.000 format.py:426(len)\n",
       "       16    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
       "       44    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
       "        2    0.000    0.000    0.000    0.000 config.py:439(__exit__)\n",
       "        2    0.000    0.000   50.344   25.172 transform.py:74(decode)\n",
       "        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
       "        7    0.000    0.000    0.000    0.000 dispatch.py:74(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 foundation.py:73(zip_cycle)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1911(create_block_manager_from_blocks)\n",
       "        5    0.000    0.000    0.000    0.000 common.py:297(is_null_slice)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "       10    0.000    0.000    0.000    0.000 construction.py:664(_sanitize_str_dtypes)\n",
       "        3    0.000    0.000    0.000    0.000 basics.py:376(<dictcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:6284(_maybe_cast_indexer)\n",
       "       50    0.000    0.000    0.000    0.000 inspect.py:2552(default)\n",
       "       21    0.000    0.000    0.000    0.000 flags.py:51(allows_duplicate_labels)\n",
       "        2    0.000    0.000    0.000    0.000 frame.py:10986(_reindex_for_setitem)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:1496(is_complex_dtype)\n",
       "        3    0.000    0.000    0.000    0.000 pretty.py:495(enq)\n",
       "        3    0.000    0.000    0.000    0.000 basics.py:319(anno_ret)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method numpy.seterrobj}\n",
       "        2    0.000    0.000   50.344   25.172 transform.py:207(decode)\n",
       "       10    0.000    0.000    0.000    0.000 frame.py:578(_constructor)\n",
       "       13    0.000    0.000    0.000    0.000 enum.py:792(value)\n",
       "        1    0.000    0.000    0.031    0.031 core.py:244(decodes)\n",
       "       14    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
       "       11    0.000    0.000    0.000    0.000 inspect.py:73(isclass)\n",
       "        6    0.000    0.000    0.000    0.000 managers.py:217(is_single_block)\n",
       "       30    0.000    0.000    0.000    0.000 foundation.py:108(_xtra)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:1722(from_blocks)\n",
       "        4    0.000    0.000    0.000    0.000 _collections_abc.py:362(__subclasshook__)\n",
       "       10    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
       "        8    0.000    0.000    0.000    0.000 indexing.py:804(_validate_key_length)\n",
       "        6    0.000    0.000    0.000    0.000 bunch.py:13(__getattr__)\n",
       "       19    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
       "        2    0.000    0.000    0.000    0.000 format.py:1970(should_trim)\n",
       "       11    0.000    0.000    0.000    0.000 formatters.py:272(_get_type)\n",
       "       11    0.000    0.000    0.000    0.000 format.py:1568(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 foundation.py:67(cycle)\n",
       "        2    0.000    0.000    0.000    0.000 threading.py:259(__exit__)\n",
       "        4    0.000    0.000    0.000    0.000 numeric.py:125(inferred_type)\n",
       "        1    0.000    0.000    0.001    0.001 format.py:1593(_format_strings)\n",
       "       12    0.000    0.000    0.000    0.000 inspect.py:2640(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'datetime.datetime' objects}\n",
       "        3    0.000    0.000    0.000    0.000 numerictypes.py:649(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 pretty.py:304(end_group)\n",
       "        3    0.000    0.000    0.000    0.000 managers.py:599(<listcomp>)\n",
       "       10    0.000    0.000    0.000    0.000 construction.py:684(_maybe_repeat)\n",
       "       13    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 html.py:377(_write_header)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis1_int32_int32}\n",
       "        1    0.000    0.000    0.051    0.051 fetch.py:24(fetch)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:182(x_names)\n",
       "        4    0.000    0.000    0.000    0.000 common.py:552(require_length_match)\n",
       "       24    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
       "        8    0.000    0.000    0.000    0.000 sre_parse.py:254(get)\n",
       "        8    0.000    0.000    0.000    0.000 base.py:518(<genexpr>)\n",
       "       12    0.000    0.000    0.000    0.000 indexing.py:745(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:2344(is_floating)\n",
       "        6    0.000    0.000    0.000    0.000 cast.py:1828(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:210(interleaved_dtype)\n",
       "        8    0.000    0.000    0.000    0.000 dispatch.py:71(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 range.py:347(dtype)\n",
       "        4    0.000    0.000    0.000    0.000 _methods.py:46(_sum)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:326(<listcomp>)\n",
       "        1    0.000    0.000    0.001    0.001 core.py:181(targ)\n",
       "       12    0.000    0.000    0.000    0.000 indexing.py:2497(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 _methods.py:60(_all)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:1992(_grouping_func)\n",
       "       11    0.000    0.000    0.000    0.000 formatters.py:357(_check_return)\n",
       "        2    0.000    0.000    0.000    0.000 foundation.py:138(__reversed__)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:4226(_wrap_reindex_result)\n",
       "        9    0.000    0.000    0.000    0.000 cast.py:1835(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis1_float32_float32}\n",
       "       16    0.000    0.000    0.000    0.000 base.py:229(disallow_kwargs)\n",
       "       15    0.000    0.000    0.000    0.000 base.py:1898(nlevels)\n",
       "        4    0.000    0.000    0.000    0.000 hmac.py:111(update)\n",
       "        9    0.000    0.000    0.000    0.000 base.py:540(_ensure_array)\n",
       "        1    0.000    0.000    0.000    0.000 foundation.py:180(map_zip)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:332(<listcomp>)\n",
       "        1    0.000    0.000    0.010    0.010 transform.py:113(__call__)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:1426(__init__)\n",
       "        7    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
       "        3    0.000    0.000    0.000    0.000 printing.py:62(justify)\n",
       "        1    0.000    0.000    0.000    0.000 torch_core.py:204(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:212(set_axis)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
       "        2    0.000    0.000    0.000    0.000 traitlets.py:1667(has_trait)\n",
       "       11    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:494(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
       "        8    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 pretty.py:313(flush)\n",
       "       30    0.000    0.000    0.000    0.000 format.py:1908(just)\n",
       "        3    0.000    0.000    0.000    0.000 pretty.py:417(_in_deferred_types)\n",
       "        2    0.000    0.000    0.000    0.000 config.py:434(<listcomp>)\n",
       "       17    0.000    0.000    0.000    0.000 base.py:326(ndim)\n",
       "        2    0.000    0.000    0.000    0.000 load.py:35(no_multiproc)\n",
       "        1    0.000    0.000    0.000    0.000 display.py:330(__repr__)\n",
       "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis1_int16_int16}\n",
       "        1    0.000    0.000    0.004    0.004 html.py:77(render)\n",
       "        5    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool_list}\n",
       "        1    0.000    0.000    0.000    0.000 formatters.py:952(__call__)\n",
       "        2    0.000    0.000    0.000    0.000 _collections_abc.py:381(__subclasshook__)\n",
       "        4    0.000    0.000    0.000    0.000 base.py:7046(ensure_has_len)\n",
       "        8    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 foundation.py:177(starmap)\n",
       "        4    0.000    0.000    0.000    0.000 config.py:619(_get_registered_option)\n",
       "        8    0.000    0.000    0.000    0.000 blocks.py:244(mgr_locs)\n",
       "        1    0.000    0.000    0.000    0.000 torch_core.py:262(to_cpu)\n",
       "        2    0.000    0.000    0.000    0.000 threading.py:265(_release_save)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:520(_next_index)\n",
       "        2    0.000    0.000    0.000    0.000 threading.py:268(_acquire_restore)\n",
       "        6    0.000    0.000    0.000    0.000 common.py:389(is_timedelta64_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'mro' of 'type' objects}\n",
       "        1    0.000    0.000    0.000    0.000 inspect.py:2873(replace)\n",
       "        3    0.000    0.000    0.000    0.000 apply.py:682(columns)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:1129(__call__)\n",
       "        2    0.000    0.000    0.000    0.000 threading.py:256(__enter__)\n",
       "        7    0.000    0.000    0.000    0.000 pretty.py:118(_safe_getattr)\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:159(isfunction)\n",
       "        1    0.000    0.000    0.031    0.031 core.py:174(decode)\n",
       "        1    0.000    0.000    0.000    0.000 session.py:846(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:785(truncate)\n",
       "        1    0.000    0.000   50.313   50.313 transform.py:114(decode)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:679(_initialize_justify)\n",
       "        7    0.000    0.000    0.000    0.000 basics.py:757(<genexpr>)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:2308(is_integer)\n",
       "        1    0.000    0.000    0.000    0.000 formatters.py:943(_check_return)\n",
       "        1    0.000    0.000    0.000    0.000 pretty.py:232(text)\n",
       "        7    0.000    0.000    0.000    0.000 threading.py:529(is_set)\n",
       "        1    0.000    0.000    0.000    0.000 hmac.py:147(hexdigest)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
       "        1    0.000    0.000    0.050    0.050 core.py:340(show_batch)\n",
       "        9    0.000    0.000    0.000    0.000 basics.py:764(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 frame.py:3883(_ensure_valid_index)\n",
       "        6    0.000    0.000    0.000    0.000 cast.py:1830(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:334(randint)\n",
       "        1    0.000    0.000    0.031    0.031 transform.py:98(_call)\n",
       "        2    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 html.py:88(should_show_dimensions)\n",
       "        4    0.000    0.000    0.000    0.000 series.py:523(_constructor)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:487(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:1438(_value_formatter)\n",
       "        2    0.000    0.000    0.000    0.000 pretty.py:184(group)\n",
       "        3    0.000    0.000    0.000    0.000 format.py:629(is_truncated_horizontally)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:45(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
       "        2    0.000    0.000    0.000    0.000 inspect.py:514(_is_wrapper)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
       "        1    0.000    0.000    0.000    0.000 html.py:92(show_row_idx_names)\n",
       "        2    0.000    0.000    0.000    0.000 base.py:890(__array__)\n",
       "        2    0.000    0.000    0.000    0.000 numeric.py:315(_is_comparable_dtype)\n",
       "        1    0.000    0.000    0.000    0.000 random.py:117(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 frame.py:821(shape)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:132(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 format.py:761(_is_in_terminal)\n",
       "        2    0.000    0.000    0.000    0.000 blocks.py:248(mgr_locs)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:649(show_row_idx_names)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:57(_validate_set_axis)\n",
       "        6    0.000    0.000    0.000    0.000 basics.py:306(<dictcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "        2    0.000    0.000    0.000    0.000 config.py:825(inner)\n",
       "        2    0.000    0.000    0.000    0.000 managers.py:1118(value_getitem)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:693(_initialize_colspace)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:220(<listcomp>)\n",
       "        6    0.000    0.000    0.000    0.000 numeric.py:331(_is_all_dates)\n",
       "        1    0.000    0.000    0.000    0.000 display.py:422(_repr_html_)\n",
       "        3    0.000    0.000    0.000    0.000 base.py:4027(is_int)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 common.py:603(get_cython_func)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
       "        1    0.000    0.000    0.000    0.000 format.py:717(_calc_max_cols_fitted)\n",
       "        1    0.000    0.000    0.000    0.000 html.py:66(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:287(<setcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:1615(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:728(_calc_max_rows_fitted)\n",
       "        1    0.000    0.000    0.000    0.000 core.py:146(__getitem__)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:685(_initialize_columns)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:3039(_get_reconciled_name_object)\n",
       "        3    0.000    0.000    0.000    0.000 numeric.py:2384(_array_equal_dispatcher)\n",
       "        4    0.000    0.000    0.000    0.000 function_base.py:4954(_delete_dispatcher)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
       "        7    0.000    0.000    0.000    0.000 base.py:6022(_is_comparable_dtype)\n",
       "        2    0.000    0.000    0.000    0.000 apply.py:938(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:661(_initialize_sparsify)\n",
       "        2    0.000    0.000    0.000    0.000 torch_core.py:255(_inner)\n",
       "        3    0.000    0.000    0.000    0.000 transform.py:164(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
       "        1    0.000    0.000    0.000    0.000 _methods.py:42(_amin)\n",
       "        2    0.000    0.000    0.000    0.000 pretty.py:512(remove)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
       "        4    0.000    0.000    0.000    0.000 contextlib.py:379(__enter__)\n",
       "        3    0.000    0.000    0.000    0.000 multiarray.py:148(concatenate)\n",
       "        2    0.000    0.000    0.000    0.000 blocks.py:306(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'splitlines' of 'str' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {method '__getitem__' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)\n",
       "        2    0.000    0.000    0.000    0.000 threading.py:271(_is_owned)\n",
       "        1    0.000    0.000    0.000    0.000 series.py:743(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 construction.py:486(<listcomp>)\n",
       "        2    0.000    0.000    0.000    0.000 html.py:73(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 base.py:3554(_assert_can_do_setop)\n",
       "        2    0.000    0.000    0.000    0.000 core.py:316(_maybe_expand)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
       "        2    0.000    0.000    0.000    0.000 range.py:372(inferred_type)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
       "        2    0.000    0.000    0.000    0.000 format.py:633(is_truncated_vertically)\n",
       "        3    0.000    0.000    0.000    0.000 numerictypes.py:650(<listcomp>)\n",
       "        3    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 base.py:3050(_validate_sort_keyword)\n",
       "        2    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
       "        1    0.000    0.000    0.000    0.000 apply.py:919(result_index)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:619(should_show_dimensions)\n",
       "        1    0.000    0.000    0.000    0.000 display.py:342(_data_and_metadata)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'append' of 'pandas._libs.internals.BlockPlacement' objects}\n",
       "        1    0.000    0.000    0.000    0.000 managers.py:222(items)\n",
       "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}\n",
       "        1    0.000    0.000    0.000    0.000 load.py:20(_fn_noops)\n",
       "        1    0.000    0.000    0.000    0.000 formatters.py:829(_check_return)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:512(__iter__)\n",
       "        1    0.000    0.000    0.000    0.000 <string>:1(before_iter)\n",
       "        1    0.000    0.000    0.000    0.000 format.py:747(_adjust_max_rows)\n",
       "        1    0.000    0.000    0.000    0.000 html.py:115(_get_columns_formatted_values)\n",
       "        1    0.000    0.000    0.000    0.000 api.py:221(<listcomp>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%prun\n",
    "dls_collab.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb9196-b20a-48f5-932c-1693cf0beb03",
   "metadata": {},
   "source": [
    "#### Train Collab Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5d8db-32fa-4dac-aa91-1e9fb9ae6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_tokens, n_labels, n_factors, y_range=None):\n",
    "        self.token_factors = Embedding(n_tokens, n_factors)\n",
    "        self.token_bias = Embedding(n_tokens, 1)\n",
    "        self.label_factors = Embedding(n_labels, n_factors)\n",
    "        self.label_bias = Embedding(n_labels, 1)\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        tokens = self.token_factors(xb[:, 0])\n",
    "        labels = self.label_factors(xb[:, 1])\n",
    "        res = (tokens * labels).sum(dim=1, keepdim=True)\n",
    "        res += self.token_bias(xb[:, 0]) + self.label_bias(xb[:, 1])\n",
    "        return sigmoid_range(res, *self.y_range) if self.y_range is not None else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f9d2e-ac6b-45e6-8758-3fadec974325",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = df_trn.token.nunique() #len(dls_collab.classes['token'])\n",
    "n_labels = df_trn.label.nunique() #len(dls_collab.classes['label'])\n",
    "model = DotProductBias(n_tokens=n_tokens, n_labels=n_labels, n_factors=400)\n",
    "learn = Learner(dls_collab, model, loss_func=MSELossFlat(), model_dir='models/collab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460838d-aa2e-4cca-a355-81ca48b158b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>49.450722</td>\n",
       "      <td>49.332771</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>48.932327</td>\n",
       "      <td>48.385563</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>45.917767</td>\n",
       "      <td>40.498795</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>30.768589</td>\n",
       "      <td>12.404538</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.441614</td>\n",
       "      <td>0.630063</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.197081</td>\n",
       "      <td>0.324881</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.143176</td>\n",
       "      <td>0.325300</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.584463</td>\n",
       "      <td>0.345507</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.427608</td>\n",
       "      <td>0.351228</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.371049</td>\n",
       "      <td>0.329182</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.317479</td>\n",
       "      <td>0.314663</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.303352</td>\n",
       "      <td>0.317572</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.286491</td>\n",
       "      <td>0.288059</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.274320</td>\n",
       "      <td>0.306007</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.241870</td>\n",
       "      <td>0.288163</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.204790</td>\n",
       "      <td>0.252116</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.172365</td>\n",
       "      <td>0.278202</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.146553</td>\n",
       "      <td>0.248570</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.114161</td>\n",
       "      <td>0.235778</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.092889</td>\n",
       "      <td>0.266751</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.081609</td>\n",
       "      <td>0.266181</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.068567</td>\n",
       "      <td>0.262004</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.062652</td>\n",
       "      <td>0.249275</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.058174</td>\n",
       "      <td>0.264907</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.050977</td>\n",
       "      <td>0.260137</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.268453</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.047202</td>\n",
       "      <td>0.265196</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.041795</td>\n",
       "      <td>0.246763</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.039031</td>\n",
       "      <td>0.249350</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.037531</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.035012</td>\n",
       "      <td>0.241679</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.029995</td>\n",
       "      <td>0.243315</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.023960</td>\n",
       "      <td>0.233536</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.021598</td>\n",
       "      <td>0.240069</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.019822</td>\n",
       "      <td>0.240565</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>0.238293</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.017127</td>\n",
       "      <td>0.233675</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>0.232295</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.229965</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.231601</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.227995</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.228086</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.225213</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>0.225983</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.225451</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.224476</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.224498</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.223441</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.223359</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.223097</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.223427</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.223560</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.222959</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.223420</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.223136</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.223324</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.223194</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.223297</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.223226</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.223231</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(60, 5e-3, wd=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f1d7a-d720-4509-9366-7ee6c87c786a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/collab/mimic3-9k_collab_tiny.pth')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save(collab_path_tiny.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072d8e4-3d05-4b04-9d92-bf024fc2f5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#1) [0.22323061525821686]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = learn.load(collab_path_tiny.stem)\n",
    "learn.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8937a3a4-5779-4b7a-9f69-c0d292ddd2eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311fd07-6250-4845-8f01-5a9ad590c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 400\n",
    "learn_collab = collab_learner(dls_collab, n_factors=n_factors, model_dir='models/collab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082d021-35bb-43ef-889f-d7e7734e5f40",
   "metadata": {},
   "source": [
    "#### Train (L2R) Learning to Rank Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d4277-0daf-4dd4-a5b3-6185f58c1eb6",
   "metadata": {},
   "source": [
    "### Bloodshed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aad4e5-08b9-49c0-947e-5e8ffee9269c",
   "metadata": {},
   "source": [
    "A little hack to circumvent custom pickle deserialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b5d64-4541-49b0-a46a-7ae5d0dfe27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.TrnDataLoader"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dataloader.py', 'r') as f: lines = f.readlines()\n",
    "exec(''.join(lines))\n",
    "TrnDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816053dd-a3aa-4010-91fe-3f97fc83d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dls_learn_rank = torch.load(dls_learn_rank_path, map_location=lambda storage, loc: storage.cuda(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5fa1c7-d97d-463d-bc8e-fdab5a1ab2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.84 ms, sys: 275 µs, total: 2.11 ms\n",
      "Wall time: 1.94 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dls = torch.load(dls_learn_rank_tiny_path)\n",
    "len(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773f817-5193-46ee-832f-332ddafbd5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dls = torch.load(dls_learn_rank_tiny_path)\n",
    "# len(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2ff77-3df8-4ac6-94fc-0b0bf106f997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.29 s, sys: 0 ns, total: 7.29 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(5):\n",
    "    for xb in dls.train: time.sleep(0.01)\n",
    "    for xb in dls.valid: time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a4e2d-28b0-44e4-bd85-f4a523d01880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(dls.train).__name__, dls.train.__class__.__name__\n",
    "# TrnDataLoader.mro(), TrnDataLoader.__mro__\n",
    "# inspect.getmro(TrnDataLoader)\n",
    "# import fastai\n",
    "# %ls {fastai.__path__[0]}\n",
    "# coll_repr(object.__subclasses__(), max_n = 20)\n",
    "# dict.__module__\n",
    "# sys.modules['fastai']\n",
    "# L(pkgutil.iter_modules(fastai.__path__))[8]\n",
    "# inspect.getmembers(fastai)[8]\n",
    "# inspect.ismodule(fastai.data.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7aa34a-9489-4c3d-8772-7f8da1bdb4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([8, 4, 64, 4])\n",
      "    xb.device: device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "xb = dls.train.one_batch()\n",
    "ic(xb.shape, xb.device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8c4bc-c043-4214-9c53-88453f007428",
   "metadata": {},
   "source": [
    "**The L2R Models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b4183-8d88-4d0e-8db7-a7aad6736d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class L2R_DotProductBias(nn.Module):\n",
    "    def __init__(self, num_lbs, num_toks, num_factors, y_range=None):\n",
    "        super().__init__()\n",
    "        self.num_toks, self.num_lbs = num_toks+1, num_lbs+1 # +1 for the `padding_idx` \n",
    "        self.token_factors = nn.Embedding(self.num_toks, num_factors, padding_idx=-1)\n",
    "        self.token_bias = nn.Embedding(self.num_toks, 1, padding_idx=-1)\n",
    "        self.label_factors = nn.Embedding(self.num_lbs, num_factors, padding_idx=-1)\n",
    "        self.label_bias = nn.Embedding(self.num_lbs, 1, padding_idx=-1)\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        xb_toks = xb[:, :, :, 0].long() # xb[...,0] # shape (64, 2233, 64)\n",
    "        xb_lbs = torch.unique(xb[:, :, :, 1], dim=-1).flatten(start_dim=1).long() # shape (64, 2233, )\n",
    "        # To convert -1 which is the padding index to the last index:\n",
    "        xb_toks, xb_lbs= xb_toks%(num_toks+1), xb_lbs%(num_lbs+1)\n",
    "        \n",
    "        toks_embs = self.token_factors(xb_toks) # shape (64, 2233, 64, 400)\n",
    "        toks_shape = toks_embs.shape\n",
    "        toks_embs = toks_embs.view(-1, *toks_shape[2:]) # shape (64*2233, 64, 400)\n",
    "\n",
    "        lbs_embs = self.label_factors(xb_lbs) # shape (64, 2233, 400)\n",
    "        lbs_shape = lbs_embs.shape\n",
    "        lbs_embs = lbs_embs.view(-1, *lbs_shape[2:]).unsqueeze(dim=-1) # shape (64*2233, 400, 1)\n",
    "        \n",
    "        res = torch.bmm(toks_embs, lbs_embs) # shape (64*2233, 64, 1)\n",
    "        # res = torch.matmul(toks_embs, lbs_embs)\n",
    "        res = res.view(toks_shape[0], toks_shape[1], *res.shape[1:]) + self.token_bias(xb_toks) + self.label_bias(xb_lbs).unsqueeze(2) # shape (64, 2233, 64, 1)\n",
    "        \n",
    "        return sigmoid_range(res, *self.y_range) if self.y_range is not None else res\n",
    "        # return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48df0a-d92e-4442-bdac-c2e7a553ea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class L2R_NN(nn.Module):\n",
    "    def __init__(self, num_lbs, num_toks, num_factors, n_act = 200, y_range=None):\n",
    "        super().__init__()\n",
    "        self.num_toks, self.num_lbs = num_toks+1, num_lbs+1 # +1 for the `padding_idx` \n",
    "        self.token_factors = nn.Embedding(self.num_toks, num_factors, padding_idx=-1)\n",
    "        self.label_factors = nn.Embedding(self.num_lbs, num_factors, padding_idx=-1)\n",
    "        self.y_range = y_range\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(num_factors*2, n_act),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_act, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        xb_toks = xb[:, :, :, 0].long() # xb[...,0] # shape (64, 2233, 64)\n",
    "        xb_lbs = torch.unique(xb[:, :, :, 1], dim=-1).flatten(start_dim=1).long() # shape (64, 2233, )\n",
    "        # To convert -1 which is the padding index to the last index:\n",
    "        xb_toks, xb_lbs= xb_toks%(num_toks+1), xb_lbs%(num_lbs+1)\n",
    "        \n",
    "        toks_embs = self.token_factors(xb_toks) # shape (64, 2233, 64, 200)\n",
    "\n",
    "        lbs_embs = self.label_factors(xb_lbs) # shape (64, 2233, 200)\n",
    "        lbs_embs = lbs_embs.unsqueeze(2) # shape (64, 2233, 1, 200)\n",
    "        lbs_embs = lbs_embs.expand(-1, -1, xb.shape[2], -1)\n",
    "        \n",
    "        embs = torch.cat((toks_embs, lbs_embs), dim=-1) # shape (64, 2233, 64, 400)\n",
    "        res = self.layers(embs)\n",
    "        \n",
    "        return sigmoid_range(res, *self.y_range) if self.y_range is not None else res\n",
    "        # return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b832c2-5480-41dc-b529-1e47bf483672",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.parameters()\n",
    "dev_gen = (p.device for p in params)\n",
    "L(dev_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6230da1-80d8-4825-8cfb-64403f89d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_factors, token_bias, label_factors, label_bias = map(partial(to_device, device=torch.device(\"cpu\")), model.parameters())\n",
    "# L(map(Tensor.size, (token_factors, token_bias, label_factors, label_bias)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1d137-e6bc-4fb3-be64-8e1729aced5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb_toks.shape: torch.Size([64, 2242, 48])\n",
      "    xb_toks.device: device(type='cuda', index=0)\n",
      "ic| xb_lbs.shape: torch.Size([64, 2242])\n"
     ]
    }
   ],
   "source": [
    "xb_toks = xb[:, :, :, 0].long() # xb[...,0]\n",
    "ic(xb_toks.shape, xb_toks.device);\n",
    "xb_lbs = torch.unique(xb[:, :, :, 1], dim=-1).flatten(start_dim=1).long()\n",
    "ic(xb_lbs.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a5f3a-1575-418d-a9d5-ee574749d017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(xb_lbs[56, 890:1050], torch.unique(xb[56, 890:1050, :, 1], dim=-1).squeeze())\n",
    "torch.equal(torch.unique(xb_toks, dim=-1, sorted=False), xb_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cdc2eb-9f40-46b3-8c61-b6c4e8f3e433",
   "metadata": {},
   "source": [
    "To convert -1 to the last index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900dadbc-06f1-4d0f-9a70-2fe2dbef6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb_toks = xb_toks % (num_toks+1)\n",
    "xb_lbs = xb_lbs % (num_lbs+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077baa38-c617-4ef9-a03e-eb63d25615d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| toks_embs.shape: torch.Size([64, 2242, 48, 400])\n",
      "ic| toks_embs.shape: torch.Size([143488, 48, 400])\n"
     ]
    }
   ],
   "source": [
    "toks_embs = model.token_factors(xb_toks)\n",
    "ic(toks_embs.shape);\n",
    "toks_shape = toks_embs.shape\n",
    "toks_embs = toks_embs.view(-1, *toks_shape[2:])\n",
    "ic(toks_embs.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec1ed6-6450-49eb-ac6d-49457a7cca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| lbs_embs.shape: torch.Size([64, 2242, 400])\n",
      "ic| lbs_embs.shape: torch.Size([143488, 400])\n"
     ]
    }
   ],
   "source": [
    "lbs_embs = model.label_factors(xb_lbs)\n",
    "ic(lbs_embs.shape);\n",
    "lbs_shape = lbs_embs.shape\n",
    "lbs_embs = lbs_embs.view(-1, *lbs_shape[2:])\n",
    "ic(lbs_embs.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff85b1-e75a-4e14-bcb3-04eb26df0931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| lbs_embs.shape: torch.Size([143488, 400, 1])\n"
     ]
    }
   ],
   "source": [
    "lbs_embs = lbs_embs.unsqueeze(dim=-1)\n",
    "ic(lbs_embs.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c46541-758b-4d85-8616-c16427d1900d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [(torch.Size([143488, 400, 1]), device(type='cuda', index=0)),(torch.Size([143488, 48, 400]), device(type='cuda', index=0))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(lbs_embs, toks_embs).map(lambda t: (t.shape, t.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b375e09-0763-453a-ab5b-ea32e78f2e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.bmm(toks_embs, lbs_embs)\n",
    "# res = torch.matmul(toks_embs, lbs_embs)\n",
    "\n",
    "res = res.view(toks_shape[0], toks_shape[1], *res.shape[1:])\n",
    "ic(res.shape);\n",
    "\n",
    "res = res + model.token_bias(xb_toks) + model.label_bias(xb_lbs).unsqueeze(2)\n",
    "ic(res.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606eb0d4-8264-4014-b161-013749629f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb_iter = iter(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a1f1f-e174-41c3-8036-fff4457f810c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([32, 2231, 64, 4])\n",
      "    xb.device: device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "xb = next(xb_iter)\n",
    "ic(xb.shape, xb.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b33ab-979c-44ec-ae1b-1f405dbc608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| preds.shape: torch.Size([32, 2231, 64, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2231, 64, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rank_model(xb)\n",
    "ic(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cfc7ee-b6c6-4fcd-882c-76559876ea13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| preds.shape: torch.Size([32, 2231, 64, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2231, 64, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rank_model_NN(xb)\n",
    "ic(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644bcecc-4827-461d-abef-13f5ba797b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='113' class='' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [113/113 01:05&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([32, 2231, 64, 4]), preds.shape = torch.Size([32, 2231, 64, 1])\n",
      "xb.shape =torch.Size([4, 2231, 64, 4]), preds.shape = torch.Size([4, 2231, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "for xb in progress_bar(dls.train):\n",
    "    preds = rank_model(xb)\n",
    "    print(f\"{xb.shape =}, {preds.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b446c-36c8-4311-aaf8-cd7dadcc480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.shape =torch.Size([1, 8922, 32, 4]), preds.shape = torch.Size([1, 8922, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "for xb in dls.valid:\n",
    "    preds = rank_model(xb)\n",
    "    print(f\"{xb.shape =}, {preds.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb28dd8-2e4d-43f5-a3eb-d3427eb51bfd",
   "metadata": {},
   "source": [
    "The following notations are borrowed from [From RankNet to LambdaRank to LambdaMART: An Overview](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf)\n",
    "\n",
    "\n",
    "Let $I$ denote the pair of indices $\\{i, j\\}$, for which we desire token_i to be ranked differently from token_j (for a given label group). Since we must include each pair just once, so it is convenient to consider pairs of indices $\\{i, j\\}$ for which token_i is more relevant than token_j.\n",
    "\n",
    "$$\\lambda_{ij} = \\sigma \\left\\{ \\frac{1}{2}(1 - S_{ij}) - \\frac{1}{1+e^{ \\sigma(p_i - p_j)}} \\right\\}  \\textsf{  Eq: 3},$$ where $\\sigma$ is a hyper-parameter which controls the shape of the sigmoid and $p_i, p_j$ are predictions made by the model for token_i and token_j respectively, and\n",
    "\n",
    "$$S_{ij} = \\begin{cases} \n",
    "                1, & \\text{if token_i is more relevant} \\\\ \n",
    "                0, & \\text{if token_i is as relevant as token_j} \\\\\n",
    "                -1, & \\text{if token_j is ore relevant} \n",
    "            \\end{cases}$$\n",
    "\n",
    "The weight update rule in gradient descent is given by:\n",
    "$$\\delta w_k = \\eta \\sum_{\\{i,j\\} \\in I} (\\lambda_{ij} \\frac{\\partial p_i}{\\partial w_k} - \\lambda_{ij} \\frac{\\partial p_j}{\\partial w_k}) = -\\eta \\sum_i \\lambda_i \\frac{\\partial p_i}{\\partial w_k},$$ where\n",
    "\n",
    "$$\\lambda_i = \\sum_{j: \\{i,j\\} \\in I} \\lambda_{ij} - \\sum_{j: \\{j,i\\} \\in I} \\lambda_{ji} \\textsf{  Eq: 4}.$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd50279-279e-4567-b773-cc670cbe8a06",
   "metadata": {},
   "source": [
    "**Implementing the above equations:**\n",
    "\n",
    "(Handcrfted Gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcffa15-dc36-41ce-9c69-b2958255ee4f",
   "metadata": {},
   "source": [
    "We can think of the tensor returned by `_summation` as essentially the summation notation in eq:4 above. It has three dimension. The length of the zeroth dim is the number of tokens. And each token contains a 2d tensor. For each token the zeroth and the first dim of 2d tensor has the following interpretation.\n",
    "\n",
    "For each token in a sequence (i.e. the i's) it contains the information about the other tokens (i.e. the j's) that  \n",
    "1. The first column value tells us the row num we got to index in the pairs array.\n",
    "2. The last column value tells us whether i is more relevant or less relevant than j. In other words, it determines the sign while computing $\\lambda_i$ in eq: 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e508170-ec11-45a7-8807-f64f4a0b117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_loss(preds, xb):\n",
    "    eps = preds.new_empty(1).fill_(1e-15)\n",
    "    ideal_rank = xb[:, :, :, -1].argsort(dim=-1, descending=True).argsort(dim=-1) # ranking by the scores, highest score gets rank 0\n",
    "    ideal_discnt_fac = torch.log2(ideal_rank+2)\n",
    "    ideal_discntd_gain = (torch.pow(2, xb[:, :, :, -1]) - 1)  / (ideal_discnt_fac + eps)\n",
    "    idcg = ideal_discntd_gain.sum(dim=-1)\n",
    "    \n",
    "    # Sort the tokens by the relevance scores so that we can compute the set $I$ defined above:\n",
    "    srtd_relvs, srtd_idxs = xb[:,:,:,-1].sort(descending=True)\n",
    "    srtd_toks  = torch.take_along_dim(xb[:, :, :, 0], srtd_idxs, dim=-1)\n",
    "    # srtd_ranks = torch.take_along_dim(xb[:,:,:,-2], srtd_idxs, dim=-1) # pulling out the original ranks from the dataset\n",
    "    srtd_ranks = torch.take_along_dim(ideal_rank, srtd_idxs, dim=-1) # pulling out the ranking by scores for this batch \n",
    "    srtd_preds = torch.take_along_dim(preds[:, :, :, 0], srtd_idxs, dim=-1)\n",
    "    # srtd_preds = preds[:, :, :, 0].take_along_dim(srtd_idxs, dim=-1)\n",
    "    \n",
    "    # In the following `ij` is essentially the set $I$\n",
    "    sl = xb.shape[2]\n",
    "    ij = torch.as_tensor(np.fromiter(itertools.combinations(np.arange(sl), 2), dtype=np.dtype((int,2))),\n",
    "                                device=xb.device)#.expand(xb.shape[0], xb.shape[1], -1, -1)\n",
    "    \n",
    "    toki_tokj = srtd_toks[:, :, ij] # these are the i,j token indices - i more relevant thatn j  \n",
    "    pi_pj = srtd_preds[:, :, ij] # these are p_i and p_j \n",
    "    si_sj = srtd_relvs[:, :, ij] # these are the relevance scores for token_i and token_j\n",
    "    ri_rj = srtd_ranks[:, :, ij] # these are the ranks for token_i and token_j\n",
    "    max_rank = ri_rj.max(); ri_rj = ri_rj % (max_rank + 2) # convert any -1s from padding to highest rank\n",
    "    dfi_dfj = 1 / torch.log2(ri_rj + 2)\n",
    "    \n",
    "    # `sigma` is from eq:3 to compute $\\lambda_{ij}$\n",
    "    sigma = 0.5\n",
    "    si, sj= si_sj[:, :, :, 0], si_sj[:, :, :, 1]\n",
    "    signs = torch.sign(si - sj)\n",
    "    pow_si, pow_sj = torch.pow(2, si), torch.pow(2, sj)\n",
    "    delta_dcg = torch.abs((pow_si - pow_sj) * (dfi_dfj[:,:,:,0] - dfi_dfj[:,:,:,1]))\n",
    "    delta_ndcg = delta_dcg / idcg.unsqueeze(-1)\n",
    "    \n",
    "    pi, pj = pi_pj[:, :, :, 0], pi_pj[:, :, :, 1]\n",
    "    exp_ij = torch.exp(sigma * (pi - pj))\n",
    "    lambda_ij = sigma * (  0.5 * (1 - signs) -  1/(1 + exp_ij) )\n",
    "    # lambda_ij = sigma * (  0.5 * (1 - signs) -  torch.sigmoid(pj-pi) )\n",
    "    \n",
    "    # lambda_ij = lambda_ij * delta_ndcg # use this for Lambda-Rank\n",
    "    \n",
    "    # from IPython import embed; embed()\n",
    "    \n",
    "    sumer = _summation(sl, ij)\n",
    "    idxr, signs = sumer[:, :, 0], sumer[:, :, -1]\n",
    "    # Now we can compute $\\lambda_i$ from eq: 4,\n",
    "    lambda_i = (lambda_ij[:, :, idxr] * signs).sum(dim=-1)\n",
    "    \n",
    "    return srtd_preds, lambda_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad996485-9aeb-43f6-8614-98644c1d9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _summation(sl, ij):\n",
    "    sumer = []\n",
    "    for i in range(sl):\n",
    "        _x = torch.nonzero(ij == i, as_tuple=False)\n",
    "        _x[:, -1] = torch.pow(-1, _x[:, 1])\n",
    "        sumer.append(_x)\n",
    "    return torch.stack(sumer, dim=0)\n",
    "\n",
    "def _idcg(xb, k=None, gain_fn=None):\n",
    "    # pdb.set_trace()\n",
    "    x = xb[:, :, :, -1]\n",
    "    ranks = x.argsort(dim=-1, descending=True).argsort(dim=-1) # ranking by the scores, highest score gets rank 0\n",
    "    dfs = 1/torch.log2(ranks + 2)\n",
    "    gains = torch.pow(2, x) if gain_fn == 'exp' else torch.pow(x, 3)\n",
    "    idg = gains * dfs\n",
    "    idcg = idg.sum(dim=-1)\n",
    "    \n",
    "    idcg_at_k = None\n",
    "    if k is not None:\n",
    "        topk, topk_idxs = torch.topk(x, k=k, dim=-1, largest=True)\n",
    "        # topk_relvs = torch.take_along_dim(x, topk_idxs, dim=-1)\n",
    "        dfs_at_k = 1/torch.log2(2 + torch.arange(k)).cuda()\n",
    "        gains_at_k = torch.pow(2, topk) if gain_fn == 'exp' else torch.pow(topk, 3)\n",
    "        idg_at_k = gains_at_k * dfs_at_k\n",
    "        idcg_at_k = idg_at_k.sum(-1)\n",
    "    \n",
    "    return idcg, idcg_at_k\n",
    "\n",
    "def rank_loss2(preds, xb, sigma=0.5, lambrank=False, gain_fn=None):\n",
    "    # In the following `ij` is essentially the set $I$\n",
    "    sl = xb.shape[2]\n",
    "    ij = torch.as_tensor(np.fromiter(itertools.combinations(np.arange(sl), 2), dtype=np.dtype((int,2))),\n",
    "                                device=xb.device)#.expand(xb.shape[0], xb.shape[1], -1, -1)\n",
    "    \n",
    "    # Sort the tokens by the model prediction scores so that we can compute the set $I$ defined above:\n",
    "    srtd_preds, srtd_idxs = preds[:, :, :,  0].sort(descending=True)\n",
    "    \n",
    "    srtd_ranks = srtd_preds.new_empty(srtd_preds.size())#srtd_idxs.argsort()\n",
    "    srtd_ranks[:,:] = torch.arange(preds.shape[2])\n",
    "    ri_rj = srtd_ranks[:, :, ij] # these are the ranks for token_i and token_j\n",
    "    dfi_dfj = 1.0 / torch.log2(ri_rj + 2)\n",
    "    dfi = dfi_dfj[:,:,:,0]\n",
    "    dfj = dfi_dfj[:,:,:,1]\n",
    "        \n",
    "    srtd_relvs = torch.take_along_dim(xb[:, :, :, -1], srtd_idxs, dim=-1)\n",
    "    pi_pj = srtd_preds[:, :, ij] # these are p_i and p_j \n",
    "    pi, pj = pi_pj[:, :, :, 0], pi_pj[:, :, :, 1]\n",
    "    exp_ij = torch.exp(sigma * (pi - pj))\n",
    "    si_sj = srtd_relvs[:, :, ij] # these are the relevance scores for token_i and token_j\n",
    "    si, sj= si_sj[:, :, :, 0], si_sj[:, :, :, 1]\n",
    "    gain_i, gain_j = ( torch.pow(2.0, si), torch.pow(2.0, sj) ) if gain_fn == 'exp' else ( torch.pow(si, 3.0), torch.pow(sj, 3.0) ) # cubic\n",
    "    signs = torch.sign(si - sj)\n",
    "    delta_dcg = torch.abs((gain_i - gain_j) * (dfi - dfj))\n",
    "    idcg, idcg_at_k = _idcg(xb, k=6, gain_fn=gain_fn)\n",
    "    delta_ndcg_at_k = delta_dcg / idcg_at_k.unsqueeze(-1)\n",
    "    \n",
    "    lambda_ij = sigma * (  0.5 * (1 - signs) -  1/(1 + exp_ij) )\n",
    "    if lambrank: lambda_ij *= delta_ndcg_at_k # use this for Lambda-Rank\n",
    "    \n",
    "    sumer = _summation(sl, ij)\n",
    "    idxr, signs = sumer[:, :, 0], sumer[:, :, -1]\n",
    "    # Now we can compute $\\lambda_i$ from eq: 4,\n",
    "    lambda_i = (lambda_ij[:, :, idxr] * signs).sum(dim=-1)\n",
    "    \n",
    "    return srtd_preds, lambda_i\n",
    "\n",
    "def rank_loss3(preds, xb, sigma=0.5, lambrank=False, gain_fn=None):\n",
    "    with torch.no_grad():\n",
    "        # pdb.set_trace()\n",
    "        x = xb[:, :, :, -1, None]\n",
    "        x_t = xb[:, :, :, -1, None].transpose(-1,-2)\n",
    "        preds_t = preds.transpose(-1,-2)\n",
    "        preds_rank = preds[:, :, :, 0].argsort(dim=-1, descending=True).argsort(dim=-1).unsqueeze(-1)\n",
    "        preds_rank_t = preds_rank.transpose(-1,-2)\n",
    "        \n",
    "        exp_ij= 1.0 + torch.exp(sigma* (preds - preds_t))\n",
    "        rel_diff = x - x_t\n",
    "        gain_diff = torch.pow(2.0, x) - torch.pow(2.0, x_t) if gain_fn == 'exp' else torch.pow(x, 3.0) - torch.pow(x_t, 3.0)\n",
    "        decay_diff = 1.0/torch.log2(preds_rank + 2.0) - 1.0/torch.log2(preds_rank_t  + 2.0)\n",
    "        idcg, idcg_at_k = _idcg(xb, k=6, gain_fn=gain_fn)\n",
    "        idcg_at_k = idcg_at_k[..., None, None]\n",
    "        # pdb.set_trace()\n",
    "        delta_ndcg_at_k = torch.abs(gain_diff * decay_diff * 1/idcg_at_k)\n",
    "        pos_pairs = (rel_diff > 0).float()\n",
    "        neg_pairs = (rel_diff < 0).float()\n",
    "        S_ij = pos_pairs - neg_pairs\n",
    "        lambda_update = sigma * (  0.5 * (1 - S_ij) -  1/exp_ij )\n",
    "        if lambrank: lambda_update *= delta_ndcg_at_k \n",
    "        lambda_update = lambda_update.sum(dim=-1, keepdim=True)\n",
    "    return preds, lambda_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad8923-adde-4e30-ae82-23f0f8b1f9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([32, 2231, 64, 4])\n",
      "    preds.shape: torch.Size([32, 2231, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "xb = dls.one_batch()\n",
    "preds = model(xb)\n",
    "ic(xb.shape, preds.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cd38e-6cde-4d28-b23a-ed0a08e8813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,xb in enumerate(dls.train):\n",
    "    print(i, xb.shape)\n",
    "    bd[i] =  xb[:, :, :, 0].view(-1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2c7cd-265c-4d9d-a9ac-4af8e366395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(profile=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181defb9-1f0d-4745-adad-f7c4bfe24a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(x.shape[0]):\n",
    "    for j in range(x.shape[1]):\n",
    "        print(f\"{x[i,j].cpu().numpy() = }\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74fb8b-6ec8-45fd-96c1-c955e9becc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27., 27., 21., 21., 21., 21., 18., 18., 18., 18., 18., 18., 18., 18., 18., 18., 17., 17., 16., 14., 14., 13., 13., 13., 13., 13., 12., 12., 12., 11., 10., 10., 10., 10.,  9.,  9.,  9.,  8.,\n",
       "         6.,  5.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  3.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[:,:,:,-1][0,3].sort(descending=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4514c-4dd0-4baf-8682-e5fd6c5aec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "btch_lbl = (6,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26edd1-9ed6-467d-bfc2-01c15e205283",
   "metadata": {},
   "source": [
    "These are the relevances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc821c-6723-4b81-8932-06edc2032873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([43., 32., 30., 30., 29., 27., 26., 26., 25., 22., 21., 20., 18., 18., 16., 15., 15., 14., 13., 13., 13., 13., 11., 11., 10., 10., 10.,  9.,  9.,  9.,  9.,  8.,  8.,  8.,  7.,  6.,  6.,  6.,\n",
       "         6.,  6.,  5.,  5.,  5.,  5.,  4.,  4.,  4.,  4.,  4.,  3.,  3.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relvs = xb[btch_lbl][:, -1].sort(descending=True).values\n",
    "relvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b23959-2aa4-4f5d-90af-bd077355dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, lambda_update = rank_loss3(preds, xb, lambrank=True, gain_fn='exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831480c1-674b-4801-80f9-fbab0daf79d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 2231, 64, 1]), torch.Size([32, 2231, 64, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, lambda_update.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ecbcb8-ca64-487e-be6e-76b037d150ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, idxs = preds[:, :, :, -1].sort(dim=-1, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715cb68-6dd9-4c38-9cce-62a7c56a5564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.6919e+01,  1.7313e+01,  1.5528e+01,  1.3897e+01,  1.3603e+01,  1.3230e+01,  1.2256e+01,  1.2162e+01,  1.1968e+01,  1.1541e+01,  1.0806e+01,  8.7038e+00,  8.1869e+00,  8.1249e+00,\n",
       "         7.4311e+00,  6.8465e+00,  5.5709e+00,  5.3884e+00,  5.3050e+00,  4.5804e+00,  3.9161e+00,  2.8923e+00,  2.8743e+00,  2.6756e+00,  2.6228e+00,  2.5613e+00,  2.5344e+00,  1.2879e+00,\n",
       "         7.9447e-01,  7.5437e-01,  7.4869e-01,  7.1853e-01,  6.0639e-01,  4.7160e-02,  1.0306e-02, -3.7450e-01, -1.2874e+00, -2.3287e+00, -2.5765e+00, -3.3385e+00, -3.6131e+00, -3.9631e+00,\n",
       "        -4.2888e+00, -4.5948e+00, -4.8598e+00, -5.0398e+00, -5.3674e+00, -5.6183e+00, -5.8409e+00, -7.0450e+00, -7.4644e+00, -7.6236e+00, -8.0989e+00, -8.5302e+00, -8.5709e+00, -9.1744e+00,\n",
       "        -9.4538e+00, -1.0686e+01, -1.3591e+01, -1.4217e+01, -1.4981e+01, -1.5726e+01, -1.6596e+01, -1.9282e+01], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[btch_lbl].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213a6c0-6658-43d6-bb1a-e74a24343108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.7216e-01,  1.8570e-01,  1.1915e-01,  8.2802e-02,  6.1525e-02,  4.6548e-02,  3.4320e-02,  2.6303e-02,  1.9694e-02,  1.4048e-02,  9.1416e-03,  4.1144e-03,  1.7195e-03, -1.0041e+00,\n",
       "         1.2586e-03,  1.9755e-03,  1.7810e-03,  2.1037e-03,  2.2783e-03,  2.0710e-03,  1.7387e-03,  1.2027e-03,  1.2919e-03,  1.2627e-03,  1.3090e-03,  1.3423e-03,  1.3909e-03,  8.0485e-04,\n",
       "         6.6036e-04,  6.7093e-04,  6.9112e-04,  7.0177e-04,  6.8337e-04,  5.3464e-04,  5.3772e-04,  4.5585e-04,  2.9819e-04,  1.8305e-04,  1.6503e-04,  1.1513e-04,  1.0289e-04,  6.1926e-05,\n",
       "        -1.4166e-04,  6.6397e-05,  5.9048e-05,  5.4659e-05,  4.7077e-05,  2.8312e-05,  3.8010e-05,  2.1393e-05,  1.7522e-05,  1.6259e-05,  1.2917e-05,  1.0459e-05,  1.0233e-05,  7.5760e-06,\n",
       "        -1.0269e-03,  3.6402e-06,  8.8572e-07,  6.6940e-07,  4.7333e-07,  3.2430e-07,  2.2206e-07, -7.8613e-06], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "their_lambdas = torch.take_along_dim(lambda_update[:, :, :, 0], idxs, dim=-1)\n",
    "their_lambdas[btch_lbl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a1812-8ad9-4276-a0d2-61dd11023c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.5670e-10, device='cuda:0'), tensor(0.1386, device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std = their_lambdas[btch_lbl].mean(), their_lambdas[btch_lbl].std()\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef2824-4d3f-467a-9543-6415d0eaa84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8429e-08, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "their_lambdas[btch_lbl].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96fbc67-a91c-450b-b462-edfe8ee73dbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d6489-df09-41e1-a558-926c73484a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "srtd_preds, my_lambdas = rank_loss2(preds, xb, lambrank=True, gain_fn='exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76e027-e16f-44bc-82d7-836949c003d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 2231, 64]), torch.Size([32, 2231, 64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srtd_preds.shape, my_lambdas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2dab0e-173b-4fcf-9a9e-4549d4de6ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.6919e+01,  1.7313e+01,  1.5528e+01,  1.3897e+01,  1.3603e+01,  1.3230e+01,  1.2256e+01,  1.2162e+01,  1.1968e+01,  1.1541e+01,  1.0806e+01,  8.7038e+00,  8.1869e+00,  8.1249e+00,\n",
       "         7.4311e+00,  6.8465e+00,  5.5709e+00,  5.3884e+00,  5.3050e+00,  4.5804e+00,  3.9161e+00,  2.8923e+00,  2.8743e+00,  2.6756e+00,  2.6228e+00,  2.5613e+00,  2.5344e+00,  1.2879e+00,\n",
       "         7.9447e-01,  7.5437e-01,  7.4869e-01,  7.1853e-01,  6.0639e-01,  4.7160e-02,  1.0306e-02, -3.7450e-01, -1.2874e+00, -2.3287e+00, -2.5765e+00, -3.3385e+00, -3.6131e+00, -3.9631e+00,\n",
       "        -4.2888e+00, -4.5948e+00, -4.8598e+00, -5.0398e+00, -5.3674e+00, -5.6183e+00, -5.8409e+00, -7.0450e+00, -7.4644e+00, -7.6236e+00, -8.0989e+00, -8.5302e+00, -8.5709e+00, -9.1744e+00,\n",
       "        -9.4538e+00, -1.0686e+01, -1.3591e+01, -1.4217e+01, -1.4981e+01, -1.5726e+01, -1.6596e+01, -1.9282e+01], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srtd_preds[btch_lbl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab6c50-7104-4ed1-ad86-44a565cdd3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.7216e-01,  1.8570e-01,  1.1915e-01,  8.2802e-02,  6.1525e-02,  4.6548e-02,  3.4320e-02,  2.6303e-02,  1.9694e-02,  1.4048e-02,  9.1416e-03,  4.1144e-03,  1.7195e-03, -1.0041e+00,\n",
       "         1.2586e-03,  1.9755e-03,  1.7810e-03,  2.1037e-03,  2.2783e-03,  2.0710e-03,  1.7387e-03,  1.2027e-03,  1.2919e-03,  1.2627e-03,  1.3090e-03,  1.3423e-03,  1.3909e-03,  8.0485e-04,\n",
       "         6.6036e-04,  6.7093e-04,  6.9112e-04,  7.0177e-04,  6.8337e-04,  5.3464e-04,  5.3772e-04,  4.5585e-04,  2.9819e-04,  1.8305e-04,  1.6503e-04,  1.1513e-04,  1.0289e-04,  6.1924e-05,\n",
       "        -1.4166e-04,  6.6396e-05,  5.9049e-05,  5.4658e-05,  4.7076e-05,  2.8314e-05,  3.8009e-05,  2.1391e-05,  1.7525e-05,  1.6259e-05,  1.2919e-05,  1.0459e-05,  1.0234e-05,  7.5749e-06,\n",
       "        -1.0269e-03,  3.6403e-06,  8.8820e-07,  6.6970e-07,  4.7114e-07,  3.2185e-07,  2.2176e-07, -7.8592e-06], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_lambdas[btch_lbl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7462b00-d0c6-4118-9212-ace34107cc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6.9849e-10, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(0.1386, device='cuda:0', grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = my_lambdas[btch_lbl].mean()\n",
    "std = my_lambdas[btch_lbl].std()\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96897097-4dd4-4fc2-857b-8c59d79bba57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.7684e-07, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs = torch.abs(their_lambdas-my_lambdas).max()\n",
    "abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334757d-e502-4eaa-ba4a-f4b2db5e0e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(their_lambdas, my_lambdas, atol=float(abs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb30c6-db1f-48cc-b5a1-61b1e8b0e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, ik = _idcg(xb, k=6, gain_fn='exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b33d9d-7923-4db2-9908-7e0f7eaf6a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2231])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ik.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd5b5c-ee5a-49c3-a62c-2c2aacbd3f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1259e+15, 5.6090e+11, 5.5252e+11,  ..., 1.8014e+16, 1.1806e+21, 1.5112e+23],\n",
       "        [9.4447e+21, 5.6090e+11, 2.8148e+14,  ..., 2.2213e+12, 2.2030e+12, 2.2213e+12],\n",
       "        [1.1529e+18, 1.1215e+12, 1.1215e+12,  ..., 1.1215e+12, 4.4031e+12, 1.8020e+16],\n",
       "        ...,\n",
       "        [1.1529e+18, 2.3697e+16, 2.0404e+13,  ..., 9.2617e+13, 4.6324e+13, 8.1517e+13],\n",
       "        [9.6715e+24, 4.6316e+13, 2.3174e+13,  ..., 1.4412e+17, 3.2595e+14, 3.7042e+14],\n",
       "        [2.3612e+21, 6.5189e+14, 6.5189e+14,  ..., 1.2379e+27, 7.6423e+00, 7.6423e+00]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba694d7-6b27-4e12-864c-6c5de3252f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1259e+15, 5.6089e+11, 5.5245e+11,  ..., 1.8014e+16, 1.1806e+21, 1.5112e+23],\n",
       "        [9.4447e+21, 5.6089e+11, 2.8148e+14,  ..., 2.2213e+12, 2.2030e+12, 2.2213e+12],\n",
       "        [1.1529e+18, 1.1215e+12, 1.1215e+12,  ..., 1.1215e+12, 4.4030e+12, 1.8020e+16],\n",
       "        ...,\n",
       "        [1.1529e+18, 2.3697e+16, 2.0404e+13,  ..., 9.2617e+13, 4.6324e+13, 8.1517e+13],\n",
       "        [9.6715e+24, 4.6316e+13, 2.3174e+13,  ..., 1.4412e+17, 3.2595e+14, 3.7042e+14],\n",
       "        [2.3612e+21, 6.5189e+14, 6.5189e+14,  ..., 1.2379e+27, 1.6523e+00, 1.6523e+00]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62539840-45cc-472a-8daa-4e41b0e5ea03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(i, ik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cca7b9-0bba-4eb5-8b36-de7f3e2666cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4540e+14, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(i-ik).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8727b1-0cd7-452e-8576-032c945a0c83",
   "metadata": {},
   "source": [
    "If we were to use a loss fuunction instead of hand creafted gradients:\n",
    "\n",
    "$$C = \\sum_{\\{i,j\\} \\in I} \\frac{1}{2}(1 - S_{ij})\\sigma(p_i-p_j) + \\log(1 + e^{-\\sigma(p_i - p_j)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8e995-0fa0-4d7c-879e-b256a0f78314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(preds, xb, sigma=0.5):\n",
    "    \n",
    "    srtd_relvs, srtd_idxs = xb[:, :, :, -1].sort(descending=True)\n",
    "    srtd_preds = torch.take_along_dim(preds[:,:,:,0], srtd_idxs, dim=-1)\n",
    "\n",
    "    sl = torch.arange(xb.shape[2], device=xb.device)\n",
    "    ij = torch.cartesian_prod(sl, sl)\n",
    "    idxs, = torch.nonzero(ij[:, 0] < ij[:, 1], as_tuple=True)\n",
    "    ij = ij[idxs]\n",
    "    \n",
    "    si_sj = srtd_relvs[:, :, ij] # these are the relevance scores for token_i and token_j\n",
    "    si, sj= si_sj[:, :, :, 0], si_sj[:, :, :, 1]\n",
    "    signs = torch.sign(si - sj)\n",
    "    pi_pj = srtd_preds[:, :, ij]\n",
    "    pi, pj = pi_pj[:,:,:,0], pi_pj[:,:,:,1]\n",
    "    exp_ij = torch.exp(-sigma*(pi -pj))\n",
    "    exp_ij[exp_ij==torch.inf] = tensor(1e6)\n",
    "    C = ( 0.5*(1 - signs)*sigma*(pi -pj) + torch.log(1 + exp_ij) ) #shape (64, 2234, 64)\n",
    "    # C = C.sum(dim=-1) # shape (64, 2234)\n",
    "    C = C.mean(dim=-1)\n",
    "    return C#.mean()\n",
    "\n",
    "def loss_fn2(preds, xb, sigma=.5):\n",
    "    \"Computes average pairwise cross-entropy loss\"\n",
    "    sl = xb.shape[2]\n",
    "    rel_diff = xb[:, :, :, -1, None] - xb[:, :, :, -1, None].transpose(-1, -2)\n",
    "    pos_pairs = (rel_diff > 0).float()\n",
    "    neg_pairs = (rel_diff < 0).float()\n",
    "    S_ij = pos_pairs - neg_pairs\n",
    "    preds_diff = preds - preds.transpose(-1, -2)\n",
    "    C = .5 * (1 - S_ij) * sigma * preds_diff - F.logsigmoid(sigma * preds_diff)\n",
    "    C = torch.triu(C, diagonal=1) # to take each pair only once\n",
    "    C = C.sum((-1,-2)) / (C.new_ones(C.shape[-2:]).triu(diagonal=1).sum())\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d8b42-b650-466d-b02e-80f7d40d2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = dls.one_batch()\n",
    "preds = model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dce71a-f437-45c3-8be5-184e4432fc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| L(xb, preds).map(Tensor.size): [torch.Size([8, 4, 64, 4]), torch.Size([8, 4, 64, 1])]\n"
     ]
    }
   ],
   "source": [
    "ic(L(xb, preds).map(Tensor.size));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785de67-c940-4d7b-a252-af4961a4592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = (preds, xb)\n",
    "C_deb = loss_fn(*inp)\n",
    "C_them = loss_fn2(*inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aca793-367d-434d-b8df-55e113ecd4d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9908c-3f7e-465d-9b4d-f242640c072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([8, 4, 64, 4])\n",
      "    preds.shape: torch.Size([8, 4, 64, 1])\n",
      "    C.shape: torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "C = loss_fn(preds, xb)\n",
    "ic(xb.shape, preds.shape, C.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191178a2-b76f-4648-be8e-d19bbdbec3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1399.1204, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(34.6843, device='cuda:0', grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.mean(), C.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c51ad-bdbe-4e1c-86a8-05f0c5728f9d",
   "metadata": {},
   "source": [
    "Good luck traing with this kinda loss! In other words, we need handcrafted gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be331d3-bc45-475b-9dd4-c338b004bcba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b1d1e-382d-415a-b572-b5edd79e7b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(params_list): 6\n"
     ]
    }
   ],
   "source": [
    "params_list = L(rank_model_NN.parameters())\n",
    "ic(len(params_list));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafce6d-1fd4-47ae-aa97-53f48812c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert params_list.map(lambda o: o.grad) == [None]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84795a05-5922-400c-bd93-8b87cfa81898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| srtd_preds.shape: torch.Size([32, 2231, 64])\n",
      "    lambda_i.shape: torch.Size([32, 2231, 64])\n"
     ]
    }
   ],
   "source": [
    "srtd_preds, lambda_i = rank_loss(preds, xb)\n",
    "ic(srtd_preds.shape, lambda_i.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c1d748-5636-400b-99e3-c60e6dfde41d",
   "metadata": {},
   "source": [
    "Now we need to compute $\\sum_i \\lambda_i \\frac{\\partial p_i}{w_k}$ to be able to do the weight update in sgd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94304211-2a3e-4269-85e3-8632cf178bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "srtd_preds.backward(lambda_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb6d75-ffa5-4626-8cd9-465198176910",
   "metadata": {},
   "source": [
    "Check if the gradients were populated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143da50-73cb-4425-838c-de7d88eb3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradIsNone(param_list):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    assert param_list.map(lambda o: o.grad) == [None]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3a36f-8778-44dd-96be-3d9eb29aae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_list[5].grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf49ae8-71eb-4a10-a318-9700aa7d900a",
   "metadata": {},
   "source": [
    "Check if the the `grad` attributes of the params got populated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82381b-d0d0-45aa-9112-dcd7172800a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(gradIsNone, args=(params_list,), contains='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd9943-205b-4200-b8d5-072e27f03da1",
   "metadata": {},
   "source": [
    "---\n",
    "Sort the tokens by the relevance scores so that we can compute the set $I$ defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeed3e3-500c-4d3e-9bad-224606994d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| btch_num: 61, lbl_num: 1023\n"
     ]
    }
   ],
   "source": [
    "btch_num, lbl_num, = 61, 1023\n",
    "ic(btch_num, lbl_num);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e953a2-81c6-4460-ac1c-1c56a9ac1285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([64, 2233, 48, 3])\n",
      "    preds.shape: torch.Size([64, 2233, 48, 1])\n",
      "    xb[:,:,:,-1].shape: torch.Size([64, 2233, 48])\n",
      "ic| srtd_relvs.shape: torch.Size([64, 2233, 48])\n",
      "    srtd_idxs.shape: torch.Size([64, 2233, 48])\n"
     ]
    }
   ],
   "source": [
    "ic(xb.shape, preds.shape, xb[:,:,:,-1].shape);\n",
    "srtd_relvs, srtd_idxs = xb[:,:,:,-1].sort(descending=True)\n",
    "ic(srtd_relvs.shape, srtd_idxs.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc192d-d76f-4dab-9ad8-23ed29dbd105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| srtd_toks.shape: torch.Size([64, 2233, 48])\n",
      "    srtd_preds.shape: torch.Size([64, 2233, 48])\n"
     ]
    }
   ],
   "source": [
    "srtd_toks  = torch.take_along_dim(xb[:, :, :, 0], srtd_idxs, dim=-1)\n",
    "srtd_preds = torch.take_along_dim(preds[:, :, :, 0], srtd_idxs, dim=-1)\n",
    "ic(srtd_toks.shape, srtd_preds.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95895629-3848-4038-95e4-9b0c7a8f86df",
   "metadata": {},
   "source": [
    "In the following `ij` is essentially the set `I`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4a846-56fe-4603-80a7-4ae0c5dc463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([64, 2233, 48, 3]), sl: 48\n",
      "ic| ij.shape: torch.Size([1128, 2])\n"
     ]
    }
   ],
   "source": [
    "sl = xb.shape[2]\n",
    "ic(xb.shape, sl);\n",
    "ij = torch.as_tensor(np.fromiter(itertools.combinations(np.arange(sl), 2), dtype=np.dtype((int,2))),\n",
    "                            device=xb.device)#.expand(xb.shape[0], xb.shape[1], -1, -1)\n",
    "ic(ij.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f7f7c-4755-4f6c-a791-a8d383d75ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 349 ms, total: 11 s\n",
      "Wall time: 11 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2238, 1128, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "btchs, lbs = list(xb.shape[:2])\n",
    "btchs, lbs\n",
    "btch_lbs_srtd_toks_combs = []\n",
    "for btch_idx in range(btchs):\n",
    "    for lbl_idx in range(lbs):\n",
    "        # btch_lbs_srtd_toks_combs.append(torch.take(btch_lbs_srtd_toks[btch_idx, lbl_idx], tok_combs))\n",
    "        btch_lbs_srtd_toks_combs.append(srtd_toks[btch_idx, lbl_idx][tok_combs])\n",
    "btch_lbs_srtd_toks_combs = torch.stack(btch_lbs_srtd_toks_combs).view(btchs, lbs, *tok_combs.shape)\n",
    "btch_lbs_srtd_toks_combs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d97a442-e0c2-4781-a957-eed3dbefbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumer = _summation(sl, ij)\n",
    "test_eq(sumer.shape, (sl, sl-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b616ca-4070-4bd9-8bbb-9050598b1bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame(ij, columns=['i', 'j'])\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df8a93-9989-406c-87be-8609bb9d5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.groupby('i').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3448e4-759d-4e66-a08c-e2948aba8b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 252 ms, sys: 0 ns, total: 252 ms\n",
      "Wall time: 283 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "toki_tokj = srtd_toks[:, :, ij] # these are the i,j token indices - i more relevant thatn j  \n",
    "si_sj = srtd_preds[:, :, ij] # these are s_i and s_j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24185ea8-b7b7-431d-9462-f82012c5acba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| toki_tokj.shape: torch.Size([64, 2233, 1128, 2])\n",
      "    si_sj.shape: torch.Size([64, 2233, 1128, 2])\n"
     ]
    }
   ],
   "source": [
    "ic(toki_tokj.shape, si_sj.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6d7b2-668b-4dd7-abf7-b258185d7bc3",
   "metadata": {},
   "source": [
    "`sigma` is from eq:3 to compute $\\lambda_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc89af-5fb1-4f5f-84e6-62f0f7d64d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| lambda_ij.shape: torch.Size([64, 2233, 1128])\n"
     ]
    }
   ],
   "source": [
    "sigma = 0.5\n",
    "lambda_ij = -sigma/(1 + torch.exp(sigma * si_sj[:, :, :, 0] - si_sj[:, :, :, 1]))\n",
    "ic(lambda_ij.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133df706-5e95-4171-accd-c7c7a82385b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.equal(btch_lbs_srtd_toks_combs[btch_num, lbl_num], btch_lbs_srtd_toks_combs_1[btch_num, lbl_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132915e-97db-484a-8392-04e82af03209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| idxr.shape: torch.Size([48, 47])\n",
      "    signs.shape: torch.Size([48, 47])\n"
     ]
    }
   ],
   "source": [
    "idxr, signs = sumer[:, :, 0], sumer[:, :, -1]\n",
    "ic(idxr.shape, signs.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e4be5-a5a1-4c9e-89f9-90317dd1dbbd",
   "metadata": {},
   "source": [
    "Now we can compute $\\lambda_i$ from eq: 4,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899f56b-28bf-4a18-8c3f-fe0c100a2a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| lambda_i.shape: torch.Size([64, 2233, 48, 47])\n",
      "ic| lambda_i.shape: torch.Size([64, 2233, 48])\n"
     ]
    }
   ],
   "source": [
    "lambda_i = (lambda_ij[:, :, idxr] * signs)\n",
    "ic(lambda_i.shape);\n",
    "lambda_i = lambda_i.sum(dim=-1)\n",
    "ic(lambda_i.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0103432-9a80-47c6-b1e3-c28104bba81a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe0ece5-ae9b-4ba3-b8b7-ac62cfefae21",
   "metadata": {},
   "source": [
    "Tensor Gradients and Jacobian Products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c27c89-ee0d-4a8c-be3b-18d1a6036b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.eye(4, 5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157f39b-3ba4-41b6-80f0-ddb285bc34a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb3e16b-2497-4012-adf7-4438772c9b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = (inp+1).pow(2).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33551b5c-f189-4531-b9dd-1a66b74008b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1., 1., 1.],\n",
       "        [1., 4., 1., 1.],\n",
       "        [1., 1., 4., 1.],\n",
       "        [1., 1., 1., 4.],\n",
       "        [1., 1., 1., 1.]], grad_fn=<TBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae79128-c4af-4421-a5c3-22a12797e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a01d6a-61d5-4570-8ce4-457e01168544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c3c9e-2596-4a2e-89b4-886a0d6af0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(torch.ones_like(out), retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781309f7-ee92-4b53-be59-1e467f39c1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"First call\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e478c-d6f7-473a-9887-b25e25c2173b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second call\n",
      "tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.]])\n"
     ]
    }
   ],
   "source": [
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nSecond call\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496126f3-d251-48ed-9f27-366a38c750c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call after zeroing gradients\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeff19ad-9cf4-440d-a49a-f8d008a96603",
   "metadata": {},
   "source": [
    "Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52709ee9-9fc1-479e-8ce4-76a29fe0aaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8., 2., 0.], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(low=0, high=10, size=(3,)).float().requires_grad_()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ef9ca-c7e6-4d8e-ac54-e380949098de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([64.,  4.,  0.], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x**2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4d672-1dd5-4819-8bf9-268597776c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(torch.ones_like(y), retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9061400-aa9d-4361-a5da-e231ef16ee88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16.,  4.,  0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b2beaa-95f0-41fa-8c08-d5d54cb05e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1049173-1681-4421-bcd2-e18e4be11085",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(torch.ones_like(y), retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe17964-4356-4416-987b-0a79a4677774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16.,  4.,  0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f3f3d-db26-434c-a374-d8309fb60eb6",
   "metadata": {},
   "source": [
    "Another example where we will compute the jacobian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761fd13-8d48-44e1-959c-7d80fa10e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.functional import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6eead3-eb5c-4867-a0c4-e999da65f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jacobian?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84037c54-02d4-42ad-8fb4-9da2b35b4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    print(\"\")\n",
    "    return (x[0]+x[1], x[2]*x[0], x[1]**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81555248-ee77-4908-8e01-33c7b581a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tensor([3., 4., 5.]).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0689b92-a75f-4e41-9f81-a2e734d6c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x.grad is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde195f7-468d-45e9-b6d2-c13046889d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(7., grad_fn=<AddBackward0>),\n",
       " tensor(15., grad_fn=<MulBackward0>),\n",
       " tensor(64., grad_fn=<PowBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042c966-b5ff-4cb0-b778-825828a6b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 0.]), tensor([5., 0., 3.]), tensor([ 0., 48.,  0.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(f, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979dd91-b350-4391-83f5-4aebd73a9be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7., grad_fn=<AddBackward0>),\n",
       " tensor(15., grad_fn=<MulBackward0>),\n",
       " tensor(64., grad_fn=<PowBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x[0]+x[1], x[2]*x[0], x[1]**3\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f276497-dc36-4f24-a99e-b43ecc2d151a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [159], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m(torch\u001b[38;5;241m.\u001b[39mones_like(z))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "z.backward(torch.ones_like(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef5e12-68ce-47e4-8778-17f6f320428e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (x**2).sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f43ff-5054-4ce4-938d-05f0b1d4b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296d57f-8463-4d43-8ace-3e1d5bce804e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  8., 10.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84933e57-0fdd-4ebf-b865-3f5a08395c58",
   "metadata": {},
   "source": [
    "Now we need an Optimizer for the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc0071-5fba-413a-9084-b0b17f96a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptimizer:\n",
    "    def __init__(self, params, lr): self.params, self.lr = list(params), lr\n",
    "    \n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params:\n",
    "            p.data.add_(-lr, p.grad.data)\n",
    "            \n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params:\n",
    "            p.grad.detach_()\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683f599-c027-4f02-9d29-e5f0577eb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "opt = BasicOptimizer(rank_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974fb23-8362-4a4b-b950-3b432b2e020c",
   "metadata": {},
   "source": [
    "Replacing our Optimizer with fastai's so that we can use callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5f6f7-246d-481a-a4a7-7a48adca0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer?\n",
    "# SGD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d352fb-168b-4303-9ce2-f37943628731",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "opt = SGD(rank_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6144a9b2-4eef-477b-940d-c6db23c775c7",
   "metadata": {},
   "source": [
    "The above is equivalent to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ffc9f0-a908-4081-9c8a-fdc0f9bf67a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mysgd_step(p, lr, **kwargs):\n",
    "    p.data.add_(p.grad.data, alpha=-lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d993e7ed-34ff-4d86-a112-acefe92043c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "opt_func = partial(Optimizer, cbs=[mysgd_step])\n",
    "opt = opt_func(rank_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf261e1a-11db-422f-80ca-1a82bb092806",
   "metadata": {},
   "source": [
    "Now if we want to add **weight decay:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbfb2e-5f07-4e1d-b58b-708016e04a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "opt_func = partial(Optimizer, cbs=[weight_decay, sgd_step])\n",
    "opt = opt_func(rank_model.parameters(), lr=lr, wd=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94098cea-9d4b-4c51-9d6b-1cd3f442e9e2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec72a8bc-b58e-4cff-81d6-0f63908369b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "opt = SGD(rank_model_NN.parameters(), lr=lr, mom=0.0, wd=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904f406-8ccd-4ad3-80f2-2591cbd2276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "opt = RMSProp(rank_model.parameters(), lr=lr, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1c0d2-8167-4a09-a218-936aaae0ab3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a5c51-5935-4e9f-9514-d43f0c5aeaf9",
   "metadata": {},
   "source": [
    "The `train_epoch` and `validate_epoch` are no longer needed now as we have a fastai like `Learner` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b836d-a41f-40a5-886a-e89c6ece82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, mb=None, metric_logger=None, **kwargs):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    losses, ndcgs, ndcgs_at_6, accs = [], [], [], []\n",
    "    pb = progress_bar(dls.valid, parent=mb)\n",
    "    for xb in pb:\n",
    "        preds = model(xb)\n",
    "        loss = loss_fn(preds, xb)\n",
    "        losses.append(loss.mean())\n",
    "        *_, _ndcg, _ndcg_at_k = ndcg(model(xb), xb, k=6)\n",
    "        ndcgs.append(_ndcg.mean())\n",
    "        ndcgs_at_6.append(_ndcg_at_k.mean())\n",
    "        # acc = order_accuracy(xb.squeeze(0))\n",
    "        acc = accuracy(xb, model)\n",
    "        accs.append(acc.mean())\n",
    "        pb.comment = f'second bar stat'\n",
    "    losses = torch.stack(losses)\n",
    "    ndcgs = torch.stack(ndcgs)\n",
    "    ndcgs_at_6 = torch.stack(ndcgs_at_6)\n",
    "    accs = torch.stack(accs)\n",
    "    logger = [round(losses.mean().item(), 4), round(ndcgs.mean().item(), 4), round(ndcgs_at_6.mean().item(), 4), round(accs.mean().item(), 4)]\n",
    "    if metric_logger is not None: metric_logger.append(logger)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae5e3e5-52af-4bf7-942c-ee0e7962f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, mb, track_trn=True, logger=None, grad_logger=None, **kwargs):\n",
    "    ndcgs, accs = [], []\n",
    "    c = 1\n",
    "    for xb in progress_bar(dls.train, parent=mb):\n",
    "        preds = model(xb)\n",
    "        \n",
    "        # import pdb; pdb.set_trace()\n",
    "        \n",
    "        ## handcrafted gradients\n",
    "        srtd_preds, lambda_i = rank_loss(preds, xb)\n",
    "        srtd_preds.backward(lambda_i)\n",
    "        \n",
    "        ## tracking gradients\n",
    "        for name,param in model.named_parameters():\n",
    "            # import pdb; pdb.set_trace()\n",
    "            # from IPython import embed; embed()\n",
    "            grad = param.grad.data.detach().clone()\n",
    "            grad_logger[name].append(grad)\n",
    "        \n",
    "        ## autograd gradients\n",
    "        if logger is not None:\n",
    "            with torch.no_grad():\n",
    "                loss = loss_fn(preds, xb)\n",
    "                logger.append(loss.mean())\n",
    "        # loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        if track_trn:\n",
    "            with torch.no_grad():\n",
    "                *_, _ndcg, _ = ndcg(preds, xb)\n",
    "                btch_ndcg_mean = _ndcg.mean()\n",
    "                ndcgs.append(btch_ndcg_mean)\n",
    "                btch_acc_mean = accuracy(xb, model).mean()\n",
    "                accs.append(btch_acc_mean)\n",
    "        mb.child.commment = f'batch ndcg mean: {btch_ndcg_mean if track_trn else \"NA\"}'\n",
    "    ndcgs, accs = (torch.stack(ndcgs), torch.stack(accs)) if track_trn else (torch.Tensor(), torch.Tensor())\n",
    "    return round(ndcgs.mean().item(), 4), round(accs.mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc153b4e-b57c-420e-9370-cd3888a1db70",
   "metadata": {},
   "source": [
    "We want to compute a metric which measures how many orderings did the model get right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0416d253-f34d-4ab9-b83a-5b6393883fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_lbs_accuracy(preds, xb, len=1000, resamps=10, threshold=.5):\n",
    "    preds = preds.squeeze(-1)\n",
    "    tok_sl = xb.shape[2]\n",
    "    acc = 0\n",
    "    for _ in range(resamps):\n",
    "        rnd_idxs = torch.randperm(tok_sl)[:len]\n",
    "        rnd_xb = xb[:, :, rnd_idxs]\n",
    "        rnd_preds = preds[:, :, rnd_idxs] \n",
    "        srtd_relv, srtd_idxs = rnd_xb[:, :, :, -1].sort(descending=True)\n",
    "        srtd_preds = torch.take_along_dim(rnd_preds, srtd_idxs, dim=-1)\n",
    "        sl = torch.arange(len if tok_sl > len else tok_sl, device=xb.device)\n",
    "        ij = torch.cartesian_prod(sl, sl)\n",
    "        idxs, = torch.nonzero(ij[:, 0] < ij[:, 1], as_tuple=True)\n",
    "        ij = ij[idxs]\n",
    "        # si_sj = srtd_relv[:, :, ij]\n",
    "        # (si_sj[:, :, :, 0] >= si_sj[:, :, :, 1]).shape, (*srtd_relv.shape[:2], 49950)\n",
    "        # torch.equal(si_sj.new_ones(*si_sj.shape[:-1]), (si_sj[:, :, :, 0] >= si_sj[:, :, :, 1]))\n",
    "        pi_pj = srtd_preds[:, :, ij]\n",
    "        probs_hat = torch.sigmoid(pi_pj[:, :, :, 0] - pi_pj[:, :, :, 1])\n",
    "        probs_hat = (probs_hat > threshold).float()\n",
    "        # acc += (pi_pj[:, :, :, 0] > pi_pj[:, :, :, 1]).float().mean(dim=-1) # earlier this was wrong\n",
    "        acc += probs_hat.mean(-1) # the last axis is the token pair (more relevant, less relevant)\n",
    "    return acc/resamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c13d5d-db2e-4ea9-bdde-8acd9a2d52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(xb, model):\n",
    "    if len(xb.shape) != 4: xb = xb.unsqueeze(0) # add the batch dim if it is not there (0: batch, 1: lbs, 2: toks, 3: tok_id,lbl_id,score)\n",
    "    btch_acc = []\n",
    "    for btch_splt in torch.split(xb, 4, dim=0):\n",
    "        lbs_acc = []\n",
    "        for lbs_splt in torch.split(btch_splt, 100, dim=1):\n",
    "            lbs_acc.append(batch_lbs_accuracy(model(lbs_splt), lbs_splt))\n",
    "        # import pdb; pdb.set_trace()\n",
    "        lbs_acc = torch.cat(lbs_acc, dim=-1)\n",
    "        btch_acc.append(lbs_acc)\n",
    "    btch_acc = torch.cat(btch_acc, dim=0)\n",
    "    return btch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ceaa2e-72f4-4b69-8a5d-14aa51ae51cb",
   "metadata": {},
   "source": [
    "<mark>NOTE: The following `ndcg` only used on a batch: </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf16cb-0751-46ac-87f5-442f60935c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_temp(preds, xb, k=None):\n",
    "    preds = preds.squeeze(-1)\n",
    "    preds_rank = preds.argsort(dim=-1, descending=True).argsort(dim=-1)\n",
    "    ideal_rank = xb[:, :, :, -1].argsort(dim=-1, descending=True).argsort(dim=-1)\n",
    "    discnt_fac = torch.log2(preds_rank+2)\n",
    "    ideal_discnt_fac = torch.log2(ideal_rank+2)\n",
    "    # eps = preds.new_empty(1).fill_(1e-15)\n",
    "    discntd_gain = torch.pow(2, xb[:, :, :, -1])  / (discnt_fac)\n",
    "    ideal_discntd_gain = torch.pow(2, xb[:, :, :, -1])  / (ideal_discnt_fac)\n",
    "    dcg = discntd_gain.sum(dim=-1)#.flatten()\n",
    "    idcg = ideal_discntd_gain.sum(dim=-1)#.flatten()\n",
    "    ndcg = dcg/idcg\n",
    "    \n",
    "    ndcg_at_k = None\n",
    "    \n",
    "    if k is not None:\n",
    "        # pdb.set_trace()\n",
    "        topk_preds, topk_preds_idxs = torch.topk(preds, k=k, dim=-1, largest=True)\n",
    "        topk_preds_relv = torch.take_along_dim(xb[:, :, :, -1], topk_preds_idxs, dim=-1)\n",
    "        topk_df = torch.log2(2 + torch.arange(k)).cuda()# torch.take_along_dim(discnt_fac, topk_preds_idxs, dim=-1)\n",
    "        dg_at_k = torch.pow(2, topk_preds_relv) / (topk_df) # changed\n",
    "        dcg_at_k = dg_at_k.sum(dim=-1)\n",
    "\n",
    "        topk, topk_idxs = torch.topk(xb[:, :, :, -1], k=k, dim=-1, largest=True)\n",
    "        idg_at_k = torch.pow(2, topk) / (topk_df) # changed\n",
    "        idcg_at_k = idg_at_k.sum(dim=-1)\n",
    "        \n",
    "        ndcg_at_k = dcg_at_k / idcg_at_k\n",
    "\n",
    "    return preds, preds_rank, ideal_rank, discnt_fac, ideal_discnt_fac, discntd_gain, ideal_discntd_gain, dcg, idcg, ndcg, ndcg_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4790ca-9de8-4801-b1ed-724a63029f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_14902/881185037.py\", line 1, in <module>\n",
      "    acc = batch_lbs_accuracy(preds, xb)\n",
      "NameError: name 'preds' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2052, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/stack_data/core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/stack_data/core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"/home/deb/miniconda3/lib/python3.10/site-packages/stack_data/core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "acc = batch_lbs_accuracy(preds, xb)\n",
    "ic(xb.shape, preds.shape, acc.shape, acc.mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2bc05-d029-45f4-a7a7-fd04ac790a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| srtd_idxs.shape: torch.Size([64, 2243, 64])\n",
      "ic| srtd_preds.shape: torch.Size([64, 2243, 64])\n",
      "ic| ij.shape: torch.Size([2016, 2]), tok_sl: 64\n"
     ]
    }
   ],
   "source": [
    "tok_sl = xb.shape[2]\n",
    "srtd_relv, srtd_idxs = xb[:, :, :, -1].sort(descending=True)\n",
    "ic(srtd_idxs.shape)\n",
    "srtd_preds = torch.take_along_dim(preds[:,:,:,0], srtd_idxs, dim=-1)\n",
    "ic(srtd_preds.shape)\n",
    "sl = torch.arange(tok_sl, device=xb.device)\n",
    "ij = torch.cartesian_prod(sl, sl)\n",
    "idxs, = torch.nonzero(ij[:, 0] < ij[:, 1], as_tuple=True)\n",
    "ij = ij[idxs]\n",
    "ic(ij.shape, tok_sl);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5cd35-6edd-4499-94b3-6e7bfe5b2e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| si_sj.shape: torch.Size([64, 2243, 2016, 2])\n",
      "ic| (si_sj[:, :, :, 0] >= si_sj[:, :, :, 1]).shape: torch.Size([64, 2243, 2016])\n",
      "ic| probs.shape: torch.Size([64, 2243, 2016])\n",
      "    probs.mean(): tensor(0.9381, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 2243, 2016]), tensor(0.9381, device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_sj = srtd_relv[:, :, ij]\n",
    "ic(si_sj.shape);\n",
    "ic((si_sj[:, :, :, 0] >= si_sj[:, :, :, 1]).shape)\n",
    "probs = torch.sigmoid(si_sj[:, :, :, 0] - si_sj[:, :, :, 1])\n",
    "assert torch.equal(si_sj.new_ones(*si_sj.shape[:-1]), (si_sj[:, :, :, 0] >= si_sj[:, :, :, 1]))\n",
    "ic(probs.shape, probs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c1d2e-4706-4544-8564-23c7ecb94c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2243, 2016])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signs = torch.sign(si_sj[:, :, :, 0] - si_sj[:, :, :, 1])\n",
    "signs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0febc-2f60-4c71-baac-5fb4e843ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.where(signs[0][0] == 1)[0].numel()\n",
    "eq = torch.where(signs[0][0] == 0)[0].numel()\n",
    "neg = torch.where(signs[0][0] == -1)[0].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bba419-a432-4068-ace6-abe972fda66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934, 82, 0, 2016)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos, eq, neg, (pos+neg+eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13ade4-9758-4f5d-b9c6-601f5c881b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1934., device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signs[0,0].float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06402bdf-4d32-4640-bc45-36c904f736b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| pi_pj.shape: torch.Size([64, 2233, 2016, 2])\n",
      "ic| probs_hat.shape: torch.Size([64, 2233, 2016])\n"
     ]
    }
   ],
   "source": [
    "pi_pj = srtd_preds[:, :, ij]\n",
    "ic(pi_pj.shape);\n",
    "probs_hat = torch.sigmoid(pi_pj[:, :, :, 0] - pi_pj[:, :, :, 1])\n",
    "# probs2 =  1/(1 + torch.exp( -0.5 * (pi_pj[:, :, :, 0] - pi_pj[:, :, :, 1])))\n",
    "ic(probs_hat.shape);\n",
    "# .float().mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb0255-93d1-4b43-9472-6d46f25e3d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4998, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_hat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573a0c6-40a8-4010-8ad3-e4d60c75ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb):\n",
    "    btch_acc = []\n",
    "    for xb_splt in torch.split(xb, 4 ,dim=0):\n",
    "        btch_acc.append(batch_lbs_accuracy(rank_model(xb_splt), xb_splt))\n",
    "    btch_acc = torch.cat(btch_acc, dim=0)\n",
    "    return btch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31690ceb-c6bd-4e27-a1ca-4b22ba6b2e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_accuracy(dset):\n",
    "    dset = dset.unsqueeze(0)\n",
    "    dset_chnked = torch.split(dset, 100, dim=1)\n",
    "    acc = []\n",
    "    for chunk in  dset_chnked:\n",
    "        btch_acc = batch_lbs_accuracy(rank_model(chunk), chunk)\n",
    "        acc.append(btch_acc)\n",
    "    acc = torch.cat(acc, dim=-1)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f411c8-b244-4705-b510-dd670992c453",
   "metadata": {},
   "source": [
    "<mark>NOTE: The following `ndcg_at_k` only used on the entite dataset: </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d4192-dbc3-418c-89d3-11b21947f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(dset, model, k=20):\n",
    "    dset = dset.unsqueeze(0)\n",
    "    dset_chnked = torch.split(dset, 100, dim=1)\n",
    "    ndcg_at_k_list = []\n",
    "    for chunk in  dset_chnked:\n",
    "        *_, ndcg_at_k = ndcg(model(chunk), chunk, k=k)\n",
    "        ndcg_at_k_list.append(ndcg_at_k)\n",
    "    ndcg_at_k_all = torch.cat(ndcg_at_k_list, dim=-1)\n",
    "    return ndcg_at_k_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f87a3-c0ac-4d97-99eb-949291f4ba69",
   "metadata": {},
   "source": [
    "Now let's write our training loop:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67eae7-fbe0-4eae-9737-8271cecca844",
   "metadata": {},
   "source": [
    "`train_model` and `validate_model` no longer needed now as we have a fastai like `Learner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f3d9f-9929-41b9-8b9f-ea08cf9c1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, **kwargs):\n",
    "    mb = master_bar(range(epochs))\n",
    "    for i,_  in enumerate(mb):\n",
    "        print(f\"epoch: {i}\")\n",
    "        print(f\"training ndcg, training accuracy = {train_epoch(model, mb, **kwargs)}\")\n",
    "        mb.main_bar.comment = f'first bar stat'\n",
    "        print(f\"validation loss, validation ndcg, validation ndcg_at_6(candidate: 32), validation accuracy = {validate_epoch(model, mb, **kwargs)}\", end='\\n----\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb08ad4-0d7d-4272-89f7-f3647cf201f6",
   "metadata": {},
   "source": [
    "Let's also write our validation loop in case we just need to validate the model and not train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f22fe-1ee5-473c-8b42-9cc522ff8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model):\n",
    "    return validate_epoch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53f8dc-dc20-443a-adc9-a4d7f58f5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, dls, grad_func, loss_func, lr, opt_func=SGD, path=None):\n",
    "        store_attr()\n",
    "        self.path = Path(path) if path is not None else getattr(dls, 'path', Path('.'))\n",
    "   \n",
    "    def one_batch(self, losses, ndcgs, ndcgs_at_6, accs, track_trn=True, logger=None, grad_logger=None, metric_logger=None, **kwargs):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        self.preds = self.model(self.xb)\n",
    "        if self.model.training: # training\n",
    "            srtd_preds, lambda_i = self.grad_func(self.preds, self.xb)\n",
    "            srtd_preds.backward(lambda_i)\n",
    "            \n",
    "            ## tracking gradients\n",
    "            for name,param in self.model.named_parameters():\n",
    "            # import pdb; pdb.set_trace()\n",
    "            # from IPython import embed; embed()\n",
    "                grad = param.grad.data.detach().clone()\n",
    "                grad_logger[name].append(grad)\n",
    "            \n",
    "            # tracking loss\n",
    "            if logger is not None:\n",
    "                with torch.no_grad():\n",
    "                    loss = self.loss_func(self.preds, self.xb)\n",
    "                    logger.append(loss.mean())\n",
    "                    losses.append(loss.mean())\n",
    "            \n",
    "            ## stepping the params\n",
    "            self.opt.step()\n",
    "            ## zeroing the grad before next batch\n",
    "            self.opt.zero_grad()\n",
    "            \n",
    "            # tracking metrics during training\n",
    "            if track_trn:\n",
    "                with torch.no_grad():\n",
    "                    *_, _ndcg, _ = ndcg(self.preds, self.xb)\n",
    "                    btch_ndcg_mean = _ndcg.mean()\n",
    "                    ndcgs.append(btch_ndcg_mean)\n",
    "                    btch_acc_mean = accuracy(self.xb, self.model).mean()\n",
    "                    accs.append(btch_acc_mean)\n",
    "            \n",
    "        else: # validation\n",
    "            loss = self.loss_func(self.preds, self.xb)\n",
    "            losses.append(loss.mean())\n",
    "            *_, _ndcg, _ndcg_at_k = ndcg(self.preds, self.xb, k=6)\n",
    "            ndcgs.append(_ndcg.mean())\n",
    "            ndcgs_at_6.append(_ndcg_at_k.mean())\n",
    "            # acc = order_accuracy(xb.squeeze(0))\n",
    "            acc = accuracy(self.xb, self.model)\n",
    "            accs.append(acc.mean())\n",
    "            \n",
    "        return losses, ndcgs, ndcgs_at_6, accs    \n",
    "        \n",
    "    def one_epoch(self, train, mb, metric_logger=None, **kwargs):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        losses, ndcgs, ndcgs_at_6, accs = [], [], [], []\n",
    "        self.model.training = train\n",
    "        dl = self.dls.train if train else self.dls.valid\n",
    "        for self.num, self.xb in enumerate(progress_bar(dl, parent=mb, leave=False)):\n",
    "            losses, ndcgs, ndcgs_at_6, accs = self.one_batch(losses, ndcgs, ndcgs_at_6, accs, **kwargs)\n",
    "        _li = [losses, ndcgs, ndcgs_at_6, accs]\n",
    "        _li = [torch.stack(o) if o else torch.Tensor() for o in _li] \n",
    "        [losses, ndcgs, ndcgs_at_6, accs] = _li\n",
    "        # import pdb; pdb.set_trace()\n",
    "        logger = [round(o.mean().item(), 4) if o.sum() else \"NA\" for o in _li]\n",
    "        # logger = [round(losses.mean().item(), 4), round(ndcgs.mean().item(), 4), round(ndcgs_at_6.mean().item(), 4), round(accs.mean().item(), 4)]\n",
    "        if not self.model.training and metric_logger is not None: metric_logger.append(logger)\n",
    "        return logger\n",
    "    \n",
    "    def create_opt(self):\n",
    "        self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
    "        self.opt.clear_state()\n",
    "        return self.opt\n",
    "    \n",
    "    def fit(self, n_epochs, best=None, **kwargs):\n",
    "        self.create_opt()\n",
    "        self.n_epochs = n_epochs\n",
    "        mb = master_bar(range(self.n_epochs))\n",
    "        columns=['train_loss', 'train_ndcg', 'train_ndcg@6', 'train_acc', 'val_loss', 'val_ndcg (candi. 32)', 'val ndcg@6 (candi. 32)', 'val_acc']\n",
    "        # index = range(self.n_epochs)\n",
    "        pdf = pd.DataFrame(columns=columns)#, index=index)\n",
    "        pdf.index.name = 'epoch'\n",
    "        if best is not None and best[0] not in columns: raise NameError(best[0]+'metric is not trackable, please check name!')\n",
    "        try:\n",
    "            for self.epoch,_ in enumerate(mb):\n",
    "                pdf.loc[self.epoch] = pd.Series(dict(zip(columns, self.one_epoch(True, mb, **kwargs) + self.one_epoch(False, mb, **kwargs))))\n",
    "                current = pdf.loc[self.epoch][best[0]]\n",
    "                if best is not None and current > best[1]: \n",
    "                    best[1] = current\n",
    "                    self.save(best[2])\n",
    "                # clear_output(wait=True)\n",
    "                # pdb.set_trace()\n",
    "                display_df(pdf.iloc[[self.epoch]])\n",
    "                # print(f\"train loss, train ndcg, train ndcg@6, train accuracy = {self.one_epoch(True, mb, **kwargs)}\")\n",
    "                # print(f\"validation loss, validation ndcg, validation ndcg_at_6(candidate: 32), validation accuracy = {self.one_epoch(False, mb, **kwargs)}\", end='\\n----\\n')\n",
    "            clear_output(wait=True)\n",
    "            display_df(pdf)\n",
    "        except CancelFitException: pass \n",
    "    \n",
    "    def validate(self, **kwargs):\n",
    "        columns=['val_loss', 'val_ndcg (candi. 32)', 'val ndcg@6 (candi. 32)', 'val_acc']\n",
    "        pdf = pd.DataFrame(columns=columns)\n",
    "        pdf.index.name = 'epoch'\n",
    "        try: \n",
    "            val = dict(zip(columns, self.one_epoch(False, None, **kwargs)))\n",
    "            pdf = pd.DataFrame([val])\n",
    "            display_df(pdf)\n",
    "        except CancelFitException: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc532f-8024-4b00-b8d8-a22543069d4f",
   "metadata": {},
   "source": [
    "**Serializing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a6dbc-6c17-49ae-8f5d-c390b04d51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "@delegates(save_model)\n",
    "def save(self:Learner, file, **kwargs):\n",
    "    \"Save model and optimizer state (if 'with_opt') to `self.path/file`\"\n",
    "    file = join_path_file(file, self.path, ext='.pth')\n",
    "    save_model(file, self.model, getattr(self, 'opt', None), **kwargs)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c0cc4-5105-427a-8fb3-617458d2515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "@delegates(load_model)\n",
    "def load(self:Learner, file, device=None, **kwargs):\n",
    "    \"Load model and optimizer state (if `with_opt`) from `self.path/file` using `device`\"\n",
    "    if device is None and hasattr(self.dls, 'device'): device = self.dls.device\n",
    "    self.opt = getattr(self, 'opt', None)\n",
    "    if self.opt is None: self.create_opt()\n",
    "    file = join_path_file(file, self.path, ext='.pth')\n",
    "    load_model(file, self.model, self.opt, device=device, **kwargs)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1001e884-f747-4c3b-bedd-22280d11a550",
   "metadata": {},
   "source": [
    "### Peace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0426335b-cb7e-4379-8354-090e2dd8f963",
   "metadata": {},
   "source": [
    "#### **Keeping records:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41ddca-6a21-4fe6-863c-dacc028ae50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ['lin', 'nn']\n",
    "algos = ['ranknet', 'lambda-rank']\n",
    "idx = pd.Index(['mimic-tiny', 'mimic-full'], name='dataset')\n",
    "cols = pd.MultiIndex.from_product([m, algos], names = ['model', 'algo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67854c21-21cc-40ac-b2be-58a8ca0ab10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=cols, index=idx)\n",
    "df[:] = 'TBD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29edf896-b531-4870-a482-912f0c27fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['mimic-tiny']['nn']['ranknet'] = {'lr': 1e-4, 'opt': 'partial(RMSProp, mom=0.9, wd=0.0)', 'best': 70.67, 'epochs': 15, 'seed': 1, 'gain': 'cubic', 'factors': 100}\n",
    "df.loc['mimic-tiny']['lin']['ranknet'] = {'lr': 1e-4, 'opt': 'partial(SGD, mom=0.9, wd=0.0)', 'best': 65.69, 'epochs': 15, 'seed': 1, 'gain': 'cubic', 'factors': 100}\n",
    "df.loc['mimic-tiny']['nn']['lambda-rank'] = {'lr': [1e-2, 1e-3, 1e-4], 'opt': 'partial(Adam, mom=0.9, wd=0.4)', 'best': 62.75, 'epochs': [15, 15], 'seed': [1, str(8667)+' (L2RDataLoader)'], 'gain': 'exp', 'factors': 200}\n",
    "df.loc['mimic-tiny']['lin']['lambda-rank'] = {'lr': [7e-3, 7e-4], 'opt': 'partial(SGD, mom=0.9, wd=0.0)', 'best': 61.7, 'epochs': [15, 15], 'seed': 1, 'gain': 'exp', 'factors': 200}\n",
    "\n",
    "df.loc['mimic-full']['nn']['ranknet'] = 'TBD'\n",
    "df.loc['mimic-full']['lin']['ranknet'] = {'lr': 1e-5, 'opt': 'partial(SGD, mom=0.9, wd=0.0)', 'best': 63.73, 'epochs': 3, 'seed': 1, 'gain': 'cubic', 'factors': 100}\n",
    "df.loc['mimic-full']['nn']['lambda-rank'] = 'TBD'\n",
    "df.loc['mimic-full']['lin']['lambda-rank'] = {'lr': [7e-4, 7e-4, 7e-4], 'opt': 'partial(RMSProp, mom=0.9, wd=0.0)', 'best': 12.85, 'epochs': [4, 2, 4, 4], 'seed': 1, 'gain': 'exp', 'factors': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b01acf-4d87-4fb2-ac26-1f4fb81494e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">lin</th>\n",
       "      <th colspan=\"2\" halign=\"left\">nn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algo</th>\n",
       "      <th>ranknet</th>\n",
       "      <th>lambda-rank</th>\n",
       "      <th>ranknet</th>\n",
       "      <th>lambda-rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mimic-tiny</th>\n",
       "      <td>{'lr': 0.0001, 'opt': 'partial(SGD, mom=0.9, wd=0.0)', 'best': 65.69, 'epochs': 15, 'seed': 1, 'gain': 'cubic', 'factors': 100}</td>\n",
       "      <td>{'lr': [0.007, 0.0007], 'opt': 'partial(SGD, mom=0.9, wd=0.0)', 'best': 61.7, 'epochs': [15, 15], 'seed': 1, 'gain': 'exp', 'factors': 200}</td>\n",
       "      <td>{'lr': 0.0001, 'opt': 'partial(RMSProp, mom=0.9, wd=0.0)', 'best': 70.67, 'epochs': 15, 'seed': 1, 'gain': 'cubic', 'factors': 100}</td>\n",
       "      <td>{'lr': [0.01, 0.001, 0.0001], 'opt': 'partial(Adam, mom=0.9, wd=0.4)', 'best': 62.75, 'epochs': [15, 15], 'seed': [1, '8667 (L2RDataLoader)'], 'gain': 'exp', 'factors': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mimic-full</th>\n",
       "      <td>{'lr': 1e-05, 'opt': 'partial(SGD, mom=0.9, wd=0.0)', 'best': 63.73, 'epochs': 3, 'seed': 1, 'gain': 'cubic', 'factors': 100}</td>\n",
       "      <td>{'lr': [0.0007, 0.0007, 0.0007], 'opt': 'partial(RMSProp, mom=0.9, wd=0.0)', 'best': 12.85, 'epochs': [4, 2, 4, 4], 'seed': 1, 'gain': 'exp', 'factors': 200}</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model                                                                                                                                   lin  \\\n",
       "algo                                                                                                                                ranknet   \n",
       "dataset                                                                                                                                       \n",
       "mimic-tiny  {'lr': 0.0001, 'opt': 'partial(SGD, mom=0.9, wd=0.0)', 'best': 65.69, 'epochs': 15, 'seed': 1, 'gain': 'cubic', 'factors': 100}   \n",
       "mimic-full    {'lr': 1e-05, 'opt': 'partial(SGD, mom=0.9, wd=0.0)', 'best': 63.73, 'epochs': 3, 'seed': 1, 'gain': 'cubic', 'factors': 100}   \n",
       "\n",
       "model                                                                                                                                                                      \\\n",
       "algo                                                                                                                                                          lambda-rank   \n",
       "dataset                                                                                                                                                                     \n",
       "mimic-tiny                    {'lr': [0.007, 0.0007], 'opt': 'partial(SGD, mom=0.9, wd=0.0)', 'best': 61.7, 'epochs': [15, 15], 'seed': 1, 'gain': 'exp', 'factors': 200}   \n",
       "mimic-full  {'lr': [0.0007, 0.0007, 0.0007], 'opt': 'partial(RMSProp, mom=0.9, wd=0.0)', 'best': 12.85, 'epochs': [4, 2, 4, 4], 'seed': 1, 'gain': 'exp', 'factors': 200}   \n",
       "\n",
       "model                                                                                                                                        nn  \\\n",
       "algo                                                                                                                                    ranknet   \n",
       "dataset                                                                                                                                           \n",
       "mimic-tiny  {'lr': 0.0001, 'opt': 'partial(RMSProp, mom=0.9, wd=0.0)', 'best': 70.67, 'epochs': 15, 'seed': 1, 'gain': 'cubic', 'factors': 100}   \n",
       "mimic-full                                                                                                                                  TBD   \n",
       "\n",
       "model                                                                                                                                                                                      \n",
       "algo                                                                                                                                                                          lambda-rank  \n",
       "dataset                                                                                                                                                                                    \n",
       "mimic-tiny  {'lr': [0.01, 0.001, 0.0001], 'opt': 'partial(Adam, mom=0.9, wd=0.4)', 'best': 62.75, 'epochs': [15, 15], 'seed': [1, '8667 (L2RDataLoader)'], 'gain': 'exp', 'factors': 200}  \n",
       "mimic-full                                                                                                                                                                            TBD  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a6492-b9e2-4ed9-8235-7f36a1a90f7e",
   "metadata": {},
   "source": [
    "#### **Get the `DataLoaders`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de44cf0-9d03-43c0-8106-6dca28e908fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae027e49-b355-4f41-8d4f-dfdc8f4834b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.initial_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1529b-527c-42e7-aa15-1399b910dca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.TrnDataLoader"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dataloader.py', 'r') as f: lines = f.readlines()\n",
    "exec(''.join(lines))\n",
    "TrnDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84384540-f4b5-4b34-b344-eb655a77b99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 ms, sys: 0 ns, total: 2.69 ms\n",
      "Wall time: 38.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dls = torch.load(dls_learn_rank_tiny_path)\n",
    "len(dls.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14d24b-85ac-4374-9316-1ab42dd4224a",
   "metadata": {},
   "source": [
    "Based on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7412c-361e-46a2-917c-9bc7d2902fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_lbs, num_toks, num_factors = 8922, 57352, 200\n",
    "num_lbs, num_toks, num_factors = 104, 328, 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e84d8-f175-4254-a7a7-ff7750c1b379",
   "metadata": {},
   "source": [
    "#### **Make the Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe1ef4-7b00-4f1b-8e6b-dc5fff0bb07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = L2R_DotProductBias(num_lbs, num_toks, num_factors, y_range=None).cuda() #.to(default_device())\n",
    "# model = L2R_NN(num_lbs, num_toks, num_factors, n_act=100, y_range=None).cuda() #.to(default_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770252a4-f881-4cd3-802d-d96d25ba4ddc",
   "metadata": {},
   "source": [
    "**Create the `Learner` and train:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e157ec-1e88-4f86-8622-59237bf98334",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [TrainEval(), TrackResults(train_metrics=True), ProgressBarCallback(), Monitor(), SaveCallBack('ranknet-tiny', monitor='acc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb917a46-0561-499c-9c7b-dce068894566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad_fn = partial(rank_loss3, gain_fn='exp', k=6)\n",
    "# learner = get_learner(model, dls, grad_fn=grad_fn, opt_func=partial(SGD, mom=0.9, wd=0.0), lambrank=True, lr=7e-4) \n",
    "# learner = get_learner(model, dls, lr=1e-5) # lin # ranknet # full\n",
    "# learner = get_learner(model, dls, grad_fn=grad_fn, opt_func=partial(RMSProp, mom=0.9, wd=0.0), lambrank=True, lr=7e-2) # lin # lambdarank # full\n",
    "# learner = get_learner(model, dls, lr=1e-4, opt_func=partial(RMSProp, mom=0.9, wd=0.0)) \n",
    "# learner = get_learner(model, dls, lr=1e-2, grad_fn=grad_fn, lambrank=True, opt_func=partial(Adam, mom=0.9, wd=0.4))  # nn lambdarank tiny\n",
    "# learner = get_learner(model, dls, lr=1e-2, grad_fn=grad_fn, lambrank=True, opt_func=partial(Adam, mom=0.9, wd=0.1))  # nn lambdarank full\n",
    "learner = get_learner(model, dls, lr=1e-4, cbs=cbs) #lin #ranknet #tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99179939-e5b9-41b5-b01a-142e058d1e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function xcube.l2r.gradients.rank_loss3(preds, xb, sigma=0.5, lambrank=False, gain_fn=None, k=6)>,\n",
       " functools.partial(<function SGD>, mom=0.9),\n",
       " None,\n",
       " 0.0001,\n",
       " <function xcube.l2r.gradients.loss_fn2(preds, xb, sigma=0.5)>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattrs(learner, 'grad_func', 'opt_func', 'opt', 'lr', 'loss_func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b627a-3658-40ce-bac0-d625ea340bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best = ['val ndcg@6 (candi. 32)', 0.6275, 'lambda-rank-tiny']\n",
    "# best = ['val ndcg@6 (candi. 32)', 0.3495, 'lambda-rank-full']\n",
    "# best = ['val_acc', 0, 'ranknet-full']\n",
    "best = ['val_acc', 0.0, 'ranknet-tiny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715d07b-7fae-4838-a400-d42a935d47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr cap\n",
    "loss_logger = []\n",
    "metric_logger = []\n",
    "grad_logger = defaultdict(list)\n",
    "# with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "            # profile_memory=True, record_shapes=True) as prof:\n",
    "learner.fit(1, best=best, logger=loss_logger, metric_logger=metric_logger, grad_logger=grad_logger, track_trn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aea3ce-722a-4065-b641-8f88cb497f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True 1.6014 0.4479 0.2691 0.4815\n",
      "0 False 1.438 0.4402 0.3158 0.6004\n",
      "Better model found at epoch 0 with acc value: 0.6004.\n",
      "1 True 0.6697 0.5408 0.3749 0.606\n",
      "1 False 1.143 0.5226 0.4193 0.6389\n",
      "Better model found at epoch 1 with acc value: 0.6389.\n",
      "2 True 0.5086 0.6191 0.4789 0.6476\n",
      "2 False 1.0935 0.5261 0.4395 0.6507\n",
      "Better model found at epoch 2 with acc value: 0.6507.\n",
      "3 True 0.4394 0.6108 0.4691 0.6708\n",
      "3 False 1.0886 0.5418 0.4482 0.655\n",
      "Better model found at epoch 3 with acc value: 0.655.\n"
     ]
    }
   ],
   "source": [
    "learner.fit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbdab59-0135-47d7-8581-ccd8ff4a218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = learner.load('ranknet-tiny', device=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f780c3e-b9ca-4731-94ee-430a57ab4644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 False 1.0886 0.5418 0.4482 0.6548\n"
     ]
    }
   ],
   "source": [
    "learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91be6248-0894-4122-83c7-c32ea5a3b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.cbs[-1].best = 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd9cd0-3d03-4185-b268-cf2bd7fcaa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('l2r_mini.log', 'w') as f: f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad635e-fa5a-4c68-8369-cf054c5a899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cat 'l2r_mini.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca525f-c69e-4ef6-a3bd-e18c4fc64de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('lambda-rank-full.pth')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.save('lambda-rank-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c07a3-164a-4b71-86d2-4770e99a5ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = learner.load('lambda-rank-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0eaec3-6613-4dae-a3fb-85b1bf76fd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_ndcg (candi. 32)</th>\n",
       "      <th>val ndcg@6 (candi. 32)</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.8274</td>\n",
       "      <td>0.4883</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>0.6054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c1ea1-a9c9-40a4-a169-b14925e70643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 104, 16, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = dls.valid.one_batch()\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947265da-d022-44c1-b5a3-ba5981ef01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a325a05e-6512-4ce2-a355-c18da81ae0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 104, 16, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edcd397-aa8d-4576-9349-0e578251d02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.0154, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(5.6613, device='cuda:0', grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.mean(), preds.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe2754e-ed13-4ed0-a090-486bb2ef6def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1555])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba5a02-d2a7-4998-a9ba-1dc4f66c8068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5017.6982, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f6854-9c9e-4a4a-b609-0bcd770461c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_temp(preds, xb, k=None):\n",
    "    preds = preds.squeeze(-1)\n",
    "    preds_rank = preds.argsort(dim=-1, descending=True).argsort(dim=-1)\n",
    "    ideal_rank = xb[:, :, :, -1].argsort(dim=-1, descending=True).argsort(dim=-1)\n",
    "    discnt_fac = torch.log2(preds_rank+2)\n",
    "    ideal_discnt_fac = torch.log2(ideal_rank+2)\n",
    "    # eps = preds.new_empty(1).fill_(1e-15)\n",
    "    discntd_gain = torch.pow(2, xb[:, :, :, -1])  / (discnt_fac)\n",
    "    ideal_discntd_gain = torch.pow(2, xb[:, :, :, -1])  / (ideal_discnt_fac)\n",
    "    dcg = discntd_gain.sum(dim=-1)#.flatten()\n",
    "    idcg = ideal_discntd_gain.sum(dim=-1)#.flatten()\n",
    "    ndcg = dcg/idcg\n",
    "    \n",
    "    ndcg_at_k = None\n",
    "    \n",
    "    if k is not None:\n",
    "        # pdb.set_trace()\n",
    "        topk_preds, topk_preds_idxs = torch.topk(preds, k=k, dim=-1, largest=True)\n",
    "        topk_preds_relv = torch.take_along_dim(xb[:, :, :, -1], topk_preds_idxs, dim=-1)\n",
    "        topk_df = torch.log2(2 + torch.arange(k)).cuda()# torch.take_along_dim(discnt_fac, topk_preds_idxs, dim=-1)\n",
    "        dg_at_k = torch.pow(2, topk_preds_relv) / (topk_df) # changed\n",
    "        dcg_at_k = dg_at_k.sum(dim=-1)\n",
    "\n",
    "        topk, topk_idxs = torch.topk(xb[:, :, :, -1], k=k, dim=-1, largest=True)\n",
    "        idg_at_k = torch.pow(2, topk) / (topk_df) # changed\n",
    "        idcg_at_k = idg_at_k.sum(dim=-1)\n",
    "        \n",
    "        ndcg_at_k = dcg_at_k / idcg_at_k\n",
    "\n",
    "    return preds, preds_rank, ideal_rank, discnt_fac, ideal_discnt_fac, discntd_gain, ideal_discntd_gain, dcg, idcg, ndcg, ndcg_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706d47c-59f7-4fb2-84fd-2240a942a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, *_, n_at_6 = ndcg(preds, xb, k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe4793f-1831-43eb-ace2-88d5afffa4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 104, 16]), torch.Size([1, 104]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, n_at_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e92079-0df2-4109-8b6c-0f9f082ee29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_at_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368431a7-00eb-4bf7-8c29-de050a5a85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = (btch, lbl) = 7,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da023d-1294-4a2b-af53-914fc853c940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9999, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_at_6[inp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335a1c6-60a5-46d0-b4b6-ccc74e56a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = preds[inp].cpu()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866758d5-8840-439e-886e-df3126ef83c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21.,  1.,  3.,  1.,  3.,  5., 14., 12.,  1., 24.,  1.,  8.,  4., 12., 22.,  6.,  6., 27.,  3., 22.,  1.,  2.,  1.,  3.,  9., 22.,  3.,  6., 11.,  7.,  1.,  2., 27.,  3.,  4., 11., 48., 26.,\n",
       "        34.,  1.,  3.,  3.,  1.,  9.,  1.,  2., 12., 10., 34.,  6., 19.,  4., 28., 11., 26.,  6.,  2., 12.,  3.,  4.,  2.,  6., 13.,  1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xb[inp][:, -1].cpu()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e933f74-4467-4505-b9a9-0406db51fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, topk_idxs = torch.topk(y, k=20, dim=-1, largest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e7d3a-bd17-4290-80e6-962325d6d49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([56, 41, 42, 47, 19, 31, 46, 53, 10, 63, 39, 37, 48, 23,  4, 28, 62, 26, 49, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1e54c-8439-46f0-a079-17b2411c4d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.,  1.,  1., 25., 19.,  5., 17., 17., 15., 15., 15., 48.,  2., 42.,  4., 11., 11., 28., 22.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gains = x[topk_idxs]\n",
    "gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8b64e-c4a8-4a10-baf9-af78d15e4aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.6309, 0.5000, 0.4307, 0.3869, 0.3562, 0.3333, 0.3155, 0.3010, 0.2891, 0.2789, 0.2702, 0.2626, 0.2560, 0.2500, 0.2447, 0.2398, 0.2354, 0.2314, 0.2277])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = 1/torch.log2(2.0 + torch.arange(20))\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824a067-1a32-4007-a414-a322ed56a8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000e+00, 1.2619e+00, 1.0000e+00, 8.6135e-01, 1.2981e+07, 1.8676e+05, 1.0667e+01, 4.1349e+04, 3.9457e+04, 9.4721e+03, 9.1404e+03, 8.8552e+03, 7.3929e+13, 1.0238e+00, 1.0995e+12, 3.9144e+00,\n",
       "        4.9114e+02, 4.8212e+02, 6.2110e+07, 9.5492e+05])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcg = torch.pow(2, gains) * dfs\n",
    "dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca341f3-8839-441d-ae8a-6d9571e371c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48., 42., 34., 30., 29., 28., 25., 22., 22., 22., 19., 17., 17., 17., 17., 16., 15., 15., 15., 14.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_x, _ = torch.topk(x, k=20, dim=-1, largest=True)\n",
    "topk_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308fb352-8b10-48fe-8335-f78b6fb7c984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8147e+14, 4.3980e+12, 1.7180e+10, 1.0737e+09, 5.3687e+08, 2.6844e+08, 3.3554e+07, 4.1943e+06, 4.1943e+06, 4.1943e+06, 5.2429e+05, 1.3107e+05, 1.3107e+05, 1.3107e+05, 1.3107e+05, 6.5536e+04,\n",
       "        3.2768e+04, 3.2768e+04, 3.2768e+04, 1.6384e+04])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_gains = torch.pow(2, topk_x)\n",
    "i_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906fc5ae-1462-4447-9bed-face3746c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idcg = i_gains*dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8791c94-8704-43c6-884e-a54237a0ef1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8147e+14, 2.7749e+12, 8.5899e+09, 4.6244e+08, 2.0769e+08, 9.5619e+07, 1.1185e+07, 1.3232e+06, 1.2626e+06, 1.2124e+06, 1.4625e+05, 3.5421e+04, 3.4426e+04, 3.3549e+04, 3.2768e+04, 1.6033e+04,\n",
       "        7.8582e+03, 7.7139e+03, 7.5818e+03, 3.7301e+03])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6bfe95-1722-4ed6-9f49-542471498f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_at_k = dcg.sum()/idcg.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7025b1-150f-4b3f-890c-a2bbe7198899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2639)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae8b6b-56bf-4506-b6dc-3468d1647189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| trn.shape: torch.Size([8922, 57352, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8922, 57352, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trn, _ = torch.load('trn_val_split_tiny.pkl')\n",
    "trn, _ = torch.load('trn_val_split.pkl')\n",
    "trn = trn.to(\"cuda:0\")\n",
    "# trn_data = dls.train.dataset.to(\"cuda:0\")\n",
    "ic(trn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2a27c-34fe-4b79-9470-9451530c0a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.37 s, sys: 0 ns, total: 5.37 s\n",
      "Wall time: 5.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ndcg_at_k = ndcg_at_k(trn, model, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe32e8-9a43-436b-8176-23f3b4af674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| _ndcg_at_k.shape: torch.Size([1, 8922])\n",
      "    _ndcg_at_k.min(): tensor(4.7923e-20, device='cuda:0')\n",
      "    _ndcg_at_k.mean(): tensor(0.1285, device='cuda:0')\n",
      "    _ndcg_at_k.max(): tensor(0.9074, device='cuda:0')\n",
      "    _ndcg_at_k.median(): tensor(0.0614, device='cuda:0')\n",
      "    _ndcg_at_k.std(): tensor(0.1649, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ic(_ndcg_at_k.shape, _ndcg_at_k.min(), _ndcg_at_k.mean(), _ndcg_at_k.max(), _ndcg_at_k.median(), _ndcg_at_k.std());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c212d-84c0-461b-a3ef-8319eb0246e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = accuracy(trn, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecc5052-77ae-4bcd-9fe1-de5ff5aba79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5699, device='cuda:0'), tensor(0.0170, device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean(), a.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b75e44-bc1a-44ed-9ac3-6f89d7fcc2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trn.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17630d19-edd6-43a9-9d19-fbd620258cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = learner.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c53296-bddd-4ba1-b1ee-54a5a72afb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 104, 328, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca3fe51-e476-4aaf-ac36-1a97905cac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, *_, test = ndcg(y, x, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fead452-64e7-4166-96fc-09b7524036df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 104, 328]), torch.Size([1, 104]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68800681-6217-434a-a11d-fad5fa8981c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4002, device='cuda:0'), tensor(0.3429, device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.mean(), test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1b466-2656-4d0b-8212-7abacdbc5762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22732760906219482"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(_ndcg_at_k.cpu().numpy(), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec7893-c8df-47d3-b680-75d26ecb60a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3ab87-26bd-4efd-91a3-4928739fc98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68787200-f373-4bd7-85ba-d12c0b9d270a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b790be-4c6f-48f7-a2ad-bc25d77f2fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['token_factors.weight', 'label_factors.weight', 'layers.0.weight', 'layers.0.bias', 'layers.2.weight', 'layers.2.bias'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_logger.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244bc1f-4795-4d3a-bf68-bdebbb3f8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.stack(loss_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b18e8-0541-479e-a8be-788b0c5e68b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = dict()\n",
    "for k,v in grad_logger.items():\n",
    "    grads[k] = torch.stack(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20076f7d-7bbb-4b8f-810e-ae7279138ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_tw = grads['token_factors.weight'].mean((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1abd968-3e11-4593-8dbb-fe246b19c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_norm(t):\n",
    "    return t.square().mean().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036a15b-29a2-4aa5-add3-e0098fa978a9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909215b2-f39a-4253-b726-8706568a90de",
   "metadata": {},
   "source": [
    "Manually running grad updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995bc45b-5d01-40e2-8c1f-7490ae24a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb_iter= iter(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a15e2-43c5-4a3d-bb41-b80d8fca4932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2231, 64, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = next(xb_iter)\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94bd64-4f2e-45f4-b51f-088047df631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| preds.shape: torch.Size([32, 2231, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "preds = model(xb)\n",
    "ic(preds.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabcb407-cda1-4c4c-9be5-4b5ebe6cc13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| preds.min(): tensor(2.8571, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "    preds.max(): tensor(8.1702, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "    preds.mean(): tensor(5.4884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "    preds.std(): tensor(0.5131, device='cuda:0', grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ic(preds.min(), preds.max(), preds.mean(), preds.std());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c69d6-e0dd-4589-bdd0-fffa9292220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%debug\n",
    "srtd_preds, lambda_i = rank_loss(preds, xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8989ba-8132-46b8-8136-734136c21d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| lambda_i.min(): tensor(-20.7688, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "    lambda_i.max(): tensor(20.7013, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "    lambda_i.mean(): tensor(1.7099e-09, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "    lambda_i.std(): tensor(9.3547, device='cuda:0', grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ic(lambda_i.min(), lambda_i.max(), lambda_i.mean(), lambda_i.std());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71164ee8-2841-4529-a96d-44f8b1cc80d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing\n",
    "btch_num = 0; lbl_num = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32632f-d955-417f-9ccc-2a23b3583d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([58., 51., 41., 35., 34., 33., 32., 29., 27., 26., 26., 23., 17., 17., 16., 16., 15., 15., 14., 13., 13., 13., 12., 12., 11., 11., 10.,  9.,  9.,  9.,  9.,  8.,  7.,  7.,  7.,  6.,  6.,  5.,\n",
       "         4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  3.,  3.,  3.,  3.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  1.,  1.], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srtd_relvs[btch_num, lbl_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4eac1-98ca-4203-adc9-2c3286682c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.0115, 5.4024, 5.5242, 6.1972, 5.0738, 5.3549, 6.2103, 5.1479, 5.6495, 4.7952, 4.4402, 5.8002, 5.6312, 5.5360, 6.3023, 4.5941, 5.2382, 5.4365, 5.5020, 4.8909, 5.0563, 5.9787, 4.7818, 4.4187,\n",
       "        4.8232, 5.6167, 5.8534, 4.9102, 5.7103, 5.4111, 4.7474, 5.6442, 5.2318, 5.3944, 5.3537, 5.1176, 5.5286, 5.1726, 4.5416, 5.6754, 5.7729, 5.0517, 5.7603, 5.0673, 5.0939, 4.6403, 5.8132, 5.7837,\n",
       "        4.6614, 5.5111, 5.6013, 4.7823, 4.2443, 5.3036, 4.8616, 6.1921, 6.2745, 5.9529, 5.3485, 5.5093, 5.5865, 4.6753, 5.6905, 4.8105], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srtd_preds[btch_num, lbl_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca151df7-b912-4cd1-af17-0fb4a495a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (ij, pi_pj[btch_num, lbl_num],  (pi-pj)[btch_num, lbl_num].unsqueeze(-1), exp_ij[btch_num, lbl_num].unsqueeze(-1), torch.sign(si-sj)[btch_num, lbl_num].unsqueeze(-1), lambda_ij[btch_num, lbl_num].unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fa5f4-9396-4069-9688-97e3e01a2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.concat(data, dim=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c9f77-3f5f-4879-8131-f41a10ceee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['i', 'j', 'pi', 'pj', 'pi-pj', 'exp_ij', 'signs', 'lambda_ij'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092aec08-a20d-4267-80ca-2272abc51991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c_ij'] = 0.5 * ( 1 - df['signs']) * .5 * df['pi-pj'] + np.log(1 + np.exp(-.5*(df['pi-pj'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bbcd35-6488-4499-a2a4-46beebdb18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c84807-3db6-4903-ba93-ef5109ae679a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.921943349842791"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(.5*-0.162543)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbec8da-8ef8-4375-98fb-f5085171b822",
   "metadata": {},
   "source": [
    "This is where 32 is more relevant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a722102c-114a-42ef-8f2c-a74940e79d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.i == 32]#.lambda_ij.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde04bea-dbb1-4fd7-a7e1-10102044ce26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.4099374"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add = df[df.i == 32].lambda_ij.sum()\n",
    "add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1ad1c-8550-431e-890f-8c708262625a",
   "metadata": {},
   "source": [
    "This is where 32 is less relevant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4730c-964a-4a4f-b8c2-a7f74f740e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.j == 32]#.lambda_ij.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3bcfa-6738-44cd-a268-1e718a629526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.798852"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = df[df.j == 32].lambda_ij.sum()\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4878714-7428-40bf-9d99-2b4d2ebfc253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3889146"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add - sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a7dcf-87eb-4654-b4f3-1b78eb0055bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_i[btch_num, lbl_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e50e5-53da-4fc5-9685-035dd147c8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.18950351590560352, 0.4764355204802511)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".5 * -1/(1+np.exp(0.5*.987530)), np.log(1 + np.exp(-.5*.987530))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a678b-e9fe-4914-b737-41101e41f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda_i = pd.DataFrame(lambda_i[btch_num, lbl_num], columns=['lambda_i'])\n",
    "df_lambda_i['i'] = range(len(df_lambda_i))\n",
    "cols = list(df_lambda_i.columns)\n",
    "df_lambda_i = df_lambda_i[cols[::-1]]\n",
    "df_lambda_i['preds'] = srtd_preds[btch_num, lbl_num].detach().cpu().numpy()\n",
    "df_lambda_i['relvs'] = srtd_relvs[btch_num, lbl_num].detach().cpu().numpy()\n",
    "ranks = df_lambda_i.preds.to_numpy().argsort()[::-1].argsort()\n",
    "df_lambda_i['preds_rank'] = ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff587d-d275-42dd-b0f6-f4e8ccfcb2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lambda_i\n",
    "# df_lambda_i.sort_values(by='preds', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f561821-3072-4159-be85-dfd3ecd34298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fde1768a-e203-4258-97ee-d1c2fa63633d",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b022a7-625f-4b22-b9f1-5385951d7334",
   "metadata": {},
   "source": [
    "**Plotting losses and metrics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080bfbaa-9bf3-48e5-90a6-d7c222ce6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15,8))\n",
    "loss = L(loss_logger).map(torch.Tensor.item)\n",
    "val_loss = L(metric_logger).itemgot(0)\n",
    "val_acc = L(metric_logger).itemgot(-1)\n",
    "val_ndcg = L(metric_logger).itemgot(2)\n",
    "\n",
    "# axes[0,0].scatter(range(len(loss)), loss)\n",
    "axes[0,0].plot(range(len(loss)), loss)\n",
    "axes[0,0].set_xlabel('batches*epochs')\n",
    "axes[0,0].set_ylabel('train loss')\n",
    "\n",
    "axes[0,1].plot(val_loss)\n",
    "axes[0,1].set_xlabel('epochs')\n",
    "axes[0,1].set_ylabel('val loss')\n",
    "\n",
    "axes[1, 0].plot(val_acc)\n",
    "axes[1,0].set_xlabel('epochs')\n",
    "axes[1,0].set_ylabel('val accuracy')\n",
    "\n",
    "axes[1,1].plot(val_ndcg)\n",
    "axes[1,1].set_xlabel('epochs')\n",
    "axes[1,1].set_ylabel('val ndcg@6 (candidate 16)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc266c9-f06c-477f-894b-94e7793b9942",
   "metadata": {},
   "source": [
    "**Plotting Statistics of the Model Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77b789-c482-4543-b5d1-c26f3f5ecfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(15,8), sharex=True)\n",
    "for (k,v), ax in zip(grad_logger.items(), axes.flatten()):\n",
    "    mean_grads = L(v).map(compose(torch.Tensor.square, torch.Tensor.mean, torch.Tensor.sqrt, torch.Tensor.item))\n",
    "    # sparsity = L(v).map(sparsity)\n",
    "    ax.plot(mean_grads, color='r', label='mean')\n",
    "    ax.set_ylabel(k)\n",
    "    # ax_a = ax.twinx()\n",
    "    # ax_a.plot(sparsity, color='b', label='sparsity')\n",
    "    ax.legend(loc='best')\n",
    "    # ax_a.legend(loc='best')\n",
    "fig.suptitle('RMS of the Gradients of Model Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04955c8f-7e51-4a13-aa14-da92dff6955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity(t): \n",
    "    return 1 - (torch.count_nonzero(t)/t.numel()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d0316-4f9d-427f-a9f6-2b6afe5dac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(15,8), sharex=True)\n",
    "for (k,v), ax in zip(grad_logger.items(), axes.flatten()):\n",
    "    sp = L(v).map(sparsity)\n",
    "    ax.scatter(range(len(sp)), sp, color='r', label='sparsity')\n",
    "    ax.set_ylabel(k)\n",
    "    # ax_a = ax.twinx()\n",
    "    # ax_a.plot(sparsity, color='b', label='sparsity')\n",
    "    ax.legend(loc='best')\n",
    "    # ax_a.legend(loc='best')\n",
    "fig.suptitle('Sparsity of the Model Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30200208-19e9-4145-a6db-162c949c7a62",
   "metadata": {},
   "source": [
    "#### Debugging why nan/inf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75790bc0-37ff-4f74-bb67-71a81d000379",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = learner.opt_func(model.parameters(), learner.lr)\n",
    "grad_func = learner.grad_func\n",
    "loss_func = learner.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31eccb9-a3f5-4455-8b36-7ee6556b9ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(functools.partial(<function rank_loss3>, gain_fn='exp', k=6, lambrank=True),\n",
       " <function xcube.l2r.gradients.loss_fn2(preds, xb, sigma=0.5)>,\n",
       " 0.01,\n",
       " functools.partial(<function Adam>, mom=0.9, wd=0.1))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_func, loss_func, learner.lr, learner.opt_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b0282-153d-4461-ae00-b0bfd3e76f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb in dls.train:\n",
    "    print(xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669cb56-0e72-41a4-a950-6209dd687368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='113' class='' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [113/113 04:05&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini-batch: 0\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -1.734759280225262e-05, p.std().item() = 1.0002665519714355\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0007847070228308439, p.std().item() = 0.9988294243812561\n",
      "n = 'layers.0.weight', p.mean().item() = 0.00018983049085363746, p.std().item() = 0.028825251385569572\n",
      "n = 'layers.0.bias', p.mean().item() = 0.0010731843067333102, p.std().item() = 0.031683795154094696\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0034287134185433388, p.std().item() = 0.061452098190784454\n",
      "n = 'layers.2.bias', p.mean().item() = 0.09137120097875595, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = 0.012845568358898163, preds.std().item() = 0.20282460749149323\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6947, device='cuda:0'), loss.std() = tensor(0.0061, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 5.82337511545461e-11, lambda_i.std().item() = 0.2391522228717804\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0002733718720264733, p.grad.std().item() = 2.4462618827819824\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0012455456890165806, p.grad.std().item() = 0.16901808977127075\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 4.3943610191345215, p.grad.std().item() = 1497.13623046875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 176.0182647705078, p.grad.std().item() = 1212.4471435546875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 229.03125, p.grad.std().item() = 16035.4541015625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00012302398681640625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -1.979047738132067e-05, p.std().item() = 0.9992666840553284\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0008219213923439384, p.std().item() = 0.9978305101394653\n",
      "n = 'layers.0.weight', p.mean().item() = 0.0001681403664406389, p.std().item() = 0.03046691045165062\n",
      "n = 'layers.0.bias', p.mean().item() = -0.0003278888761997223, p.std().item() = 0.03212932497262955\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004625285975635052, p.std().item() = 0.05998653545975685\n",
      "n = 'layers.2.bias', p.mean().item() = 0.10052809119224548, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 1\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -1.979047738132067e-05, p.std().item() = 0.9992666840553284\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0008219213923439384, p.std().item() = 0.9978305101394653\n",
      "n = 'layers.0.weight', p.mean().item() = 0.0001681403664406389, p.std().item() = 0.03046691045165062\n",
      "n = 'layers.0.bias', p.mean().item() = -0.0003278888761997223, p.std().item() = 0.03212932497262955\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004625285975635052, p.std().item() = 0.05998653545975685\n",
      "n = 'layers.2.bias', p.mean().item() = 0.10052809119224548, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.0238512996584177, preds.std().item() = 0.3368228077888489\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7032, device='cuda:0'), loss.std() = tensor(0.0128, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.296743847502341e-11, lambda_i.std().item() = 0.20782262086868286\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -8.536045788787305e-05, p.grad.std().item() = 5.414724826812744\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0010023872600868344, p.grad.std().item() = 0.19096243381500244\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 30.21754264831543, p.grad.std().item() = 1553.90478515625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1344.9471435546875, p.grad.std().item() = 1631.909423828125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 1388.9776611328125, p.grad.std().item() = 27199.939453125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0004138946533203125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -2.4510287403245457e-05, p.std().item() = 0.998268187046051\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0008997046970762312, p.std().item() = 0.9968523383140564\n",
      "n = 'layers.0.weight', p.mean().item() = 5.612354652839713e-05, p.std().item() = 0.03220618516206741\n",
      "n = 'layers.0.bias', p.mean().item() = -0.006230754777789116, p.std().item() = 0.03282256796956062\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004483462776988745, p.std().item() = 0.054828766733407974\n",
      "n = 'layers.2.bias', p.mean().item() = 0.09537748247385025, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 2\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -2.4510287403245457e-05, p.std().item() = 0.998268187046051\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0008997046970762312, p.std().item() = 0.9968523383140564\n",
      "n = 'layers.0.weight', p.mean().item() = 5.612354652839713e-05, p.std().item() = 0.03220618516206741\n",
      "n = 'layers.0.bias', p.mean().item() = -0.006230754777789116, p.std().item() = 0.03282256796956062\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004483462776988745, p.std().item() = 0.054828766733407974\n",
      "n = 'layers.2.bias', p.mean().item() = 0.09537748247385025, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.02285429649055004, preds.std().item() = 0.36543673276901245\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7038, device='cuda:0'), loss.std() = tensor(0.0132, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.366449976733193e-11, lambda_i.std().item() = 0.2444065660238266\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.000248988188104704, p.grad.std().item() = 5.883663654327393\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.00216209189966321, p.grad.std().item() = 0.1844872236251831\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 11.176956176757812, p.grad.std().item() = 1314.9306640625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 932.0648803710938, p.grad.std().item() = 1259.3189697265625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 554.9796142578125, p.grad.std().item() = 22262.0625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0003662109375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -3.0107039492577314e-05, p.std().item() = 0.9972711205482483\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0009172670543193817, p.std().item() = 0.9958670139312744\n",
      "n = 'layers.0.weight', p.mean().item() = -4.692780930781737e-05, p.std().item() = 0.033923957496881485\n",
      "n = 'layers.0.bias', p.mean().item() = -0.012285151518881321, p.std().item() = 0.03360461816191673\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0042050061747431755, p.std().item() = 0.049573227763175964\n",
      "n = 'layers.2.bias', p.mean().item() = 0.08829467743635178, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 3\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -3.0107039492577314e-05, p.std().item() = 0.9972711205482483\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0009172670543193817, p.std().item() = 0.9958670139312744\n",
      "n = 'layers.0.weight', p.mean().item() = -4.692780930781737e-05, p.std().item() = 0.033923957496881485\n",
      "n = 'layers.0.bias', p.mean().item() = -0.012285151518881321, p.std().item() = 0.03360461816191673\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0042050061747431755, p.std().item() = 0.049573227763175964\n",
      "n = 'layers.2.bias', p.mean().item() = 0.08829467743635178, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.00398308876901865, preds.std().item() = 0.36827531456947327\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7011, device='cuda:0'), loss.std() = tensor(0.0103, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 4.3101324592731416e-11, lambda_i.std().item() = 0.19687506556510925\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0009061897289939225, p.grad.std().item() = 7.3087921142578125\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0044909012503921986, p.grad.std().item() = 0.21172818541526794\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -10.048721313476562, p.grad.std().item() = 1496.6190185546875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1798.8193359375, p.grad.std().item() = 1847.297119140625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 6389.28125, p.grad.std().item() = 40917.58984375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0003662109375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -3.6259669286664575e-05, p.std().item() = 0.9962751269340515\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0008934364304877818, p.std().item() = 0.9948356747627258\n",
      "n = 'layers.0.weight', p.mean().item() = -0.00014212630048859864, p.std().item() = 0.03538146987557411\n",
      "n = 'layers.0.bias', p.mean().item() = -0.018614616245031357, p.std().item() = 0.034054629504680634\n",
      "n = 'layers.2.weight', p.mean().item() = -0.003899357281625271, p.std().item() = 0.044018663465976715\n",
      "n = 'layers.2.bias', p.mean().item() = 0.08033449947834015, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 4\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -3.6259669286664575e-05, p.std().item() = 0.9962751269340515\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0008934364304877818, p.std().item() = 0.9948356747627258\n",
      "n = 'layers.0.weight', p.mean().item() = -0.00014212630048859864, p.std().item() = 0.03538146987557411\n",
      "n = 'layers.0.bias', p.mean().item() = -0.018614616245031357, p.std().item() = 0.034054629504680634\n",
      "n = 'layers.2.weight', p.mean().item() = -0.003899357281625271, p.std().item() = 0.044018663465976715\n",
      "n = 'layers.2.bias', p.mean().item() = 0.08033449947834015, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.01403773669153452, preds.std().item() = 0.3300888240337372\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6904, device='cuda:0'), loss.std() = tensor(0.0121, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.392540217811884e-11, lambda_i.std().item() = 0.22984090447425842\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0008083858992904425, p.grad.std().item() = 5.105569839477539\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.00223007844761014, p.grad.std().item() = 0.1981440782546997\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 2.4402337074279785, p.grad.std().item() = 993.99462890625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 923.9244384765625, p.grad.std().item() = 1102.767333984375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 4738.8369140625, p.grad.std().item() = 25735.38671875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0005950927734375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.335599805926904e-05, p.std().item() = 0.9952811002731323\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0008643674664199352, p.std().item() = 0.9938316345214844\n",
      "n = 'layers.0.weight', p.mean().item() = -0.00024672079598531127, p.std().item() = 0.036858219653367996\n",
      "n = 'layers.0.bias', p.mean().item() = -0.024773763492703438, p.std().item() = 0.03478144109249115\n",
      "n = 'layers.2.weight', p.mean().item() = -0.003774472279474139, p.std().item() = 0.03887547552585602\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07174249738454819, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 5\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.335599805926904e-05, p.std().item() = 0.9952811002731323\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0008643674664199352, p.std().item() = 0.9938316345214844\n",
      "n = 'layers.0.weight', p.mean().item() = -0.00024672079598531127, p.std().item() = 0.036858219653367996\n",
      "n = 'layers.0.bias', p.mean().item() = -0.024773763492703438, p.std().item() = 0.03478144109249115\n",
      "n = 'layers.2.weight', p.mean().item() = -0.003774472279474139, p.std().item() = 0.03887547552585602\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07174249738454819, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.009866004809737206, preds.std().item() = 0.273455411195755\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6932, device='cuda:0'), loss.std() = tensor(0.0085, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.626959397904031e-11, lambda_i.std().item() = 0.2591142952442169\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.00021730204753112048, p.grad.std().item() = 4.794558525085449\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0021780887618660927, p.grad.std().item() = 0.16672763228416443\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -1.0056942701339722, p.grad.std().item() = 1113.4127197265625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -50.68861389160156, p.grad.std().item() = 672.2142333984375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 2886.98583984375, p.grad.std().item() = 22725.99609375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0006580352783203125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.136263644089922e-05, p.std().item() = 0.9942889213562012\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0008131081704050303, p.std().item() = 0.9928547143936157\n",
      "n = 'layers.0.weight', p.mean().item() = -0.00033119693398475647, p.std().item() = 0.038393303751945496\n",
      "n = 'layers.0.bias', p.mean().item() = -0.03017120249569416, p.std().item() = 0.0360039547085762\n",
      "n = 'layers.2.weight', p.mean().item() = -0.003872215747833252, p.std().item() = 0.03527938574552536\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06874794512987137, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 6\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.136263644089922e-05, p.std().item() = 0.9942889213562012\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0008131081704050303, p.std().item() = 0.9928547143936157\n",
      "n = 'layers.0.weight', p.mean().item() = -0.00033119693398475647, p.std().item() = 0.038393303751945496\n",
      "n = 'layers.0.bias', p.mean().item() = -0.03017120249569416, p.std().item() = 0.0360039547085762\n",
      "n = 'layers.2.weight', p.mean().item() = -0.003872215747833252, p.std().item() = 0.03527938574552536\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06874794512987137, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.0023910210002213717, preds.std().item() = 0.2315392941236496\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6921, device='cuda:0'), loss.std() = tensor(0.0096, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.731320362218796e-11, lambda_i.std().item() = 0.29426488280296326\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0003299351956229657, p.grad.std().item() = 3.6763763427734375\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.000873811193741858, p.grad.std().item() = 0.14119520783424377\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 6.117428779602051, p.grad.std().item() = 792.339599609375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -165.1493377685547, p.grad.std().item() = 552.1015014648438\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 5267.7666015625, p.grad.std().item() = 16270.1328125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0011444091796875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.927454913035035e-05, p.std().item() = 0.9932987093925476\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0007807862712070346, p.std().item() = 0.9918769001960754\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0003999804030172527, p.std().item() = 0.039926961064338684\n",
      "n = 'layers.0.bias', p.mean().item() = -0.034492362290620804, p.std().item() = 0.03738541156053543\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004401594866067171, p.std().item() = 0.033119793981313705\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06335367262363434, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 7\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.927454913035035e-05, p.std().item() = 0.9932987093925476\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0007807862712070346, p.std().item() = 0.9918769001960754\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0003999804030172527, p.std().item() = 0.039926961064338684\n",
      "n = 'layers.0.bias', p.mean().item() = -0.034492362290620804, p.std().item() = 0.03738541156053543\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004401594866067171, p.std().item() = 0.033119793981313705\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06335367262363434, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.016735423356294632, preds.std().item() = 0.23388023674488068\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6930, device='cuda:0'), loss.std() = tensor(0.0078, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.350400760801733e-11, lambda_i.std().item() = 0.22448565065860748\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00043026640196330845, p.grad.std().item() = 3.4330861568450928\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.002095174277201295, p.grad.std().item() = 0.1476789116859436\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 1.875321388244629, p.grad.std().item() = 787.8773193359375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 93.98866271972656, p.grad.std().item() = 653.4296875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 5430.90625, p.grad.std().item() = 18439.2421875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0001201629638671875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.630102870985866e-05, p.std().item() = 0.9923102855682373\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0007691890350542963, p.std().item() = 0.9909272193908691\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0004519916546996683, p.std().item() = 0.041467759758234024\n",
      "n = 'layers.0.bias', p.mean().item() = -0.038464877754449844, p.std().item() = 0.038503892719745636\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005172367673367262, p.std().item() = 0.03148559108376503\n",
      "n = 'layers.2.bias', p.mean().item() = 0.0589672327041626, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 8\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.630102870985866e-05, p.std().item() = 0.9923102855682373\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0007691890350542963, p.std().item() = 0.9909272193908691\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0004519916546996683, p.std().item() = 0.041467759758234024\n",
      "n = 'layers.0.bias', p.mean().item() = -0.038464877754449844, p.std().item() = 0.038503892719745636\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005172367673367262, p.std().item() = 0.03148559108376503\n",
      "n = 'layers.2.bias', p.mean().item() = 0.0589672327041626, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.06818319112062454, preds.std().item() = 0.24016143381595612\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6933, device='cuda:0'), loss.std() = tensor(0.0087, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.735062673181915e-11, lambda_i.std().item() = 0.3032383322715759\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0004962895764037967, p.grad.std().item() = 3.636373519897461\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.004691338632255793, p.grad.std().item() = 0.15235140919685364\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 8.215487480163574, p.grad.std().item() = 780.3555908203125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -371.06536865234375, p.grad.std().item() = 901.2301025390625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 3105.22265625, p.grad.std().item() = 28268.662109375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00032806396484375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.179931708378717e-05, p.std().item() = 0.9913239479064941\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0007064162055030465, p.std().item() = 0.989963710308075\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0005037300288677216, p.std().item() = 0.04288439452648163\n",
      "n = 'layers.0.bias', p.mean().item() = -0.04190707206726074, p.std().item() = 0.03960277885198593\n",
      "n = 'layers.2.weight', p.mean().item() = -0.006340104155242443, p.std().item() = 0.031232010573148727\n",
      "n = 'layers.2.bias', p.mean().item() = 0.054184552282094955, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 9\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.179931708378717e-05, p.std().item() = 0.9913239479064941\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0007064162055030465, p.std().item() = 0.989963710308075\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0005037300288677216, p.std().item() = 0.04288439452648163\n",
      "n = 'layers.0.bias', p.mean().item() = -0.04190707206726074, p.std().item() = 0.03960277885198593\n",
      "n = 'layers.2.weight', p.mean().item() = -0.006340104155242443, p.std().item() = 0.031232010573148727\n",
      "n = 'layers.2.bias', p.mean().item() = 0.054184552282094955, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.09088834375143051, preds.std().item() = 0.24660824239253998\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6935, device='cuda:0'), loss.std() = tensor(0.0078, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.493160258942311e-11, lambda_i.std().item() = 0.31312355399131775\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00014737877063453197, p.grad.std().item() = 3.828598976135254\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0008374953176826239, p.grad.std().item() = 0.13778898119926453\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -4.7578606605529785, p.grad.std().item() = 811.8342895507812\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -170.13246154785156, p.grad.std().item() = 505.401123046875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 2536.87744140625, p.grad.std().item() = 17572.666015625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000263214111328125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.576629286631942e-05, p.std().item() = 0.990339457988739\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0006576450541615486, p.std().item() = 0.9890099167823792\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0005379021749831736, p.std().item() = 0.04428759589791298\n",
      "n = 'layers.0.bias', p.mean().item() = -0.04453577473759651, p.std().item() = 0.04083889722824097\n",
      "n = 'layers.2.weight', p.mean().item() = -0.007510187570005655, p.std().item() = 0.03161762282252312\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04920872673392296, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 10\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.576629286631942e-05, p.std().item() = 0.990339457988739\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0006576450541615486, p.std().item() = 0.9890099167823792\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0005379021749831736, p.std().item() = 0.04428759589791298\n",
      "n = 'layers.0.bias', p.mean().item() = -0.04453577473759651, p.std().item() = 0.04083889722824097\n",
      "n = 'layers.2.weight', p.mean().item() = -0.007510187570005655, p.std().item() = 0.03161762282252312\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04920872673392296, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.15574133396148682, preds.std().item() = 0.27457931637763977\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6942, device='cuda:0'), loss.std() = tensor(0.0093, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.071233793480957e-11, lambda_i.std().item() = 0.26228341460227966\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0006477271672338247, p.grad.std().item() = 4.122488975524902\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.003667257959023118, p.grad.std().item() = 0.16403594613075256\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -3.4189658164978027, p.grad.std().item() = 759.8529663085938\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 167.7137451171875, p.grad.std().item() = 730.7295532226562\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -1735.4674072265625, p.grad.std().item() = 23047.3828125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 7.82012939453125e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.810651004547253e-05, p.std().item() = 0.9893563985824585\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0005901889526285231, p.std().item() = 0.9880493879318237\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0005816973280161619, p.std().item() = 0.045565444976091385\n",
      "n = 'layers.0.bias', p.mean().item() = -0.047480352222919464, p.std().item() = 0.041656412184238434\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008521482348442078, p.std().item() = 0.03174465894699097\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04452446848154068, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 11\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.810651004547253e-05, p.std().item() = 0.9893563985824585\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0005901889526285231, p.std().item() = 0.9880493879318237\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0005816973280161619, p.std().item() = 0.045565444976091385\n",
      "n = 'layers.0.bias', p.mean().item() = -0.047480352222919464, p.std().item() = 0.041656412184238434\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008521482348442078, p.std().item() = 0.03174465894699097\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04452446848154068, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.1975356936454773, preds.std().item() = 0.2907639443874359\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6979, device='cuda:0'), loss.std() = tensor(0.0090, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.804373731128521e-11, lambda_i.std().item() = 0.2568388879299164\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -7.012858259258792e-05, p.grad.std().item() = 5.507950782775879\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0008299019536934793, p.grad.std().item() = 0.1597623974084854\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 3.655200242996216, p.grad.std().item() = 898.6481323242188\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 40.25695037841797, p.grad.std().item() = 498.5871887207031\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -2968.966064453125, p.grad.std().item() = 18247.099609375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00107574462890625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.925670070108026e-05, p.std().item() = 0.9883748888969421\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0005406553391367197, p.std().item() = 0.9870822429656982\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006115650176070631, p.std().item() = 0.04678146541118622\n",
      "n = 'layers.0.bias', p.mean().item() = -0.05015413463115692, p.std().item() = 0.04249199479818344\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00927781406790018, p.std().item() = 0.03196251392364502\n",
      "n = 'layers.2.bias', p.mean().item() = 0.043563924729824066, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 12\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.925670070108026e-05, p.std().item() = 0.9883748888969421\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0005406553391367197, p.std().item() = 0.9870822429656982\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006115650176070631, p.std().item() = 0.04678146541118622\n",
      "n = 'layers.0.bias', p.mean().item() = -0.05015413463115692, p.std().item() = 0.04249199479818344\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00927781406790018, p.std().item() = 0.03196251392364502\n",
      "n = 'layers.2.bias', p.mean().item() = 0.043563924729824066, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.2372158318758011, preds.std().item() = 0.34540656208992004\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6964, device='cuda:0'), loss.std() = tensor(0.0122, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.473420659045217e-11, lambda_i.std().item() = 0.23631121218204498\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00056172237964347, p.grad.std().item() = 5.3201003074646\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.001134171150624752, p.grad.std().item() = 0.16430844366550446\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 2.7274093627929688, p.grad.std().item() = 796.9984741210938\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 76.27427673339844, p.grad.std().item() = 677.970703125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 6639.6328125, p.grad.std().item() = 19417.923828125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00036334991455078125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.950973667902872e-05, p.std().item() = 0.9873952269554138\n",
      "n = 'label_factors.weight', p.mean().item() = 0.000489116064272821, p.std().item() = 0.9861137866973877\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006483712932094932, p.std().item() = 0.04792465642094612\n",
      "n = 'layers.0.bias', p.mean().item() = -0.052502259612083435, p.std().item() = 0.04318453371524811\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010249032638967037, p.std().item() = 0.032123517245054245\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04356195032596588, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 13\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.950973667902872e-05, p.std().item() = 0.9873952269554138\n",
      "n = 'label_factors.weight', p.mean().item() = 0.000489116064272821, p.std().item() = 0.9861137866973877\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006483712932094932, p.std().item() = 0.04792465642094612\n",
      "n = 'layers.0.bias', p.mean().item() = -0.052502259612083435, p.std().item() = 0.04318453371524811\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010249032638967037, p.std().item() = 0.032123517245054245\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04356195032596588, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.2778472304344177, preds.std().item() = 0.36728695034980774\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6925, device='cuda:0'), loss.std() = tensor(0.0113, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.1657186327340696e-10, lambda_i.std().item() = 0.3605416417121887\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0005267898086458445, p.grad.std().item() = 5.954685688018799\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.00011499591346364468, p.grad.std().item() = 0.20413242280483246\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -10.270813941955566, p.grad.std().item() = 987.6343994140625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -688.900146484375, p.grad.std().item() = 1150.1043701171875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -4042.53173828125, p.grad.std().item() = 47996.75\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00028896331787109375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.93615254224278e-05, p.std().item() = 0.9864174723625183\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0004382231563795358, p.std().item() = 0.9851678609848022\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006869324715808034, p.std().item() = 0.04909447580575943\n",
      "n = 'layers.0.bias', p.mean().item() = -0.05394052341580391, p.std().item() = 0.04432586207985878\n",
      "n = 'layers.2.weight', p.mean().item() = -0.011211153119802475, p.std().item() = 0.03345600888133049\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04423169791698456, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 14\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.93615254224278e-05, p.std().item() = 0.9864174723625183\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0004382231563795358, p.std().item() = 0.9851678609848022\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006869324715808034, p.std().item() = 0.04909447580575943\n",
      "n = 'layers.0.bias', p.mean().item() = -0.05394052341580391, p.std().item() = 0.04432586207985878\n",
      "n = 'layers.2.weight', p.mean().item() = -0.011211153119802475, p.std().item() = 0.03345600888133049\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04423169791698456, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.32200658321380615, preds.std().item() = 0.4078938663005829\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7113, device='cuda:0'), loss.std() = tensor(0.0150, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 5.88077364582773e-11, lambda_i.std().item() = 0.21744880080223083\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0009675712208263576, p.grad.std().item() = 7.393805027008057\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0004723479214590043, p.grad.std().item() = 0.2886631488800049\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -3.2236416339874268, p.grad.std().item() = 977.2217407226562\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1549.031494140625, p.grad.std().item() = 1487.4178466796875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -10248.3759765625, p.grad.std().item() = 54872.1640625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00034236907958984375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.932635344332084e-05, p.std().item() = 0.985440731048584\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0004186993173789233, p.std().item() = 0.9842067956924438\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007046989630907774, p.std().item() = 0.05008925125002861\n",
      "n = 'layers.0.bias', p.mean().item() = -0.05680171772837639, p.std().item() = 0.04478267952799797\n",
      "n = 'layers.2.weight', p.mean().item() = -0.011278082616627216, p.std().item() = 0.03271773084998131\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04402961954474449, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 15\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.932635344332084e-05, p.std().item() = 0.985440731048584\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0004186993173789233, p.std().item() = 0.9842067956924438\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007046989630907774, p.std().item() = 0.05008925125002861\n",
      "n = 'layers.0.bias', p.mean().item() = -0.05680171772837639, p.std().item() = 0.04478267952799797\n",
      "n = 'layers.2.weight', p.mean().item() = -0.011278082616627216, p.std().item() = 0.03271773084998131\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04402961954474449, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.35183560848236084, preds.std().item() = 0.42209070920944214\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7011, device='cuda:0'), loss.std() = tensor(0.0141, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 4.539727968544405e-11, lambda_i.std().item() = 0.24046844244003296\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00015684691607020795, p.grad.std().item() = 6.360663414001465\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0034086345694959164, p.grad.std().item() = 0.20368243753910065\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 6.974626541137695, p.grad.std().item() = 869.7683715820312\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 564.2564086914062, p.grad.std().item() = 905.4714965820312\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 1892.388671875, p.grad.std().item() = 31795.046875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0005950927734375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.94156439951621e-05, p.std().item() = 0.9844654202461243\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00038334119017235935, p.std().item() = 0.9832532405853271\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007225206354632974, p.std().item() = 0.05104856938123703\n",
      "n = 'layers.0.bias', p.mean().item() = -0.059839680790901184, p.std().item() = 0.04496107995510101\n",
      "n = 'layers.2.weight', p.mean().item() = -0.011283604428172112, p.std().item() = 0.03147054836153984\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04518416151404381, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 16\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.94156439951621e-05, p.std().item() = 0.9844654202461243\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00038334119017235935, p.std().item() = 0.9832532405853271\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007225206354632974, p.std().item() = 0.05104856938123703\n",
      "n = 'layers.0.bias', p.mean().item() = -0.059839680790901184, p.std().item() = 0.04496107995510101\n",
      "n = 'layers.2.weight', p.mean().item() = -0.011283604428172112, p.std().item() = 0.03147054836153984\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04518416151404381, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.36531636118888855, preds.std().item() = 0.42687085270881653\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6995, device='cuda:0'), loss.std() = tensor(0.0146, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.887863196469723e-11, lambda_i.std().item() = 0.3665689527988434\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0005639431765303016, p.grad.std().item() = 6.278127670288086\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.001263146405108273, p.grad.std().item() = 0.2422531694173813\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 11.734228134155273, p.grad.std().item() = 935.3468017578125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -636.6746826171875, p.grad.std().item() = 918.9573364257812\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -16239.912109375, p.grad.std().item() = 53762.0390625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000209808349609375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.945272955112159e-05, p.std().item() = 0.9834915995597839\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0003568331303540617, p.std().item() = 0.9823163151741028\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007471769349649549, p.std().item() = 0.052028633654117584\n",
      "n = 'layers.0.bias', p.mean().item() = -0.06203339621424675, p.std().item() = 0.045410238206386566\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010954679921269417, p.std().item() = 0.031407278031110764\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04574957117438316, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 17\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.945272955112159e-05, p.std().item() = 0.9834915995597839\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0003568331303540617, p.std().item() = 0.9823163151741028\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007471769349649549, p.std().item() = 0.052028633654117584\n",
      "n = 'layers.0.bias', p.mean().item() = -0.06203339621424675, p.std().item() = 0.045410238206386566\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010954679921269417, p.std().item() = 0.031407278031110764\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04574957117438316, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.3512917757034302, preds.std().item() = 0.41389837861061096\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7010, device='cuda:0'), loss.std() = tensor(0.0106, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.806244539665386e-11, lambda_i.std().item() = 0.2856822907924652\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 2.0636432964238338e-05, p.grad.std().item() = 6.157074928283691\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.000839817977976054, p.grad.std().item() = 0.20478945970535278\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -5.4265851974487305, p.grad.std().item() = 777.1470947265625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -53.36471939086914, p.grad.std().item() = 585.3323364257812\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -755.8787231445312, p.grad.std().item() = 24207.818359375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0001983642578125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.907901454018429e-05, p.std().item() = 0.982519268989563\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0003368536417838186, p.std().item() = 0.9813818335533142\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007862143102101982, p.std().item() = 0.05296649411320686\n",
      "n = 'layers.0.bias', p.mean().item() = -0.06402834504842758, p.std().item() = 0.04594774544239044\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010699601843953133, p.std().item() = 0.03153456747531891\n",
      "n = 'layers.2.bias', p.mean().item() = 0.045806579291820526, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 18\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.907901454018429e-05, p.std().item() = 0.982519268989563\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0003368536417838186, p.std().item() = 0.9813818335533142\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007862143102101982, p.std().item() = 0.05296649411320686\n",
      "n = 'layers.0.bias', p.mean().item() = -0.06402834504842758, p.std().item() = 0.04594774544239044\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010699601843953133, p.std().item() = 0.03153456747531891\n",
      "n = 'layers.2.bias', p.mean().item() = 0.045806579291820526, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.355001300573349, preds.std().item() = 0.4185064136981964\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7012, device='cuda:0'), loss.std() = tensor(0.0116, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 5.1972058601190696e-11, lambda_i.std().item() = 0.31827834248542786\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0005108172190375626, p.grad.std().item() = 9.174160957336426\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.000153714616317302, p.grad.std().item() = 0.21147160232067108\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -7.137170791625977, p.grad.std().item() = 1043.2950439453125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -16.807981491088867, p.grad.std().item() = 601.5681762695312\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -520.9644165039062, p.grad.std().item() = 25493.544921875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0005645751953125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.827774243196473e-05, p.std().item() = 0.9815481901168823\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0003200179780833423, p.std().item() = 0.9804419875144958\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008088047034107149, p.std().item() = 0.05382091924548149\n",
      "n = 'layers.0.bias', p.mean().item() = -0.06589985638856888, p.std().item() = 0.046509094536304474\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010540027171373367, p.std().item() = 0.03182962164282799\n",
      "n = 'layers.2.bias', p.mean().item() = 0.047101981937885284, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 19\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.827774243196473e-05, p.std().item() = 0.9815481901168823\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0003200179780833423, p.std().item() = 0.9804419875144958\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008088047034107149, p.std().item() = 0.05382091924548149\n",
      "n = 'layers.0.bias', p.mean().item() = -0.06589985638856888, p.std().item() = 0.046509094536304474\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010540027171373367, p.std().item() = 0.03182962164282799\n",
      "n = 'layers.2.bias', p.mean().item() = 0.047101981937885284, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.34429579973220825, preds.std().item() = 0.44507896900177\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7004, device='cuda:0'), loss.std() = tensor(0.0137, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 5.7764123345682705e-11, lambda_i.std().item() = 0.2491500824689865\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00013562291860580444, p.grad.std().item() = 7.260527610778809\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.00067877396941185, p.grad.std().item() = 0.23841024935245514\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -26.193674087524414, p.grad.std().item() = 790.0252685546875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 448.6206970214844, p.grad.std().item() = 685.157470703125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -1338.6868896484375, p.grad.std().item() = 26541.451171875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0007305145263671875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.718068809481338e-05, p.std().item() = 0.980578601360321\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00030326598789542913, p.std().item() = 0.9795017838478088\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008058479870669544, p.std().item() = 0.054621994495391846\n",
      "n = 'layers.0.bias', p.mean().item() = -0.06798593699932098, p.std().item() = 0.04685985669493675\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010204744525253773, p.std().item() = 0.031685564666986465\n",
      "n = 'layers.2.bias', p.mean().item() = 0.046660564839839935, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 20\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.718068809481338e-05, p.std().item() = 0.980578601360321\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00030326598789542913, p.std().item() = 0.9795017838478088\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008058479870669544, p.std().item() = 0.054621994495391846\n",
      "n = 'layers.0.bias', p.mean().item() = -0.06798593699932098, p.std().item() = 0.04685985669493675\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010204744525253773, p.std().item() = 0.031685564666986465\n",
      "n = 'layers.2.bias', p.mean().item() = 0.046660564839839935, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.3439292311668396, preds.std().item() = 0.46283969283103943\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7021, device='cuda:0'), loss.std() = tensor(0.0150, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 5.870337549396254e-11, lambda_i.std().item() = 0.2588682472705841\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 6.782871787436306e-05, p.grad.std().item() = 6.271938800811768\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.00035314157139509916, p.grad.std().item() = 0.23873206973075867\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 10.678568840026855, p.grad.std().item() = 665.3027954101562\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 314.0838317871094, p.grad.std().item() = 583.0945434570312\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 1884.5745849609375, p.grad.std().item() = 20970.283203125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0003299713134765625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.586333231301978e-05, p.std().item() = 0.9796104431152344\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0002944444422610104, p.std().item() = 0.9785619378089905\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008115072268992662, p.std().item() = 0.055389709770679474\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07012443244457245, p.std().item() = 0.04704016447067261\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009911973029375076, p.std().item() = 0.03140944242477417\n",
      "n = 'layers.2.bias', p.mean().item() = 0.046960338950157166, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 21\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.586333231301978e-05, p.std().item() = 0.9796104431152344\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0002944444422610104, p.std().item() = 0.9785619378089905\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008115072268992662, p.std().item() = 0.055389709770679474\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07012443244457245, p.std().item() = 0.04704016447067261\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009911973029375076, p.std().item() = 0.03140944242477417\n",
      "n = 'layers.2.bias', p.mean().item() = 0.046960338950157166, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.33521121740341187, preds.std().item() = 0.442254900932312\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7003, device='cuda:0'), loss.std() = tensor(0.0209, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.992224854673879e-11, lambda_i.std().item() = 0.2987005412578583\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00010483441292308271, p.grad.std().item() = 6.024572849273682\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.00023342491476796567, p.grad.std().item() = 0.23395957052707672\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 10.196691513061523, p.grad.std().item() = 632.9849243164062\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -213.19882202148438, p.grad.std().item() = 406.73583984375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 3811.086181640625, p.grad.std().item() = 15096.2099609375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000762939453125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.451180135831237e-05, p.std().item() = 0.9786438345909119\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0002856570645235479, p.std().item() = 0.9776183366775513\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008182918536476791, p.std().item() = 0.056133050471544266\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07184911519289017, p.std().item() = 0.04725335165858269\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009853026829659939, p.std().item() = 0.031559057533741\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04565374553203583, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 22\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.451180135831237e-05, p.std().item() = 0.9786438345909119\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0002856570645235479, p.std().item() = 0.9776183366775513\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008182918536476791, p.std().item() = 0.056133050471544266\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07184911519289017, p.std().item() = 0.04725335165858269\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009853026829659939, p.std().item() = 0.031559057533741\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04565374553203583, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.3473590314388275, preds.std().item() = 0.47575631737709045\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6954, device='cuda:0'), loss.std() = tensor(0.0160, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.086149722557167e-11, lambda_i.std().item() = 0.28954991698265076\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0004465179517865181, p.grad.std().item() = 7.126779556274414\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0016394852427765727, p.grad.std().item() = 0.2369024008512497\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 22.499658584594727, p.grad.std().item() = 725.8029174804688\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -188.12237548828125, p.grad.std().item() = 442.9888916015625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -1168.343994140625, p.grad.std().item() = 25955.1484375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00032901763916015625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.327827188419178e-05, p.std().item() = 0.9776787161827087\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0002863715053535998, p.std().item() = 0.9766817092895508\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008352842996828258, p.std().item() = 0.0568571612238884\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07324980199337006, p.std().item() = 0.04764034226536751\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009794547222554684, p.std().item() = 0.03205125778913498\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04514489695429802, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 23\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.327827188419178e-05, p.std().item() = 0.9776787161827087\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0002863715053535998, p.std().item() = 0.9766817092895508\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008352842996828258, p.std().item() = 0.0568571612238884\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07324980199337006, p.std().item() = 0.04764034226536751\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009794547222554684, p.std().item() = 0.03205125778913498\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04514489695429802, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.397697389125824, preds.std().item() = 0.4927162826061249\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6934, device='cuda:0'), loss.std() = tensor(0.0157, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.230422846942858e-10, lambda_i.std().item() = 0.30901411175727844\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0003431496152188629, p.grad.std().item() = 8.44312858581543\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0009051436791196465, p.grad.std().item() = 0.25744467973709106\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -1.165462613105774, p.grad.std().item() = 866.8766479492188\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -488.7823181152344, p.grad.std().item() = 840.372802734375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -10495.291015625, p.grad.std().item() = 34770.4609375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0004119873046875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.230104529298842e-05, p.std().item() = 0.9767153263092041\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00028051144909113646, p.std().item() = 0.9757444858551025\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008375694160349667, p.std().item() = 0.05755593627691269\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07416406273841858, p.std().item() = 0.04833467677235603\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009522169828414917, p.std().item() = 0.03303643316030502\n",
      "n = 'layers.2.bias', p.mean().item() = 0.0455278716981411, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 24\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.230104529298842e-05, p.std().item() = 0.9767153263092041\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00028051144909113646, p.std().item() = 0.9757444858551025\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008375694160349667, p.std().item() = 0.05755593627691269\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07416406273841858, p.std().item() = 0.04833467677235603\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009522169828414917, p.std().item() = 0.03303643316030502\n",
      "n = 'layers.2.bias', p.mean().item() = 0.0455278716981411, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.3497125506401062, preds.std().item() = 0.5095140337944031\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7060, device='cuda:0'), loss.std() = tensor(0.0146, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.854504882992103e-10, lambda_i.std().item() = 0.4196665585041046\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0006816792883910239, p.grad.std().item() = 14.023271560668945\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0021557752043008804, p.grad.std().item() = 0.31635358929634094\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 6.522756099700928, p.grad.std().item() = 1482.489013671875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1025.3240966796875, p.grad.std().item() = 1515.3707275390625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -6867.03466796875, p.grad.std().item() = 64794.984375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00045680999755859375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.122056558728218e-05, p.std().item() = 0.9757535457611084\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00024995519197545946, p.std().item() = 0.9748157262802124\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008494149660691619, p.std().item() = 0.05826873704791069\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07417362928390503, p.std().item() = 0.049458906054496765\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009451424703001976, p.std().item() = 0.035210467875003815\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04679949954152107, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 25\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.122056558728218e-05, p.std().item() = 0.9757535457611084\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00024995519197545946, p.std().item() = 0.9748157262802124\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008494149660691619, p.std().item() = 0.05826873704791069\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07417362928390503, p.std().item() = 0.049458906054496765\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009451424703001976, p.std().item() = 0.035210467875003815\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04679949954152107, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.34748131036758423, preds.std().item() = 0.5572555065155029\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7063, device='cuda:0'), loss.std() = tensor(0.0177, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.0404847816669616e-10, lambda_i.std().item() = 0.2313310205936432\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0005991440266370773, p.grad.std().item() = 10.226112365722656\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.001586642931215465, p.grad.std().item() = 0.287002295255661\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 18.495882034301758, p.grad.std().item() = 933.7076416015625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 751.821533203125, p.grad.std().item() = 1027.4312744140625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 6690.36279296875, p.grad.std().item() = 41525.609375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00033855438232421875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.95353519404307e-05, p.std().item() = 0.9747929573059082\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00023523015261162072, p.std().item() = 0.9738810062408447\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0009023030870594084, p.std().item() = 0.058918170630931854\n",
      "n = 'layers.0.bias', p.mean().item() = -0.0748019739985466, p.std().item() = 0.050234586000442505\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009363013319671154, p.std().item() = 0.03641073778271675\n",
      "n = 'layers.2.bias', p.mean().item() = 0.047248806804418564, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 26\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.95353519404307e-05, p.std().item() = 0.9747929573059082\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00023523015261162072, p.std().item() = 0.9738810062408447\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0009023030870594084, p.std().item() = 0.058918170630931854\n",
      "n = 'layers.0.bias', p.mean().item() = -0.0748019739985466, p.std().item() = 0.050234586000442505\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009363013319671154, p.std().item() = 0.03641073778271675\n",
      "n = 'layers.2.bias', p.mean().item() = 0.047248806804418564, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.3626441955566406, preds.std().item() = 0.6041624546051025\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7017, device='cuda:0'), loss.std() = tensor(0.0242, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.027274761042037e-11, lambda_i.std().item() = 0.2284136414527893\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.00034673724439926445, p.grad.std().item() = 10.347517013549805\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.004400488920509815, p.grad.std().item() = 0.31422269344329834\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -7.105541229248047, p.grad.std().item() = 887.264892578125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 754.4243774414062, p.grad.std().item() = 949.7815551757812\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -5238.56982421875, p.grad.std().item() = 44093.34375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00016021728515625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.72092501190491e-05, p.std().item() = 0.9738330841064453\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00025084614753723145, p.std().item() = 0.9729426503181458\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0009568384848535061, p.std().item() = 0.059508971869945526\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07598714530467987, p.std().item() = 0.05060951039195061\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008892232552170753, p.std().item() = 0.03671935573220253\n",
      "n = 'layers.2.bias', p.mean().item() = 0.0473206490278244, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 27\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.72092501190491e-05, p.std().item() = 0.9738330841064453\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00025084614753723145, p.std().item() = 0.9729426503181458\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0009568384848535061, p.std().item() = 0.059508971869945526\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07598714530467987, p.std().item() = 0.05060951039195061\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008892232552170753, p.std().item() = 0.03671935573220253\n",
      "n = 'layers.2.bias', p.mean().item() = 0.0473206490278244, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.3545205891132355, preds.std().item() = 0.6566570997238159\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6990, device='cuda:0'), loss.std() = tensor(0.0229, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.943785989590225e-11, lambda_i.std().item() = 0.3046964406967163\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0004087870183866471, p.grad.std().item() = 9.551858901977539\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0011071583721786737, p.grad.std().item() = 0.2737961709499359\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -18.966970443725586, p.grad.std().item() = 907.970458984375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -217.54556274414062, p.grad.std().item() = 538.1668090820312\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -4301.3134765625, p.grad.std().item() = 37247.99609375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0001468658447265625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.425623723771423e-05, p.std().item() = 0.9728744626045227\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00025912400451488793, p.std().item() = 0.9720150232315063\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010083052329719067, p.std().item() = 0.0601273775100708\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07687433809041977, p.std().item() = 0.051019106060266495\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008493210189044476, p.std().item() = 0.03746674582362175\n",
      "n = 'layers.2.bias', p.mean().item() = 0.047690775245428085, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 28\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.425623723771423e-05, p.std().item() = 0.9728744626045227\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00025912400451488793, p.std().item() = 0.9720150232315063\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010083052329719067, p.std().item() = 0.0601273775100708\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07687433809041977, p.std().item() = 0.051019106060266495\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008493210189044476, p.std().item() = 0.03746674582362175\n",
      "n = 'layers.2.bias', p.mean().item() = 0.047690775245428085, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.41497376561164856, preds.std().item() = 0.6590840220451355\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6994, device='cuda:0'), loss.std() = tensor(0.0230, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.971351967921535e-11, lambda_i.std().item() = 0.21960295736789703\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0005325316451489925, p.grad.std().item() = 9.960606575012207\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0077864034101367, p.grad.std().item() = 0.3204253017902374\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -18.54047203063965, p.grad.std().item() = 915.1238403320312\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 489.6598205566406, p.grad.std().item() = 817.4848022460938\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 4565.15576171875, p.grad.std().item() = 25357.56640625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00021457672119140625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.107668014010414e-05, p.std().item() = 0.9719170331954956\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0003094192361459136, p.std().item() = 0.9710880517959595\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010279995622113347, p.std().item() = 0.06069847196340561\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07816002517938614, p.std().item() = 0.05144021660089493\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008168683387339115, p.std().item() = 0.037830423563718796\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04847880080342293, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 29\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.107668014010414e-05, p.std().item() = 0.9719170331954956\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0003094192361459136, p.std().item() = 0.9710880517959595\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010279995622113347, p.std().item() = 0.06069847196340561\n",
      "n = 'layers.0.bias', p.mean().item() = -0.07816002517938614, p.std().item() = 0.05144021660089493\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008168683387339115, p.std().item() = 0.037830423563718796\n",
      "n = 'layers.2.bias', p.mean().item() = 0.04847880080342293, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.3563353717327118, preds.std().item() = 0.668209433555603\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7130, device='cuda:0'), loss.std() = tensor(0.0200, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.461851275758491e-11, lambda_i.std().item() = 0.22393181920051575\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0006500882445834577, p.grad.std().item() = 11.410815238952637\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.013406905345618725, p.grad.std().item() = 0.33818891644477844\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 5.345865726470947, p.grad.std().item() = 940.920654296875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 901.743896484375, p.grad.std().item() = 1200.7720947265625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -4555.46826171875, p.grad.std().item() = 41160.84765625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000598907470703125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.770434654550627e-05, p.std().item() = 0.9709605574607849\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00042027237941510975, p.std().item() = 0.9701593518257141\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010463473154231906, p.std().item() = 0.06120927631855011\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08005402982234955, p.std().item() = 0.05172063037753105\n",
      "n = 'layers.2.weight', p.mean().item() = -0.007456160616129637, p.std().item() = 0.03745713829994202\n",
      "n = 'layers.2.bias', p.mean().item() = 0.050425563007593155, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 30\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.770434654550627e-05, p.std().item() = 0.9709605574607849\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00042027237941510975, p.std().item() = 0.9701593518257141\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010463473154231906, p.std().item() = 0.06120927631855011\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08005402982234955, p.std().item() = 0.05172063037753105\n",
      "n = 'layers.2.weight', p.mean().item() = -0.007456160616129637, p.std().item() = 0.03745713829994202\n",
      "n = 'layers.2.bias', p.mean().item() = 0.050425563007593155, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.35590094327926636, preds.std().item() = 0.6491313576698303\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7001, device='cuda:0'), loss.std() = tensor(0.0182, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.176728044650972e-11, lambda_i.std().item() = 0.25124573707580566\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.000435581459896639, p.grad.std().item() = 10.365165710449219\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.000664934457745403, p.grad.std().item() = 0.3239499032497406\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -32.45053482055664, p.grad.std().item() = 907.1541137695312\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 9.510246276855469, p.grad.std().item() = 449.65673828125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -3979.10400390625, p.grad.std().item() = 29126.974609375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 8.392333984375e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.44068607268855e-05, p.std().item() = 0.9700055718421936\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0005246132495813072, p.std().item() = 0.9692208170890808\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001036784378811717, p.std().item() = 0.06169399619102478\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08178993314504623, p.std().item() = 0.052077796310186386\n",
      "n = 'layers.2.weight', p.mean().item() = -0.006788718048483133, p.std().item() = 0.03741860017180443\n",
      "n = 'layers.2.bias', p.mean().item() = 0.05201740935444832, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 31\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.44068607268855e-05, p.std().item() = 0.9700055718421936\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0005246132495813072, p.std().item() = 0.9692208170890808\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001036784378811717, p.std().item() = 0.06169399619102478\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08178993314504623, p.std().item() = 0.052077796310186386\n",
      "n = 'layers.2.weight', p.mean().item() = -0.006788718048483133, p.std().item() = 0.03741860017180443\n",
      "n = 'layers.2.bias', p.mean().item() = 0.05201740935444832, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.3457132875919342, preds.std().item() = 0.6718911528587341\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7017, device='cuda:0'), loss.std() = tensor(0.0196, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.0227432789555735e-10, lambda_i.std().item() = 0.2530584931373596\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00027104030596092343, p.grad.std().item() = 10.861027717590332\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0023902347311377525, p.grad.std().item() = 0.326768159866333\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -4.396446704864502, p.grad.std().item() = 951.9741821289062\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 31.970138549804688, p.grad.std().item() = 385.665283203125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -10727.7373046875, p.grad.std().item() = 28102.767578125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -5.7220458984375e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.1315513701410964e-05, p.std().item() = 0.9690515398979187\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0006272460450418293, p.std().item() = 0.9682899713516235\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010269035119563341, p.std().item() = 0.062186844646930695\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08340487629175186, p.std().item() = 0.05246853455901146\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005932847037911415, p.std().item() = 0.03764168545603752\n",
      "n = 'layers.2.bias', p.mean().item() = 0.053587328642606735, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 32\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.1315513701410964e-05, p.std().item() = 0.9690515398979187\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0006272460450418293, p.std().item() = 0.9682899713516235\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010269035119563341, p.std().item() = 0.062186844646930695\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08340487629175186, p.std().item() = 0.05246853455901146\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005932847037911415, p.std().item() = 0.03764168545603752\n",
      "n = 'layers.2.bias', p.mean().item() = 0.053587328642606735, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.2919483482837677, preds.std().item() = 0.6492997407913208\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7033, device='cuda:0'), loss.std() = tensor(0.0170, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.272524414960515e-11, lambda_i.std().item() = 0.23763763904571533\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00023348983086179942, p.grad.std().item() = 11.414762496948242\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.007769303862005472, p.grad.std().item() = 0.3542114794254303\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 16.066009521484375, p.grad.std().item() = 954.3826904296875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 778.9165649414062, p.grad.std().item() = 1244.322021484375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 5972.21728515625, p.grad.std().item() = 41017.78125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0004749298095703125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.8634232371114194e-05, p.std().item() = 0.9680982828140259\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0007664235308766365, p.std().item() = 0.9673562049865723\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010235083755105734, p.std().item() = 0.06263093650341034\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08540008217096329, p.std().item() = 0.05263226106762886\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005114892031997442, p.std().item() = 0.03724212571978569\n",
      "n = 'layers.2.bias', p.mean().item() = 0.05600636079907417, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 33\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.8634232371114194e-05, p.std().item() = 0.9680982828140259\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0007664235308766365, p.std().item() = 0.9673562049865723\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010235083755105734, p.std().item() = 0.06263093650341034\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08540008217096329, p.std().item() = 0.05263226106762886\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005114892031997442, p.std().item() = 0.03724212571978569\n",
      "n = 'layers.2.bias', p.mean().item() = 0.05600636079907417, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.24617236852645874, preds.std().item() = 0.6064730882644653\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6932, device='cuda:0'), loss.std() = tensor(0.0203, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.1965052559848033e-10, lambda_i.std().item() = 0.2921978831291199\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0007973610190674663, p.grad.std().item() = 11.37447738647461\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0015573137206956744, p.grad.std().item() = 0.32877784967422485\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -3.8402647972106934, p.grad.std().item() = 1057.69580078125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -287.0850524902344, p.grad.std().item() = 817.408203125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 3109.4912109375, p.grad.std().item() = 35546.37109375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00026702880859375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.66559395135846e-05, p.std().item() = 0.967146098613739\n",
      "n = 'label_factors.weight', p.mean().item() = 0.000875583034940064, p.std().item() = 0.9664195775985718\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010098381899297237, p.std().item() = 0.06308238208293915\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08696062117815018, p.std().item() = 0.05280420556664467\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004643806256353855, p.std().item() = 0.03737003728747368\n",
      "n = 'layers.2.bias', p.mean().item() = 0.057617079466581345, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 34\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.66559395135846e-05, p.std().item() = 0.967146098613739\n",
      "n = 'label_factors.weight', p.mean().item() = 0.000875583034940064, p.std().item() = 0.9664195775985718\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010098381899297237, p.std().item() = 0.06308238208293915\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08696062117815018, p.std().item() = 0.05280420556664467\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004643806256353855, p.std().item() = 0.03737003728747368\n",
      "n = 'layers.2.bias', p.mean().item() = 0.057617079466581345, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.1760755330324173, preds.std().item() = 0.5868532657623291\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6919, device='cuda:0'), loss.std() = tensor(0.0211, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.820027875775736e-11, lambda_i.std().item() = 0.21389509737491608\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0024481266736984253, p.grad.std().item() = 10.09195613861084\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.009931216947734356, p.grad.std().item() = 0.3375096917152405\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -0.8532443046569824, p.grad.std().item() = 888.63671875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 607.7888793945312, p.grad.std().item() = 1355.3624267578125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 13249.859375, p.grad.std().item() = 44057.609375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00020599365234375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.542741226032376e-05, p.std().item() = 0.9661946296691895\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0010304099414497614, p.std().item() = 0.9655033349990845\n",
      "n = 'layers.0.weight', p.mean().item() = -0.000995623180642724, p.std().item() = 0.06353197246789932\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08874174952507019, p.std().item() = 0.053002383559942245\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0043660420924425125, p.std().item() = 0.0370715893805027\n",
      "n = 'layers.2.bias', p.mean().item() = 0.059525735676288605, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 35\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.542741226032376e-05, p.std().item() = 0.9661946296691895\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0010304099414497614, p.std().item() = 0.9655033349990845\n",
      "n = 'layers.0.weight', p.mean().item() = -0.000995623180642724, p.std().item() = 0.06353197246789932\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08874174952507019, p.std().item() = 0.053002383559942245\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0043660420924425125, p.std().item() = 0.0370715893805027\n",
      "n = 'layers.2.bias', p.mean().item() = 0.059525735676288605, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.2230525016784668, preds.std().item() = 0.6088410019874573\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7017, device='cuda:0'), loss.std() = tensor(0.0213, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.1177123115935217e-10, lambda_i.std().item() = 0.2997035086154938\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.001655520056374371, p.grad.std().item() = 11.725717544555664\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.004458975978195667, p.grad.std().item() = 0.38722413778305054\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -3.8748350143432617, p.grad.std().item() = 1029.355224609375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -501.9792175292969, p.grad.std().item() = 939.34912109375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -5198.36328125, p.grad.std().item() = 38626.96484375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000270843505859375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.5265795051818714e-05, p.std().item() = 0.9652442932128906\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0011392120504751801, p.std().item() = 0.9645870327949524\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010064842645078897, p.std().item() = 0.06400086730718613\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08996238559484482, p.std().item() = 0.05342729017138481\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0041267829947173595, p.std().item() = 0.037538543343544006\n",
      "n = 'layers.2.bias', p.mean().item() = 0.060653410851955414, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 36\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.5265795051818714e-05, p.std().item() = 0.9652442932128906\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0011392120504751801, p.std().item() = 0.9645870327949524\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010064842645078897, p.std().item() = 0.06400086730718613\n",
      "n = 'layers.0.bias', p.mean().item() = -0.08996238559484482, p.std().item() = 0.05342729017138481\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0041267829947173595, p.std().item() = 0.037538543343544006\n",
      "n = 'layers.2.bias', p.mean().item() = 0.060653410851955414, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.25030431151390076, preds.std().item() = 0.6182973384857178\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6908, device='cuda:0'), loss.std() = tensor(0.0178, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.0410065864885354e-10, lambda_i.std().item() = 0.2401471585035324\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0006278402870520949, p.grad.std().item() = 10.415088653564453\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0031096595339477062, p.grad.std().item() = 0.34593814611434937\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 3.48330020904541, p.grad.std().item() = 942.6389770507812\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -160.21961975097656, p.grad.std().item() = 629.2247924804688\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 14389.08203125, p.grad.std().item() = 27751.671875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 6.866455078125e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.6246823330875486e-05, p.std().item() = 0.9642952680587769\n",
      "n = 'label_factors.weight', p.mean().item() = 0.001216383883729577, p.std().item() = 0.9636850357055664\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001016397261992097, p.std().item() = 0.0644838884472847\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09097427129745483, p.std().item() = 0.05400577932596207\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004371323622763157, p.std().item() = 0.038250550627708435\n",
      "n = 'layers.2.bias', p.mean().item() = 0.061522264033555984, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 37\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.6246823330875486e-05, p.std().item() = 0.9642952680587769\n",
      "n = 'label_factors.weight', p.mean().item() = 0.001216383883729577, p.std().item() = 0.9636850357055664\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001016397261992097, p.std().item() = 0.0644838884472847\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09097427129745483, p.std().item() = 0.05400577932596207\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004371323622763157, p.std().item() = 0.038250550627708435\n",
      "n = 'layers.2.bias', p.mean().item() = 0.061522264033555984, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.19618773460388184, preds.std().item() = 0.6593761444091797\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6927, device='cuda:0'), loss.std() = tensor(0.0177, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.095796370309543e-10, lambda_i.std().item() = 0.2551385760307312\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0006830081692896783, p.grad.std().item() = 11.424084663391113\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0035990984179079533, p.grad.std().item() = 0.3997037410736084\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -1.935042381286621, p.grad.std().item() = 997.8712768554688\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -296.0547180175781, p.grad.std().item() = 650.4102783203125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 10617.7568359375, p.grad.std().item() = 24151.3671875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00035190582275390625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.861339402850717e-05, p.std().item() = 0.9633472561836243\n",
      "n = 'label_factors.weight', p.mean().item() = 0.001264382852241397, p.std().item() = 0.9627877473831177\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001038421643897891, p.std().item() = 0.06498481333255768\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09167661517858505, p.std().item() = 0.054677776992321014\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005059090908616781, p.std().item() = 0.0393298976123333\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06308930367231369, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 38\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -4.861339402850717e-05, p.std().item() = 0.9633472561836243\n",
      "n = 'label_factors.weight', p.mean().item() = 0.001264382852241397, p.std().item() = 0.9627877473831177\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001038421643897891, p.std().item() = 0.06498481333255768\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09167661517858505, p.std().item() = 0.054677776992321014\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005059090908616781, p.std().item() = 0.0393298976123333\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06308930367231369, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.2955600321292877, preds.std().item() = 0.7013367414474487\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7020, device='cuda:0'), loss.std() = tensor(0.0177, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 2.75514524389342e-11, lambda_i.std().item() = 0.2136775702238083\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0018994183046743274, p.grad.std().item() = 13.558540344238281\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.015811553224921227, p.grad.std().item() = 0.4107781946659088\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 4.065276622772217, p.grad.std().item() = 1152.69140625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 699.3985595703125, p.grad.std().item() = 1327.582763671875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 8608.626953125, p.grad.std().item() = 48471.55078125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0001773834228515625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.223457992542535e-05, p.std().item() = 0.9624001383781433\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0013844132190570235, p.std().item() = 0.9619036316871643\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010601207613945007, p.std().item() = 0.06547669321298599\n",
      "n = 'layers.0.bias', p.mean().item() = -0.0927819013595581, p.std().item() = 0.05529047176241875\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005735606886446476, p.std().item() = 0.03972921893000603\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06491010636091232, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 39\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.223457992542535e-05, p.std().item() = 0.9624001383781433\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0013844132190570235, p.std().item() = 0.9619036316871643\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010601207613945007, p.std().item() = 0.06547669321298599\n",
      "n = 'layers.0.bias', p.mean().item() = -0.0927819013595581, p.std().item() = 0.05529047176241875\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005735606886446476, p.std().item() = 0.03972921893000603\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06491010636091232, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.33267509937286377, preds.std().item() = 0.7067320942878723\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6837, device='cuda:0'), loss.std() = tensor(0.0239, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.058583744225857e-11, lambda_i.std().item() = 0.22459259629249573\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00120804482139647, p.grad.std().item() = 9.801721572875977\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0060500591062009335, p.grad.std().item() = 0.4748227596282959\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 13.489574432373047, p.grad.std().item() = 758.83349609375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 260.1484375, p.grad.std().item() = 671.9388427734375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 6634.3798828125, p.grad.std().item() = 23393.576171875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 2.86102294921875e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.744384179706685e-05, p.std().item() = 0.9614542722702026\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015177516033872962, p.std().item() = 0.9610190391540527\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001078098895959556, p.std().item() = 0.06592752784490585\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09400627017021179, p.std().item() = 0.05597937852144241\n",
      "n = 'layers.2.weight', p.mean().item() = -0.006429868750274181, p.std().item() = 0.039794690907001495\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06649763137102127, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 40\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -5.744384179706685e-05, p.std().item() = 0.9614542722702026\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015177516033872962, p.std().item() = 0.9610190391540527\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001078098895959556, p.std().item() = 0.06592752784490585\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09400627017021179, p.std().item() = 0.05597937852144241\n",
      "n = 'layers.2.weight', p.mean().item() = -0.006429868750274181, p.std().item() = 0.039794690907001495\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06649763137102127, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.3809363543987274, preds.std().item() = 0.7714603543281555\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.6932, device='cuda:0'), loss.std() = tensor(0.0291, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.171509996435233e-11, lambda_i.std().item() = 0.26611897349357605\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.002148823579773307, p.grad.std().item() = 11.324371337890625\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.00820092111825943, p.grad.std().item() = 0.5373907685279846\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -5.535007476806641, p.grad.std().item() = 945.7329711914062\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -632.7279052734375, p.grad.std().item() = 1041.3812255859375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -4052.201171875, p.grad.std().item() = 53221.5390625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000431060791015625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.461620796471834e-05, p.std().item() = 0.9605098962783813\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015896976692602038, p.std().item() = 0.9601402878761292\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010938026243820786, p.std().item() = 0.0663984939455986\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09464982897043228, p.std().item() = 0.05689694732427597\n",
      "n = 'layers.2.weight', p.mean().item() = -0.007245731074362993, p.std().item() = 0.04082070663571358\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06890470534563065, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 41\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -6.461620796471834e-05, p.std().item() = 0.9605098962783813\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015896976692602038, p.std().item() = 0.9601402878761292\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010938026243820786, p.std().item() = 0.0663984939455986\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09464982897043228, p.std().item() = 0.05689694732427597\n",
      "n = 'layers.2.weight', p.mean().item() = -0.007245731074362993, p.std().item() = 0.04082070663571358\n",
      "n = 'layers.2.bias', p.mean().item() = 0.06890470534563065, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.4237727224826813, preds.std().item() = 0.8230016231536865\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7046, device='cuda:0'), loss.std() = tensor(0.0275, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.2387717240880392e-10, lambda_i.std().item() = 0.2731694281101227\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.00025003525661304593, p.grad.std().item() = 11.739304542541504\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0061935847625136375, p.grad.std().item() = 0.5104656219482422\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -4.651611804962158, p.grad.std().item() = 1044.1171875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -275.24114990234375, p.grad.std().item() = 751.3527221679688\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -20023.79296875, p.grad.std().item() = 49628.48828125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000335693359375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.340475713135675e-05, p.std().item() = 0.9595667719841003\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0016304445452988148, p.std().item() = 0.9592388272285461\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010911752469837666, p.std().item() = 0.06681577116250992\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09494686126708984, p.std().item() = 0.057705108076334\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00758319441229105, p.std().item() = 0.04241596534848213\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07184476405382156, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 42\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -7.340475713135675e-05, p.std().item() = 0.9595667719841003\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0016304445452988148, p.std().item() = 0.9592388272285461\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010911752469837666, p.std().item() = 0.06681577116250992\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09494686126708984, p.std().item() = 0.057705108076334\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00758319441229105, p.std().item() = 0.04241596534848213\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07184476405382156, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.5003061890602112, preds.std().item() = 0.8920149207115173\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7035, device='cuda:0'), loss.std() = tensor(0.0277, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.6937881652800968e-10, lambda_i.std().item() = 0.3306315541267395\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.004389385227113962, p.grad.std().item() = 14.10799789428711\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.013812430202960968, p.grad.std().item() = 0.6660010814666748\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -11.389653205871582, p.grad.std().item() = 1151.21337890625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1262.73388671875, p.grad.std().item() = 1959.70458984375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -8299.4375, p.grad.std().item() = 77627.0390625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0005016326904296875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -8.411648741457611e-05, p.std().item() = 0.958625316619873\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015978541923686862, p.std().item() = 0.9583499431610107\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010832053376361728, p.std().item() = 0.06730224192142487\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09442003816366196, p.std().item() = 0.05897820368409157\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00804506428539753, p.std().item() = 0.045059800148010254\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07331597805023193, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 43\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -8.411648741457611e-05, p.std().item() = 0.958625316619873\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015978541923686862, p.std().item() = 0.9583499431610107\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010832053376361728, p.std().item() = 0.06730224192142487\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09442003816366196, p.std().item() = 0.05897820368409157\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00804506428539753, p.std().item() = 0.045059800148010254\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07331597805023193, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.5375407338142395, preds.std().item() = 1.0357609987258911\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7274, device='cuda:0'), loss.std() = tensor(0.0441, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.432413795000926e-11, lambda_i.std().item() = 0.23965834081172943\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0024479504209011793, p.grad.std().item() = 16.840452194213867\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.009184013120830059, p.grad.std().item() = 0.592907190322876\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -20.177852630615234, p.grad.std().item() = 1164.4722900390625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 554.4218139648438, p.grad.std().item() = 1046.786865234375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -3620.192626953125, p.grad.std().item() = 35506.359375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00031280517578125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -9.580262849340215e-05, p.std().item() = 0.9576844573020935\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0016127554699778557, p.std().item() = 0.9574612379074097\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010758255375549197, p.std().item() = 0.0678032711148262\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09424809366464615, p.std().item() = 0.059954844415187836\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008168622851371765, p.std().item() = 0.04700426012277603\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07535884529352188, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 44\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -9.580262849340215e-05, p.std().item() = 0.9576844573020935\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0016127554699778557, p.std().item() = 0.9574612379074097\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010758255375549197, p.std().item() = 0.0678032711148262\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09424809366464615, p.std().item() = 0.059954844415187836\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008168622851371765, p.std().item() = 0.04700426012277603\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07535884529352188, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.5396573543548584, preds.std().item() = 1.0400551557540894\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7111, device='cuda:0'), loss.std() = tensor(0.0398, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.0697059904529738e-10, lambda_i.std().item() = 0.2804749310016632\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.002588712377473712, p.grad.std().item() = 15.748218536376953\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.020207783207297325, p.grad.std().item() = 0.8147677779197693\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -2.5866448879241943, p.grad.std().item() = 1163.821044921875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1369.641845703125, p.grad.std().item() = 1889.052490234375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -5475.111328125, p.grad.std().item() = 71619.734375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000110626220703125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00010898237087531015, p.std().item() = 0.956744909286499\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00154350814409554, p.std().item() = 0.9566011428833008\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010700620478019118, p.std().item() = 0.06841978430747986\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09317135810852051, p.std().item() = 0.06127028912305832\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008475322276353836, p.std().item() = 0.04997619614005089\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07695292681455612, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 45\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00010898237087531015, p.std().item() = 0.956744909286499\n",
      "n = 'label_factors.weight', p.mean().item() = 0.00154350814409554, p.std().item() = 0.9566011428833008\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010700620478019118, p.std().item() = 0.06841978430747986\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09317135810852051, p.std().item() = 0.06127028912305832\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008475322276353836, p.std().item() = 0.04997619614005089\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07695292681455612, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.6981582641601562, preds.std().item() = 1.2197113037109375\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7180, device='cuda:0'), loss.std() = tensor(0.0501, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 2.8021078513074116e-11, lambda_i.std().item() = 0.2392473816871643\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0026167011819779873, p.grad.std().item() = 20.164085388183594\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.017251677811145782, p.grad.std().item() = 0.8455893993377686\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -35.519813537597656, p.grad.std().item() = 1291.709716796875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 862.207275390625, p.grad.std().item() = 1173.91748046875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -12568.86328125, p.grad.std().item() = 44501.12890625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0006809234619140625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00012285579578019679, p.std().item() = 0.9558061957359314\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015527926152572036, p.std().item() = 0.9557167887687683\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001028265804052353, p.std().item() = 0.06892739981412888\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09301471710205078, p.std().item() = 0.062277089804410934\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00819273479282856, p.std().item() = 0.05168639495968819\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07989852875471115, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 46\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00012285579578019679, p.std().item() = 0.9558061957359314\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015527926152572036, p.std().item() = 0.9557167887687683\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001028265804052353, p.std().item() = 0.06892739981412888\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09301471710205078, p.std().item() = 0.062277089804410934\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00819273479282856, p.std().item() = 0.05168639495968819\n",
      "n = 'layers.2.bias', p.mean().item() = 0.07989852875471115, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.7519160509109497, preds.std().item() = 1.3065855503082275\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7224, device='cuda:0'), loss.std() = tensor(0.0393, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 5.536380728865531e-11, lambda_i.std().item() = 0.24856723845005035\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0015123040648177266, p.grad.std().item() = 20.7320613861084\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.003438411047682166, p.grad.std().item() = 0.8872891068458557\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 17.711393356323242, p.grad.std().item() = 1379.3851318359375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -284.72515869140625, p.grad.std().item() = 914.8158569335938\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 594.3937377929688, p.grad.std().item() = 38158.87109375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0004892349243164062, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00013715933891944587, p.std().item() = 0.9548686146736145\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015436316607519984, p.std().item() = 0.9548705816268921\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010358329163864255, p.std().item() = 0.06952077895402908\n",
      "n = 'layers.0.bias', p.mean().item() = -0.0927376076579094, p.std().item() = 0.063250333070755\n",
      "n = 'layers.2.weight', p.mean().item() = -0.007993187755346298, p.std().item() = 0.053479038178920746\n",
      "n = 'layers.2.bias', p.mean().item() = 0.08363698422908783, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 47\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00013715933891944587, p.std().item() = 0.9548686146736145\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015436316607519984, p.std().item() = 0.9548705816268921\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010358329163864255, p.std().item() = 0.06952077895402908\n",
      "n = 'layers.0.bias', p.mean().item() = -0.0927376076579094, p.std().item() = 0.063250333070755\n",
      "n = 'layers.2.weight', p.mean().item() = -0.007993187755346298, p.std().item() = 0.053479038178920746\n",
      "n = 'layers.2.bias', p.mean().item() = 0.08363698422908783, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.7229291796684265, preds.std().item() = 1.3643066883087158\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7294, device='cuda:0'), loss.std() = tensor(0.0495, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 5.0928442019149145e-11, lambda_i.std().item() = 0.22805964946746826\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.002234972547739744, p.grad.std().item() = 21.118024826049805\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.012465321458876133, p.grad.std().item() = 0.8001601696014404\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 0.5968597531318665, p.grad.std().item() = 1414.3941650390625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 793.9141845703125, p.grad.std().item() = 1337.001708984375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -14534.4521484375, p.grad.std().item() = 34107.4296875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000335693359375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00015171041013672948, p.std().item() = 0.9539320468902588\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015824754955247045, p.std().item() = 0.9540095329284668\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010638191597536206, p.std().item() = 0.07003654539585114\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09319084882736206, p.std().item() = 0.06406695395708084\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0073448964394629, p.std().item() = 0.054582081735134125\n",
      "n = 'layers.2.bias', p.mean().item() = 0.0877702459692955, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 48\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00015171041013672948, p.std().item() = 0.9539320468902588\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0015824754955247045, p.std().item() = 0.9540095329284668\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010638191597536206, p.std().item() = 0.07003654539585114\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09319084882736206, p.std().item() = 0.06406695395708084\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0073448964394629, p.std().item() = 0.054582081735134125\n",
      "n = 'layers.2.bias', p.mean().item() = 0.0877702459692955, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.7425307631492615, preds.std().item() = 1.3542897701263428\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7402, device='cuda:0'), loss.std() = tensor(0.0591, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 2.1185397186540555e-11, lambda_i.std().item() = 0.225770503282547\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.003507925197482109, p.grad.std().item() = 31.461938858032227\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.03058614209294319, p.grad.std().item() = 1.0045719146728516\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 46.587425231933594, p.grad.std().item() = 1916.6243896484375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1914.7081298828125, p.grad.std().item() = 2242.54052734375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -27293.013671875, p.grad.std().item() = 85266.796875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00022125244140625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00016614445485174656, p.std().item() = 0.9529958963394165\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0017245952039957047, p.std().item() = 0.9531158804893494\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0011157677508890629, p.std().item() = 0.07036484777927399\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09508929401636124, p.std().item() = 0.06449198722839355\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005896169226616621, p.std().item() = 0.05386681854724884\n",
      "n = 'layers.2.bias', p.mean().item() = 0.09201955795288086, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 49\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00016614445485174656, p.std().item() = 0.9529958963394165\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0017245952039957047, p.std().item() = 0.9531158804893494\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0011157677508890629, p.std().item() = 0.07036484777927399\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09508929401636124, p.std().item() = 0.06449198722839355\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005896169226616621, p.std().item() = 0.05386681854724884\n",
      "n = 'layers.2.bias', p.mean().item() = 0.09201955795288086, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.6382560133934021, preds.std().item() = 1.4030556678771973\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7268, device='cuda:0'), loss.std() = tensor(0.0581, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.0347448592407105e-10, lambda_i.std().item() = 0.23235085606575012\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0009160470217466354, p.grad.std().item() = 19.655723571777344\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.010453256778419018, p.grad.std().item() = 0.8754149675369263\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -29.40019989013672, p.grad.std().item() = 1281.3299560546875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -522.2678833007812, p.grad.std().item() = 1090.039794921875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -6564.19873046875, p.grad.std().item() = 36372.3515625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000110626220703125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00018092678510583937, p.std().item() = 0.9520607590675354\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0018116544233635068, p.std().item() = 0.9522441029548645\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0011732425773516297, p.std().item() = 0.0707830935716629\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09647321701049805, p.std().item() = 0.06509006023406982\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00451521435752511, p.std().item() = 0.05377345532178879\n",
      "n = 'layers.2.bias', p.mean().item() = 0.09561731666326523, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 50\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00018092678510583937, p.std().item() = 0.9520607590675354\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0018116544233635068, p.std().item() = 0.9522441029548645\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0011732425773516297, p.std().item() = 0.0707830935716629\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09647321701049805, p.std().item() = 0.06509006023406982\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00451521435752511, p.std().item() = 0.05377345532178879\n",
      "n = 'layers.2.bias', p.mean().item() = 0.09561731666326523, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.5639384388923645, preds.std().item() = 1.348757266998291\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7146, device='cuda:0'), loss.std() = tensor(0.0442, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.962787373916314e-11, lambda_i.std().item() = 0.21959978342056274\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00152697809971869, p.grad.std().item() = 17.974321365356445\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.010899134911596775, p.grad.std().item() = 0.7890310883522034\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -1.9715675115585327, p.grad.std().item() = 1145.5511474609375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 345.6839294433594, p.grad.std().item() = 875.6834106445312\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 16212.2568359375, p.grad.std().item() = 31301.59375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0006351470947265625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0001958070497494191, p.std().item() = 0.9511265158653259\n",
      "n = 'label_factors.weight', p.mean().item() = 0.001907765632495284, p.std().item() = 0.9513866901397705\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0012290835147723556, p.std().item() = 0.07124940305948257\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09796767681837082, p.std().item() = 0.06577149033546448\n",
      "n = 'layers.2.weight', p.mean().item() = -0.003623292315751314, p.std().item() = 0.05360526219010353\n",
      "n = 'layers.2.bias', p.mean().item() = 0.10024456679821014, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 51\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0001958070497494191, p.std().item() = 0.9511265158653259\n",
      "n = 'label_factors.weight', p.mean().item() = 0.001907765632495284, p.std().item() = 0.9513866901397705\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0012290835147723556, p.std().item() = 0.07124940305948257\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09796767681837082, p.std().item() = 0.06577149033546448\n",
      "n = 'layers.2.weight', p.mean().item() = -0.003623292315751314, p.std().item() = 0.05360526219010353\n",
      "n = 'layers.2.bias', p.mean().item() = 0.10024456679821014, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.5565907955169678, preds.std().item() = 1.275183916091919\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7192, device='cuda:0'), loss.std() = tensor(0.0380, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.1333665256296754e-10, lambda_i.std().item() = 0.24743562936782837\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0012669161660596728, p.grad.std().item() = 24.29429054260254\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.022604621946811676, p.grad.std().item() = 0.8743523955345154\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 2.101330041885376, p.grad.std().item() = 1434.7344970703125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -811.9478759765625, p.grad.std().item() = 1254.52685546875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 5514.19482421875, p.grad.std().item() = 43584.4140625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000171661376953125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00021157425362616777, p.std().item() = 0.9501937627792358\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019312020158395171, p.std().item() = 0.9505337476730347\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001285064616240561, p.std().item() = 0.07175866514444351\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09881618618965149, p.std().item() = 0.06672009080648422\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0030860677361488342, p.std().item() = 0.05428330972790718\n",
      "n = 'layers.2.bias', p.mean().item() = 0.10403972119092941, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 52\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00021157425362616777, p.std().item() = 0.9501937627792358\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019312020158395171, p.std().item() = 0.9505337476730347\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001285064616240561, p.std().item() = 0.07175866514444351\n",
      "n = 'layers.0.bias', p.mean().item() = -0.09881618618965149, p.std().item() = 0.06672009080648422\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0030860677361488342, p.std().item() = 0.05428330972790718\n",
      "n = 'layers.2.bias', p.mean().item() = 0.10403972119092941, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.6903099417686462, preds.std().item() = 1.4437967538833618\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7247, device='cuda:0'), loss.std() = tensor(0.0457, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.983659566779266e-11, lambda_i.std().item() = 0.204436257481575\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.004283569753170013, p.grad.std().item() = 23.18157386779785\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.030204441398382187, p.grad.std().item() = 0.9286621809005737\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -28.960695266723633, p.grad.std().item() = 1466.79248046875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1123.338623046875, p.grad.std().item() = 1667.1888427734375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 12890.982421875, p.grad.std().item() = 63138.7421875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000247955322265625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00022783550957683474, p.std().item() = 0.9492619633674622\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020185792818665504, p.std().item() = 0.9497054815292358\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013270521303638816, p.std().item() = 0.07226870954036713\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10043498873710632, p.std().item() = 0.06768793612718582\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0026926985010504723, p.std().item() = 0.05411364883184433\n",
      "n = 'layers.2.bias', p.mean().item() = 0.10689040273427963, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 53\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00022783550957683474, p.std().item() = 0.9492619633674622\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020185792818665504, p.std().item() = 0.9497054815292358\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013270521303638816, p.std().item() = 0.07226870954036713\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10043498873710632, p.std().item() = 0.06768793612718582\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0026926985010504723, p.std().item() = 0.05411364883184433\n",
      "n = 'layers.2.bias', p.mean().item() = 0.10689040273427963, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.5282233953475952, preds.std().item() = 1.3884437084197998\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7123, device='cuda:0'), loss.std() = tensor(0.0410, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.716799504426831e-11, lambda_i.std().item() = 0.2251356691122055\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.002497382229194045, p.grad.std().item() = 18.735084533691406\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.016676628962159157, p.grad.std().item() = 1.0505766868591309\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -4.977602005004883, p.grad.std().item() = 1124.2816162109375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -644.2503051757812, p.grad.std().item() = 1158.982666015625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 10730.1923828125, p.grad.std().item() = 30624.3359375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00031948089599609375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0002445829741191119, p.std().item() = 0.9483312964439392\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002047843998298049, p.std().item() = 0.9489202499389648\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013591706519946456, p.std().item() = 0.07293228805065155\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10150200873613358, p.std().item() = 0.06886269152164459\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0026991248596459627, p.std().item() = 0.05459194630384445\n",
      "n = 'layers.2.bias', p.mean().item() = 0.10870777070522308, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 54\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0002445829741191119, p.std().item() = 0.9483312964439392\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002047843998298049, p.std().item() = 0.9489202499389648\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013591706519946456, p.std().item() = 0.07293228805065155\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10150200873613358, p.std().item() = 0.06886269152164459\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0026991248596459627, p.std().item() = 0.05459194630384445\n",
      "n = 'layers.2.bias', p.mean().item() = 0.10870777070522308, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.6459894180297852, preds.std().item() = 1.4427869319915771\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7556, device='cuda:0'), loss.std() = tensor(0.0667, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.950479775058582e-11, lambda_i.std().item() = 0.24857567250728607\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0023517911322414875, p.grad.std().item() = 31.5372371673584\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.03760749101638794, p.grad.std().item() = 1.0728179216384888\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 14.685855865478516, p.grad.std().item() = 1916.9205322265625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1117.5472412109375, p.grad.std().item() = 1568.37158203125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -24757.267578125, p.grad.std().item() = 57735.91015625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00041961669921875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0002618126745801419, p.std().item() = 0.9474014043807983\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002162051619961858, p.std().item() = 0.9481161832809448\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013843945926055312, p.std().item() = 0.07346218079328537\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10312224924564362, p.std().item() = 0.06964399665594101\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0020389019045978785, p.std().item() = 0.054094359278678894\n",
      "n = 'layers.2.bias', p.mean().item() = 0.11131134629249573, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 55\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0002618126745801419, p.std().item() = 0.9474014043807983\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002162051619961858, p.std().item() = 0.9481161832809448\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013843945926055312, p.std().item() = 0.07346218079328537\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10312224924564362, p.std().item() = 0.06964399665594101\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0020389019045978785, p.std().item() = 0.054094359278678894\n",
      "n = 'layers.2.bias', p.mean().item() = 0.11131134629249573, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.588803768157959, preds.std().item() = 1.4179623126983643\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7246, device='cuda:0'), loss.std() = tensor(0.0554, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.194253691724441e-11, lambda_i.std().item() = 0.22473366558551788\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.001935875858180225, p.grad.std().item() = 22.251222610473633\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.009075511246919632, p.grad.std().item() = 1.0147029161453247\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 4.3589324951171875, p.grad.std().item() = 1318.42822265625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 195.03358459472656, p.grad.std().item() = 636.7884521484375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -10277.2958984375, p.grad.std().item() = 28740.9921875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0002593994140625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0002795589971356094, p.std().item() = 0.9464725852012634\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002271226141601801, p.std().item() = 0.947316586971283\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013987807324156165, p.std().item() = 0.07396936416625977\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10470897704362869, p.std().item() = 0.07042334228754044\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0011910643661394715, p.std().item() = 0.0534060001373291\n",
      "n = 'layers.2.bias', p.mean().item() = 0.11426820605993271, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 56\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0002795589971356094, p.std().item() = 0.9464725852012634\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002271226141601801, p.std().item() = 0.947316586971283\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013987807324156165, p.std().item() = 0.07396936416625977\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10470897704362869, p.std().item() = 0.07042334228754044\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0011910643661394715, p.std().item() = 0.0534060001373291\n",
      "n = 'layers.2.bias', p.mean().item() = 0.11426820605993271, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.6479774713516235, preds.std().item() = 1.3284287452697754\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7097, device='cuda:0'), loss.std() = tensor(0.0420, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.2105941249451746e-10, lambda_i.std().item() = 0.29026174545288086\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -4.76132299809251e-06, p.grad.std().item() = 28.494976043701172\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.06629464775323868, p.grad.std().item() = 1.2640067338943481\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -5.805830955505371, p.grad.std().item() = 1811.4266357421875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1732.0555419921875, p.grad.std().item() = 2438.982177734375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -1621.153076171875, p.grad.std().item() = 83959.5625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -9.5367431640625e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00029896385967731476, p.std().item() = 0.9455452561378479\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002229690784588456, p.std().item() = 0.9465570449829102\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001418139785528183, p.std().item() = 0.07461123168468475\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10510442405939102, p.std().item() = 0.07150304317474365\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0006617061444558203, p.std().item() = 0.05405263230204582\n",
      "n = 'layers.2.bias', p.mean().item() = 0.11717113852500916, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 57\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00029896385967731476, p.std().item() = 0.9455452561378479\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002229690784588456, p.std().item() = 0.9465570449829102\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001418139785528183, p.std().item() = 0.07461123168468475\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10510442405939102, p.std().item() = 0.07150304317474365\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0006617061444558203, p.std().item() = 0.05405263230204582\n",
      "n = 'layers.2.bias', p.mean().item() = 0.11717113852500916, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.6437767744064331, preds.std().item() = 1.4321166276931763\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7465, device='cuda:0'), loss.std() = tensor(0.0691, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.222557885626756e-11, lambda_i.std().item() = 0.23199985921382904\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 3.300301978015341e-05, p.grad.std().item() = 25.465452194213867\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0036856969818472862, p.grad.std().item() = 0.9686576724052429\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -11.566617012023926, p.grad.std().item() = 1413.855224609375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 120.67489624023438, p.grad.std().item() = 839.9769897460938\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 4097.74609375, p.grad.std().item() = 31711.615234375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000324249267578125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0003196116304025054, p.std().item() = 0.9446192383766174\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002197247464209795, p.std().item() = 0.9457982778549194\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014276758302003145, p.std().item() = 0.0752490758895874\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10569857060909271, p.std().item() = 0.07275477051734924\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00034316888195462525, p.std().item() = 0.05469100549817085\n",
      "n = 'layers.2.bias', p.mean().item() = 0.11900589615106583, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 58\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0003196116304025054, p.std().item() = 0.9446192383766174\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002197247464209795, p.std().item() = 0.9457982778549194\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014276758302003145, p.std().item() = 0.0752490758895874\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10569857060909271, p.std().item() = 0.07275477051734924\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00034316888195462525, p.std().item() = 0.05469100549817085\n",
      "n = 'layers.2.bias', p.mean().item() = 0.11900589615106583, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.5744296312332153, preds.std().item() = 1.4117542505264282\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7230, device='cuda:0'), loss.std() = tensor(0.0618, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.881168717111976e-11, lambda_i.std().item() = 0.22066707909107208\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0021771632600575686, p.grad.std().item() = 21.447378158569336\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0032173392828553915, p.grad.std().item() = 1.0052067041397095\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -8.97857666015625, p.grad.std().item() = 1243.473876953125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 17.150177001953125, p.grad.std().item() = 768.0466918945312\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 8866.884765625, p.grad.std().item() = 25149.17578125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0005893707275390625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00034131944994442165, p.std().item() = 0.9436942934989929\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0021585060749202967, p.std().item() = 0.9450450539588928\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001428311108611524, p.std().item() = 0.07590316236019135\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1062767282128334, p.std().item() = 0.07410592585802078\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00020671247330028564, p.std().item() = 0.055342141538858414\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12201409786939621, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 59\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00034131944994442165, p.std().item() = 0.9436942934989929\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0021585060749202967, p.std().item() = 0.9450450539588928\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001428311108611524, p.std().item() = 0.07590316236019135\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1062767282128334, p.std().item() = 0.07410592585802078\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00020671247330028564, p.std().item() = 0.055342141538858414\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12201409786939621, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.6252335906028748, preds.std().item() = 1.5149062871932983\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7245, device='cuda:0'), loss.std() = tensor(0.0564, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.152508612109145e-11, lambda_i.std().item() = 0.21326710283756256\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0014395861653611064, p.grad.std().item() = 28.69525718688965\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.00548422709107399, p.grad.std().item() = 0.9971580505371094\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 17.19231414794922, p.grad.std().item() = 1719.7449951171875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 235.17864990234375, p.grad.std().item() = 1002.093505859375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 4465.12158203125, p.grad.std().item() = 31783.990234375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 3.4332275390625e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0003644033567979932, p.std().item() = 0.9427705407142639\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002134190406650305, p.std().item() = 0.944280207157135\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001437298720702529, p.std().item() = 0.0765622928738594\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10692258924245834, p.std().item() = 0.07532833516597748\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00015345215797424316, p.std().item() = 0.055980946868658066\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12465473264455795, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 60\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0003644033567979932, p.std().item() = 0.9427705407142639\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002134190406650305, p.std().item() = 0.944280207157135\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001437298720702529, p.std().item() = 0.0765622928738594\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10692258924245834, p.std().item() = 0.07532833516597748\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00015345215797424316, p.std().item() = 0.055980946868658066\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12465473264455795, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.6637246012687683, preds.std().item() = 1.5518678426742554\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7510, device='cuda:0'), loss.std() = tensor(0.0758, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.493160258942311e-11, lambda_i.std().item() = 0.2093668282032013\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.001749466871842742, p.grad.std().item() = 28.496599197387695\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.023640573024749756, p.grad.std().item() = 1.013625979423523\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 7.257013320922852, p.grad.std().item() = 1597.4879150390625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 649.9688720703125, p.grad.std().item() = 1154.5198974609375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 19104.1015625, p.grad.std().item() = 30883.25390625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00087738037109375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00038828220567665994, p.std().item() = 0.9418475031852722\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002148982137441635, p.std().item() = 0.9435119032859802\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014409113209694624, p.std().item() = 0.0772438645362854\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10801276564598083, p.std().item() = 0.07659482955932617\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0005819915095344186, p.std().item() = 0.05629660189151764\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12490933388471603, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 61\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00038828220567665994, p.std().item() = 0.9418475031852722\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002148982137441635, p.std().item() = 0.9435119032859802\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014409113209694624, p.std().item() = 0.0772438645362854\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10801276564598083, p.std().item() = 0.07659482955932617\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0005819915095344186, p.std().item() = 0.05629660189151764\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12490933388471603, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.7707844376564026, preds.std().item() = 1.6026185750961304\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7265, device='cuda:0'), loss.std() = tensor(0.0610, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.842771571064944e-11, lambda_i.std().item() = 0.22850514948368073\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00010680838022381067, p.grad.std().item() = 24.36548614501953\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.037244029343128204, p.grad.std().item() = 1.1469480991363525\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -15.3952054977417, p.grad.std().item() = 1360.3341064453125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -944.8362426757812, p.grad.std().item() = 1353.941162109375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 10401.814453125, p.grad.std().item() = 50600.67578125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0008487701416015625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00041358586167916656, p.std().item() = 0.9409260749816895\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002097632270306349, p.std().item() = 0.9427318572998047\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014344570226967335, p.std().item() = 0.07790683209896088\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10848177969455719, p.std().item() = 0.07812932878732681\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0013668545288965106, p.std().item() = 0.05736900493502617\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12700803577899933, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 62\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00041358586167916656, p.std().item() = 0.9409260749816895\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002097632270306349, p.std().item() = 0.9427318572998047\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014344570226967335, p.std().item() = 0.07790683209896088\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10848177969455719, p.std().item() = 0.07812932878732681\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0013668545288965106, p.std().item() = 0.05736900493502617\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12700803577899933, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.788769006729126, preds.std().item() = 1.6054779291152954\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7302, device='cuda:0'), loss.std() = tensor(0.0683, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.18194609286671e-11, lambda_i.std().item() = 0.224408358335495\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0006892665405757725, p.grad.std().item() = 26.629579544067383\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.024474846199154854, p.grad.std().item() = 1.2582238912582397\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 11.755592346191406, p.grad.std().item() = 1458.7733154296875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 611.2501220703125, p.grad.std().item() = 1244.01416015625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 5632.072265625, p.grad.std().item() = 42369.03125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0001811981201171875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0004395563737489283, p.std().item() = 0.9400056600570679\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020983205176889896, p.std().item() = 0.9419362545013428\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014064296847209334, p.std().item() = 0.07846145331859589\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10941159725189209, p.std().item() = 0.07966303080320358\n",
      "n = 'layers.2.weight', p.mean().item() = -0.002138787182047963, p.std().item() = 0.05776688829064369\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12849201261997223, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 63\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0004395563737489283, p.std().item() = 0.9400056600570679\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020983205176889896, p.std().item() = 0.9419362545013428\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014064296847209334, p.std().item() = 0.07846145331859589\n",
      "n = 'layers.0.bias', p.mean().item() = -0.10941159725189209, p.std().item() = 0.07966303080320358\n",
      "n = 'layers.2.weight', p.mean().item() = -0.002138787182047963, p.std().item() = 0.05776688829064369\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12849201261997223, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.756932258605957, preds.std().item() = 1.7797585725784302\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7309, device='cuda:0'), loss.std() = tensor(0.0767, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.573302484604639e-11, lambda_i.std().item() = 0.22277705371379852\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.002786799566820264, p.grad.std().item() = 25.75371742248535\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.00042235286673530936, p.grad.std().item() = 1.1984666585922241\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 2.213824987411499, p.grad.std().item() = 1385.64208984375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 27.721710205078125, p.grad.std().item() = 837.9625854492188\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 1924.1407470703125, p.grad.std().item() = 25295.41015625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000186920166015625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00046601510257460177, p.std().item() = 0.9390863180160522\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002095166128128767, p.std().item() = 0.9411537647247314\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013763029128313065, p.std().item() = 0.07900159060955048\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11032190918922424, p.std().item() = 0.08126045763492584\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0028460759203881025, p.std().item() = 0.057985953986644745\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12940165400505066, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 64\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.00046601510257460177, p.std().item() = 0.9390863180160522\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002095166128128767, p.std().item() = 0.9411537647247314\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013763029128313065, p.std().item() = 0.07900159060955048\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11032190918922424, p.std().item() = 0.08126045763492584\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0028460759203881025, p.std().item() = 0.057985953986644745\n",
      "n = 'layers.2.bias', p.mean().item() = 0.12940165400505066, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.8090407252311707, preds.std().item() = 1.6892842054367065\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7377, device='cuda:0'), loss.std() = tensor(0.0580, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.007878999321093e-11, lambda_i.std().item() = 0.20824335515499115\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.005680401809513569, p.grad.std().item() = 25.533193588256836\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.00619525695219636, p.grad.std().item() = 1.2606796026229858\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 1.8377209901809692, p.grad.std().item() = 1377.161376953125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 17.993560791015625, p.grad.std().item() = 1232.1129150390625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 1755.8365478515625, p.grad.std().item() = 39853.546875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 6.198883056640625e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0004931120201945305, p.std().item() = 0.9381681084632874\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020710828248411417, p.std().item() = 0.9404134750366211\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013875506119802594, p.std().item() = 0.07968258857727051\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11132153123617172, p.std().item() = 0.08317077904939651\n",
      "n = 'layers.2.weight', p.mean().item() = -0.003599775955080986, p.std().item() = 0.05846110358834267\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1300739347934723, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 65\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0004931120201945305, p.std().item() = 0.9381681084632874\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020710828248411417, p.std().item() = 0.9404134750366211\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013875506119802594, p.std().item() = 0.07968258857727051\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11132153123617172, p.std().item() = 0.08317077904939651\n",
      "n = 'layers.2.weight', p.mean().item() = -0.003599775955080986, p.std().item() = 0.05846110358834267\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1300739347934723, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.9412024617195129, preds.std().item() = 1.8011783361434937\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7462, device='cuda:0'), loss.std() = tensor(0.0712, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.858425715712158e-11, lambda_i.std().item() = 0.2067740261554718\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0012611454585567117, p.grad.std().item() = 28.24112892150879\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.014393975026905537, p.grad.std().item() = 1.2011668682098389\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 19.706260681152344, p.grad.std().item() = 1677.873779296875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 483.07708740234375, p.grad.std().item() = 920.0528564453125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -7664.70458984375, p.grad.std().item() = 49009.74609375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 2.6702880859375e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0005203172913752496, p.std().item() = 0.9372508525848389\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002071239287033677, p.std().item() = 0.9396896362304688\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014164531603455544, p.std().item() = 0.08041393756866455\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11269383877515793, p.std().item() = 0.08515197038650513\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004044720437377691, p.std().item() = 0.0586501881480217\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1306108683347702, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 66\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0005203172913752496, p.std().item() = 0.9372508525848389\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002071239287033677, p.std().item() = 0.9396896362304688\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014164531603455544, p.std().item() = 0.08041393756866455\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11269383877515793, p.std().item() = 0.08515197038650513\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004044720437377691, p.std().item() = 0.0586501881480217\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1306108683347702, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -0.9893608689308167, preds.std().item() = 1.758284091949463\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7419, device='cuda:0'), loss.std() = tensor(0.0678, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.972485254776785e-11, lambda_i.std().item() = 0.20869478583335876\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00045900564873591065, p.grad.std().item() = 30.4207820892334\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.011389541439712048, p.grad.std().item() = 1.1832469701766968\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -13.92588996887207, p.grad.std().item() = 1568.6539306640625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -311.5047302246094, p.grad.std().item() = 1030.6016845703125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -428.169677734375, p.grad.std().item() = 32204.423828125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00037384033203125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0005484545254148543, p.std().item() = 0.9363349080085754\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020553735084831715, p.std().item() = 0.9389652013778687\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014366720570251346, p.std().item() = 0.08112841099500656\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11383403837680817, p.std().item() = 0.08716010302305222\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004491342697292566, p.std().item() = 0.059001341462135315\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1319485455751419, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 67\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0005484545254148543, p.std().item() = 0.9363349080085754\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020553735084831715, p.std().item() = 0.9389652013778687\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014366720570251346, p.std().item() = 0.08112841099500656\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11383403837680817, p.std().item() = 0.08716010302305222\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004491342697292566, p.std().item() = 0.059001341462135315\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1319485455751419, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.198064923286438, preds.std().item() = 1.9235233068466187\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7659, device='cuda:0'), loss.std() = tensor(0.0755, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 5.395492733151208e-11, lambda_i.std().item() = 0.2107360064983368\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0019861399196088314, p.grad.std().item() = 29.283966064453125\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.024747716262936592, p.grad.std().item() = 1.232332468032837\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 16.698339462280273, p.grad.std().item() = 1513.86767578125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 605.9649658203125, p.grad.std().item() = 1021.107666015625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -4483.69873046875, p.grad.std().item() = 33708.5546875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -2.574920654296875e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0005770930438302457, p.std().item() = 0.9354204535484314\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020861378870904446, p.std().item() = 0.9382141828536987\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014346400275826454, p.std().item() = 0.08175776153802872\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1153370663523674, p.std().item() = 0.08900324255228043\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004793798550963402, p.std().item() = 0.058908749371767044\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1332114040851593, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 68\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0005770930438302457, p.std().item() = 0.9354204535484314\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020861378870904446, p.std().item() = 0.9382141828536987\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014346400275826454, p.std().item() = 0.08175776153802872\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1153370663523674, p.std().item() = 0.08900324255228043\n",
      "n = 'layers.2.weight', p.mean().item() = -0.004793798550963402, p.std().item() = 0.058908749371767044\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1332114040851593, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.1817456483840942, preds.std().item() = 1.9311935901641846\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7366, device='cuda:0'), loss.std() = tensor(0.0730, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.580391341357242e-11, lambda_i.std().item() = 0.20922201871871948\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0010980821680277586, p.grad.std().item() = 29.539386749267578\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.022929655387997627, p.grad.std().item() = 1.422630786895752\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -1.1455968618392944, p.grad.std().item() = 1498.7791748046875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -429.3090515136719, p.grad.std().item() = 1097.659912109375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -2387.189453125, p.grad.std().item() = 43952.96875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00042247772216796875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0006062695174477994, p.std().item() = 0.9345070719718933\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002075811382383108, p.std().item() = 0.9374839067459106\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014620694564655423, p.std().item() = 0.08247397094964981\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11655662208795547, p.std().item() = 0.09103868901729584\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005128311458975077, p.std().item() = 0.059183038771152496\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1353219747543335, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 69\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0006062695174477994, p.std().item() = 0.9345070719718933\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002075811382383108, p.std().item() = 0.9374839067459106\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014620694564655423, p.std().item() = 0.08247397094964981\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11655662208795547, p.std().item() = 0.09103868901729584\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005128311458975077, p.std().item() = 0.059183038771152496\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1353219747543335, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.3123875856399536, preds.std().item() = 1.9870566129684448\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7553, device='cuda:0'), loss.std() = tensor(0.0861, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.2568702703133e-11, lambda_i.std().item() = 0.21206898987293243\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0011405979748815298, p.grad.std().item() = 25.603511810302734\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.0257429126650095, p.grad.std().item() = 1.271328330039978\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -15.642457008361816, p.grad.std().item() = 1399.580322265625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 611.5844116210938, p.grad.std().item() = 1202.4488525390625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 4352.31005859375, p.grad.std().item() = 35599.25\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00026416778564453125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0006353999488055706, p.std().item() = 0.9335945844650269\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002104556653648615, p.std().item() = 0.936748743057251\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014896984212100506, p.std().item() = 0.08315970003604889\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11810966581106186, p.std().item() = 0.09296005219221115\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0054680597968399525, p.std().item() = 0.059067148715257645\n",
      "n = 'layers.2.bias', p.mean().item() = 0.13659584522247314, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 70\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0006353999488055706, p.std().item() = 0.9335945844650269\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002104556653648615, p.std().item() = 0.936748743057251\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014896984212100506, p.std().item() = 0.08315970003604889\n",
      "n = 'layers.0.bias', p.mean().item() = -0.11810966581106186, p.std().item() = 0.09296005219221115\n",
      "n = 'layers.2.weight', p.mean().item() = -0.0054680597968399525, p.std().item() = 0.059067148715257645\n",
      "n = 'layers.2.bias', p.mean().item() = 0.13659584522247314, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.221932291984558, preds.std().item() = 2.1151089668273926\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7507, device='cuda:0'), loss.std() = tensor(0.0824, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.086149722557167e-11, lambda_i.std().item() = 0.19975733757019043\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0012994257267564535, p.grad.std().item() = 27.028667449951172\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.061674199998378754, p.grad.std().item() = 1.6333155632019043\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -32.9069938659668, p.grad.std().item() = 1377.270263671875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1441.153076171875, p.grad.std().item() = 1700.3577880859375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 1335.406005859375, p.grad.std().item() = 68273.265625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000278472900390625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0006643451051786542, p.std().item() = 0.9326825737953186\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022194692865014076, p.std().item() = 0.9360089898109436\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0015010974602773786, p.std().item() = 0.08380693942308426\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12051185965538025, p.std().item() = 0.09449004381895065\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005570616573095322, p.std().item() = 0.05789659172296524\n",
      "n = 'layers.2.bias', p.mean().item() = 0.13839316368103027, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 71\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0006643451051786542, p.std().item() = 0.9326825737953186\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022194692865014076, p.std().item() = 0.9360089898109436\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0015010974602773786, p.std().item() = 0.08380693942308426\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12051185965538025, p.std().item() = 0.09449004381895065\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005570616573095322, p.std().item() = 0.05789659172296524\n",
      "n = 'layers.2.bias', p.mean().item() = 0.13839316368103027, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.230927586555481, preds.std().item() = 2.058295726776123\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7484, device='cuda:0'), loss.std() = tensor(0.0767, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 5.49463599619493e-11, lambda_i.std().item() = 0.21181835234165192\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0019074279116466641, p.grad.std().item() = 27.029739379882812\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.021801413968205452, p.grad.std().item() = 1.344342827796936\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 13.903925895690918, p.grad.std().item() = 1336.928466796875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 543.6961669921875, p.grad.std().item() = 1004.4195556640625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 9456.294921875, p.grad.std().item() = 33544.09765625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0002589225769042969, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0006934009143151343, p.std().item() = 0.9317716956138611\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0023545545991510153, p.std().item() = 0.9352335333824158\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014889856101945043, p.std().item() = 0.0843527540564537\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12301373481750488, p.std().item() = 0.09581612795591354\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005867773666977882, p.std().item() = 0.0564902164041996\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1393890529870987, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 72\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0006934009143151343, p.std().item() = 0.9317716956138611\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0023545545991510153, p.std().item() = 0.9352335333824158\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0014889856101945043, p.std().item() = 0.0843527540564537\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12301373481750488, p.std().item() = 0.09581612795591354\n",
      "n = 'layers.2.weight', p.mean().item() = -0.005867773666977882, p.std().item() = 0.0564902164041996\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1393890529870987, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.3548763990402222, preds.std().item() = 1.9547505378723145\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7429, device='cuda:0'), loss.std() = tensor(0.0866, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.915824246085279e-11, lambda_i.std().item() = 0.21037770807743073\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.003035617060959339, p.grad.std().item() = 30.069461822509766\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.007347023580223322, p.grad.std().item() = 1.3651920557022095\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 30.536123275756836, p.grad.std().item() = 1541.208740234375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -208.69927978515625, p.grad.std().item() = 968.6878662109375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 15566.6171875, p.grad.std().item() = 29432.96484375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00016498565673828125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0007226094021461904, p.std().item() = 0.9308621883392334\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0024568464141339064, p.std().item() = 0.9344925880432129\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0015286970883607864, p.std().item() = 0.08502357453107834\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12509970366954803, p.std().item() = 0.09714917838573456\n",
      "n = 'layers.2.weight', p.mean().item() = -0.006519424729049206, p.std().item() = 0.05539606139063835\n",
      "n = 'layers.2.bias', p.mean().item() = 0.13988280296325684, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 73\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0007226094021461904, p.std().item() = 0.9308621883392334\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0024568464141339064, p.std().item() = 0.9344925880432129\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0015286970883607864, p.std().item() = 0.08502357453107834\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12509970366954803, p.std().item() = 0.09714917838573456\n",
      "n = 'layers.2.weight', p.mean().item() = -0.006519424729049206, p.std().item() = 0.05539606139063835\n",
      "n = 'layers.2.bias', p.mean().item() = 0.13988280296325684, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.162660837173462, preds.std().item() = 1.8588660955429077\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7609, device='cuda:0'), loss.std() = tensor(0.0927, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.596045486004456e-11, lambda_i.std().item() = 0.2136366367340088\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.002317051636055112, p.grad.std().item() = 24.491670608520508\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.010854863561689854, p.grad.std().item() = 1.2356334924697876\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -6.3804402351379395, p.grad.std().item() = 1218.647705078125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -253.16416931152344, p.grad.std().item() = 955.3192138671875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 7706.59912109375, p.grad.std().item() = 28194.572265625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00038433074951171875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0007519443170167506, p.std().item() = 0.9299540519714355\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002534026512876153, p.std().item() = 0.9337284564971924\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0015690596774220467, p.std().item() = 0.08559881150722504\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12681947648525238, p.std().item() = 0.09846089035272598\n",
      "n = 'layers.2.weight', p.mean().item() = -0.007341892924159765, p.std().item() = 0.054750360548496246\n",
      "n = 'layers.2.bias', p.mean().item() = 0.14123617112636566, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 74\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0007519443170167506, p.std().item() = 0.9299540519714355\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002534026512876153, p.std().item() = 0.9337284564971924\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0015690596774220467, p.std().item() = 0.08559881150722504\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12681947648525238, p.std().item() = 0.09846089035272598\n",
      "n = 'layers.2.weight', p.mean().item() = -0.007341892924159765, p.std().item() = 0.054750360548496246\n",
      "n = 'layers.2.bias', p.mean().item() = 0.14123617112636566, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.501112937927246, preds.std().item() = 1.9290276765823364\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7441, device='cuda:0'), loss.std() = tensor(0.0806, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.908735389332676e-11, lambda_i.std().item() = 0.2559370696544647\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0017835694598034024, p.grad.std().item() = 40.04988479614258\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0537237673997879, p.grad.std().item() = 1.458107590675354\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -1.9950401782989502, p.grad.std().item() = 1872.9986572265625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1340.5057373046875, p.grad.std().item() = 1738.71484375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -5595.2177734375, p.grad.std().item() = 66814.8046875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0001220703125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0007822656189091504, p.std().item() = 0.9290477633476257\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002546630334109068, p.std().item() = 0.9329623579978943\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0016070589190348983, p.std().item() = 0.08618468046188354\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12747099995613098, p.std().item() = 0.0999264270067215\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008119682781398296, p.std().item() = 0.05524098128080368\n",
      "n = 'layers.2.bias', p.mean().item() = 0.14274580776691437, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 75\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0007822656189091504, p.std().item() = 0.9290477633476257\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002546630334109068, p.std().item() = 0.9329623579978943\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0016070589190348983, p.std().item() = 0.08618468046188354\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12747099995613098, p.std().item() = 0.0999264270067215\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008119682781398296, p.std().item() = 0.05524098128080368\n",
      "n = 'layers.2.bias', p.mean().item() = 0.14274580776691437, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.572866439819336, preds.std().item() = 2.0645132064819336\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7519, device='cuda:0'), loss.std() = tensor(0.0934, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.80811604209164e-11, lambda_i.std().item() = 0.21409226953983307\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00010283286246703938, p.grad.std().item() = 28.562156677246094\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.06383731216192245, p.grad.std().item() = 1.5584224462509155\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 26.32097816467285, p.grad.std().item() = 1467.8406982421875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1357.2139892578125, p.grad.std().item() = 1658.302978515625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -1968.25146484375, p.grad.std().item() = 70729.4765625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00023651123046875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0008130273781716824, p.std().item() = 0.928143322467804\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0024836347438395023, p.std().item() = 0.9321836233139038\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0016425466164946556, p.std().item() = 0.0867631807923317\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1272016167640686, p.std().item() = 0.10167285054922104\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008954313583672047, p.std().item() = 0.056758083403110504\n",
      "n = 'layers.2.bias', p.mean().item() = 0.14467394351959229, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 76\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0008130273781716824, p.std().item() = 0.928143322467804\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0024836347438395023, p.std().item() = 0.9321836233139038\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0016425466164946556, p.std().item() = 0.0867631807923317\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1272016167640686, p.std().item() = 0.10167285054922104\n",
      "n = 'layers.2.weight', p.mean().item() = -0.008954313583672047, p.std().item() = 0.056758083403110504\n",
      "n = 'layers.2.bias', p.mean().item() = 0.14467394351959229, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.647771954536438, preds.std().item() = 2.1263222694396973\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7464, device='cuda:0'), loss.std() = tensor(0.0861, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.0561389957031153e-10, lambda_i.std().item() = 0.20377950370311737\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0007455070735886693, p.grad.std().item() = 30.262645721435547\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.01780751906335354, p.grad.std().item() = 1.3723300695419312\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 14.469393730163574, p.grad.std().item() = 1398.00634765625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -321.03839111328125, p.grad.std().item() = 977.91357421875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -1671.6068115234375, p.grad.std().item() = 34250.8359375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0005655288696289062, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0008439241209998727, p.std().item() = 0.9272401928901672\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002407316816970706, p.std().item() = 0.9314161539077759\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001708792638964951, p.std().item() = 0.08736135065555573\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12685254216194153, p.std().item() = 0.10342361032962799\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00969959981739521, p.std().item() = 0.05848871171474457\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1477418690919876, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 77\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0008439241209998727, p.std().item() = 0.9272401928901672\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002407316816970706, p.std().item() = 0.9314161539077759\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001708792638964951, p.std().item() = 0.08736135065555573\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12685254216194153, p.std().item() = 0.10342361032962799\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00969959981739521, p.std().item() = 0.05848871171474457\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1477418690919876, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.6852471828460693, preds.std().item() = 2.3761720657348633\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7357, device='cuda:0'), loss.std() = tensor(0.0946, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.990010207960864e-11, lambda_i.std().item() = 0.18116158246994019\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00158320099581033, p.grad.std().item() = 28.366989135742188\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.03421757370233536, p.grad.std().item() = 1.620823621749878\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -11.923681259155273, p.grad.std().item() = 1265.161376953125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 708.949462890625, p.grad.std().item() = 1014.159912109375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 8255.1279296875, p.grad.std().item() = 39263.328125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00013065338134765625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0008741211495362222, p.std().item() = 0.9263375997543335\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002373842755332589, p.std().item() = 0.9306632876396179\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0017620290163904428, p.std().item() = 0.08798635005950928\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12701396644115448, p.std().item() = 0.1049402579665184\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010444876737892628, p.std().item() = 0.059547193348407745\n",
      "n = 'layers.2.bias', p.mean().item() = 0.15019090473651886, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 78\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0008741211495362222, p.std().item() = 0.9263375997543335\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002373842755332589, p.std().item() = 0.9306632876396179\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0017620290163904428, p.std().item() = 0.08798635005950928\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12701396644115448, p.std().item() = 0.1049402579665184\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010444876737892628, p.std().item() = 0.059547193348407745\n",
      "n = 'layers.2.bias', p.mean().item() = 0.15019090473651886, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -1.8593666553497314, preds.std().item() = 2.427224636077881\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7433, device='cuda:0'), loss.std() = tensor(0.1015, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.44954437079015e-11, lambda_i.std().item() = 0.20221960544586182\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0033197328448295593, p.grad.std().item() = 32.27437210083008\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.008289181627333164, p.grad.std().item() = 1.4280136823654175\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -18.929096221923828, p.grad.std().item() = 1418.2689208984375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -245.93373107910156, p.grad.std().item() = 1052.6397705078125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 19578.0, p.grad.std().item() = 36457.21875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00022220611572265625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0009039972210302949, p.std().item() = 0.92543625831604\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002325571607798338, p.std().item() = 0.9299123883247375\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0017970000626519322, p.std().item() = 0.08858814835548401\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12697410583496094, p.std().item() = 0.10648062080144882\n",
      "n = 'layers.2.weight', p.mean().item() = -0.01152802910655737, p.std().item() = 0.06056542322039604\n",
      "n = 'layers.2.bias', p.mean().item() = 0.15293650329113007, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 79\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0009039972210302949, p.std().item() = 0.92543625831604\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002325571607798338, p.std().item() = 0.9299123883247375\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0017970000626519322, p.std().item() = 0.08858814835548401\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12697410583496094, p.std().item() = 0.10648062080144882\n",
      "n = 'layers.2.weight', p.mean().item() = -0.01152802910655737, p.std().item() = 0.06056542322039604\n",
      "n = 'layers.2.bias', p.mean().item() = 0.15293650329113007, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.0587122440338135, preds.std().item() = 2.4523391723632812\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.8126, device='cuda:0'), loss.std() = tensor(0.1258, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.0963181751311168e-10, lambda_i.std().item() = 0.21664130687713623\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0029031261801719666, p.grad.std().item() = 32.868309020996094\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.0009720505913719535, p.grad.std().item() = 1.5891379117965698\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 1.4709495306015015, p.grad.std().item() = 1595.6964111328125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -150.67169189453125, p.grad.std().item() = 1266.462646484375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 14637.341796875, p.grad.std().item() = 37651.36328125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00044345855712890625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0009337522787973285, p.std().item() = 0.9245362281799316\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022785004694014788, p.std().item() = 0.9291406869888306\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0017853379249572754, p.std().item() = 0.08907430619001389\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1268751472234726, p.std().item() = 0.1082223430275917\n",
      "n = 'layers.2.weight', p.mean().item() = -0.012779442593455315, p.std().item() = 0.061265818774700165\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1543004959821701, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 80\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0009337522787973285, p.std().item() = 0.9245362281799316\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022785004694014788, p.std().item() = 0.9291406869888306\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0017853379249572754, p.std().item() = 0.08907430619001389\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1268751472234726, p.std().item() = 0.1082223430275917\n",
      "n = 'layers.2.weight', p.mean().item() = -0.012779442593455315, p.std().item() = 0.061265818774700165\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1543004959821701, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.149160385131836, preds.std().item() = 2.664134979248047\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7972, device='cuda:0'), loss.std() = tensor(0.1315, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.199076668655934e-11, lambda_i.std().item() = 0.18578468263149261\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0007408579695038497, p.grad.std().item() = 36.16393280029297\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.038477301597595215, p.grad.std().item() = 1.608323097229004\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -56.26282501220703, p.grad.std().item() = 1651.111083984375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 906.09716796875, p.grad.std().item() = 1165.4229736328125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 11513.576171875, p.grad.std().item() = 61897.1796875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0001678466796875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0009624152444303036, p.std().item() = 0.923636257648468\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022769642528146505, p.std().item() = 0.9283819198608398\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0017446221318095922, p.std().item() = 0.08955541998147964\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12745486199855804, p.std().item() = 0.10968642681837082\n",
      "n = 'layers.2.weight', p.mean().item() = -0.013969178311526775, p.std().item() = 0.06094415485858917\n",
      "n = 'layers.2.bias', p.mean().item() = 0.15593452751636505, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 81\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0009624152444303036, p.std().item() = 0.923636257648468\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022769642528146505, p.std().item() = 0.9283819198608398\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0017446221318095922, p.std().item() = 0.08955541998147964\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12745486199855804, p.std().item() = 0.10968642681837082\n",
      "n = 'layers.2.weight', p.mean().item() = -0.013969178311526775, p.std().item() = 0.06094415485858917\n",
      "n = 'layers.2.bias', p.mean().item() = 0.15593452751636505, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.1403379440307617, preds.std().item() = 2.5879693031311035\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7670, device='cuda:0'), loss.std() = tensor(0.0989, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.40445274538537e-11, lambda_i.std().item() = 0.1929784119129181\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.000728493498172611, p.grad.std().item() = 27.32876205444336\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.013732168823480606, p.grad.std().item() = 1.5089167356491089\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -7.7192559242248535, p.grad.std().item() = 1170.1917724609375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 253.59803771972656, p.grad.std().item() = 715.21533203125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 7362.3974609375, p.grad.std().item() = 27687.14453125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0002593994140625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.000990316504612565, p.std().item() = 0.9227370023727417\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002293001627549529, p.std().item() = 0.9276053309440613\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0016848428640514612, p.std().item() = 0.08995621651411057\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12814486026763916, p.std().item() = 0.11100679636001587\n",
      "n = 'layers.2.weight', p.mean().item() = -0.01515056099742651, p.std().item() = 0.060454584658145905\n",
      "n = 'layers.2.bias', p.mean().item() = 0.15803784132003784, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 82\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.000990316504612565, p.std().item() = 0.9227370023727417\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002293001627549529, p.std().item() = 0.9276053309440613\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0016848428640514612, p.std().item() = 0.08995621651411057\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12814486026763916, p.std().item() = 0.11100679636001587\n",
      "n = 'layers.2.weight', p.mean().item() = -0.01515056099742651, p.std().item() = 0.060454584658145905\n",
      "n = 'layers.2.bias', p.mean().item() = 0.15803784132003784, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.333171844482422, preds.std().item() = 2.617741584777832\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7992, device='cuda:0'), loss.std() = tensor(0.1242, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.94191448716397e-11, lambda_i.std().item() = 0.18247008323669434\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 5.6567507272120565e-05, p.grad.std().item() = 34.092315673828125\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.054382842034101486, p.grad.std().item() = 1.6117579936981201\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -25.765758514404297, p.grad.std().item() = 1615.645263671875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1082.996826171875, p.grad.std().item() = 1528.7589111328125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 9363.564453125, p.grad.std().item() = 57977.89453125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00010013580322265625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0010172248585149646, p.std().item() = 0.9218380451202393\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0023687565699219704, p.std().item() = 0.9268202185630798\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0016196668148040771, p.std().item() = 0.09032769501209259\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12949980795383453, p.std().item() = 0.11208900064229965\n",
      "n = 'layers.2.weight', p.mean().item() = -0.016256701201200485, p.std().item() = 0.059229087084531784\n",
      "n = 'layers.2.bias', p.mean().item() = 0.15967993438243866, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 83\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0010172248585149646, p.std().item() = 0.9218380451202393\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0023687565699219704, p.std().item() = 0.9268202185630798\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0016196668148040771, p.std().item() = 0.09032769501209259\n",
      "n = 'layers.0.bias', p.mean().item() = -0.12949980795383453, p.std().item() = 0.11208900064229965\n",
      "n = 'layers.2.weight', p.mean().item() = -0.016256701201200485, p.std().item() = 0.059229087084531784\n",
      "n = 'layers.2.bias', p.mean().item() = 0.15967993438243866, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.549429178237915, preds.std().item() = 2.6285531520843506\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7517, device='cuda:0'), loss.std() = tensor(0.1085, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.1004926830926465e-10, lambda_i.std().item() = 0.20102010667324066\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0029024919494986534, p.grad.std().item() = 30.448740005493164\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.025567498058080673, p.grad.std().item() = 1.5252041816711426\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -9.167072296142578, p.grad.std().item() = 1299.9774169921875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -557.0421142578125, p.grad.std().item() = 1207.244873046875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 5652.4833984375, p.grad.std().item() = 29197.34375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 6.771087646484375e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0010436723241582513, p.std().item() = 0.9209404587745667\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0023983363062143326, p.std().item() = 0.9260590076446533\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0015512044774368405, p.std().item() = 0.09075399488210678\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13036032021045685, p.std().item() = 0.11331421136856079\n",
      "n = 'layers.2.weight', p.mean().item() = -0.017413649708032608, p.std().item() = 0.05852371081709862\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16098366677761078, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 84\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0010436723241582513, p.std().item() = 0.9209404587745667\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0023983363062143326, p.std().item() = 0.9260590076446533\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0015512044774368405, p.std().item() = 0.09075399488210678\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13036032021045685, p.std().item() = 0.11331421136856079\n",
      "n = 'layers.2.weight', p.mean().item() = -0.017413649708032608, p.std().item() = 0.05852371081709862\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16098366677761078, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.422860860824585, preds.std().item() = 2.7494091987609863\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7950, device='cuda:0'), loss.std() = tensor(0.1326, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.157726660324883e-11, lambda_i.std().item() = 0.20140227675437927\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.002853339770808816, p.grad.std().item() = 31.635108947753906\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.036947816610336304, p.grad.std().item() = 1.5679110288619995\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -52.65200424194336, p.grad.std().item() = 1389.9085693359375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 822.380126953125, p.grad.std().item() = 1056.6060791015625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 1899.8115234375, p.grad.std().item() = 51770.09765625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -4.38690185546875e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0010695031378418207, p.std().item() = 0.9200437068939209\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0024836529046297073, p.std().item() = 0.9252537488937378\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001411117729730904, p.std().item() = 0.09103727340698242\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13169780373573303, p.std().item() = 0.11414831876754761\n",
      "n = 'layers.2.weight', p.mean().item() = -0.018364518880844116, p.std().item() = 0.05710799619555473\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1622621864080429, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 85\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0010695031378418207, p.std().item() = 0.9200437068939209\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0024836529046297073, p.std().item() = 0.9252537488937378\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001411117729730904, p.std().item() = 0.09103727340698242\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13169780373573303, p.std().item() = 0.11414831876754761\n",
      "n = 'layers.2.weight', p.mean().item() = -0.018364518880844116, p.std().item() = 0.05710799619555473\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1622621864080429, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.4420650005340576, preds.std().item() = 2.6597578525543213\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7482, device='cuda:0'), loss.std() = tensor(0.1038, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.1208431405229646e-10, lambda_i.std().item() = 0.2008340209722519\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0033236430026590824, p.grad.std().item() = 26.95248031616211\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.012179763987660408, p.grad.std().item() = 1.3392682075500488\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -8.523544311523438, p.grad.std().item() = 1112.3682861328125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -107.56431579589844, p.grad.std().item() = 789.7516479492188\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -15156.669921875, p.grad.std().item() = 26746.29296875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000213623046875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0010948858689516783, p.std().item() = 0.9191479682922363\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002558707259595394, p.std().item() = 0.9244312644004822\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0012599921319633722, p.std().item() = 0.09130929410457611\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1328754723072052, p.std().item() = 0.11482248455286026\n",
      "n = 'layers.2.weight', p.mean().item() = -0.01891399174928665, p.std().item() = 0.055865880101919174\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16394802927970886, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 86\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0010948858689516783, p.std().item() = 0.9191479682922363\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002558707259595394, p.std().item() = 0.9244312644004822\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0012599921319633722, p.std().item() = 0.09130929410457611\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1328754723072052, p.std().item() = 0.11482248455286026\n",
      "n = 'layers.2.weight', p.mean().item() = -0.01891399174928665, p.std().item() = 0.055865880101919174\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16394802927970886, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.506927967071533, preds.std().item() = 2.5936450958251953\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7611, device='cuda:0'), loss.std() = tensor(0.1042, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.007878999321093e-11, lambda_i.std().item() = 0.19657425582408905\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.002902305917814374, p.grad.std().item() = 29.496545791625977\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.006241499911993742, p.grad.std().item() = 1.299261450767517\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -14.529136657714844, p.grad.std().item() = 1314.1768798828125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 253.9252166748047, p.grad.std().item() = 967.6683349609375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -7329.72998046875, p.grad.std().item() = 28375.80859375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000141143798828125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0011198279680684209, p.std().item() = 0.9182529449462891\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0026408773846924305, p.std().item() = 0.9236106872558594\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0011169081553816795, p.std().item() = 0.0915997326374054\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13409839570522308, p.std().item() = 0.11534886807203293\n",
      "n = 'layers.2.weight', p.mean().item() = -0.01924508437514305, p.std().item() = 0.054545994848012924\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16509680449962616, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 87\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0011198279680684209, p.std().item() = 0.9182529449462891\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0026408773846924305, p.std().item() = 0.9236106872558594\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0011169081553816795, p.std().item() = 0.0915997326374054\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13409839570522308, p.std().item() = 0.11534886807203293\n",
      "n = 'layers.2.weight', p.mean().item() = -0.01924508437514305, p.std().item() = 0.054545994848012924\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16509680449962616, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.5698204040527344, preds.std().item() = 2.5635807514190674\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7633, device='cuda:0'), loss.std() = tensor(0.0859, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.698536335671747e-11, lambda_i.std().item() = 0.2008604258298874\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0035622920840978622, p.grad.std().item() = 27.95442771911621\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.052195869386196136, p.grad.std().item() = 1.5588772296905518\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -28.9077205657959, p.grad.std().item() = 1301.2109375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1462.8704833984375, p.grad.std().item() = 1916.8056640625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -4887.2958984375, p.grad.std().item() = 83447.734375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000133514404296875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0011446505086496472, p.std().item() = 0.9173594117164612\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002639614976942539, p.std().item() = 0.922844648361206\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0009821243584156036, p.std().item() = 0.09208648651838303\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13423693180084229, p.std().item() = 0.11646723002195358\n",
      "n = 'layers.2.weight', p.mean().item() = -0.019697096198797226, p.std().item() = 0.05469420552253723\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16646744310855865, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 88\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0011446505086496472, p.std().item() = 0.9173594117164612\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002639614976942539, p.std().item() = 0.922844648361206\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0009821243584156036, p.std().item() = 0.09208648651838303\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13423693180084229, p.std().item() = 0.11646723002195358\n",
      "n = 'layers.2.weight', p.mean().item() = -0.019697096198797226, p.std().item() = 0.05469420552253723\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16646744310855865, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.460087537765503, preds.std().item() = 2.5415258407592773\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7642, device='cuda:0'), loss.std() = tensor(0.1116, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.371272953664686e-11, lambda_i.std().item() = 0.20477217435836792\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0011082340497523546, p.grad.std().item() = 27.610509872436523\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.022459726780653, p.grad.std().item() = 1.280814290046692\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 15.977059364318848, p.grad.std().item() = 1178.95947265625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -451.3932800292969, p.grad.std().item() = 896.2709350585938\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 7227.8466796875, p.grad.std().item() = 32899.0078125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0005083084106445312, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0011691524414345622, p.std().item() = 0.916467010974884\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0026106711011379957, p.std().item() = 0.9220656752586365\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008575211395509541, p.std().item() = 0.09254509955644608\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13410553336143494, p.std().item() = 0.11775995790958405\n",
      "n = 'layers.2.weight', p.mean().item() = -0.020320767536759377, p.std().item() = 0.055265288800001144\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16636690497398376, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 89\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0011691524414345622, p.std().item() = 0.916467010974884\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0026106711011379957, p.std().item() = 0.9220656752586365\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008575211395509541, p.std().item() = 0.09254509955644608\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13410553336143494, p.std().item() = 0.11775995790958405\n",
      "n = 'layers.2.weight', p.mean().item() = -0.020320767536759377, p.std().item() = 0.055265288800001144\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16636690497398376, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.559077024459839, preds.std().item() = 2.5690183639526367\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7696, device='cuda:0'), loss.std() = tensor(0.1102, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.569955244925765e-11, lambda_i.std().item() = 0.19339510798454285\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0009680982329882681, p.grad.std().item() = 27.788524627685547\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.03580959513783455, p.grad.std().item() = 1.408108115196228\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -33.18265151977539, p.grad.std().item() = 1305.409423828125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1061.9986572265625, p.grad.std().item() = 1337.383544921875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -177.62953186035156, p.grad.std().item() = 59371.15625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00025844573974609375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0011929655447602272, p.std().item() = 0.9155753254890442\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0026192371733486652, p.std().item() = 0.9212767481803894\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007288835477083921, p.std().item() = 0.09292604774236679\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13473080098628998, p.std().item() = 0.11867082118988037\n",
      "n = 'layers.2.weight', p.mean().item() = -0.020678598433732986, p.std().item() = 0.05491962656378746\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1669275462627411, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 90\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0011929655447602272, p.std().item() = 0.9155753254890442\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0026192371733486652, p.std().item() = 0.9212767481803894\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007288835477083921, p.std().item() = 0.09292604774236679\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13473080098628998, p.std().item() = 0.11867082118988037\n",
      "n = 'layers.2.weight', p.mean().item() = -0.020678598433732986, p.std().item() = 0.05491962656378746\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1669275462627411, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.3874199390411377, preds.std().item() = 2.519299030303955\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7702, device='cuda:0'), loss.std() = tensor(0.0904, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.1385846432343527e-10, lambda_i.std().item() = 0.21670353412628174\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0003812300565186888, p.grad.std().item() = 23.247644424438477\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.057214658707380295, p.grad.std().item() = 1.6873327493667603\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 18.58108139038086, p.grad.std().item() = 1196.0855712890625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1661.19775390625, p.grad.std().item() = 2251.69873046875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -694.0404663085938, p.grad.std().item() = 76587.2109375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000324249267578125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0012164595536887646, p.std().item() = 0.9146846532821655\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0025423860643059015, p.std().item() = 0.920562744140625\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006754203350283206, p.std().item() = 0.09350568801164627\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13433626294136047, p.std().item() = 0.1202673688530922\n",
      "n = 'layers.2.weight', p.mean().item() = -0.021167797967791557, p.std().item() = 0.055710356682538986\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16657719016075134, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 91\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0012164595536887646, p.std().item() = 0.9146846532821655\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0025423860643059015, p.std().item() = 0.920562744140625\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006754203350283206, p.std().item() = 0.09350568801164627\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13433626294136047, p.std().item() = 0.1202673688530922\n",
      "n = 'layers.2.weight', p.mean().item() = -0.021167797967791557, p.std().item() = 0.055710356682538986\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16657719016075134, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.638998031616211, preds.std().item() = 2.631531000137329\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7625, device='cuda:0'), loss.std() = tensor(0.1147, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.1474553252011077e-10, lambda_i.std().item() = 0.21280211210250854\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.002792449900880456, p.grad.std().item() = 26.146333694458008\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.04445120692253113, p.grad.std().item() = 1.5578981637954712\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 32.17649841308594, p.grad.std().item() = 1236.73583984375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1380.5809326171875, p.grad.std().item() = 1900.7315673828125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -1949.3824462890625, p.grad.std().item() = 69054.328125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000537872314453125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.001239502802491188, p.std().item() = 0.9137954711914062\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002416682429611683, p.std().item() = 0.9198790788650513\n",
      "n = 'layers.0.weight', p.mean().item() = -0.000672859838232398, p.std().item() = 0.0941721573472023\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13312742114067078, p.std().item() = 0.12223915010690689\n",
      "n = 'layers.2.weight', p.mean().item() = -0.02175876498222351, p.std().item() = 0.057390641421079636\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16762730479240417, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 92\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.001239502802491188, p.std().item() = 0.9137954711914062\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002416682429611683, p.std().item() = 0.9198790788650513\n",
      "n = 'layers.0.weight', p.mean().item() = -0.000672859838232398, p.std().item() = 0.0941721573472023\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13312742114067078, p.std().item() = 0.12223915010690689\n",
      "n = 'layers.2.weight', p.mean().item() = -0.02175876498222351, p.std().item() = 0.057390641421079636\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16762730479240417, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.9280998706817627, preds.std().item() = 2.9699549674987793\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7908, device='cuda:0'), loss.std() = tensor(0.1290, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.117458705740987e-11, lambda_i.std().item() = 0.19938445091247559\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.00036972135421819985, p.grad.std().item() = 26.055465698242188\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.008821533061563969, p.grad.std().item() = 1.465623140335083\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -22.4599552154541, p.grad.std().item() = 1098.71826171875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -428.787109375, p.grad.std().item() = 1049.567138671875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -7016.85986328125, p.grad.std().item() = 34113.07421875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -9.5367431640625e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0012617508182302117, p.std().item() = 0.912907063961029\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002287772484123707, p.std().item() = 0.9192012548446655\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006526220240630209, p.std().item() = 0.09485531598329544\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1318276822566986, p.std().item() = 0.12428269535303116\n",
      "n = 'layers.2.weight', p.mean().item() = -0.022189965471625328, p.std().item() = 0.05932850390672684\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16880963742733002, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 93\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0012617508182302117, p.std().item() = 0.912907063961029\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002287772484123707, p.std().item() = 0.9192012548446655\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006526220240630209, p.std().item() = 0.09485531598329544\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1318276822566986, p.std().item() = 0.12428269535303116\n",
      "n = 'layers.2.weight', p.mean().item() = -0.022189965471625328, p.std().item() = 0.05932850390672684\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16880963742733002, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.206573247909546, preds.std().item() = 3.1989526748657227\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.8047, device='cuda:0'), loss.std() = tensor(0.1452, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.267306366744776e-11, lambda_i.std().item() = 0.1901826709508896\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.002064214553683996, p.grad.std().item() = 35.64094924926758\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.049116842448711395, p.grad.std().item() = 1.8433011770248413\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 12.676209449768066, p.grad.std().item() = 1555.162109375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1494.1612548828125, p.grad.std().item() = 1771.2305908203125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -22855.138671875, p.grad.std().item() = 81824.9609375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0001068115234375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0012830591294914484, p.std().item() = 0.9120192527770996\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002236422384157777, p.std().item() = 0.9184499382972717\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006287622381933033, p.std().item() = 0.09532076120376587\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1316484957933426, p.std().item() = 0.1256340593099594\n",
      "n = 'layers.2.weight', p.mean().item() = -0.021884843707084656, p.std().item() = 0.059767160564661026\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16958653926849365, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 94\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0012830591294914484, p.std().item() = 0.9120192527770996\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002236422384157777, p.std().item() = 0.9184499382972717\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006287622381933033, p.std().item() = 0.09532076120376587\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1316484957933426, p.std().item() = 0.1256340593099594\n",
      "n = 'layers.2.weight', p.mean().item() = -0.021884843707084656, p.std().item() = 0.059767160564661026\n",
      "n = 'layers.2.bias', p.mean().item() = 0.16958653926849365, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.2006070613861084, preds.std().item() = 3.1498613357543945\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.8378, device='cuda:0'), loss.std() = tensor(0.1435, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.275871654639388e-11, lambda_i.std().item() = 0.18090908229351044\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0019734613597393036, p.grad.std().item() = 29.85749053955078\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.018479643389582634, p.grad.std().item() = 1.4353622198104858\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 20.804508209228516, p.grad.std().item() = 1243.8885498046875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 519.234619140625, p.grad.std().item() = 1031.6195068359375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 519.9415283203125, p.grad.std().item() = 30154.607421875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00011730194091796875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0013035095762461424, p.std().item() = 0.9111320376396179\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022112736478447914, p.std().item() = 0.9176831245422363\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006138342432677746, p.std().item() = 0.09574030339717865\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13188813626766205, p.std().item() = 0.12673398852348328\n",
      "n = 'layers.2.weight', p.mean().item() = -0.021515363827347755, p.std().item() = 0.05995362997055054\n",
      "n = 'layers.2.bias', p.mean().item() = 0.17058199644088745, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 95\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0013035095762461424, p.std().item() = 0.9111320376396179\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022112736478447914, p.std().item() = 0.9176831245422363\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006138342432677746, p.std().item() = 0.09574030339717865\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13188813626766205, p.std().item() = 0.12673398852348328\n",
      "n = 'layers.2.weight', p.mean().item() = -0.021515363827347755, p.std().item() = 0.05995362997055054\n",
      "n = 'layers.2.bias', p.mean().item() = 0.17058199644088745, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.3425750732421875, preds.std().item() = 3.245729923248291\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.8061, device='cuda:0'), loss.std() = tensor(0.1378, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.293002230428613e-11, lambda_i.std().item() = 0.17597660422325134\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0034068082459270954, p.grad.std().item() = 40.90977096557617\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.05423052981495857, p.grad.std().item() = 1.6754933595657349\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 48.681575775146484, p.grad.std().item() = 1583.2684326171875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1386.3116455078125, p.grad.std().item() = 1711.5439453125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 3945.29931640625, p.grad.std().item() = 80959.703125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0001735687255859375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.001322853029705584, p.std().item() = 0.9102451205253601\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022428371012210846, p.std().item() = 0.9169191122055054\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006286126445047557, p.std().item() = 0.09612887352705002\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13299722969532013, p.std().item() = 0.12733493745326996\n",
      "n = 'layers.2.weight', p.mean().item() = -0.021026529371738434, p.std().item() = 0.05913790687918663\n",
      "n = 'layers.2.bias', p.mean().item() = 0.17100822925567627, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 96\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.001322853029705584, p.std().item() = 0.9102451205253601\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022428371012210846, p.std().item() = 0.9169191122055054\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006286126445047557, p.std().item() = 0.09612887352705002\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13299722969532013, p.std().item() = 0.12733493745326996\n",
      "n = 'layers.2.weight', p.mean().item() = -0.021026529371738434, p.std().item() = 0.05913790687918663\n",
      "n = 'layers.2.bias', p.mean().item() = 0.17100822925567627, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.20409893989563, preds.std().item() = 3.0948290824890137\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7988, device='cuda:0'), loss.std() = tensor(0.1434, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.011620616394822e-11, lambda_i.std().item() = 0.18334601819515228\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0014371090801432729, p.grad.std().item() = 32.495635986328125\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.005737103521823883, p.grad.std().item() = 1.5755631923675537\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 38.24758529663086, p.grad.std().item() = 1332.5155029296875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 149.81520080566406, p.grad.std().item() = 871.89453125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -5200.90478515625, p.grad.std().item() = 26771.751953125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00014400482177734375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0013414445566013455, p.std().item() = 0.9093587398529053\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002254762686789036, p.std().item() = 0.9161702990531921\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006838903063908219, p.std().item() = 0.09657370299100876\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13416439294815063, p.std().item() = 0.1280120462179184\n",
      "n = 'layers.2.weight', p.mean().item() = -0.020435823127627373, p.std().item() = 0.058272190392017365\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1717606782913208, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 97\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0013414445566013455, p.std().item() = 0.9093587398529053\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002254762686789036, p.std().item() = 0.9161702990531921\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0006838903063908219, p.std().item() = 0.09657370299100876\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13416439294815063, p.std().item() = 0.1280120462179184\n",
      "n = 'layers.2.weight', p.mean().item() = -0.020435823127627373, p.std().item() = 0.058272190392017365\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1717606782913208, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.2807722091674805, preds.std().item() = 3.204521656036377\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7768, device='cuda:0'), loss.std() = tensor(0.1187, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.663485735414199e-11, lambda_i.std().item() = 0.16813214123249054\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0015672834124416113, p.grad.std().item() = 22.565526962280273\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.006014315877109766, p.grad.std().item() = 1.6408631801605225\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 20.797863006591797, p.grad.std().item() = 1047.7205810546875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 105.1113052368164, p.grad.std().item() = 719.9381103515625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 10554.984375, p.grad.std().item() = 23114.291015625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0004253387451171875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0013594108168035746, p.std().item() = 0.9084734320640564\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022674892097711563, p.std().item() = 0.9154281616210938\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007576760253868997, p.std().item() = 0.09704867750406265\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13527347147464752, p.std().item() = 0.12866728007793427\n",
      "n = 'layers.2.weight', p.mean().item() = -0.02008921653032303, p.std().item() = 0.057473015040159225\n",
      "n = 'layers.2.bias', p.mean().item() = 0.17354516685009003, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 98\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0013594108168035746, p.std().item() = 0.9084734320640564\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022674892097711563, p.std().item() = 0.9154281616210938\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007576760253868997, p.std().item() = 0.09704867750406265\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13527347147464752, p.std().item() = 0.12866728007793427\n",
      "n = 'layers.2.weight', p.mean().item() = -0.02008921653032303, p.std().item() = 0.057473015040159225\n",
      "n = 'layers.2.bias', p.mean().item() = 0.17354516685009003, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.2650721073150635, preds.std().item() = 3.0173583030700684\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7929, device='cuda:0'), loss.std() = tensor(0.1227, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.345182712585995e-11, lambda_i.std().item() = 0.2056456357240677\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0012685800902545452, p.grad.std().item() = 45.240577697753906\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.01975439116358757, p.grad.std().item() = 1.443247675895691\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 10.88570785522461, p.grad.std().item() = 1985.9307861328125\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -578.3075561523438, p.grad.std().item() = 1049.8173828125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -36937.43359375, p.grad.std().item() = 43627.71484375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000469207763671875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0013776249252259731, p.std().item() = 0.9075899124145508\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022631234023720026, p.std().item() = 0.9146654605865479\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007949206046760082, p.std().item() = 0.09745702892541885\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13590751588344574, p.std().item() = 0.12946882843971252\n",
      "n = 'layers.2.weight', p.mean().item() = -0.019048750400543213, p.std().item() = 0.056787408888339996\n",
      "n = 'layers.2.bias', p.mean().item() = 0.17636136710643768, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 99\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0013776249252259731, p.std().item() = 0.9075899124145508\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0022631234023720026, p.std().item() = 0.9146654605865479\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0007949206046760082, p.std().item() = 0.09745702892541885\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13590751588344574, p.std().item() = 0.12946882843971252\n",
      "n = 'layers.2.weight', p.mean().item() = -0.019048750400543213, p.std().item() = 0.056787408888339996\n",
      "n = 'layers.2.bias', p.mean().item() = 0.17636136710643768, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.1143457889556885, preds.std().item() = 2.957336664199829\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7912, device='cuda:0'), loss.std() = tensor(0.1257, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.0639661374156617e-10, lambda_i.std().item() = 0.1958763599395752\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0006521210889331996, p.grad.std().item() = 27.836082458496094\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.05611535534262657, p.grad.std().item() = 1.7054851055145264\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 2.1711254119873047, p.grad.std().item() = 1168.6187744140625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1334.89794921875, p.grad.std().item() = 1635.4456787109375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -4871.86572265625, p.grad.std().item() = 69040.578125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.000194549560546875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0013962418306618929, p.std().item() = 0.9067082405090332\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0021978404838591814, p.std().item() = 0.9139164090156555\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008185544866137207, p.std().item() = 0.09788632392883301\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13567675650119781, p.std().item() = 0.13065418601036072\n",
      "n = 'layers.2.weight', p.mean().item() = -0.018174506723880768, p.std().item() = 0.057201236486434937\n",
      "n = 'layers.2.bias', p.mean().item() = 0.178374782204628, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 100\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0013962418306618929, p.std().item() = 0.9067082405090332\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0021978404838591814, p.std().item() = 0.9139164090156555\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0008185544866137207, p.std().item() = 0.09788632392883301\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13567675650119781, p.std().item() = 0.13065418601036072\n",
      "n = 'layers.2.weight', p.mean().item() = -0.018174506723880768, p.std().item() = 0.057201236486434937\n",
      "n = 'layers.2.bias', p.mean().item() = 0.178374782204628, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.1369011402130127, preds.std().item() = 3.152305841445923\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7665, device='cuda:0'), loss.std() = tensor(0.1076, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.577782317249373e-11, lambda_i.std().item() = 0.1923971176147461\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0027701144572347403, p.grad.std().item() = 34.20102310180664\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.007029685657471418, p.grad.std().item() = 1.4598779678344727\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 0.9561564326286316, p.grad.std().item() = 1448.896240234375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -174.70773315429688, p.grad.std().item() = 811.3628540039062\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -5578.4140625, p.grad.std().item() = 32655.927734375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00027751922607421875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0014150121714919806, p.std().item() = 0.9058273434638977\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0021272439043968916, p.std().item() = 0.9131777286529541\n",
      "n = 'layers.0.weight', p.mean().item() = -0.000864985806401819, p.std().item() = 0.09833867847919464\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1353377252817154, p.std().item() = 0.1318577080965042\n",
      "n = 'layers.2.weight', p.mean().item() = -0.017297908663749695, p.std().item() = 0.05781867727637291\n",
      "n = 'layers.2.bias', p.mean().item() = 0.18091221153736115, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 101\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0014150121714919806, p.std().item() = 0.9058273434638977\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0021272439043968916, p.std().item() = 0.9131777286529541\n",
      "n = 'layers.0.weight', p.mean().item() = -0.000864985806401819, p.std().item() = 0.09833867847919464\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1353377252817154, p.std().item() = 0.1318577080965042\n",
      "n = 'layers.2.weight', p.mean().item() = -0.017297908663749695, p.std().item() = 0.05781867727637291\n",
      "n = 'layers.2.bias', p.mean().item() = 0.18091221153736115, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.2514591217041016, preds.std().item() = 3.1411919593811035\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7881, device='cuda:0'), loss.std() = tensor(0.1336, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.3332708789019e-11, lambda_i.std().item() = 0.19691510498523712\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -2.6678597350837663e-05, p.grad.std().item() = 31.040510177612305\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.012452855706214905, p.grad.std().item() = 1.4754208326339722\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 27.494298934936523, p.grad.std().item() = 1305.1636962890625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -153.6822052001953, p.grad.std().item() = 658.3218994140625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -15956.810546875, p.grad.std().item() = 33167.77734375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00032711029052734375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0014339917106553912, p.std().item() = 0.9049473404884338\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020503040868788958, p.std().item() = 0.9124370813369751\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0009049800573848188, p.std().item() = 0.09875909984111786\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13491849601268768, p.std().item() = 0.13299217820167542\n",
      "n = 'layers.2.weight', p.mean().item() = -0.01620413549244404, p.std().item() = 0.05817849189043045\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1823074072599411, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 102\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0014339917106553912, p.std().item() = 0.9049473404884338\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020503040868788958, p.std().item() = 0.9124370813369751\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0009049800573848188, p.std().item() = 0.09875909984111786\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13491849601268768, p.std().item() = 0.13299217820167542\n",
      "n = 'layers.2.weight', p.mean().item() = -0.01620413549244404, p.std().item() = 0.05817849189043045\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1823074072599411, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.2830941677093506, preds.std().item() = 3.3028512001037598\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7753, device='cuda:0'), loss.std() = tensor(0.1234, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 4.839767475672829e-11, lambda_i.std().item() = 0.16034702956676483\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 6.490318628493696e-05, p.grad.std().item() = 23.35230255126953\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.01404672209173441, p.grad.std().item() = 1.6618716716766357\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 8.461518287658691, p.grad.std().item() = 956.73046875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 453.755859375, p.grad.std().item() = 651.3284301757812\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 20135.123046875, p.grad.std().item() = 33163.39453125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 4.3392181396484375e-05, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.001452530617825687, p.std().item() = 0.9040675163269043\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019913031719624996, p.std().item() = 0.911708414554596\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0009817328536882997, p.std().item() = 0.09924931824207306\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13487085700035095, p.std().item() = 0.13396355509757996\n",
      "n = 'layers.2.weight', p.mean().item() = -0.015566622838377953, p.std().item() = 0.05832478776574135\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1834377497434616, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 103\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.001452530617825687, p.std().item() = 0.9040675163269043\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019913031719624996, p.std().item() = 0.911708414554596\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0009817328536882997, p.std().item() = 0.09924931824207306\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13487085700035095, p.std().item() = 0.13396355509757996\n",
      "n = 'layers.2.weight', p.mean().item() = -0.015566622838377953, p.std().item() = 0.05832478776574135\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1834377497434616, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.220489025115967, preds.std().item() = 3.195150375366211\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.8042, device='cuda:0'), loss.std() = tensor(0.1355, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.514032451805264e-11, lambda_i.std().item() = 0.19381076097488403\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.002990064211189747, p.grad.std().item() = 38.21466827392578\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.04268481582403183, p.grad.std().item() = 1.7855422496795654\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 2.0533299446105957, p.grad.std().item() = 1546.822998046875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 1206.801025390625, p.grad.std().item() = 1552.8402099609375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -19336.810546875, p.grad.std().item() = 66501.0390625\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00037860870361328125, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0014712376287207007, p.std().item() = 0.9031884670257568\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019941998180001974, p.std().item() = 0.9109038710594177\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010075096506625414, p.std().item() = 0.09950777143239975\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1355915516614914, p.std().item() = 0.13434156775474548\n",
      "n = 'layers.2.weight', p.mean().item() = -0.014469699934124947, p.std().item() = 0.0575215145945549\n",
      "n = 'layers.2.bias', p.mean().item() = 0.18545086681842804, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 104\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0014712376287207007, p.std().item() = 0.9031884670257568\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019941998180001974, p.std().item() = 0.9109038710594177\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010075096506625414, p.std().item() = 0.09950777143239975\n",
      "n = 'layers.0.bias', p.mean().item() = -0.1355915516614914, p.std().item() = 0.13434156775474548\n",
      "n = 'layers.2.weight', p.mean().item() = -0.014469699934124947, p.std().item() = 0.0575215145945549\n",
      "n = 'layers.2.bias', p.mean().item() = 0.18545086681842804, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.196944236755371, preds.std().item() = 3.1096901893615723\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7812, device='cuda:0'), loss.std() = tensor(0.1171, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.76450015393948e-11, lambda_i.std().item() = 0.18045294284820557\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 3.9269551052711904e-05, p.grad.std().item() = 29.408634185791016\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.016777371987700462, p.grad.std().item() = 1.4400417804718018\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 36.04988479614258, p.grad.std().item() = 1278.0504150390625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 374.8757629394531, p.grad.std().item() = 953.9278564453125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 4374.11669921875, p.grad.std().item() = 26060.841796875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00018978118896484375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0014900934183970094, p.std().item() = 0.9023105502128601\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020165699534118176, p.std().item() = 0.9100782871246338\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010513780871406198, p.std().item() = 0.09975900501012802\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13642217218875885, p.std().item() = 0.1345938742160797\n",
      "n = 'layers.2.weight', p.mean().item() = -0.013560679741203785, p.std().item() = 0.056749727576971054\n",
      "n = 'layers.2.bias', p.mean().item() = 0.18776516616344452, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 105\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0014900934183970094, p.std().item() = 0.9023105502128601\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0020165699534118176, p.std().item() = 0.9100782871246338\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0010513780871406198, p.std().item() = 0.09975900501012802\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13642217218875885, p.std().item() = 0.1345938742160797\n",
      "n = 'layers.2.weight', p.mean().item() = -0.013560679741203785, p.std().item() = 0.056749727576971054\n",
      "n = 'layers.2.bias', p.mean().item() = 0.18776516616344452, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.9809935092926025, preds.std().item() = 2.9869871139526367\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7852, device='cuda:0'), loss.std() = tensor(0.1230, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.0290050062033984e-10, lambda_i.std().item() = 0.19030092656612396\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.001096544787287712, p.grad.std().item() = 29.35496711730957\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.024315224960446358, p.grad.std().item() = 1.560589075088501\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 18.401960372924805, p.grad.std().item() = 1297.119140625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -624.5577392578125, p.grad.std().item() = 1025.0574951171875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -8507.576171875, p.grad.std().item() = 40536.171875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000179290771484375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0015094209229573607, p.std().item() = 0.9014336466789246\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002021918771788478, p.std().item() = 0.9092504978179932\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001095856772735715, p.std().item() = 0.10002228617668152\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13678056001663208, p.std().item() = 0.13479341566562653\n",
      "n = 'layers.2.weight', p.mean().item() = -0.012628214433789253, p.std().item() = 0.05650210753083229\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19032630324363708, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 106\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0015094209229573607, p.std().item() = 0.9014336466789246\n",
      "n = 'label_factors.weight', p.mean().item() = 0.002021918771788478, p.std().item() = 0.9092504978179932\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001095856772735715, p.std().item() = 0.10002228617668152\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13678056001663208, p.std().item() = 0.13479341566562653\n",
      "n = 'layers.2.weight', p.mean().item() = -0.012628214433789253, p.std().item() = 0.05650210753083229\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19032630324363708, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.902092456817627, preds.std().item() = 2.8356971740722656\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7420, device='cuda:0'), loss.std() = tensor(0.0905, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.139463491569799e-11, lambda_i.std().item() = 0.185678631067276\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.003113793907687068, p.grad.std().item() = 23.490148544311523\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.04631275311112404, p.grad.std().item() = 1.643416166305542\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 13.331720352172852, p.grad.std().item() = 1078.6746826171875\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -1268.2803955078125, p.grad.std().item() = 1437.323974609375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 7154.6650390625, p.grad.std().item() = 72685.1171875\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0001430511474609375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0015295346966013312, p.std().item() = 0.9005582928657532\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019863408524543047, p.std().item() = 0.9084384441375732\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0011668333318084478, p.std().item() = 0.10034926980733871\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13618817925453186, p.std().item() = 0.1352505087852478\n",
      "n = 'layers.2.weight', p.mean().item() = -0.012080156244337559, p.std().item() = 0.057428788393735886\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19223493337631226, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 107\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0015295346966013312, p.std().item() = 0.9005582928657532\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019863408524543047, p.std().item() = 0.9084384441375732\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0011668333318084478, p.std().item() = 0.10034926980733871\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13618817925453186, p.std().item() = 0.1352505087852478\n",
      "n = 'layers.2.weight', p.mean().item() = -0.012080156244337559, p.std().item() = 0.057428788393735886\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19223493337631226, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -2.7706170082092285, preds.std().item() = 2.9162631034851074\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7513, device='cuda:0'), loss.std() = tensor(0.0986, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 9.07945593708881e-11, lambda_i.std().item() = 0.18192653357982635\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0022287399042397738, p.grad.std().item() = 26.099864959716797\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.009321002289652824, p.grad.std().item() = 1.4820060729980469\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -28.796831130981445, p.grad.std().item() = 1066.0166015625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 251.5722198486328, p.grad.std().item() = 670.135498046875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 4414.86669921875, p.grad.std().item() = 20940.33984375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.0001964569091796875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0015497407875955105, p.std().item() = 0.89968341588974\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019671889021992683, p.std().item() = 0.9076261520385742\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0012255182955414057, p.std().item() = 0.10072124749422073\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13575702905654907, p.std().item() = 0.1355404406785965\n",
      "n = 'layers.2.weight', p.mean().item() = -0.011607794091105461, p.std().item() = 0.05830729007720947\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19340232014656067, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 108\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0015497407875955105, p.std().item() = 0.89968341588974\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019671889021992683, p.std().item() = 0.9076261520385742\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0012255182955414057, p.std().item() = 0.10072124749422073\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13575702905654907, p.std().item() = 0.1355404406785965\n",
      "n = 'layers.2.weight', p.mean().item() = -0.011607794091105461, p.std().item() = 0.05830729007720947\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19340232014656067, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.075732469558716, preds.std().item() = 2.996744155883789\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7967, device='cuda:0'), loss.std() = tensor(0.1191, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 1.0561389957031153e-10, lambda_i.std().item() = 0.19313646852970123\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.005889348220080137, p.grad.std().item() = 32.562870025634766\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.01504959911108017, p.grad.std().item() = 1.5122202634811401\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -8.610806465148926, p.grad.std().item() = 1401.2698974609375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -595.9221801757812, p.grad.std().item() = 1350.2135009765625\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 11471.39453125, p.grad.std().item() = 34920.78125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.0002651214599609375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0015704486286267638, p.std().item() = 0.8988094329833984\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019299015402793884, p.std().item() = 0.9068382978439331\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0012799707474187016, p.std().item() = 0.10111149400472641\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13503813743591309, p.std().item() = 0.13602764904499054\n",
      "n = 'layers.2.weight', p.mean().item() = -0.011395897716283798, p.std().item() = 0.05940771847963333\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1951664835214615, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 109\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0015704486286267638, p.std().item() = 0.8988094329833984\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019299015402793884, p.std().item() = 0.9068382978439331\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0012799707474187016, p.std().item() = 0.10111149400472641\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13503813743591309, p.std().item() = 0.13602764904499054\n",
      "n = 'layers.2.weight', p.mean().item() = -0.011395897716283798, p.std().item() = 0.05940771847963333\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1951664835214615, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.065370798110962, preds.std().item() = 3.077261209487915\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7541, device='cuda:0'), loss.std() = tensor(0.1083, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 7.22703841216088e-11, lambda_i.std().item() = 0.19343002140522003\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0012680807849392295, p.grad.std().item() = 39.59743118286133\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.032627545297145844, p.grad.std().item() = 1.6250125169754028\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -9.880276679992676, p.grad.std().item() = 1725.9447021484375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 892.3458251953125, p.grad.std().item() = 1234.520751953125\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -21171.58203125, p.grad.std().item() = 71678.5234375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00040435791015625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.001591406064108014, p.std().item() = 0.8979359865188599\n",
      "n = 'label_factors.weight', p.mean().item() = 0.001926483935676515, p.std().item() = 0.9060320258140564\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001297998009249568, p.std().item() = 0.1013823002576828\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13506874442100525, p.std().item() = 0.13629212975502014\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010687680914998055, p.std().item() = 0.05932758003473282\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1956183761358261, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 110\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.001591406064108014, p.std().item() = 0.8979359865188599\n",
      "n = 'label_factors.weight', p.mean().item() = 0.001926483935676515, p.std().item() = 0.9060320258140564\n",
      "n = 'layers.0.weight', p.mean().item() = -0.001297998009249568, p.std().item() = 0.1013823002576828\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13506874442100525, p.std().item() = 0.13629212975502014\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010687680914998055, p.std().item() = 0.05932758003473282\n",
      "n = 'layers.2.bias', p.mean().item() = 0.1956183761358261, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.1413731575012207, preds.std().item() = 3.1692910194396973\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.8023, device='cuda:0'), loss.std() = tensor(0.1406, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 8.703754383887485e-11, lambda_i.std().item() = 0.185069739818573\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.002058903221040964, p.grad.std().item() = 31.718000411987305\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.024387015029788017, p.grad.std().item() = 1.583886742591858\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -3.4189209938049316, p.grad.std().item() = 1303.8052978515625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -645.57568359375, p.grad.std().item() = 1031.9935302734375\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 2481.562744140625, p.grad.std().item() = 50038.83203125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = 0.00017452239990234375, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0016127279959619045, p.std().item() = 0.8970634937286377\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0018946720520034432, p.std().item() = 0.9052440524101257\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013246557209640741, p.std().item() = 0.10169624537229538\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13469287753105164, p.std().item() = 0.1367456316947937\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010070975869894028, p.std().item() = 0.06000670790672302\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19552625715732574, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 111\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0016127279959619045, p.std().item() = 0.8970634937286377\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0018946720520034432, p.std().item() = 0.9052440524101257\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013246557209640741, p.std().item() = 0.10169624537229538\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13469287753105164, p.std().item() = 0.1367456316947937\n",
      "n = 'layers.2.weight', p.mean().item() = -0.010070975869894028, p.std().item() = 0.06000670790672302\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19552625715732574, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.0808420181274414, preds.std().item() = 3.1498219966888428\n",
      "loss.shape = torch.Size([32, 2231]), loss.mean() = tensor(0.7990, device='cuda:0'), loss.std() = tensor(0.1389, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.115587203314732e-11, lambda_i.std().item() = 0.17264722287654877\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = -0.0023720914032310247, p.grad.std().item() = 30.2102108001709\n",
      "n = 'label_factors.weight', p.grad.mean().item() = -0.041139572858810425, p.grad.std().item() = 1.6788650751113892\n",
      "n = 'layers.0.weight', p.grad.mean().item() = -16.1324520111084, p.grad.std().item() = 1266.2095947265625\n",
      "n = 'layers.0.bias', p.grad.mean().item() = 974.5369873046875, p.grad.std().item() = 1193.9256591796875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = -351.7588195800781, p.grad.std().item() = 54943.20703125\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.00016117095947265625, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0016335630789399147, p.std().item() = 0.8961915373802185\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019070738926529884, p.std().item() = 0.9044297337532043\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013296434190124273, p.std().item() = 0.10193848609924316\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13507026433944702, p.std().item() = 0.1369725912809372\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009424838237464428, p.std().item() = 0.059943828731775284\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19587215781211853, p.std().item() = nan\n",
      "-------\n",
      "mini-batch: 112\n",
      "The params before update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0016335630789399147, p.std().item() = 0.8961915373802185\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019070738926529884, p.std().item() = 0.9044297337532043\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013296434190124273, p.std().item() = 0.10193848609924316\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13507026433944702, p.std().item() = 0.1369725912809372\n",
      "n = 'layers.2.weight', p.mean().item() = -0.009424838237464428, p.std().item() = 0.059943828731775284\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19587215781211853, p.std().item() = nan\n",
      "preds are good! No nan/inf, but preds.mean().item() = -3.947190761566162, preds.std().item() = 2.671699285507202\n",
      "loss.shape = torch.Size([4, 2231]), loss.mean() = tensor(0.6747, device='cuda:0'), loss.std() = tensor(0.0897, device='cuda:0')\n",
      "lambda_i are good! No nan/inf, but lambda_i.mean().item() = 6.478765857131918e-10, lambda_i.std().item() = 0.24233655631542206\n",
      "The gradients\n",
      "n = 'token_factors.weight', p.grad.mean().item() = 0.0007790217641741037, p.grad.std().item() = 32.56541442871094\n",
      "n = 'label_factors.weight', p.grad.mean().item() = 0.01978415809571743, p.grad.std().item() = 1.0051461458206177\n",
      "n = 'layers.0.weight', p.grad.mean().item() = 22.390331268310547, p.grad.std().item() = 1443.1566162109375\n",
      "n = 'layers.0.bias', p.grad.mean().item() = -600.4844360351562, p.grad.std().item() = 1094.5975341796875\n",
      "n = 'layers.2.weight', p.grad.mean().item() = 5181.07373046875, p.grad.std().item() = 31936.130859375\n",
      "n = 'layers.2.bias', p.grad.mean().item() = -0.000732421875, p.grad.std().item() = nan\n",
      "The params after update\n",
      "n = 'token_factors.weight', p.mean().item() = -0.0016522742807865143, p.std().item() = 0.8953196406364441\n",
      "n = 'label_factors.weight', p.mean().item() = 0.0019030466210097075, p.std().item() = 0.9035980701446533\n",
      "n = 'layers.0.weight', p.mean().item() = -0.0013063851511105895, p.std().item() = 0.10213199257850647\n",
      "n = 'layers.0.bias', p.mean().item() = -0.13495877385139465, p.std().item() = 0.13731786608695984\n",
      "n = 'layers.2.weight', p.mean().item() = -0.00900451559573412, p.std().item() = 0.06021321564912796\n",
      "n = 'layers.2.bias', p.mean().item() = 0.19813936948776245, p.std().item() = nan\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for i,xb in enumerate(progress_bar(dls.train)):\n",
    "    print(f\"mini-batch: {i}\")\n",
    "    \n",
    "    print('The params before update')\n",
    "    for n,p in model.named_parameters():\n",
    "        print(f\"{n = }, {p.mean().item() = }, {p.std().item() = }\")\n",
    "        \n",
    "        if p.sum().isnan():\n",
    "            print(\"there is a nan in {n}\")\n",
    "            import pdb; pdb.set_trace()\n",
    "            print('---')\n",
    "            \n",
    "    preds = model(xb)\n",
    "    \n",
    "    if ( ~(torch.isnan(preds).logical_not().all()) or ~(torch.isinf(preds).logical_not().all()) ):\n",
    "        print(f\"DAMN! preds have nan/inf: {i}\")\n",
    "        import pdb; pdb.set_trace()\n",
    "        print(\"broken\")\n",
    "    else: print(f\"preds are good! No nan/inf, but {preds.mean().item() = }, {preds.std().item() = }\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss = loss_func(preds, xb)\n",
    "        if ( ~(torch.isnan(loss).logical_not().all()) or ~(torch.isinf(loss).logical_not().all()) ):\n",
    "            print(f\"DAMN! loss is nan/inf: {i}\")\n",
    "            import pdb; pdb.set_trace()\n",
    "            print(\"broken\")\n",
    "        else: print(f\"{loss.shape = }, {loss.mean() = }, {loss.std() = }\")\n",
    "    \n",
    "    preds, lambda_i = grad_func(preds, xb)\n",
    "    preds, lambda_i = preds.squeeze(-1), lambda_i.squeeze(-1)\n",
    "    with torch.no_grad():\n",
    "        norm_lambda_i = nn.BatchNorm1d(2231, device=xb.device)(lambda_i)\n",
    "    preds.backward(norm_lambda_i)\n",
    "    \n",
    "    if ( ~(torch.isnan(lambda_i).logical_not().all()) or ~(torch.isinf(lambda_i).logical_not().all()) ):\n",
    "        print(f\"DAMN! lambda_i have nan/inf: {i}\")\n",
    "        import pdb; pdb.set_trace()\n",
    "        print(\"broken\")\n",
    "    else: print(f\"lambda_i are good! No nan/inf, but {lambda_i.mean().item() = }, {lambda_i.std().item() = }\")\n",
    "    \n",
    "    print('The gradients')\n",
    "    for n,p in model.named_parameters():\n",
    "        print(f\"{n = }, {p.grad.mean().item() = }, {p.grad.std().item() = }\")\n",
    "        \n",
    "        if p.grad.sum().isnan():\n",
    "            print(f\"DAMN! There is a nan/inf in {n} grad\")\n",
    "            import pdb; pdb.set_trace()\n",
    "            print('broken')\n",
    "            \n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    print('The params after update')\n",
    "    for n,p in model.named_parameters():\n",
    "        print(f\"{n = }, {p.mean().item() = }, {p.std().item() = }\")\n",
    "        \n",
    "        if p.sum().isnan():\n",
    "            print(f\"DAMN! There is a nan/inf in {n}\")\n",
    "            import pdb; pdb.set_trace()\n",
    "            print('broken')\n",
    "        \n",
    "    print(\"-------\")\n",
    "    \n",
    "    # if not torch.logical_not(torch.isnan(preds.flatten())).all():\n",
    "    #     print(f\"DAMN: {i}\")\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a857d6b-c2bf-43f9-a0f9-d113e3b9e34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_ndcg (candi. 32)</th>\n",
       "      <th>val ndcg@6 (candi. 32)</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8255</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.5525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61820dfb-21a6-4873-8b10-d406824f5260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2231, 64]), torch.Size([4, 2231, 64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_i.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a662f5-eb5a-4ea4-a327-256e89780438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2231, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_i_sum = lambda_i.sum(-1).unsqueeze(-1)\n",
    "lambda_i_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777164c-e85b-447d-8169-ff8c6d874e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_i_norm = lambda_i/lambda_i_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b52a5-fc41-4fd1-8bb7-4b52f7ea3d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1677e-01,  1.0218e-01,  8.9841e-02,  7.9228e-02,  6.9976e-02,  6.1817e-02,  5.4553e-02,  4.8031e-02,  4.9332e-09,  4.5990e-09,  4.2766e-09,  3.9651e-09,  3.6640e-09,  3.3728e-09,\n",
       "         3.0908e-09,  2.8176e-09,  3.7630e-03,  4.4693e-03,  5.1448e-03,  5.7916e-03,  6.4118e-03,  7.0072e-03,  7.5795e-03,  8.1301e-03,  9.6947e-01,  5.1925e-01,  3.5953e-01,  2.7497e-01,\n",
       "         2.2151e-01,  1.8413e-01,  1.5622e-01,  1.3443e-01,  3.9025e-02,  3.3656e-02,  2.8742e-02,  2.4221e-02,  2.0044e-02,  1.6168e-02,  1.2558e-02,  9.1857e-03,  2.5526e-09,  2.2956e-09,\n",
       "         2.0461e-09,  1.8037e-09,  1.5680e-09,  1.3389e-09,  1.1159e-09,  8.9876e-10, -3.8376e-08, -3.9198e-08, -3.9999e-08, -4.0780e-08, -4.1543e-08, -4.2288e-08, -4.3015e-08, -4.3726e-08,\n",
       "        -4.3490e-01, -4.4265e-01, -4.4995e-01, -4.5685e-01, -4.6338e-01, -4.6957e-01, -4.7545e-01, -4.8105e-01], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_i[0, 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a6597-1b0c-4caa-8f08-c202495323cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.7954e+05,  8.5716e+05,  7.5364e+05,  6.6461e+05,  5.8700e+05,  5.1856e+05,  4.5763e+05,  4.0291e+05,  4.1383e-02,  3.8579e-02,  3.5874e-02,  3.3262e-02,  3.0736e-02,  2.8293e-02,\n",
       "         2.5927e-02,  2.3635e-02,  3.1567e+04,  3.7491e+04,  4.3157e+04,  4.8583e+04,  5.3786e+04,  5.8781e+04,  6.3581e+04,  6.8201e+04,  8.1325e+06,  4.3558e+06,  3.0160e+06,  2.3066e+06,\n",
       "         1.8582e+06,  1.5446e+06,  1.3105e+06,  1.1276e+06,  3.2737e+05,  2.8233e+05,  2.4110e+05,  2.0318e+05,  1.6814e+05,  1.3562e+05,  1.0534e+05,  7.7055e+04,  2.1413e-02,  1.9257e-02,\n",
       "         1.7164e-02,  1.5130e-02,  1.3154e-02,  1.1231e-02,  9.3607e-03,  7.5393e-03, -3.2192e-01, -3.2881e-01, -3.3554e-01, -3.4209e-01, -3.4849e-01, -3.5474e-01, -3.6084e-01, -3.6680e-01,\n",
       "        -3.6482e+06, -3.7132e+06, -3.7745e+06, -3.8323e+06, -3.8871e+06, -3.9390e+06, -3.9884e+06, -4.0353e+06], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_i_norm[0, 56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822e433-fa07-4b73-82f4-e46d6b1f6457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds.shape, preds.sum().isnan(), preds.min().isinf(), preds.max().isinf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24c879-cd0e-48fb-91ad-b68946a972c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = 'token_factors.weight', p.shape = torch.Size([57353, 200])\n",
      "nan:  False\n",
      "inf:  False\n",
      "-inf:  False\n",
      "p.mean().item() = -0.030002744868397713, p.std().item() = 4.039689540863037\n",
      "p.grad.mean().item() = 0.0, p.grad.std().item() = 0.0\n",
      "---\n",
      "name = 'token_bias.weight', p.shape = torch.Size([57353, 1])\n",
      "nan:  False\n",
      "inf:  False\n",
      "-inf:  False\n",
      "p.mean().item() = -1.710799217224121, p.std().item() = 5.6113080978393555\n",
      "p.grad.mean().item() = 0.0, p.grad.std().item() = 0.0\n",
      "---\n",
      "name = 'label_factors.weight', p.shape = torch.Size([8923, 200])\n",
      "nan:  False\n",
      "inf:  False\n",
      "-inf:  False\n",
      "p.mean().item() = 0.015834469348192215, p.std().item() = 1.6407610177993774\n",
      "p.grad.mean().item() = 0.0, p.grad.std().item() = 0.0\n",
      "---\n",
      "name = 'label_bias.weight', p.shape = torch.Size([8923, 1])\n",
      "nan:  False\n",
      "inf:  False\n",
      "-inf:  False\n",
      "p.mean().item() = 16.79933738708496, p.std().item() = 10.657652854919434\n",
      "p.grad.mean().item() = 0.0, p.grad.std().item() = 0.0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "model = learner.model\n",
    "for name,p in model.named_parameters():\n",
    "    print(f\"{name = }, {p.shape = }\")\n",
    "    print(\"nan: \", p.sum().isnan().item())\n",
    "    print(\"inf: \", p.max().isinf().item())\n",
    "    print(\"-inf: \", p.min().isinf().item())\n",
    "    print(f\"{p.mean().item() = }, {p.std().item() = }\")\n",
    "    if p.grad is not None: print(f\"{p.grad.mean().item() = }, {p.grad.std().item() = }\") \n",
    "    else: print('grad is None')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d8973-3a06-458c-974d-6d337cfb33ae",
   "metadata": {},
   "source": [
    "Save the model: <mark> Also need to save optimizer's state now </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce2036-0432-47d4-a58f-219612829330",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_sd = opt.state_dict()\n",
    "torch.save(opt_sd, 'ranknet_opt_sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921909a4-0edc-4c82-a083-09e834859711",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = rank_model.state_dict()\n",
    "sum([sys.getsizeof(v.storage()) for v in sd.values()])/1024**2\n",
    "torch.save(sd, 'ranknet_sd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efa9b2-7a1b-4eab-a84c-31569bb3c220",
   "metadata": {},
   "source": [
    "Load it back and validate: <mark>(fix this later, as we are now using the fastai's optimizer)</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5dcc3-3849-49a3-ae84-c88c1820f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranknet_sd = torch.load('ranknet_sd')\n",
    "rank_model.load_state_dict(ranknet_sd)\n",
    "opt_sd = torch.load('ranknet_opt_sd')\n",
    "opt.load_state_dict(opt_sd)\n",
    "# [torch.equal(p1, p2) for p1, p2 in zip(opt.params, rank_model.state_dict().values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29f66a6-4451-46e8-8bff-e80254dfb537",
   "metadata": {},
   "source": [
    "#### Toy Implementation of RankNet and LambdaRank:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be44b3-aae4-4105-880c-86dd938f1d9e",
   "metadata": {},
   "source": [
    "Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d3ba1-b40a-42a6-bfc4-c3098029b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 50\n",
    "n_docs = 20\n",
    "n_rel = 5\n",
    "n_irr = n_docs - n_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004c2ed-6afc-4f76-b662-07cc320240e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| doc_features.shape: torch.Size([20, 50])\n"
     ]
    }
   ],
   "source": [
    "doc_features = torch.randn(n_docs, input_dim).to('cuda:0')\n",
    "ic(doc_features.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea27b80-ec96-4341-ba21-7d43fd21782a",
   "metadata": {},
   "source": [
    "Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99359a5-98c5-4d29-b36a-0d0fba6c0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(input_dim, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53977a-7497-48f7-a795-34bc2e834acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5840c73-3006-4798-97d6-427346c679ee",
   "metadata": {},
   "source": [
    "Document scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99ed89a-53d5-401a-a58e-33cbe50a6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_scores = model(doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2442a4-4950-4fb0-8d42-5e1639cac9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2bd87f-e126-44a6-88f9-361b67680937",
   "metadata": {},
   "source": [
    "Document Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09849c10-47e9-42dc-9f37-9109ec8d6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores, sorted_idxs = doc_scores.sort(dim=0, descending=True)\n",
    "doc_ranks = torch.zeros(n_docs).to('cuda:0')\n",
    "doc_ranks[sorted_idxs] = 1 + torch.arange(n_docs).view((n_docs, 1)).to('cuda:0').float()\n",
    "doc_ranks = doc_ranks.view((n_docs, 1))\n",
    "# Alternatively,\n",
    "doc_ranks2 = 1 + doc_scores.argsort(descending=True, dim=0).argsort(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9fa056-9786-4b97-9b93-4411275ea6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>ranks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.263623</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.251701</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.231704</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.195766</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.256772</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.238881</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.224846</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.284661</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.215124</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.310080</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.251531</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.256881</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.120806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.288171</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.249740</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.321594</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.206383</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.221547</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.277746</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.257285</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      scores  ranks\n",
       "0  -0.263623   15.0\n",
       "1  -0.251701   11.0\n",
       "2  -0.231704    7.0\n",
       "3  -0.195766    2.0\n",
       "4  -0.256772   12.0\n",
       "5  -0.238881    8.0\n",
       "6  -0.224846    6.0\n",
       "7  -0.284661   17.0\n",
       "8  -0.215124    4.0\n",
       "9  -0.310080   19.0\n",
       "10 -0.251531   10.0\n",
       "11 -0.256881   13.0\n",
       "12 -0.120806    1.0\n",
       "13 -0.288171   18.0\n",
       "14 -0.249740    9.0\n",
       "15 -0.321594   20.0\n",
       "16 -0.206383    3.0\n",
       "17 -0.221547    5.0\n",
       "18 -0.277746   16.0\n",
       "19 -0.257285   14.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(torch.cat((doc_scores, doc_ranks), dim=-1), columns = ['scores', 'ranks',])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a558b0da-d3a2-4688-9ef4-be9aa1924edd",
   "metadata": {},
   "source": [
    "Compute Lambdas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c4bbc-421c-42d2-a3b3-13a95ae6339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idcg(n_rel):\n",
    "    # Assuming binary relevance.\n",
    "    nums = np.ones(n_rel)\n",
    "    denoms = np.log2(np.arange(n_rel) + 1 + 1)\n",
    "    return (nums / denoms).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce85385-43a1-4ae5-877b-6a68ccb847b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| score_diffs.shape: torch.Size([5, 15])\n",
      "ic| dcg_diffs.shape: torch.Size([5, 15])\n"
     ]
    }
   ],
   "source": [
    "score_diffs = doc_scores[:n_rel] - doc_scores[n_rel:].view(n_irr)\n",
    "ic(score_diffs.shape);\n",
    "\n",
    "exped = score_diffs.exp()\n",
    "\n",
    "N = 1 / idcg(n_rel)\n",
    "\n",
    "dcg_diffs = 1 / ( 1 + doc_ranks[:n_rel] ).log2() - 1 / ( 1 + doc_ranks[n_rel:] ).log2().view(n_irr)\n",
    "ic(dcg_diffs.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5bac2-31bc-4444-a439-a2bd821909d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>j: less relevant</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i: more relevant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024741</td>\n",
       "      <td>-0.038777</td>\n",
       "      <td>0.021039</td>\n",
       "      <td>-0.048499</td>\n",
       "      <td>0.046457</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>-0.006741</td>\n",
       "      <td>-0.142816</td>\n",
       "      <td>0.024549</td>\n",
       "      <td>-0.013882</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>-0.057239</td>\n",
       "      <td>-0.042075</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>-0.006337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012820</td>\n",
       "      <td>-0.026855</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>-0.036577</td>\n",
       "      <td>0.058379</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>-0.130895</td>\n",
       "      <td>0.036470</td>\n",
       "      <td>-0.001961</td>\n",
       "      <td>0.069893</td>\n",
       "      <td>-0.045318</td>\n",
       "      <td>-0.030154</td>\n",
       "      <td>0.026045</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007177</td>\n",
       "      <td>-0.006858</td>\n",
       "      <td>0.052957</td>\n",
       "      <td>-0.016581</td>\n",
       "      <td>0.078375</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.025177</td>\n",
       "      <td>-0.110898</td>\n",
       "      <td>0.056467</td>\n",
       "      <td>0.018036</td>\n",
       "      <td>0.089889</td>\n",
       "      <td>-0.025321</td>\n",
       "      <td>-0.010157</td>\n",
       "      <td>0.046042</td>\n",
       "      <td>0.025581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043115</td>\n",
       "      <td>0.029079</td>\n",
       "      <td>0.088895</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.114313</td>\n",
       "      <td>0.055764</td>\n",
       "      <td>0.061115</td>\n",
       "      <td>-0.074960</td>\n",
       "      <td>0.092405</td>\n",
       "      <td>0.053974</td>\n",
       "      <td>0.125827</td>\n",
       "      <td>0.010617</td>\n",
       "      <td>0.025781</td>\n",
       "      <td>0.081980</td>\n",
       "      <td>0.061519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017891</td>\n",
       "      <td>-0.031926</td>\n",
       "      <td>0.027889</td>\n",
       "      <td>-0.041649</td>\n",
       "      <td>0.053308</td>\n",
       "      <td>-0.005241</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>-0.135966</td>\n",
       "      <td>0.031399</td>\n",
       "      <td>-0.007032</td>\n",
       "      <td>0.064822</td>\n",
       "      <td>-0.050389</td>\n",
       "      <td>-0.035225</td>\n",
       "      <td>0.020974</td>\n",
       "      <td>0.000513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "j: less relevant        0         1         2         3         4         5   \\\n",
       "i: more relevant                                                               \n",
       "0                -0.024741 -0.038777  0.021039 -0.048499  0.046457 -0.012092   \n",
       "1                -0.012820 -0.026855  0.032960 -0.036577  0.058379 -0.000170   \n",
       "2                 0.007177 -0.006858  0.052957 -0.016581  0.078375  0.019826   \n",
       "3                 0.043115  0.029079  0.088895  0.019357  0.114313  0.055764   \n",
       "4                -0.017891 -0.031926  0.027889 -0.041649  0.053308 -0.005241   \n",
       "\n",
       "j: less relevant        6         7         8         9         10        11  \\\n",
       "i: more relevant                                                               \n",
       "0                -0.006741 -0.142816  0.024549 -0.013882  0.057971 -0.057239   \n",
       "1                 0.005180 -0.130895  0.036470 -0.001961  0.069893 -0.045318   \n",
       "2                 0.025177 -0.110898  0.056467  0.018036  0.089889 -0.025321   \n",
       "3                 0.061115 -0.074960  0.092405  0.053974  0.125827  0.010617   \n",
       "4                 0.000109 -0.135966  0.031399 -0.007032  0.064822 -0.050389   \n",
       "\n",
       "j: less relevant        12        13        14  \n",
       "i: more relevant                                \n",
       "0                -0.042075  0.014123 -0.006337  \n",
       "1                -0.030154  0.026045  0.005584  \n",
       "2                -0.010157  0.046042  0.025581  \n",
       "3                 0.025781  0.081980  0.061519  \n",
       "4                -0.035225  0.020974  0.000513  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(score_diffs)\n",
    "df.index.name = 'i: more relevant'\n",
    "df.columns.name = 'j: less relevant'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfab474-002a-4019-9401-91bfff27b719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| lamb_updates.shape: torch.Size([5, 15])\n"
     ]
    }
   ],
   "source": [
    "lamb_updates = 1 / (1 + exped) * N * dcg_diffs.abs()\n",
    "ic(lamb_updates.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248622d-110d-40ad-ae1b-8108b7a1b1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>j: less relevant</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i: more relevant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011239</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.031382</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.136252</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.043608</td>\n",
       "      <td>0.023696</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>0.006526</td>\n",
       "      <td>0.026202</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.130268</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.038336</td>\n",
       "      <td>0.018575</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.003887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.015439</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>0.119316</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.017114</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>0.009122</td>\n",
       "      <td>0.014693</td>\n",
       "      <td>0.012953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052343</td>\n",
       "      <td>0.045910</td>\n",
       "      <td>0.063380</td>\n",
       "      <td>0.033630</td>\n",
       "      <td>0.063887</td>\n",
       "      <td>0.056357</td>\n",
       "      <td>0.060545</td>\n",
       "      <td>0.064932</td>\n",
       "      <td>0.063976</td>\n",
       "      <td>0.054435</td>\n",
       "      <td>0.064088</td>\n",
       "      <td>0.022085</td>\n",
       "      <td>0.040857</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>0.061632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007738</td>\n",
       "      <td>0.014811</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.027774</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.132153</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.039944</td>\n",
       "      <td>0.020124</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.002421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "j: less relevant        0         1         2         3         4         5   \\\n",
       "i: more relevant                                                               \n",
       "0                 0.011239  0.018360  0.001709  0.031382  0.003085  0.006665   \n",
       "1                 0.006233  0.013278  0.006526  0.026202  0.007831  0.001717   \n",
       "2                 0.003019  0.003892  0.015439  0.016644  0.016612  0.007433   \n",
       "3                 0.052343  0.045910  0.063380  0.033630  0.063887  0.056357   \n",
       "4                 0.007738  0.014811  0.005088  0.027774  0.006414  0.003201   \n",
       "\n",
       "j: less relevant        6         7         8         9         10        11  \\\n",
       "i: more relevant                                                               \n",
       "0                 0.002152  0.136252  0.002444  0.008714  0.003677  0.043608   \n",
       "1                 0.002756  0.130268  0.007248  0.003749  0.008391  0.038336   \n",
       "2                 0.011836  0.119316  0.016137  0.005429  0.017114  0.028621   \n",
       "3                 0.060545  0.064932  0.063976  0.054435  0.064088  0.022085   \n",
       "4                 0.001287  0.132153  0.005814  0.005240  0.006985  0.039944   \n",
       "\n",
       "j: less relevant        12        13        14  \n",
       "i: more relevant                                \n",
       "0                 0.023696  0.000901  0.001014  \n",
       "1                 0.018575  0.005740  0.003887  \n",
       "2                 0.009122  0.014693  0.012953  \n",
       "3                 0.040857  0.062822  0.061632  \n",
       "4                 0.020124  0.004294  0.002421  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(lamb_updates)\n",
    "df.index.name = 'i: more relevant'\n",
    "df.columns.name = 'j: less relevant'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68b68d-d89c-46b2-8128-7abf426622bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambs = torch.zeros((n_docs, 1)).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faaa6a0-2088-435e-b2df-8397c60f94c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2765],\n",
       "        [0.2428],\n",
       "        [0.3217],\n",
       "        [0.1853],\n",
       "        [1.7076]], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamb_updates.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaaf2e8-0a90-4d24-85b2-542829f30b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1494],\n",
       "        [0.2626],\n",
       "        [0.1673],\n",
       "        [0.1906],\n",
       "        [0.1732],\n",
       "        [0.1788],\n",
       "        [0.1588],\n",
       "        [0.1950],\n",
       "        [0.1970],\n",
       "        [0.1991],\n",
       "        [0.1422],\n",
       "        [0.1870],\n",
       "        [0.1939],\n",
       "        [0.1836],\n",
       "        [0.1553]], device='cuda:0', grad_fn=<TBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamb_updates.sum(dim=0, keepdim=True).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed45ecec-5f5e-43cb-9c5e-5360d58b1770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101699fc-986f-440a-965a-11551f1cb2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d2a1022-5b8f-4e28-8413-d15e40ce2cc3",
   "metadata": {},
   "source": [
    "#### Analysis to find out what the L2R model is upto:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8eb5ec-bbe7-4c73-914c-48f7a486358f",
   "metadata": {},
   "source": [
    "**On the entire dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4e444-20c3-4cd1-97c6-ab7bde7b4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_accuracy(dset):\n",
    "    dset = dset.unsqueeze(0)\n",
    "    dset_chnked = torch.split(dset, 100, dim=1)\n",
    "    acc = []\n",
    "    for chunk in  dset_chnked:\n",
    "        btch_acc = batch_lbs_accuracy(rank_model(chunk), chunk)\n",
    "        acc.append(btch_acc)\n",
    "    acc = torch.cat(acc, dim=-1)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aecaec-8830-4af2-9b70-0c62099f301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(dset, k=20):\n",
    "    dset = dset.unsqueeze(0)\n",
    "    dset_chnked = torch.split(dset, 100, dim=1)\n",
    "    ndcg_at_k_list = []\n",
    "    for chunk in  dset_chnked:\n",
    "        *_, ndcg_at_k = ndcg(rank_model(chunk), chunk, k=k)\n",
    "        ndcg_at_k_list.append(ndcg_at_k)\n",
    "    ndcg_at_k_all = torch.cat(ndcg_at_k_list, dim=-1)\n",
    "    return ndcg_at_k_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd0fa89-0b5d-44b5-ba25-351d9f15bc78",
   "metadata": {},
   "source": [
    "The `model` we are analysing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04416069-80b0-4933-8580-4dbc62d72064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rank_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e552673-7f1e-4b86-b28d-21412b380e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| trn.shape: torch.Size([8922, 57352, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8922, 57352, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn, _ = torch.load('trn_val_split.pkl')\n",
    "trn = trn.to(\"cuda:0\")\n",
    "# trn_data = dls.train.dataset.to(\"cuda:0\")\n",
    "ic(trn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda60ba7-1478-4d30-b72f-e3aff49e5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 0 ns, total: 11.5 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ndcg_at_20 = ndcg_at_k(trn, model, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1b5ff-0f4c-4f2f-9940-d6585209cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| ndcg_at_20.shape: torch.Size([1, 8922])\n",
      "    ndcg_at_20.min(): tensor(1.1836e-26, device='cuda:0')\n",
      "    ndcg_at_20.mean(): tensor(0.0003, device='cuda:0')\n",
      "    ndcg_at_20.max(): tensor(0.2974, device='cuda:0')\n",
      "    ndcg_at_20.median(): tensor(1.9523e-18, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ic(ndcg_at_20.shape, ndcg_at_20.min(), ndcg_at_20.mean(), ndcg_at_20.max(), ndcg_at_20.median());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d685084-2ce7-4850-8a74-bed9efa563ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 602 ms, total: 1min 48s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc = accuracy(trn, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad2c1e-0225-4730-957b-30e01c669099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| acc.shape: torch.Size([1, 8922])\n",
      "    acc.min(): tensor(0.9998, device='cuda:0')\n",
      "    acc.mean(): tensor(1.0000, device='cuda:0')\n",
      "    acc.max(): tensor(1., device='cuda:0')\n",
      "    acc.median(): tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ic(acc.shape, acc.min(), acc.mean(), acc.max(), acc.median());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcd63a6-e197-4253-89b9-7bb2aed7d67e",
   "metadata": {},
   "source": [
    "(Below is ndcg formulation with just relevance on the numerator instead of 2 to the power of relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb6ead-4801-4a62-9768-020e5bd7e73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| ndcg_at_20.shape: torch.Size([1, 8922])\n",
      "    ndcg_at_20.min(): tensor(0.0988, device='cuda:0')\n",
      "    ndcg_at_20.mean(): tensor(0.4004, device='cuda:0')\n",
      "    ndcg_at_20.max(): tensor(0.6808, device='cuda:0')\n",
      "    ndcg_at_20.median(): tensor(0.4071, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ic(ndcg_at_20.shape, ndcg_at_20.min(), ndcg_at_20.mean(), ndcg_at_20.max(), ndcg_at_20.median());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1c09e-3ba0-43b8-8d7e-abf0837d86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_at_20 = [None]\n",
    "import gc; gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93dfaa5-af6e-4704-b4a7-9fb3e08e18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ic(len(trn_data_chunked), trn_data.shape[1]/100, trn_data_chunked[-1].shape, trn_data.shape[1]%100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d2baa4-81e2-44ce-aa1e-13cadadd4586",
   "metadata": {},
   "source": [
    "On some selected labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b024e4b-1fdc-4ae0-9163-5f53d2bd5209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([1, 200, 57352, 3])\n"
     ]
    }
   ],
   "source": [
    "xb = trn[7000:7200]\n",
    "xb = xb.unsqueeze(0)\n",
    "ic(xb.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d073746-d059-4724-8fb3-1d6936cbe630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 699 ms, sys: 10.7 ms, total: 709 ms\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds, preds_rank, ideal_rank, discnt_fac, ideal_discnt_fac, discntd_gain, ideal_discntd_gain, dcg, idcg, _ndcg, _ndcg_at_k = ndcg(model(xb), xb, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd782b-ce2f-4aa9-99e1-32d3affb5b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.6429e-07, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ndcg_at_k.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd359e-19e8-44c6-b35f-8c934df48294",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca38c4f-cb4f-4c75-b82a-daff3ac07e27",
   "metadata": {},
   "source": [
    "**On a training batch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913892a7-8288-4579-9d04-9954c73cf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb_iter = iter(dls.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e3566-974f-4845-88cf-5f2f38cc665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = next(xb_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9f7c1-ba3e-4f69-b4ed-d182a4511f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb.shape: torch.Size([64, 2233, 64, 4])\n",
      "    xb.device: device(type='cuda', index=0)\n",
      "    preds.shape: torch.Size([64, 2233, 64, 1])\n",
      "    preds.device: device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "preds = rank_model(xb)\n",
    "ic(xb.shape, xb.device, preds.shape, preds.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dfc2ef-7007-4d37-b6be-83d53521cec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.41 s, sys: 3.31 ms, total: 1.42 s\n",
      "Wall time: 3.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds, preds_rank, ideal_rank, discnt_fac, ideal_discnt_fac, discntd_gain, ideal_discntd_gain, dcg, idcg, _ndcg, _ndcg_at_k = ndcg(model(xb), xb, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16a2cd-6b28-44ea-96b3-baec42507a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| _ndcg.shape: torch.Size([64, 2233])\n",
      "    _ndcg.mean(): tensor(0.7898, device='cuda:0')\n",
      "    _ndcg_at_k.shape: torch.Size([64, 2233])\n",
      "    _ndcg_at_k.mean(): tensor(0.2059, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ic(_ndcg.shape, _ndcg.mean(), _ndcg_at_k.shape, _ndcg_at_k.mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f81bf-52e8-4d4d-bd1c-d4b4116db54b",
   "metadata": {},
   "source": [
    "Let's compute order accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892049e-fab0-4451-9c8e-c8f50994ba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| btch_acc.shape: torch.Size([64, 2233])\n",
      "    btch_acc.mean(): tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "btch_acc = accuracy(xb, rank_model)\n",
    "ic(btch_acc.shape, btch_acc.mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef7551-9e7c-4094-9b19-a496daaee801",
   "metadata": {},
   "source": [
    "**On a validation batch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc553f9c-9b74-4ae3-a3a5-17023d53af06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| xb_val.shape: torch.Size([1, 8922, 32, 4])\n",
      "    xb_val.device: device(type='cuda', index=0)\n"
     ]
    }
   ],
   "source": [
    "xb_val = dls.valid.one_batch()\n",
    "ic(xb_val.shape, xb_val.device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7980f5-05bf-475c-809f-f0426fa91966",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, preds_rank, ideal_rank, discnt_fac, ideal_discnt_fac, discntd_gain, ideal_discntd_gain, dcg, idcg, _ndcg, _ndcg_at_k = ndcg(rank_model(xb_val), xb_val, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf23fe-a51b-4237-8c3e-d1518998183d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| _ndcg.shape: torch.Size([1, 8922])\n",
      "    _ndcg.mean(): tensor(0.7097, device='cuda:0')\n",
      "    _ndcg_at_k.shape: torch.Size([1, 8922])\n",
      "    _ndcg_at_k.mean(): tensor(0.1040, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ic(_ndcg.shape, _ndcg.mean(), _ndcg_at_k.shape, _ndcg_at_k.mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699c9f9-b670-4380-be0c-9e7039487c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = xb_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d896ed-2993-4e20-8307-399c38836029",
   "metadata": {},
   "source": [
    "Let's compute order accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172059a-5b84-46d1-b77e-858e61f883c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| acc.shape: torch.Size([1, 8922])\n",
      "    acc.mean(): tensor(0.5952, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(xb, rank_model)\n",
    "ic(acc.shape, acc.mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ba8bf-7a5f-424e-8799-5144f88c55f8",
   "metadata": {},
   "source": [
    "**Let's pick a label and see the rankings produced by the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4c70d-445f-468d-abe7-53ab2dd7a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = 7056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ac76e-2858-4132-bf1a-4e13443136c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200, 57352, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bccce07-6a7f-4854-b3df-bd61af691604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7056.], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0, lbl%100, :, 1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e6712-df78-42cf-a339-a3824511fde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| dcg[0, lbl%100]: tensor(49457.4609, device='cuda:0')\n",
      "    idcg[0, lbl%100]: tensor(51637.4922, device='cuda:0')\n",
      "    _ndcg[0, lbl%100]: tensor(0.9578, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ic(dcg[0, lbl%100], idcg[0, lbl%100], _ndcg[0, lbl%100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949db1d-c217-4ad6-a8ee-c0c0b6393f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8407e-16, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ndcg_at_k[0, lbl%100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0df86-9be3-4a02-a7d0-517d81a246ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(_df): 57352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>lbl</th>\n",
       "      <th>score</th>\n",
       "      <th>preds</th>\n",
       "      <th>model_rank</th>\n",
       "      <th>ideal_rank</th>\n",
       "      <th>model_discount factor</th>\n",
       "      <th>ideal_discount_factor</th>\n",
       "      <th>discounted gain</th>\n",
       "      <th>ideal discounted gain</th>\n",
       "      <th>random_rank</th>\n",
       "      <th>random_discount_factor</th>\n",
       "      <th>random_discnt_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.836050</td>\n",
       "      <td>4.503600e+15</td>\n",
       "      <td>7.652698e+14</td>\n",
       "      <td>53131</td>\n",
       "      <td>15.697321</td>\n",
       "      <td>2.869024e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39530.0</td>\n",
       "      <td>1.584962</td>\n",
       "      <td>15.270733</td>\n",
       "      <td>9.463946e+00</td>\n",
       "      <td>5.726525e+01</td>\n",
       "      <td>19867</td>\n",
       "      <td>14.278232</td>\n",
       "      <td>1.050550e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39531.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.270770</td>\n",
       "      <td>7.500000e+00</td>\n",
       "      <td>5.726539e+01</td>\n",
       "      <td>38645</td>\n",
       "      <td>15.238069</td>\n",
       "      <td>9.843767e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39532.0</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>15.270806</td>\n",
       "      <td>6.460148e+00</td>\n",
       "      <td>5.726552e+01</td>\n",
       "      <td>2377</td>\n",
       "      <td>11.216140</td>\n",
       "      <td>1.337358e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39533.0</td>\n",
       "      <td>2.584962</td>\n",
       "      <td>15.270843</td>\n",
       "      <td>5.802793e+00</td>\n",
       "      <td>5.726566e+01</td>\n",
       "      <td>24434</td>\n",
       "      <td>14.576720</td>\n",
       "      <td>1.029038e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tok     lbl  score  preds  model_rank  ideal_rank  model_discount factor  \\\n",
       "0  0.0  7056.0   52.0    0.0         0.0       455.0               1.000000   \n",
       "1  1.0  7056.0    4.0    0.0         1.0     39530.0               1.584962   \n",
       "2  2.0  7056.0    4.0    0.0         2.0     39531.0               2.000000   \n",
       "3  3.0  7056.0    4.0    0.0         3.0     39532.0               2.321928   \n",
       "4  4.0  7056.0    4.0    0.0         4.0     39533.0               2.584962   \n",
       "\n",
       "   ideal_discount_factor  discounted gain  ideal discounted gain  random_rank  \\\n",
       "0               8.836050     4.503600e+15           7.652698e+14        53131   \n",
       "1              15.270733     9.463946e+00           5.726525e+01        19867   \n",
       "2              15.270770     7.500000e+00           5.726539e+01        38645   \n",
       "3              15.270806     6.460148e+00           5.726552e+01         2377   \n",
       "4              15.270843     5.802793e+00           5.726566e+01        24434   \n",
       "\n",
       "   random_discount_factor  random_discnt_gain  \n",
       "0               15.697321        2.869024e+14  \n",
       "1               14.278232        1.050550e+00  \n",
       "2               15.238069        9.843767e-01  \n",
       "3               11.216140        1.337358e+00  \n",
       "4               14.576720        1.029038e+00  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 1e-15\n",
    "_data = torch.concat(\n",
    "            (xb[0, lbl%100], preds[0, lbl%100].unsqueeze(-1), preds_rank[0, lbl%100].unsqueeze(-1), ideal_rank[0, lbl%100].unsqueeze(-1), discnt_fac[0, lbl%100].unsqueeze(-1), ideal_discnt_fac[0, lbl%100].unsqueeze(-1), discntd_gain[0, lbl%100].unsqueeze(-1), ideal_discntd_gain[0, lbl%100].unsqueeze(-1)\n",
    "        ), dim=-1)\n",
    "_df = pd.DataFrame(_data, \n",
    "             columns=['tok', 'lbl', 'score', 'preds', 'model_rank', 'ideal_rank', 'model_discount factor', 'ideal_discount_factor', 'discounted gain', 'ideal discounted gain'])#.sort_values(by='score', ascending=False)\n",
    "ic(len(_df));\n",
    "random_rank = torch.randperm(len(_df))\n",
    "_df['random_rank'] = random_rank\n",
    "random_discnt_fac = torch.log2(2 + random_rank)\n",
    "_df['random_discount_factor'] = random_discnt_fac\n",
    "\n",
    "_df['discounted gain'] = (np.power(2, _df['score']) - 1) / (_df['model_discount factor'] + eps)\n",
    "_df['ideal discounted gain'] = (np.power(2, _df['score']) - 1) / (_df['ideal discounted gain'] + eps)\n",
    "_df['random_discnt_gain'] = (np.power(2, _df['score']) - 1) / (_df['random_discount_factor'] + eps)\n",
    "\n",
    "_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b068a5-87a5-4ca4-b6a1-45be7d327b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>lbl</th>\n",
       "      <th>score</th>\n",
       "      <th>preds</th>\n",
       "      <th>model_rank</th>\n",
       "      <th>ideal_rank</th>\n",
       "      <th>model_discount factor</th>\n",
       "      <th>ideal_discount_factor</th>\n",
       "      <th>discounted gain</th>\n",
       "      <th>ideal discounted gain</th>\n",
       "      <th>random_rank</th>\n",
       "      <th>random_discount_factor</th>\n",
       "      <th>random_discnt_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.836050</td>\n",
       "      <td>4.503600e+15</td>\n",
       "      <td>7.652698e+14</td>\n",
       "      <td>53131</td>\n",
       "      <td>15.697321</td>\n",
       "      <td>2.869024e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39429</th>\n",
       "      <td>39429.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39429.0</td>\n",
       "      <td>29941.0</td>\n",
       "      <td>15.267043</td>\n",
       "      <td>14.869931</td>\n",
       "      <td>8.318572e+00</td>\n",
       "      <td>2.697831e+02</td>\n",
       "      <td>17258</td>\n",
       "      <td>14.075145</td>\n",
       "      <td>9.022998e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38227</th>\n",
       "      <td>38227.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38227.0</td>\n",
       "      <td>24383.0</td>\n",
       "      <td>15.222380</td>\n",
       "      <td>14.573707</td>\n",
       "      <td>6.720368e+01</td>\n",
       "      <td>1.490890e+03</td>\n",
       "      <td>45839</td>\n",
       "      <td>15.484351</td>\n",
       "      <td>6.606670e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38228</th>\n",
       "      <td>38228.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38228.0</td>\n",
       "      <td>49027.0</td>\n",
       "      <td>15.222418</td>\n",
       "      <td>15.581347</td>\n",
       "      <td>1.970778e-01</td>\n",
       "      <td>2.337202e+01</td>\n",
       "      <td>21011</td>\n",
       "      <td>14.358994</td>\n",
       "      <td>2.089283e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38229</th>\n",
       "      <td>38229.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38229.0</td>\n",
       "      <td>49028.0</td>\n",
       "      <td>15.222455</td>\n",
       "      <td>15.581377</td>\n",
       "      <td>1.970773e-01</td>\n",
       "      <td>2.337206e+01</td>\n",
       "      <td>47460</td>\n",
       "      <td>15.534485</td>\n",
       "      <td>1.931187e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38230</th>\n",
       "      <td>38230.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38230.0</td>\n",
       "      <td>26157.0</td>\n",
       "      <td>15.222493</td>\n",
       "      <td>14.675020</td>\n",
       "      <td>3.356874e+01</td>\n",
       "      <td>8.332151e+02</td>\n",
       "      <td>26441</td>\n",
       "      <td>14.690598</td>\n",
       "      <td>3.478415e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38231</th>\n",
       "      <td>38231.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38231.0</td>\n",
       "      <td>28058.0</td>\n",
       "      <td>15.222530</td>\n",
       "      <td>14.776227</td>\n",
       "      <td>1.675149e+01</td>\n",
       "      <td>4.709922e+02</td>\n",
       "      <td>50023</td>\n",
       "      <td>15.610362</td>\n",
       "      <td>1.633530e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38232</th>\n",
       "      <td>38232.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38232.0</td>\n",
       "      <td>26158.0</td>\n",
       "      <td>15.222569</td>\n",
       "      <td>14.675075</td>\n",
       "      <td>3.356858e+01</td>\n",
       "      <td>8.332181e+02</td>\n",
       "      <td>25692</td>\n",
       "      <td>14.649144</td>\n",
       "      <td>3.488258e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38233</th>\n",
       "      <td>38233.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38233.0</td>\n",
       "      <td>24384.0</td>\n",
       "      <td>15.222607</td>\n",
       "      <td>14.573766</td>\n",
       "      <td>6.720268e+01</td>\n",
       "      <td>1.490896e+03</td>\n",
       "      <td>42174</td>\n",
       "      <td>15.364135</td>\n",
       "      <td>6.658364e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38234</th>\n",
       "      <td>38234.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38234.0</td>\n",
       "      <td>26159.0</td>\n",
       "      <td>15.222644</td>\n",
       "      <td>14.675130</td>\n",
       "      <td>3.356841e+01</td>\n",
       "      <td>8.332213e+02</td>\n",
       "      <td>23758</td>\n",
       "      <td>14.536247</td>\n",
       "      <td>3.515350e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tok     lbl  score  preds  model_rank  ideal_rank  \\\n",
       "0          0.0  7056.0   52.0    0.0         0.0       455.0   \n",
       "39429  39429.0  7056.0    7.0    0.0     39429.0     29941.0   \n",
       "38227  38227.0  7056.0   10.0    0.0     38227.0     24383.0   \n",
       "38228  38228.0  7056.0    2.0    0.0     38228.0     49027.0   \n",
       "38229  38229.0  7056.0    2.0    0.0     38229.0     49028.0   \n",
       "38230  38230.0  7056.0    9.0    0.0     38230.0     26157.0   \n",
       "38231  38231.0  7056.0    8.0    0.0     38231.0     28058.0   \n",
       "38232  38232.0  7056.0    9.0    0.0     38232.0     26158.0   \n",
       "38233  38233.0  7056.0   10.0    0.0     38233.0     24384.0   \n",
       "38234  38234.0  7056.0    9.0    0.0     38234.0     26159.0   \n",
       "\n",
       "       model_discount factor  ideal_discount_factor  discounted gain  \\\n",
       "0                   1.000000               8.836050     4.503600e+15   \n",
       "39429              15.267043              14.869931     8.318572e+00   \n",
       "38227              15.222380              14.573707     6.720368e+01   \n",
       "38228              15.222418              15.581347     1.970778e-01   \n",
       "38229              15.222455              15.581377     1.970773e-01   \n",
       "38230              15.222493              14.675020     3.356874e+01   \n",
       "38231              15.222530              14.776227     1.675149e+01   \n",
       "38232              15.222569              14.675075     3.356858e+01   \n",
       "38233              15.222607              14.573766     6.720268e+01   \n",
       "38234              15.222644              14.675130     3.356841e+01   \n",
       "\n",
       "       ideal discounted gain  random_rank  random_discount_factor  \\\n",
       "0               7.652698e+14        53131               15.697321   \n",
       "39429           2.697831e+02        17258               14.075145   \n",
       "38227           1.490890e+03        45839               15.484351   \n",
       "38228           2.337202e+01        21011               14.358994   \n",
       "38229           2.337206e+01        47460               15.534485   \n",
       "38230           8.332151e+02        26441               14.690598   \n",
       "38231           4.709922e+02        50023               15.610362   \n",
       "38232           8.332181e+02        25692               14.649144   \n",
       "38233           1.490896e+03        42174               15.364135   \n",
       "38234           8.332213e+02        23758               14.536247   \n",
       "\n",
       "       random_discnt_gain  \n",
       "0            2.869024e+14  \n",
       "39429        9.022998e+00  \n",
       "38227        6.606670e+01  \n",
       "38228        2.089283e-01  \n",
       "38229        1.931187e-01  \n",
       "38230        3.478415e+01  \n",
       "38231        1.633530e+01  \n",
       "38232        3.488258e+01  \n",
       "38233        6.658364e+01  \n",
       "38234        3.515350e+01  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df1 = _df.sort_values(by='preds', ascending=False).head(20)\n",
    "_df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ddf4f-688e-480c-8ab5-40920db7ba44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5481220478165346.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_dcg20 = ( (pow(2, _df1.score) - 1) / (np.log2(2 + np.arange(20)) + eps) ).sum()\n",
    "lbl_dcg20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a1322-9db4-4255-9a78-beb5d9c75c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbl_dcg20 = _df1['discounted gain'].sum()\n",
    "# lbl_dcg20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c6073-f4a4-44c6-9ca2-8072f2e3cbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>lbl</th>\n",
       "      <th>score</th>\n",
       "      <th>preds</th>\n",
       "      <th>model_rank</th>\n",
       "      <th>ideal_rank</th>\n",
       "      <th>model_discount factor</th>\n",
       "      <th>ideal_discount_factor</th>\n",
       "      <th>discounted gain</th>\n",
       "      <th>ideal discounted gain</th>\n",
       "      <th>random_rank</th>\n",
       "      <th>random_discount_factor</th>\n",
       "      <th>random_discnt_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41633</th>\n",
       "      <td>41633.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.175395</td>\n",
       "      <td>21063.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.362560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.765215e+29</td>\n",
       "      <td>2.510199e+28</td>\n",
       "      <td>46470</td>\n",
       "      <td>15.504074</td>\n",
       "      <td>1.635248e+29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46021</th>\n",
       "      <td>46021.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.183124</td>\n",
       "      <td>25097.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.615342</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>8.673424e+28</td>\n",
       "      <td>3.558745e+28</td>\n",
       "      <td>27876</td>\n",
       "      <td>14.766839</td>\n",
       "      <td>8.584442e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22263</th>\n",
       "      <td>22263.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-1.027545</td>\n",
       "      <td>26530.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.695446</td>\n",
       "      <td>2.584962</td>\n",
       "      <td>8.626146e+28</td>\n",
       "      <td>3.276829e+28</td>\n",
       "      <td>37411</td>\n",
       "      <td>15.191252</td>\n",
       "      <td>8.344610e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18628</th>\n",
       "      <td>18628.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.953648</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.578373</td>\n",
       "      <td>1.584962</td>\n",
       "      <td>1.198342e+29</td>\n",
       "      <td>2.009179e+28</td>\n",
       "      <td>6920</td>\n",
       "      <td>12.756973</td>\n",
       "      <td>9.936923e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18638</th>\n",
       "      <td>18638.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.686037</td>\n",
       "      <td>21875.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.417128</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.792671e+28</td>\n",
       "      <td>2.535301e+28</td>\n",
       "      <td>52030</td>\n",
       "      <td>15.667111</td>\n",
       "      <td>8.091157e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20038</th>\n",
       "      <td>20038.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-13.829051</td>\n",
       "      <td>46904.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.517485</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>8.169175e+28</td>\n",
       "      <td>2.943393e+28</td>\n",
       "      <td>41464</td>\n",
       "      <td>15.339642</td>\n",
       "      <td>8.263886e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17155</th>\n",
       "      <td>17155.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-12.660876</td>\n",
       "      <td>45510.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.473959</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.096077e+28</td>\n",
       "      <td>1.920683e+28</td>\n",
       "      <td>25385</td>\n",
       "      <td>14.631803</td>\n",
       "      <td>4.331833e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14456</th>\n",
       "      <td>14456.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-23.737192</td>\n",
       "      <td>54115.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.723794</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>1.007749e+28</td>\n",
       "      <td>5.178296e+27</td>\n",
       "      <td>55496</td>\n",
       "      <td>15.760148</td>\n",
       "      <td>1.005424e+28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14135</th>\n",
       "      <td>14135.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.254682</td>\n",
       "      <td>17779.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.118049</td>\n",
       "      <td>3.321928</td>\n",
       "      <td>5.611835e+27</td>\n",
       "      <td>2.741565e+27</td>\n",
       "      <td>53704</td>\n",
       "      <td>15.712795</td>\n",
       "      <td>5.042270e+27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16272</th>\n",
       "      <td>16272.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>33.406235</td>\n",
       "      <td>1496.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.548821</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>3.755309e+27</td>\n",
       "      <td>1.442550e+27</td>\n",
       "      <td>39661</td>\n",
       "      <td>15.275506</td>\n",
       "      <td>2.593307e+27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tok     lbl  score      preds  model_rank  ideal_rank  \\\n",
       "41633  41633.0  7056.0  101.0   2.175395     21063.0         0.0   \n",
       "46021  46021.0  7056.0  100.0  -0.183124     25097.0         5.0   \n",
       "22263  22263.0  7056.0  100.0  -1.027545     26530.0         4.0   \n",
       "18628  18628.0  7056.0  100.0  32.953648      1527.0         1.0   \n",
       "18638  18638.0  7056.0  100.0   1.686037     21875.0         2.0   \n",
       "20038  20038.0  7056.0  100.0 -13.829051     46904.0         3.0   \n",
       "17155  17155.0  7056.0   99.0 -12.660876     45510.0         6.0   \n",
       "14456  14456.0  7056.0   97.0 -23.737192     54115.0         7.0   \n",
       "14135  14135.0  7056.0   96.0   4.254682     17779.0         8.0   \n",
       "16272  16272.0  7056.0   95.0  33.406235      1496.0         9.0   \n",
       "\n",
       "       model_discount factor  ideal_discount_factor  discounted gain  \\\n",
       "41633              14.362560               1.000000     1.765215e+29   \n",
       "46021              14.615342               2.807355     8.673424e+28   \n",
       "22263              14.695446               2.584962     8.626146e+28   \n",
       "18628              10.578373               1.584962     1.198342e+29   \n",
       "18638              14.417128               2.000000     8.792671e+28   \n",
       "20038              15.517485               2.321928     8.169175e+28   \n",
       "17155              15.473959               3.000000     4.096077e+28   \n",
       "14456              15.723794               3.169925     1.007749e+28   \n",
       "14135              14.118049               3.321928     5.611835e+27   \n",
       "16272              10.548821               3.459432     3.755309e+27   \n",
       "\n",
       "       ideal discounted gain  random_rank  random_discount_factor  \\\n",
       "41633           2.510199e+28        46470               15.504074   \n",
       "46021           3.558745e+28        27876               14.766839   \n",
       "22263           3.276829e+28        37411               15.191252   \n",
       "18628           2.009179e+28         6920               12.756973   \n",
       "18638           2.535301e+28        52030               15.667111   \n",
       "20038           2.943393e+28        41464               15.339642   \n",
       "17155           1.920683e+28        25385               14.631803   \n",
       "14456           5.178296e+27        55496               15.760148   \n",
       "14135           2.741565e+27        53704               15.712795   \n",
       "16272           1.442550e+27        39661               15.275506   \n",
       "\n",
       "       random_discnt_gain  \n",
       "41633        1.635248e+29  \n",
       "46021        8.584442e+28  \n",
       "22263        8.344610e+28  \n",
       "18628        9.936923e+28  \n",
       "18638        8.091157e+28  \n",
       "20038        8.263886e+28  \n",
       "17155        4.331833e+28  \n",
       "14456        1.005424e+28  \n",
       "14135        5.042270e+27  \n",
       "16272        2.593307e+27  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df2 = _df.sort_values(by='score', ascending=False).head(20)\n",
    "_df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f32a77-2c02-4eac-94eb-b329d997e6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.762852934816773e+30"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_idcg20 = ( (pow(2, _df2.score) - 1) / (np.log2(2 + np.arange(20)) + eps) ).sum()\n",
    "lbl_idcg20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef7db8a-05b8-475b-a498-bb20e19a7b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbl_idcg20 = _df2['ideal discounted gain'].sum()\n",
    "# lbl_idcg20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1bdfb-b27f-46ef-a52f-69e67c48a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbl_ndcg20 = lbl_dcg20/lbl_idcg20\n",
    "# lbl_ndcg20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6238ff12-fddd-4fed-8ff7-3410cbe19c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.511296818022338e-16"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_ndcg20 = lbl_dcg20 /lbl_idcg20\n",
    "lbl_ndcg20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acfe35-90a9-469e-b1bf-c948a74c2679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(lbl_ndcg20, _ndcg_at_k[0, lbl%100].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18dd1a-c852-461c-9cec-e2f45651c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tok</th>\n",
       "      <th>lbl</th>\n",
       "      <th>score</th>\n",
       "      <th>preds</th>\n",
       "      <th>model_rank</th>\n",
       "      <th>ideal_rank</th>\n",
       "      <th>model_discount factor</th>\n",
       "      <th>ideal_discount_factor</th>\n",
       "      <th>discounted gain</th>\n",
       "      <th>ideal discounted gain</th>\n",
       "      <th>random_rank</th>\n",
       "      <th>random_discount_factor</th>\n",
       "      <th>random_discnt_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>6452.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-8.187328</td>\n",
       "      <td>38783.0</td>\n",
       "      <td>36091.0</td>\n",
       "      <td>15.243211</td>\n",
       "      <td>15.139431</td>\n",
       "      <td>2.033692e+00</td>\n",
       "      <td>9.386447e+01</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16794</th>\n",
       "      <td>16794.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-7.473664</td>\n",
       "      <td>37611.0</td>\n",
       "      <td>7553.0</td>\n",
       "      <td>15.198944</td>\n",
       "      <td>12.883216</td>\n",
       "      <td>2.759602e+05</td>\n",
       "      <td>2.456187e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.584962</td>\n",
       "      <td>2.646310e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35009</th>\n",
       "      <td>35009.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-11.835570</td>\n",
       "      <td>44385.0</td>\n",
       "      <td>27803.0</td>\n",
       "      <td>15.437850</td>\n",
       "      <td>14.763057</td>\n",
       "      <td>1.651784e+01</td>\n",
       "      <td>4.705724e+02</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.275000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57162</th>\n",
       "      <td>57162.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.476361</td>\n",
       "      <td>19059.0</td>\n",
       "      <td>39396.0</td>\n",
       "      <td>14.218336</td>\n",
       "      <td>15.265835</td>\n",
       "      <td>2.180283e+00</td>\n",
       "      <td>9.464817e+01</td>\n",
       "      <td>3</td>\n",
       "      <td>2.321928</td>\n",
       "      <td>1.335097e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47032</th>\n",
       "      <td>47032.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-19.453012</td>\n",
       "      <td>51849.0</td>\n",
       "      <td>35224.0</td>\n",
       "      <td>15.662085</td>\n",
       "      <td>15.104353</td>\n",
       "      <td>4.022453e+00</td>\n",
       "      <td>1.585957e+02</td>\n",
       "      <td>4</td>\n",
       "      <td>2.584963</td>\n",
       "      <td>2.437173e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39202</th>\n",
       "      <td>39202.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.024749</td>\n",
       "      <td>19741.0</td>\n",
       "      <td>26507.0</td>\n",
       "      <td>14.269053</td>\n",
       "      <td>14.694195</td>\n",
       "      <td>3.581177e+01</td>\n",
       "      <td>8.343037e+02</td>\n",
       "      <td>5</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>1.820219e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55155</th>\n",
       "      <td>55155.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.111054</td>\n",
       "      <td>37005.0</td>\n",
       "      <td>56015.0</td>\n",
       "      <td>15.175510</td>\n",
       "      <td>15.773577</td>\n",
       "      <td>6.589564e-02</td>\n",
       "      <td>1.577358e+01</td>\n",
       "      <td>6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.333333e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15844</th>\n",
       "      <td>15844.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.391142</td>\n",
       "      <td>37482.0</td>\n",
       "      <td>43443.0</td>\n",
       "      <td>15.193987</td>\n",
       "      <td>15.406902</td>\n",
       "      <td>4.607086e-01</td>\n",
       "      <td>3.594944e+01</td>\n",
       "      <td>7</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>2.208254e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35714</th>\n",
       "      <td>35714.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.225584</td>\n",
       "      <td>28616.0</td>\n",
       "      <td>23093.0</td>\n",
       "      <td>14.804635</td>\n",
       "      <td>14.495293</td>\n",
       "      <td>6.909998e+01</td>\n",
       "      <td>1.482869e+03</td>\n",
       "      <td>8</td>\n",
       "      <td>3.321928</td>\n",
       "      <td>3.079537e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20591</th>\n",
       "      <td>20591.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-16.564301</td>\n",
       "      <td>49692.0</td>\n",
       "      <td>44555.0</td>\n",
       "      <td>15.600784</td>\n",
       "      <td>15.443364</td>\n",
       "      <td>4.486954e-01</td>\n",
       "      <td>3.603452e+01</td>\n",
       "      <td>9</td>\n",
       "      <td>3.459432</td>\n",
       "      <td>2.023454e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54762</th>\n",
       "      <td>54762.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-13.837959</td>\n",
       "      <td>46917.0</td>\n",
       "      <td>38602.0</td>\n",
       "      <td>15.517884</td>\n",
       "      <td>15.236463</td>\n",
       "      <td>1.997695e+00</td>\n",
       "      <td>9.446606e+01</td>\n",
       "      <td>10</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>8.647231e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>2342.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.376895</td>\n",
       "      <td>19198.0</td>\n",
       "      <td>2445.0</td>\n",
       "      <td>14.228819</td>\n",
       "      <td>11.256799</td>\n",
       "      <td>1.207400e+09</td>\n",
       "      <td>5.687951e+09</td>\n",
       "      <td>11</td>\n",
       "      <td>3.700440</td>\n",
       "      <td>4.642656e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53977</th>\n",
       "      <td>53977.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-22.591963</td>\n",
       "      <td>53561.0</td>\n",
       "      <td>55106.0</td>\n",
       "      <td>15.708949</td>\n",
       "      <td>15.749974</td>\n",
       "      <td>6.365798e-02</td>\n",
       "      <td>1.574998e+01</td>\n",
       "      <td>12</td>\n",
       "      <td>3.807355</td>\n",
       "      <td>2.626495e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>3246.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-12.946091</td>\n",
       "      <td>45862.0</td>\n",
       "      <td>8963.0</td>\n",
       "      <td>15.485075</td>\n",
       "      <td>13.130088</td>\n",
       "      <td>6.771520e+04</td>\n",
       "      <td>6.883941e+05</td>\n",
       "      <td>13</td>\n",
       "      <td>3.906891</td>\n",
       "      <td>2.683912e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24586</th>\n",
       "      <td>24586.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-13.977197</td>\n",
       "      <td>47075.0</td>\n",
       "      <td>12858.0</td>\n",
       "      <td>15.522735</td>\n",
       "      <td>13.650603</td>\n",
       "      <td>8.443809e+03</td>\n",
       "      <td>1.052470e+05</td>\n",
       "      <td>14</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.276775e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>11426.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.802952</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>2719.0</td>\n",
       "      <td>11.000704</td>\n",
       "      <td>11.409922</td>\n",
       "      <td>7.808532e+08</td>\n",
       "      <td>2.970014e+09</td>\n",
       "      <td>15</td>\n",
       "      <td>4.087463</td>\n",
       "      <td>2.101532e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29003</th>\n",
       "      <td>29003.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-2.219074</td>\n",
       "      <td>28602.0</td>\n",
       "      <td>17870.0</td>\n",
       "      <td>14.803929</td>\n",
       "      <td>14.125414</td>\n",
       "      <td>5.532991e+02</td>\n",
       "      <td>8.900098e+03</td>\n",
       "      <td>16</td>\n",
       "      <td>4.169925</td>\n",
       "      <td>1.964304e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36063</th>\n",
       "      <td>36063.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-7.784392</td>\n",
       "      <td>38155.0</td>\n",
       "      <td>27863.0</td>\n",
       "      <td>15.219660</td>\n",
       "      <td>14.766167</td>\n",
       "      <td>1.675464e+01</td>\n",
       "      <td>4.706716e+02</td>\n",
       "      <td>17</td>\n",
       "      <td>4.247928</td>\n",
       "      <td>6.002927e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7105</th>\n",
       "      <td>7105.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-3.259494</td>\n",
       "      <td>30447.0</td>\n",
       "      <td>12178.0</td>\n",
       "      <td>14.894107</td>\n",
       "      <td>13.572227</td>\n",
       "      <td>8.800192e+03</td>\n",
       "      <td>1.046427e+05</td>\n",
       "      <td>18</td>\n",
       "      <td>4.321928</td>\n",
       "      <td>3.032697e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55287</th>\n",
       "      <td>55287.0</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.269970</td>\n",
       "      <td>13489.0</td>\n",
       "      <td>56114.0</td>\n",
       "      <td>13.719709</td>\n",
       "      <td>15.776125</td>\n",
       "      <td>7.288784e-02</td>\n",
       "      <td>1.577612e+01</td>\n",
       "      <td>19</td>\n",
       "      <td>4.392317</td>\n",
       "      <td>2.276703e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tok     lbl  score      preds  model_rank  ideal_rank  \\\n",
       "6452    6452.0  7056.0    5.0  -8.187328     38783.0     36091.0   \n",
       "16794  16794.0  7056.0   22.0  -7.473664     37611.0      7553.0   \n",
       "35009  35009.0  7056.0    8.0 -11.835570     44385.0     27803.0   \n",
       "57162  57162.0  7056.0    5.0   3.476361     19059.0     39396.0   \n",
       "47032  47032.0  7056.0    6.0 -19.453012     51849.0     35224.0   \n",
       "39202  39202.0  7056.0    9.0   3.024749     19741.0     26507.0   \n",
       "55155  55155.0  7056.0    1.0  -7.111054     37005.0     56015.0   \n",
       "15844  15844.0  7056.0    3.0  -7.391142     37482.0     43443.0   \n",
       "35714  35714.0  7056.0   10.0  -2.225584     28616.0     23093.0   \n",
       "20591  20591.0  7056.0    3.0 -16.564301     49692.0     44555.0   \n",
       "54762  54762.0  7056.0    5.0 -13.837959     46917.0     38602.0   \n",
       "2342    2342.0  7056.0   34.0   3.376895     19198.0      2445.0   \n",
       "53977  53977.0  7056.0    1.0 -22.591963     53561.0     55106.0   \n",
       "3246    3246.0  7056.0   20.0 -12.946091     45862.0      8963.0   \n",
       "24586  24586.0  7056.0   17.0 -13.977197     47075.0     12858.0   \n",
       "11426  11426.0  7056.0   33.0  26.802952      2047.0      2719.0   \n",
       "29003  29003.0  7056.0   13.0  -2.219074     28602.0     17870.0   \n",
       "36063  36063.0  7056.0    8.0  -7.784392     38155.0     27863.0   \n",
       "7105    7105.0  7056.0   17.0  -3.259494     30447.0     12178.0   \n",
       "55287  55287.0  7056.0    1.0   7.269970     13489.0     56114.0   \n",
       "\n",
       "       model_discount factor  ideal_discount_factor  discounted gain  \\\n",
       "6452               15.243211              15.139431     2.033692e+00   \n",
       "16794              15.198944              12.883216     2.759602e+05   \n",
       "35009              15.437850              14.763057     1.651784e+01   \n",
       "57162              14.218336              15.265835     2.180283e+00   \n",
       "47032              15.662085              15.104353     4.022453e+00   \n",
       "39202              14.269053              14.694195     3.581177e+01   \n",
       "55155              15.175510              15.773577     6.589564e-02   \n",
       "15844              15.193987              15.406902     4.607086e-01   \n",
       "35714              14.804635              14.495293     6.909998e+01   \n",
       "20591              15.600784              15.443364     4.486954e-01   \n",
       "54762              15.517884              15.236463     1.997695e+00   \n",
       "2342               14.228819              11.256799     1.207400e+09   \n",
       "53977              15.708949              15.749974     6.365798e-02   \n",
       "3246               15.485075              13.130088     6.771520e+04   \n",
       "24586              15.522735              13.650603     8.443809e+03   \n",
       "11426              11.000704              11.409922     7.808532e+08   \n",
       "29003              14.803929              14.125414     5.532991e+02   \n",
       "36063              15.219660              14.766167     1.675464e+01   \n",
       "7105               14.894107              13.572227     8.800192e+03   \n",
       "55287              13.719709              15.776125     7.288784e-02   \n",
       "\n",
       "       ideal discounted gain  random_rank  random_discount_factor  \\\n",
       "6452            9.386447e+01            0                1.000000   \n",
       "16794           2.456187e+06            1                1.584962   \n",
       "35009           4.705724e+02            2                2.000000   \n",
       "57162           9.464817e+01            3                2.321928   \n",
       "47032           1.585957e+02            4                2.584963   \n",
       "39202           8.343037e+02            5                2.807355   \n",
       "55155           1.577358e+01            6                3.000000   \n",
       "15844           3.594944e+01            7                3.169925   \n",
       "35714           1.482869e+03            8                3.321928   \n",
       "20591           3.603452e+01            9                3.459432   \n",
       "54762           9.446606e+01           10                3.584963   \n",
       "2342            5.687951e+09           11                3.700440   \n",
       "53977           1.574998e+01           12                3.807355   \n",
       "3246            6.883941e+05           13                3.906891   \n",
       "24586           1.052470e+05           14                4.000000   \n",
       "11426           2.970014e+09           15                4.087463   \n",
       "29003           8.900098e+03           16                4.169925   \n",
       "36063           4.706716e+02           17                4.247928   \n",
       "7105            1.046427e+05           18                4.321928   \n",
       "55287           1.577612e+01           19                4.392317   \n",
       "\n",
       "       random_discnt_gain  \n",
       "6452         3.100000e+01  \n",
       "16794        2.646310e+06  \n",
       "35009        1.275000e+02  \n",
       "57162        1.335097e+01  \n",
       "47032        2.437173e+01  \n",
       "39202        1.820219e+02  \n",
       "55155        3.333333e-01  \n",
       "15844        2.208254e+00  \n",
       "35714        3.079537e+02  \n",
       "20591        2.023454e+00  \n",
       "54762        8.647231e+00  \n",
       "2342         4.642656e+09  \n",
       "53977        2.626495e-01  \n",
       "3246         2.683912e+05  \n",
       "24586        3.276775e+04  \n",
       "11426        2.101532e+09  \n",
       "29003        1.964304e+03  \n",
       "36063        6.002927e+01  \n",
       "7105         3.032697e+04  \n",
       "55287        2.276703e-01  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df3 = _df.sort_values(by='random_rank', ascending=True).head(20)\n",
    "_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd839029-e890-4c1a-a34b-c78a99bd2c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6747168816.981719"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_rnd_dcg20 = ( (pow(2, _df3.score) - 1) / (np.log2(2 + np.arange(20)) + eps) ).sum()\n",
    "lbl_rnd_dcg20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d39bb-20fe-41e5-956b-2482e345bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbl_rnd_dcg20 = _df3['random_discnt_gain'].sum()\n",
    "# lbl_rnd_dcg20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768de66b-3144-41c4-af65-480700114a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1708035747742436e-21"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_rnd_ndcg20 = lbl_rnd_dcg20/lbl_idcg20\n",
    "lbl_rnd_ndcg20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c36c8-b483-4275-8d41-9569427267a3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac9e8bf-b73d-4d75-9b88-b6b2e1818633",
   "metadata": {},
   "source": [
    "#### Looking at the token ranks for each label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5222fc16-2f7a-46ea-9fbd-1f806b69686a",
   "metadata": {},
   "source": [
    "##### Setting things up ... for analysis later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41285b-39fc-49bd-b42e-9d9029870f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.parent/'data'/'code_desc.pkl', 'rb') as f: lbs_desc = pickle.load(f)\n",
    "df_toks = pd.read_feather(collab_tok_path)\n",
    "df_lbs = pd.read_feather(collab_lbl_path)\n",
    "df_lbs['description'] = df_lbs['lbl_val'].map(lambda x: lbs_desc.get(x, \"Not Found\"))\n",
    "# df_collab = pd.read_feather(collab_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e45036-9f3e-4657-aa7f-c2ef764ec139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collab = pd.DataFrame()\n",
    "lst = [df_collab]\n",
    "del lst\n",
    "del df_collab\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0b078-60a6-4f29-a79e-2bb05d9b70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_toks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de2e05-16fd-4da9-9a41-e73341766b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218d7d6-f9b1-40d4-880c-0599be8503ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toks_tiny = df_toks.iloc[:num]\n",
    "df_lbs_tiny = df_lbs.iloc[:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfcd006-560c-40df-8efe-e9d47ea472a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbs_list = random.sample(list(df_lbs.lbl_val), k=10)\n",
    "# df_lbs[df_lbs.lbl_val.isin(lbs_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae98eb-08ee-49f2-bd5c-e3269fa0adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_collab.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d468a91-2cb9-484e-93ef-1b9f4155b69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| datetime.fromtimestamp(time.time()): datetime.datetime(2022, 7, 30, 16, 33, 23, 596222)\n",
      "ic| datetime.fromtimestamp(collab_path.stat().st_ctime): datetime.datetime(2022, 7, 28, 7, 31, 24, 743458)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "ic(datetime.fromtimestamp(time.time()))\n",
    "ic(datetime.fromtimestamp(collab_path.stat().st_ctime));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53360df5-3a1b-4298-bbc2-bdc5f0362763",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_collab = torch.load(dls_collab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1cb11-8683-42dd-9744-aef8de761258",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_collab.classes['token'].map_objs([9, 17]), dls_collab.classes['token'].map_ids([1,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68542627-9a0e-4008-97ec-f91722950ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_dict = load_learner(collab_path, cpu=False)\n",
    "if 'model' in collab_dict.keys(): collab_dict = collab_dict['model'] # in case the optimizer was saved as well\n",
    "test_eq(type(collab_dict), OrderedDict)\n",
    "test_eq(collab_dict.keys(), ['token_factors.weight', 'token_bias.weight', 'label_factors.weight', 'label_bias.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d809a-221b-452d-bd82-694258435460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| key: 'token_factors.weight'\n",
      "    collab_dict[key].shape: torch.Size([57352, 400])\n",
      "ic| key: 'token_bias.weight'\n",
      "    collab_dict[key].shape: torch.Size([57352, 1])\n",
      "ic| key: 'label_factors.weight'\n",
      "    collab_dict[key].shape: torch.Size([8922, 400])\n",
      "ic| key: 'label_bias.weight'\n",
      "    collab_dict[key].shape: torch.Size([8922, 1])\n"
     ]
    }
   ],
   "source": [
    "for key in collab_dict.keys():\n",
    "    ic(key, collab_dict[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950270de-f881-42eb-b893-41b648fd8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_red = df_toks.token.to_numpy() #dls_collab.classes['token']\n",
    "lbs = df_lbs.lbl.to_numpy() #dls_collab.classes['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fc54c-9a23-489f-8981-2153af627978",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 400\n",
    "# 0 is a nan added by collab dataloaders\n",
    "tok_wgts = collab_dict['u_weight.weight'].detach(); test_eq(tok_wgts.shape, (len(toks_red), n_factors))\n",
    "lbs_wgts = collab_dict['i_weight.weight'].detach(); test_eq(lbs_wgts.shape, (len(lbs), n_factors))\n",
    "tok_bias = collab_dict['u_bias.weight'].detach(); test_eq(tok_bias.shape, [len(toks_red), 1])\n",
    "lbs_bias = collab_dict['i_bias.weight'].detach(); test_eq(lbs_bias.shape, [len(lbs), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1458c8bc-1533-4395-beed-28e7391fb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lbl_list = ['038.2', '038.19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fee141-7e85-4729-8804-e9ecd439ab8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbl</th>\n",
       "      <th>lbl_val</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>038.19</td>\n",
       "      <td>Other staphylococcal septicemia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>038.2</td>\n",
       "      <td>Pneumococcal septicemia [Streptococcus pneumoniae septicemia]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lbl lbl_val                                                    description\n",
       "78   78  038.19                                Other staphylococcal septicemia\n",
       "79   79   038.2  Pneumococcal septicemia [Streptococcus pneumoniae septicemia]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lbs[df_lbs.lbl_val.isin(a_lbl_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab758b62-de46-463b-8799-fe3042e89a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| lbl_list: array([78, 79])\n"
     ]
    }
   ],
   "source": [
    "lbl_list = df_lbs.loc[df_lbs.lbl_val.isin(a_lbl_list)].lbl.to_numpy()\n",
    "# lbl_list = df_lbs[df_lbs.lbl_val.isin(a_lbl_list)].index\n",
    "ic(lbl_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e18e3-7e4a-4b6a-9a10-3346935266a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| df_lbs.iloc[lbl_list]:     lbl lbl_val                                                    description\n",
      "                           78   78  038.19                                Other staphylococcal septicemia\n",
      "                           79   79   038.2  Pneumococcal septicemia [Streptococcus pneumoniae septicemia]\n"
     ]
    }
   ],
   "source": [
    "ic(df_lbs.iloc[lbl_list]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcffbd3-e9ee-48d5-bd57-3bb3aaa7bfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| lbl_idxs: [79, 80]\n"
     ]
    }
   ],
   "source": [
    "lbl_idxs = lbs.map_objs(lbl_list)\n",
    "ic(lbl_idxs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc452c-c821-4724-b369-c5a16f093721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| lbs_wgts.shape: torch.Size([8923, 400])\n"
     ]
    }
   ],
   "source": [
    "ic(lbs_wgts.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e7953-5b3b-4cce-bc96-bfb87480c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| sclt_lbl_wgts.shape: torch.Size([2, 400])\n"
     ]
    }
   ],
   "source": [
    "sclt_lbl_wgts = lbs_wgts[lbl_idxs]\n",
    "ic(sclt_lbl_wgts.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae0798-0811-46f0-88b1-655aff1f1e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| sclt_lbl_bias.shape: torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "sclt_lbl_bias = lbs_bias[lbl_idxs]\n",
    "ic(sclt_lbl_bias.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e29854-f7fa-4c0e-a507-4a66d8930d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| tok_wgts.shape: torch.Size([33648, 400])\n",
      "ic| tok_bias.shape: torch.Size([33648, 1])\n"
     ]
    }
   ],
   "source": [
    "ic(tok_wgts.shape)\n",
    "ic(tok_bias.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44269029-9483-4790-9267-5865b36d675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| lbl_all_toks.shape: torch.Size([33647, 2])\n"
     ]
    }
   ],
   "source": [
    "lbl_all_toks = (tok_wgts[1:] @ sclt_lbl_wgts.T) + tok_bias[1:] + sclt_lbl_bias.T \n",
    "lbl_all_toks = sigmoid_range(lbl_all_toks, low=0, high=1)\n",
    "ic(lbl_all_toks.shape);\n",
    "# ic('#######')\n",
    "# lbl_all_toks_full = (tok_wgts @ sclt_lbl_wgts.T) + tok_bias + sclt_lbl_bias.T \n",
    "# lbl_all_toks_full = sigmoid_range(lbl_all_toks_full, low=0, high=1)\n",
    "# ic(lbl_all_toks_full.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7325f316-0cb9-41ae-9799-0feaa8810bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| sorted_tok_idxs: tensor([[17573, 17573],\n",
      "                             [33311, 27710],\n",
      "                             [31448, 33311],\n",
      "                             ...,\n",
      "                             [  383,  7374],\n",
      "                             [ 7731,  7731],\n",
      "                             [  313, 10875]], device='cuda:0')\n",
      "ic| sorted_tok_idxs.shape: torch.Size([33647, 2])\n"
     ]
    }
   ],
   "source": [
    "sorted_tok_idxs = torch.argsort(lbl_all_toks, dim=0, descending=True)\n",
    "ic(sorted_tok_idxs)\n",
    "ic(sorted_tok_idxs.shape);\n",
    "# ic('########')\n",
    "# sorted_tok_idxs_full = torch.argsort(lbl_all_toks_full, dim=0, descending=True)\n",
    "# ic(sorted_tok_idxs_full)\n",
    "# ic(sorted_tok_idxs_full.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a52c7a-26ec-4372-9f8b-82ecd9b19385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "toks_red_array = L(copy.deepcopy(toks_red))\n",
    "toks_red_array.remove('#na#')\n",
    "toks_red_array = tensor(toks_red_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911f89ea-428a-425b-a43e-1c22e16a6f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| toks_all: array(['xxunk', 'xxpad', 'xxbos', ..., 'pipelle', 'xxfake', 'xxfake'], dtype='<U29')\n"
     ]
    }
   ],
   "source": [
    "toks_all = df_toks.tok_val.to_numpy(dtype=np.str_)\n",
    "ic(toks_all);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b06ddc-a038-4066-aa74-bd2bf1d1c22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| toks_array.shape: (33647, 2)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "toks_array = toks_all[toks_red_array[sorted_tok_idxs]]\n",
    "ic(toks_array.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e88a77-2012-4245-82a1-d659674c7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# toks_array_0 = toks_all[toks_red_array[sorted_tok_idxs[:,0]]]\n",
    "# toks_array_1 = toks_all[toks_red_array[sorted_tok_idxs[:,1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c1f13-97c1-4ce5-af04-d04720b830be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# toks_0 = df_toks.iloc[toks_red_array[sorted_tok_idxs[:,0]]].tok_val.to_numpy(dtype=np.str_)\n",
    "# toks_1 = df_toks.iloc[toks_red_array[sorted_tok_idxs[:,1]]].tok_val.to_numpy(dtype=np.str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96be61-550e-44eb-8653-186028a2d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# toks_0_full = df_toks.iloc[(o for o in toks_red[sorted_tok_idxs_full[:,0]] if o!='#na#')].tok_val.to_numpy(dtype=np.str_)\n",
    "# toks_1_full = df_toks.iloc[(o for o in toks_red[sorted_tok_idxs_full[:,1]] if o!='#na#')].tok_val.to_numpy(dtype=np.str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba612f61-ca22-4426-8805-4d3de9fb2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.logical_not(tensor(toks_0 == toks_0_full)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa8760-4d77-458e-ab25-cad412017673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbs_sorted_tokens(df_toks, df_lbs, collab_path, dls_collab_path=None, lbl_list=None):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    collab_dict = load_learner(collab_path, cpu=False)\n",
    "    if 'model' in collab_dict.keys(): collab_dict = collab_dict['model'] # in case the optimizer was saved as well\n",
    "    test_eq(type(collab_dict), OrderedDict)\n",
    "    test_eq(collab_dict.keys(), ['token_factors.weight', 'token_bias.weight', 'label_factors.weight', 'label_bias.weight'])\n",
    "    \n",
    "    toks = df_toks.token.to_numpy() # dls_collab.classes['token'] # not needed\n",
    "    toks_arr = to_device(tensor(toks))\n",
    "    lbs = df_lbs.lbl.to_numpy() # dls_collab.classes['label'] # not needed\n",
    "    \n",
    "    n_factors = collab_dict['token_factors.weight'].shape[1]\n",
    "    tok_wgts = collab_dict['token_factors.weight'].detach(); test_eq(tok_wgts.shape, (len(toks), n_factors))\n",
    "    lbs_wgts = collab_dict['label_factors.weight'].detach(); test_eq(lbs_wgts.shape, (len(lbs), n_factors))\n",
    "    tok_bias = collab_dict['token_bias.weight'].detach(); test_eq(tok_bias.shape, [len(toks), 1])\n",
    "    lbs_bias = collab_dict['label_bias.weight'].detach(); test_eq(lbs_bias.shape, [len(lbs), 1])\n",
    "    \n",
    "    lbl_idxs = df_lbs.loc[df_lbs.lbl_val.isin(lbl_list)].lbl.to_numpy() if lbl_list is not None else df_lbs.lbl.to_numpy()\n",
    "    sclt_lbl_wgts = lbs_wgts[lbl_idxs]\n",
    "    sclt_lbl_bias = lbs_bias[lbl_idxs]\n",
    "    lbl_all_toks = (tok_wgts @ sclt_lbl_wgts.T) + tok_bias + sclt_lbl_bias.T # there is no nan\n",
    "    test_eq(lbl_all_toks.shape, (len(toks), len(lbs)))\n",
    "    # lbl_all_toks = sigmoid_range(lbl_all_toks, low=0, high=1) # not needed\n",
    "    sorted_tok_vals, sorted_tok_idxs = torch.sort(lbl_all_toks, dim=0, descending=True)\n",
    "    sorted_tok_vals, sorted_tok_idxs = sorted_tok_vals.cpu(), sorted_tok_idxs.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "    # sorted_toks = toks_arr[sorted_tok_idxs].cpu() # no longer needed\n",
    "    # test_eq(sorted_toks, sorted_tok_idxs.cpu())\n",
    "    # toks_names = df_toks.tok_val.to_numpy(dtype=np.str_)\n",
    "    # sorted_tok_names= toks_names[sorted_toks]\n",
    "    return sorted_tok_vals, sorted_tok_idxs #, sorted_tok_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e8a34-315c-4de4-8feb-8e23ada854bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbs_list = None\n",
    "lbs_idxs = df_lbs_tiny.loc[df_lbs_tiny.lbl_val.isin(lbs_list)].lbl.to_numpy() if lbs_list is not None else df_lbs_tiny.lbl.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8efcbc-d61c-43f8-b43a-70bf76beb99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 985 ms, sys: 182 ms, total: 1.17 s\n",
      "Wall time: 2.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sorted_tok_vals, sorted_tok_idxs = lbs_sorted_tokens(df_toks_tiny, df_lbs_tiny, collab_path_tiny, lbl_list=lbs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1026e9d-b5e9-4e3a-945e-689e697ed442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.77 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "13.9 s ± 11.2 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with open('sorted_toks.pt', 'wb') as f: pickle.dump(sorted_toks, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ffac1-6bdb-45b3-941e-f8c88468df6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 15.3 s, total: 16.9 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "torch.save((sorted_tok_vals, sorted_tok_idxs), 'sorted_toks.pt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f7d85-bf0e-49cb-8996-4b9aa7b33cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| df_cf.memory_usage().sum()/1024**3: 1.906476616859436\n"
     ]
    }
   ],
   "source": [
    "cols = np.arange(sorted_tok_idxs.shape[0]).astype(np.str)\n",
    "df_cf = pd.DataFrame(sorted_tok_idxs.T, index=range(sorted_tok_idxs.shape[1]), columns=cols, dtype=np.int32)\n",
    "df_cf['lbl'] = lbs_idxs\n",
    "cols = list(df_cf.columns)\n",
    "cols =  [cols[-1]] + cols[:-1]\n",
    "df_cf = df_cf[cols]\n",
    "df_cf = pd.merge(df_lbs, df_cf, on='lbl')\n",
    "ic(df_cf.memory_usage().sum()/1024**3);\n",
    "df_cf.to_feather('mut_info_cf.ft')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92f1367-ff17-4524-a6c4-2ce34e7d6f78",
   "metadata": {},
   "source": [
    "##### Loading things up.. for analysis now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979cb65-fe2b-4e4a-aa21-09548f61d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf = pd.read_feather('mut_info_cf.ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e0574-25a7-4979-91b2-84ac9ad7dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tok_vals, sorted_tok_idxs = torch.load('sorted_toks.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f177b8-e4b1-4dfd-be3c-9b2a1e64fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_names = df_toks_tiny.tok_val.to_numpy(dtype=np.str_)\n",
    "lbl_names = df_lbs_tiny.lbl_val.to_numpy(dtype=np.str_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f410d782-187f-4498-90b4-7bd0eff5f269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| tid: 3374, lid: 434\n"
     ]
    }
   ],
   "source": [
    "tid = np.where(toks_names == 'quetiapine')[0].item()\n",
    "lid = np.where(lbl_names == '157.3')[0].item()\n",
    "ic(tid, lid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f60fbf-d029-47e7-b0ef-11633fe55604",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_collab.token == tid) & (df_collab.label == lid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ab4d8-018d-4302-af6b-d12f4407b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_collab.head(5)\n",
    "# df_collab.pivot(index='token', columns='label', values='rank') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb550b-65be-40f3-a981-174c446e1978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| collab_bootstrap.keys(): dict_keys(['toks', 'lbs', 'mut_info_lbl_entropy', 'mutual_info_jaccard'])\n"
     ]
    }
   ],
   "source": [
    "collab_bootstrap = torch.load(collab_bootst_path)\n",
    "ic(collab_bootstrap.keys());\n",
    "info = collab_bootstrap.get('mutual_info_jaccard', None)\n",
    "assert info is not None\n",
    "info = torch.tensor(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970efd3-8a10-4f47-a0e1-c87eb2ffb963",
   "metadata": {},
   "source": [
    "Removing negs before boxcox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d32813-7ca7-4ffc-bd07-db8478d05a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| torch.sum(info<0): tensor(111226814, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ic(torch.sum(info<0));\n",
    "eps = torch.ones(1).new_empty(1).fill_(1e-20).item()\n",
    "info[info<0] = eps\n",
    "test_eq(torch.sum(info<0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4acedcd-6a6d-4514-862c-9056441a4fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 19s, sys: 22.9 s, total: 3min 42s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bcx_info, *_ = boxcox(info.cpu().flatten() + eps)\n",
    "bcx_info = bcx_info.reshape(info.shape[0], info.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02545605-8754-4911-8f4b-30c0bce2c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bcx_info, 'bcx_info.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab7628c-5679-46bb-94f4-cf2b7a477ca6",
   "metadata": {},
   "source": [
    "Rank the bcx_info in the GPU, then move it to CPU and free up the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c20ab-e0a6-45f8-beac-595dc66bbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcx_info = torch.load('bcx_info.pkl')\n",
    "test_eq(type(bcx_info), ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d07130-0a1b-4db6-9ca2-25518ddb9088",
   "metadata": {},
   "source": [
    "**Use the following cell only for the tiny dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee2757e-6703-492b-bd08-5aa9cd09d5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| bcx_info.shape: (100, 100)\n"
     ]
    }
   ],
   "source": [
    "bcx_info = bcx_info[:num, :num]\n",
    "ic(bcx_info.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece75124-924a-45f8-8ca2-afd15ecef16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcx_info = torch.as_tensor(bcx_info, device=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13729b76-e7e7-49ec-b7f1-9a2458f63466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.14 ms, sys: 423 µs, total: 2.56 ms\n",
      "Wall time: 33 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rnk_info = torch.argsort(bcx_info, dim=0, descending=True).argsort(dim=0)\n",
    "rnk_info = to_device(rnk_info, device=torch.device(\"cpu\"))\n",
    "rnk_info = rnk_info.numpy()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9fa0f-cddf-43e2-aac3-b74dd6a79121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| rnk_info.shape: (100, 100)\n"
     ]
    }
   ],
   "source": [
    "ic(rnk_info.shape); # these are the ranks of all the tokens for the corresponding labels\n",
    "# rnk_info_df = pd.DataFrame(rnk_info)\n",
    "# rnk_info_df.columns.name = 'labels'\n",
    "# rnk_info_df.index.name = 'tokens'\n",
    "# rnk_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b20a6f4-b13f-4975-a847-f87f684c08fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.84 ms, sys: 0 ns, total: 4.84 ms\n",
      "Wall time: 3.23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sorted_toks_orig_ranks = np.empty_like(sorted_tok_idxs)\n",
    "for lbl in range(sorted_tok_idxs.shape[1]):\n",
    "    sorted_toks_orig_ranks[:, lbl] = rnk_info[:, lbl][sorted_tok_idxs[:, lbl]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c6b03-6e46-4e29-ab91-0ae5b72389ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.46 ms, sys: 461 µs, total: 2.92 ms\n",
      "Wall time: 2.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bcx_info_cpu = bcx_info.cpu().numpy()\n",
    "sorted_toks_bcx_info = np.empty_like(sorted_tok_idxs, dtype=np.float)\n",
    "for lbl in range(sorted_tok_idxs.shape[1]):\n",
    "    sorted_toks_bcx_info[:, lbl] = bcx_info_cpu[:, lbl][sorted_tok_idxs[:, lbl]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba35e5-1401-4a37-b24e-ef89bd4dae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_toks = np.stack((sorted_tok_idxs, sorted_toks_bcx_info, sorted_toks_orig_ranks, sorted_tok_vals), axis=-1)\n",
    "test_eq(sorted_toks.shape, (*sorted_tok_idxs.shape, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564c2c9-e8b2-47a7-9703-cbcf03cba3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.MultiIndex.from_product([range(sorted_toks.shape[1]), ('idx', 'info', 'act_rank', 'pred')], names=['label', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c00b3b-bd83-414d-ba3d-92b7fc6a6968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th colspan=\"4\" halign=\"left\">0</th>\n",
       "      <th colspan=\"4\" halign=\"left\">1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">2</th>\n",
       "      <th colspan=\"4\" halign=\"left\">3</th>\n",
       "      <th colspan=\"4\" halign=\"left\">4</th>\n",
       "      <th colspan=\"4\" halign=\"left\">5</th>\n",
       "      <th colspan=\"4\" halign=\"left\">6</th>\n",
       "      <th colspan=\"4\" halign=\"left\">7</th>\n",
       "      <th colspan=\"4\" halign=\"left\">8</th>\n",
       "      <th colspan=\"4\" halign=\"left\">9</th>\n",
       "      <th colspan=\"4\" halign=\"left\">10</th>\n",
       "      <th colspan=\"4\" halign=\"left\">11</th>\n",
       "      <th colspan=\"4\" halign=\"left\">12</th>\n",
       "      <th colspan=\"4\" halign=\"left\">13</th>\n",
       "      <th colspan=\"4\" halign=\"left\">14</th>\n",
       "      <th colspan=\"4\" halign=\"left\">15</th>\n",
       "      <th colspan=\"4\" halign=\"left\">16</th>\n",
       "      <th colspan=\"4\" halign=\"left\">17</th>\n",
       "      <th colspan=\"4\" halign=\"left\">18</th>\n",
       "      <th colspan=\"4\" halign=\"left\">19</th>\n",
       "      <th colspan=\"4\" halign=\"left\">20</th>\n",
       "      <th colspan=\"4\" halign=\"left\">21</th>\n",
       "      <th colspan=\"4\" halign=\"left\">22</th>\n",
       "      <th colspan=\"4\" halign=\"left\">23</th>\n",
       "      <th colspan=\"4\" halign=\"left\">24</th>\n",
       "      <th colspan=\"4\" halign=\"left\">25</th>\n",
       "      <th colspan=\"4\" halign=\"left\">26</th>\n",
       "      <th colspan=\"4\" halign=\"left\">27</th>\n",
       "      <th colspan=\"4\" halign=\"left\">28</th>\n",
       "      <th colspan=\"4\" halign=\"left\">29</th>\n",
       "      <th colspan=\"4\" halign=\"left\">30</th>\n",
       "      <th colspan=\"4\" halign=\"left\">31</th>\n",
       "      <th colspan=\"4\" halign=\"left\">32</th>\n",
       "      <th colspan=\"4\" halign=\"left\">33</th>\n",
       "      <th colspan=\"4\" halign=\"left\">34</th>\n",
       "      <th colspan=\"4\" halign=\"left\">35</th>\n",
       "      <th colspan=\"4\" halign=\"left\">36</th>\n",
       "      <th colspan=\"4\" halign=\"left\">37</th>\n",
       "      <th colspan=\"4\" halign=\"left\">38</th>\n",
       "      <th colspan=\"4\" halign=\"left\">39</th>\n",
       "      <th colspan=\"4\" halign=\"left\">40</th>\n",
       "      <th colspan=\"4\" halign=\"left\">41</th>\n",
       "      <th colspan=\"4\" halign=\"left\">42</th>\n",
       "      <th colspan=\"4\" halign=\"left\">43</th>\n",
       "      <th colspan=\"4\" halign=\"left\">44</th>\n",
       "      <th colspan=\"4\" halign=\"left\">45</th>\n",
       "      <th colspan=\"4\" halign=\"left\">46</th>\n",
       "      <th colspan=\"4\" halign=\"left\">47</th>\n",
       "      <th colspan=\"4\" halign=\"left\">48</th>\n",
       "      <th colspan=\"4\" halign=\"left\">49</th>\n",
       "      <th colspan=\"4\" halign=\"left\">50</th>\n",
       "      <th colspan=\"4\" halign=\"left\">51</th>\n",
       "      <th colspan=\"4\" halign=\"left\">52</th>\n",
       "      <th colspan=\"4\" halign=\"left\">53</th>\n",
       "      <th colspan=\"4\" halign=\"left\">54</th>\n",
       "      <th colspan=\"4\" halign=\"left\">55</th>\n",
       "      <th colspan=\"4\" halign=\"left\">56</th>\n",
       "      <th colspan=\"4\" halign=\"left\">57</th>\n",
       "      <th colspan=\"4\" halign=\"left\">58</th>\n",
       "      <th colspan=\"4\" halign=\"left\">59</th>\n",
       "      <th colspan=\"4\" halign=\"left\">60</th>\n",
       "      <th colspan=\"4\" halign=\"left\">61</th>\n",
       "      <th colspan=\"4\" halign=\"left\">62</th>\n",
       "      <th colspan=\"4\" halign=\"left\">63</th>\n",
       "      <th colspan=\"4\" halign=\"left\">64</th>\n",
       "      <th colspan=\"4\" halign=\"left\">65</th>\n",
       "      <th colspan=\"4\" halign=\"left\">66</th>\n",
       "      <th colspan=\"4\" halign=\"left\">67</th>\n",
       "      <th colspan=\"4\" halign=\"left\">68</th>\n",
       "      <th colspan=\"4\" halign=\"left\">69</th>\n",
       "      <th colspan=\"4\" halign=\"left\">70</th>\n",
       "      <th colspan=\"4\" halign=\"left\">71</th>\n",
       "      <th colspan=\"4\" halign=\"left\">72</th>\n",
       "      <th colspan=\"4\" halign=\"left\">73</th>\n",
       "      <th colspan=\"4\" halign=\"left\">74</th>\n",
       "      <th colspan=\"4\" halign=\"left\">75</th>\n",
       "      <th colspan=\"4\" halign=\"left\">76</th>\n",
       "      <th colspan=\"4\" halign=\"left\">77</th>\n",
       "      <th colspan=\"4\" halign=\"left\">78</th>\n",
       "      <th colspan=\"4\" halign=\"left\">79</th>\n",
       "      <th colspan=\"4\" halign=\"left\">80</th>\n",
       "      <th colspan=\"4\" halign=\"left\">81</th>\n",
       "      <th colspan=\"4\" halign=\"left\">82</th>\n",
       "      <th colspan=\"4\" halign=\"left\">83</th>\n",
       "      <th colspan=\"4\" halign=\"left\">84</th>\n",
       "      <th colspan=\"4\" halign=\"left\">85</th>\n",
       "      <th colspan=\"4\" halign=\"left\">86</th>\n",
       "      <th colspan=\"4\" halign=\"left\">87</th>\n",
       "      <th colspan=\"4\" halign=\"left\">88</th>\n",
       "      <th colspan=\"4\" halign=\"left\">89</th>\n",
       "      <th colspan=\"4\" halign=\"left\">90</th>\n",
       "      <th colspan=\"4\" halign=\"left\">91</th>\n",
       "      <th colspan=\"4\" halign=\"left\">92</th>\n",
       "      <th colspan=\"4\" halign=\"left\">93</th>\n",
       "      <th colspan=\"4\" halign=\"left\">94</th>\n",
       "      <th colspan=\"4\" halign=\"left\">95</th>\n",
       "      <th colspan=\"4\" halign=\"left\">96</th>\n",
       "      <th colspan=\"4\" halign=\"left\">97</th>\n",
       "      <th colspan=\"4\" halign=\"left\">98</th>\n",
       "      <th colspan=\"4\" halign=\"left\">99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key2</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.209785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.206440</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-6.378193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.409137</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-6.588891</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-6.129146</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-6.182239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.207527</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.221110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.218801</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-5.775692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.789716</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-6.275874</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.282557</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-5.709177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.726708</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-6.060895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.059132</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.983247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.989470</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-6.028867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.041323</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-6.117087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.113903</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-5.901704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.909033</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-5.891960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.903122</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-5.789740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.805620</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-3.940301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.934020</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.983247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.991196</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-6.077859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.072291</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-6.196057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.237668</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-6.070198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.083841</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-6.006469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.007827</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-5.770156</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.778278</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-5.245574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.248561</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-5.542492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.536958</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-5.703646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.705223</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.717038</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-5.601665</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-5.507920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.510865</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-5.930282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.927581</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-6.028867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.030078</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-6.134938</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.143692</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-5.849577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.856101</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-6.158427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.153932</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-5.374472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.366094</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.600779</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-6.036506</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-5.874065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.871864</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-6.313117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.334147</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-6.140011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.140745</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-5.766344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.767742</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-5.849577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.855848</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-6.070198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.075658</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-6.195378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.216457</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-6.107600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.121827</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-6.146663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.165133</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.983247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.989765</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.549222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.550990</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-5.836143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.833795</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-5.901704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.920306</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-5.586688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.599098</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-6.134938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.145071</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-6.196057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.221061</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-6.365438</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.397769</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-6.111759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.105064</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-6.134938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.150967</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.476279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.491059</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.983247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.978225</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-5.849577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.874820</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-6.470216</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.782003</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-5.077253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.086127</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-6.091972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.144179</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-6.158427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.189448</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-5.534416</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-6.161404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.165813</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-5.728308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.728362</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-6.238058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.234853</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-5.779319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.781091</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-5.751393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.752360</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.228091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.245189</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-5.562530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.576107</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.228091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.249218</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-6.337839</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-5.600626</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.289662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.283247</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-6.358535</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-5.970652</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-6.354778</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-5.834315</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-6.286141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.307220</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-4.806090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.806323</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-5.789685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.785295</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-4.939904</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.936449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.282387</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-5.004199</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-4.841265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.838974</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-5.101474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.154175</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-4.732475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.740738</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-5.446089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.444146</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-5.688428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.677827</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-4.690676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.702187</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-4.719597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.720963</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-4.849282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.856553</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-4.846297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.843096</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-4.961876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.961539</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-3.930341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.929331</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-6.873151</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-5.735173</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-4.908507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.912350</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-6.534252</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-6.265768</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-5.719459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.722820</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-6.070054</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-5.759802</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-5.099403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.100125</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-5.623547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.616222</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-6.771860</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-5.219338</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-5.299616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.303560</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-7.353806</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-5.779118</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-4.959163</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-4.489558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.0</td>\n",
       "      <td>-6.219368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.242119</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-6.454948</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.457011</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-6.230028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.223404</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-6.275874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.293755</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-6.240831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.240847</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-5.910188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.917663</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-6.331505</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.344807</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-6.130860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.114508</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-6.894968</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-6.097312</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-6.143131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.140545</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-6.044409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.052176</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-6.156014</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.159112</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-6.146663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.154080</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-6.134938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.136778</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-6.107600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.112395</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-4.462110</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.458435</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-6.158427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.172926</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-6.161673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.162069</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.455512</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.438261</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-6.219368</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.203945</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.039419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.032581</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-5.807189</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.814392</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-5.266717</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.268564</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-5.580114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.579801</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-5.769703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.777030</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.765828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.761786</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-5.951787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.954525</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.232370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.245910</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-6.044409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.056815</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-6.143131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.147087</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.983247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.984535</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-6.221133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.235856</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-5.911748</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.805452</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-6.282807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.310916</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-6.588891</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.050550</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-6.370296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.390576</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-6.158427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.163455</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-6.402689</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.155170</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.983247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.987694</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-6.216141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.221207</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-6.438037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.432988</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-6.158427</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.163053</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.228091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.242920</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.228091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.238089</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-6.548010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.554848</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-5.952051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.943097</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-6.130860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.132979</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-6.079284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.078047</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-6.143131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.156491</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-6.313117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.321089</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-6.643223</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-6.443179</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.976879</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-6.221260</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-6.195378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.209301</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-6.548010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.546859</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.228091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.227862</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-6.300496</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.304437</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-5.946779</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.866240</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-5.116639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.119152</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-6.146663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.144928</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-6.331505</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.334547</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-6.200252</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-5.721776</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-6.223698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.219057</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-5.730041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.736298</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-6.328879</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.331000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-5.814093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.811885</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-6.618454</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-6.066234</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-6.221301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.250992</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.702554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.704838</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-6.370296</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.389161</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-5.892754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.894948</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-6.296583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.306055</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-6.049853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.049420</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-6.583543</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-6.090720</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-6.313117</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.328473</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-4.925375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.932771</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-5.810853</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.802298</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-4.960993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.964064</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-5.115004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.109031</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-5.132164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.136580</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-5.350877</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.353909</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-5.365047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.359856</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-5.758117</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.755056</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.691516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.698607</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-4.875638</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.857039</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-4.913362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.917946</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-5.686593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.682671</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-5.158384</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.854918</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-5.289307</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.292850</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-3.970979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.969098</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-6.512794</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-6.092467</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-5.908459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.917121</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-6.467428</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-6.272301</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-5.962330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.962266</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-5.797782</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.794234</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-6.024241</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.027439</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-5.727442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.726045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.245051</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.355571</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-5.383586</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.384628</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-6.480022</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-5.847100</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-4.977380</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-4.505052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.0</td>\n",
       "      <td>-6.240334</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.246603</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.662710</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.541097</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-6.480742</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.307346</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-6.331505</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.365513</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-6.364440</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.359645</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-6.217120</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.219978</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-6.780406</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-6.414482</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-6.195378</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.190402</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-6.940001</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-6.320796</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-6.324052</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.328280</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-6.221133</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.217917</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-6.171896</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.180599</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-6.182239</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.180636</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-6.150773</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.165330</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-6.249234</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.252928</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-4.488357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.481386</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-6.221301</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.223852</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-6.619645</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-6.169834</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-6.464425</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.464385</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-6.618454</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-6.215768</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-6.372712</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-6.037009</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-5.815135</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.819547</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-5.288770</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.295113</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-5.639951</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.641968</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-5.819183</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.819251</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-6.212671</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-5.965829</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-7.591816</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-6.204265</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-6.257469</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.251998</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-6.195378</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.207242</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-6.324052</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-6.150760</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.228091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.227783</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.228091</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.238778</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-7.128593</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-5.965558</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-6.370296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.383852</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-6.257469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.269179</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.476279</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.495346</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-6.182239</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.201119</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-6.511463</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-6.343021</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.228091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.231473</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-6.240334</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.227340</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.476279</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.471385</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-6.217120</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.210379</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-6.313117</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.312078</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-6.833242</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-6.443336</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-6.586070</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.586352</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-6.161404</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.155777</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-6.134938</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.144638</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-6.161404</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.160436</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-6.253382</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.261949</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-6.359660</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.384645</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.455512</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.459650</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-6.261224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.256142</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-6.329358</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.338180</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.549222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.557016</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-6.300496</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.303432</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-6.603251</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.348537</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-5.920697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.922410</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-5.262535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.258935</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-6.195378</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.192425</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-6.324052</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.335538</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-6.084221</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-5.723261</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-6.238058</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.241138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.753846</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.751369</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-6.637797</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-6.346422</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-5.894030</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.902766</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-6.070198</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.067514</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-6.317314</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.313829</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-5.861041</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.867354</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-6.464425</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.459091</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-5.896406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.898395</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.307454</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.307156</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-6.057899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.054447</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-6.660027</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-6.236250</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-6.329358</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.344307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.046092</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.046387</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-5.791017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.806690</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-4.978734</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.975702</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-5.133687</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.133000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-5.485133</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.478284</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-5.392830</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.398625</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-5.364374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.371370</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-5.764222</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.763424</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-5.975066</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.973187</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-4.989712</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.936715</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-5.255649</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.254946</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-5.778876</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.777435</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-6.042273</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-4.873288</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-5.386950</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.380569</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-4.010327</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.009221</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-6.098917</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.095601</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-6.150773</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.141796</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-6.530053</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-6.275233</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-6.039551</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.039298</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-5.795397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.797428</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-6.056923</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.049633</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-6.649372</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-5.730793</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-6.324862</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-5.527510</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-5.452182</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.452777</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-5.945722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.945576</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-4.511155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.519406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>-6.625558</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-6.251883</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.549222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.554122</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-6.309279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.312391</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.455512</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.456026</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-6.370844</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.363751</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-6.249234</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.249772</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.600779</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.455039</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-6.311167</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.304888</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-6.349417</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.354245</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-6.368240</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.381281</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-6.221301</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.231865</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-6.172530</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.180791</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-6.217120</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.216530</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-6.202125</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.204170</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.549222</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.258662</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-4.507672</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.510556</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-6.324052</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.326668</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-6.174577</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.183572</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-6.454948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.475404</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-6.572208</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-6.216390</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-6.110777</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.113202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.728776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.827851</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-5.302331</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.305170</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-5.644109</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.644223</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-5.826686</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.822942</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-6.049853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.048114</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-6.990874</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-6.221961</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-6.259565</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.257571</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-6.221301</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.227348</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-6.202125</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.202123</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-6.691357</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-6.465548</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-6.235842</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.249428</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-6.009958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.012503</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-6.411710</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.413867</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-6.539048</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-6.273180</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-6.500648</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.502325</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-6.249234</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.250063</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-6.364440</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.361938</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.455512</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.463291</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-6.230028</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.230957</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-6.468452</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.483478</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.228091</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.222253</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-6.464425</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-6.451281</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-6.799016</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-6.497480</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-6.627138</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.617065</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-6.524523</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-6.360283</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-6.158427</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.168409</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-6.740957</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-6.160839</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-6.275874</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.286424</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-6.464425</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.451509</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-6.468452</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-6.470255</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-6.477499</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-6.262456</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.476279</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.472601</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-6.566573</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.569449</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-6.365438</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.368578</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-6.365438</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.370860</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-5.926846</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.925239</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-5.688428</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.692982</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-6.253382</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.262632</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.455512</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.466951</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-5.826158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.831306</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-6.258624</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.264011</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-5.867534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.870164</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-6.392454</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-6.385984</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-5.945722</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.951723</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-6.068260</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.067588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.336077</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.344388</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-5.882263</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.878037</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.455512</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.459464</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-5.900869</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.900371</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-6.364440</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.365460</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-6.393664</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-6.097986</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-6.237360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.239362</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-6.378193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.372351</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-7.200351</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-5.091616</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-5.832678</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.833019</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-4.990871</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.980806</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-5.157475</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.156066</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-5.504945</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.516371</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-5.462380</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.452002</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-5.521792</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.517632</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-5.785132</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.782202</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.113518</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.110330</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-4.971684</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.973066</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-5.355205</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.319679</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-5.775953</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.778328</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-5.071329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.069152</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-5.384874</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.382573</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-4.102417</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.103675</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-6.104436</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.100065</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-6.182239</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.185272</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-6.627779</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-6.332142</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-6.096475</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.095916</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-5.833680</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.833448</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-6.223698</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.217341</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-5.782372</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.777117</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-5.641105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.642994</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-5.492447</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.496153</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-5.955873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.959344</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-4.586379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.583322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.310939</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.314555</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-6.586070</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.578732</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.310939</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.320697</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-6.464425</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.485068</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-6.372328</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-6.376309</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-6.282807</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.273282</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-6.454948</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.464305</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-6.331505</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.338234</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-6.392454</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.390116</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-6.359660</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.381303</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-6.344256</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.355586</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-6.199615</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.201021</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-6.736660</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-6.224261</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-6.286141</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.286999</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-6.275874</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.281922</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-4.536525</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.540329</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-6.805135</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-6.462296</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-6.202522</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.205570</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-6.586070</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.588339</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.209785</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.228810</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-6.119213</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.119181</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-5.842688</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.849417</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-5.273103</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.314286</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-5.655513</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.658987</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-5.901546</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.899521</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-6.057899</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.062016</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-6.267476</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.262732</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-6.620191</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.302452</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-6.221133</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.230107</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-6.221133</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.223449</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.455512</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.466901</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-6.313117</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.317309</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-6.043469</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.052843</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-6.454948</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.447219</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-6.309279</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.309877</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.549222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.539858</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-6.253382</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.259783</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-6.372328</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.369914</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-6.464425</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.467321</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-6.675759</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.270102</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-6.500648</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.519234</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-6.235842</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.230178</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-6.784420</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-6.454251</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-6.549222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.544451</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.662710</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.617170</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-6.392454</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.382545</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.228091</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.226757</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-6.238058</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.229351</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-6.500648</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-6.489244</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-6.455512</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.454201</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-6.464425</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.471692</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-6.268482</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.279225</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-6.677761</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-6.478706</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-6.627138</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.619775</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.476279</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-6.437866</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.476279</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.476952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.943341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.945606</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-6.399796</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-5.937406</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-6.331505</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.330876</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-6.619365</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.499627</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-5.890154</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.886685</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-6.338272</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.339762</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-5.895584</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.892632</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-6.385644</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.397864</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-6.284039</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-5.981733</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-6.086826</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.088886</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-6.476279</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.453732</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-5.930282</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.930590</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-6.819258</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-6.476225</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-5.942923</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.946708</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-6.370844</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.376408</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.108628</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.106754</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-6.354255</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.253492</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-6.370296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.394812</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-5.102791</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.103552</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-5.834847</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.835123</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-5.006681</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-5.013330</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-5.156481</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.165165</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-6.225242</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-5.516737</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-5.448400</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.452592</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-5.512191</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.522265</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.003216</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-5.809843</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-6.184637</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.187559</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-5.016879</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.008533</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-5.339369</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.344602</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-5.818552</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-5.816669</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-5.262899</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-5.264668</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-5.794258</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-5.400883</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-4.195492</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.199290</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-6.096283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.102666</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-6.195378</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.191125</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-6.372328</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.369525</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-6.343839</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-6.110246</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-5.863704</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.861121</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-6.222270</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-6.219057</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-5.969609</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-5.813753</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-7.245023</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-5.683380</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-5.510035</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-5.513776</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-6.142846</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.135499</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-4.603284</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.602691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.736045</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.736048</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.732467</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.739051</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.741116</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-9.738787</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.739703</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.739460</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.734538</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.735209</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.738401</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.732499</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.733868</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.737289</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.742003</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.728175</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.736752</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.744748</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.742700</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.730780</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.736245</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.730020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.733356</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.734082</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.721565</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.734002</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.733186</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.739254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.744131</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.738722</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.738281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.737617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.737058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.734204</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.733026</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.731474</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.727341</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.733254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.736431</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.721487</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.737429</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.746287</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.742451</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.734765</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.737298</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.731956</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.728438</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.729780</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.737868</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.737443</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.737937</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.736635</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.733876</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.735138</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.733182</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.737107</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.725956</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.730526</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.734692</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.738967</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.734627</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.734056</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.730145</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.726907</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.727899</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.729106</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.726359</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.779644</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.734325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.735436</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.734463</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.733220</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.734617</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.736211</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.731956</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.735878</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.733600</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.730465</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.728991</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.739847</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.728591</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.731763</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.741066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.729050</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.734412</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.732044</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.735693</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.727961</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.729873</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.736639</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-9.732518</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-9.733492</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.734880</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.732196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.732396</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.731427</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.733614</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.732234</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.735483</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.733828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.739898</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.736523</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.736560</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.739160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.744051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.739154</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.741989</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.747756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.737733</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-9.737255</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-9.739338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.733826</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.737035</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.737843</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.742458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.730686</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.740916</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.745674</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.744297</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.736571</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.737804</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.737329</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.735886</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.738252</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.731416</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.737104</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.740986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.739285</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.744469</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.739348</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-9.738815</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.737807</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.739939</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.735894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.733351</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.732134</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.734338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.734562</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.737681</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.728613</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.738865</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-9.747201</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.745400</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.735175</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.738612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.735113</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.731973</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.736673</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.738751</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.743547</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.739881</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.738748</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.735381</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.735368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.736837</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.737754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.729997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.734992</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.738513</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.745404</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.734641</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.734358</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.735061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.741680</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.728675</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.735067</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.736040</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.797387</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.735950</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.736580</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.734673</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.735376</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.738548</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.737751</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.738721</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.737626</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.735757</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.731701</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.735601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.740124</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.729023</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.733335</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.741921</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.729384</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.736106</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.733565</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.744117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.729630</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.730498</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.736886</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.737035</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.734220</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.736528</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.734276</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.736037</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.731923</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.734844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.733034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.736398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.735018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.741494</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.737504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.741411</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.744978</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.747046</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.740463</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.744608</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.750010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.742346</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.748471</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.740447</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.734141</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.746912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.737889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.757664</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.736979</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.745246</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.784444</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.745339</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.736653</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.753265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.739262</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.741858</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.743327</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.732510</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.737425</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.741468</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.744000</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.747035</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.742479</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.740854</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.739771</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.868471</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.737282</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.739572</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.736856</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.740038</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.737960</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.739258</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.743909</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.740138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.751760</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.745702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.741208</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.739818</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.739193</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.733766</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.740248</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.751773</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.744169</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.741224</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.749399</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-9.747395</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.737254</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.739243</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.744504</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.731354</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.736590</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.739035</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.745927</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.740032</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.735862</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.739370</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.742630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.739616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.735845</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.749786</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.811434</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.742347</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.737024</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.737544</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.737366</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.740950</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.738492</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.739339</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.741815</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.736565</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.738268</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.735865</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.747544</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.734732</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.734577</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.742312</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.735067</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.737699</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.733966</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.750275</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.735549</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.731700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.737006</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.740822</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.738712</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.740213</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.735433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.742655</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.732054</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.737084</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.734362</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.736816</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.737608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.744768</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.739672</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.746467</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.749709</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.798129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.745497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.746089</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.771820</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.747684</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.749693</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.745355</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.734818</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.751837</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.745402</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.773057</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.737529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.747725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.812429</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.746693</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.740093</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.780827</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.743031</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.742970</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.746374</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.734055</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.740233</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.741498</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.748805</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.760663</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.743685</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.745809</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.740050</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.887436</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.747350</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.743623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.737259</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.742881</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.738618</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.742168</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.746951</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.746779</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.773637</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.764245</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.743615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.742810</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.739234</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.735850</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.752468</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.760437</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.746710</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-9.741903</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.754594</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.754959</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.739686</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.763390</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.748107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.742269</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.736703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.740134</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.756600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.740938</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.738839</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.742396</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.748480</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.741485</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.742193</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.749865</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.859339</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.746536</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.737098</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.745873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.873932</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.790779</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.741970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.740574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.745522</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.738027</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.739939</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.740923</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.747748</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.740969</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.735214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.814561</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.738807</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.737867</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.735077</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.933986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.740797</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.734659</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.737267</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.749562</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.739071</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.843504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.735964</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.743469</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.738361</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.737380</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.734757</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.739737</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.742069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.746672</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.741522</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.817535</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.753163</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.852698</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.745788</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.755100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.788496</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.751492</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.753802</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.748753</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.735373</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.755458</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.749751</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.798615</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.740290</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.752284</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.815358</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.761417</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.745934</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.789155</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.748559</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.745940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.910607</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.736728</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.787331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.806970</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.749821</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.823350</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.749327</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.848978</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.741735</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.975471</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.749283</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.744203</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.754106</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.747803</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.743312</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>89.0</td>\n",
       "      <td>-9.801399</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.748071</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-9.752300</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.780558</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.801290</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.748940</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.750406</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.739717</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.741558</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.755829</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-9.845098</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.754340</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.743132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.756827</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-9.766459</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.740934</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-9.784596</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.748240</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.749172</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.740966</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.741769</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.762114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.741757</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.827401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.745969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.766183</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.756805</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.751494</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.752332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.920288</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.747378</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.743192</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.746218</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.891241</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.817722</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-9.746170</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.742110</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.748466</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.742846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.741092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-9.742655</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.751253</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.742553</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.742047</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.819942</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.739064</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.742714</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.735802</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-10.009768</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-9.742281</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-9.735478</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.848498</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-9.766806</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.750229</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.934364</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-9.742120</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.749361</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.744190</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.742350</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-9.745341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.739832</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.734209</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-9.742805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label     0                                  1                                \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       99.0 -6.209785      0.0 -6.206440  92.0 -6.378193      1.0 -6.409137   \n",
       "1       97.0 -6.219368      1.0 -6.242119  94.0 -6.454948      2.0 -6.457011   \n",
       "2       61.0 -6.240334      2.0 -6.246603  24.0 -6.662710     10.0 -6.541097   \n",
       "3       39.0 -6.625558     39.0 -6.251883  96.0 -6.549222      3.0 -6.554122   \n",
       "4       96.0 -6.310939      3.0 -6.314555  29.0 -6.586070      4.0 -6.578732   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      12.0 -9.734209     97.0 -9.736045   4.0 -9.734209     95.0 -9.736048   \n",
       "96       8.0 -9.734209     99.0 -9.739898  11.0 -9.727593     91.0 -9.736523   \n",
       "97       7.0 -9.734209     94.0 -9.741494  51.0 -9.734209     96.0 -9.737504   \n",
       "98       1.0 -9.734209     93.0 -9.744768  17.0 -9.727593     88.0 -9.739672   \n",
       "99       4.0 -9.734209     95.0 -9.746672   3.0 -9.734209     98.0 -9.741522   \n",
       "\n",
       "label     2                                  3                                \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       76.0 -6.588891     32.0 -6.129146  44.0 -6.182239      0.0 -6.207527   \n",
       "1       46.0 -6.230028      0.0 -6.223404  75.0 -6.275874      1.0 -6.293755   \n",
       "2       21.0 -6.480742     10.0 -6.307346  35.0 -6.331505      3.0 -6.365513   \n",
       "3       42.0 -6.309279      1.0 -6.312391  99.0 -6.455512      4.0 -6.456026   \n",
       "4       96.0 -6.310939      2.0 -6.320697  97.0 -6.464425      5.0 -6.485068   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       8.0 -9.734209     99.0 -9.732467   3.0 -9.734209     98.0 -9.739051   \n",
       "96       2.0 -9.734209     92.0 -9.736560  12.0 -9.734209     97.0 -9.739160   \n",
       "97       1.0 -9.734209     93.0 -9.741411  50.0 -9.727593     89.0 -9.744978   \n",
       "98       3.0 -9.734209     98.0 -9.746467  51.0 -9.734209     96.0 -9.749709   \n",
       "99       4.0 -9.734209     95.0 -9.817535   8.0 -9.734209     99.0 -9.753163   \n",
       "\n",
       "label     4                                  5                                \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       96.0 -6.221110      0.0 -6.218801  43.0 -5.775692      0.0 -5.789716   \n",
       "1       43.0 -6.240831      1.0 -6.240847  61.0 -5.910188      1.0 -5.917663   \n",
       "2       92.0 -6.364440      3.0 -6.359645  73.0 -6.217120      4.0 -6.219978   \n",
       "3       72.0 -6.370844      5.0 -6.363751  91.0 -6.249234      5.0 -6.249772   \n",
       "4       86.0 -6.372328      6.0 -6.376309  28.0 -6.282807      7.0 -6.273282   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       2.0 -9.734209     92.0 -9.741116  14.0 -9.727593     87.0 -9.738787   \n",
       "96       1.0 -9.734209     93.0 -9.744051   1.0 -9.734209     93.0 -9.739154   \n",
       "97      12.0 -9.734209     97.0 -9.747046   8.0 -9.734209     99.0 -9.740463   \n",
       "98       8.0 -9.734209     99.0 -9.798129   2.0 -9.734209     92.0 -9.745497   \n",
       "99       3.0 -9.734209     98.0 -9.852698  12.0 -9.734209     97.0 -9.745788   \n",
       "\n",
       "label     6                                  7                                \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       75.0 -6.275874      2.0 -6.282557  32.0 -5.709177      0.0 -5.726708   \n",
       "1       35.0 -6.331505      3.0 -6.344807  79.0 -6.130860      1.0 -6.114508   \n",
       "2       28.0 -6.780406     32.0 -6.414482  84.0 -6.195378      2.0 -6.190402   \n",
       "3       96.0 -6.600779     10.0 -6.455039  98.0 -6.311167      3.0 -6.304888   \n",
       "4       94.0 -6.454948      4.0 -6.464305  35.0 -6.331505      4.0 -6.338234   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       4.0 -9.734209     95.0 -9.739703  12.0 -9.734209     97.0 -9.739460   \n",
       "96       3.0 -9.734209     98.0 -9.741989   7.0 -9.734209     94.0 -9.747756   \n",
       "97      11.0 -9.727593     91.0 -9.744608   4.0 -9.734209     95.0 -9.750010   \n",
       "98       1.0 -9.734209     93.0 -9.746089  51.0 -9.734209     96.0 -9.771820   \n",
       "99       7.0 -9.734209     94.0 -9.755100   1.0 -9.734209     93.0 -9.788496   \n",
       "\n",
       "label     8                                  9                                \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       66.0 -6.060895      1.0 -6.059132   6.0 -5.983247      0.0 -5.989470   \n",
       "1       80.0 -6.894968     72.0 -6.097312  54.0 -6.143131      1.0 -6.140545   \n",
       "2       35.0 -6.940001     76.0 -6.320796  77.0 -6.324052      2.0 -6.328280   \n",
       "3       29.0 -6.349417      2.0 -6.354245  72.0 -6.368240      4.0 -6.381281   \n",
       "4       52.0 -6.392454      5.0 -6.390116  53.0 -6.359660      3.0 -6.381303   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       8.0 -9.734209     99.0 -9.734538  11.0 -9.727593     91.0 -9.735209   \n",
       "96       1.0 -9.734209     93.0 -9.737733  14.0 -9.727593     87.0 -9.737255   \n",
       "97       2.0 -9.734209     92.0 -9.742346   2.0 -9.734209     92.0 -9.748471   \n",
       "98      12.0 -9.734209     97.0 -9.747684   3.0 -9.734209     98.0 -9.749693   \n",
       "99       4.0 -9.734209     95.0 -9.751492   1.0 -9.734209     93.0 -9.753802   \n",
       "\n",
       "label     10                                 11                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       37.0 -6.028867      0.0 -6.041323  74.0 -6.117087      0.0 -6.113903   \n",
       "1       71.0 -6.044409      1.0 -6.052176  98.0 -6.156014      3.0 -6.159112   \n",
       "2       76.0 -6.221133      2.0 -6.217917  63.0 -6.171896      4.0 -6.180599   \n",
       "3       90.0 -6.221301      3.0 -6.231865  28.0 -6.172530      5.0 -6.180791   \n",
       "4       93.0 -6.344256      5.0 -6.355586  81.0 -6.199615      7.0 -6.201021   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       2.0 -9.734209     92.0 -9.738401   7.0 -9.734209     94.0 -9.732499   \n",
       "96      14.0 -9.727593     87.0 -9.739338   1.0 -9.734209     93.0 -9.733826   \n",
       "97      17.0 -9.727593     88.0 -9.740447   3.0 -9.734209     98.0 -9.734141   \n",
       "98      50.0 -9.727593     89.0 -9.745355   8.0 -9.734209     99.0 -9.734818   \n",
       "99      12.0 -9.734209     97.0 -9.748753  12.0 -9.734209     97.0 -9.735373   \n",
       "\n",
       "label     12                                 13                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       46.0 -5.901704      0.0 -5.909033  48.0 -5.891960      0.0 -5.903122   \n",
       "1       87.0 -6.146663      1.0 -6.154080  56.0 -6.134938      1.0 -6.136778   \n",
       "2       44.0 -6.182239      2.0 -6.180636  64.0 -6.150773      3.0 -6.165330   \n",
       "3       73.0 -6.217120      3.0 -6.216530  70.0 -6.202125      4.0 -6.204170   \n",
       "4       72.0 -6.736660     23.0 -6.224261  63.0 -6.286141      5.0 -6.286999   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      17.0 -9.727593     88.0 -9.733868  17.0 -9.727593     88.0 -9.737289   \n",
       "96       8.0 -9.734209     99.0 -9.737035  51.0 -9.734209     96.0 -9.737843   \n",
       "97      12.0 -9.734209     97.0 -9.746912   2.0 -9.734209     92.0 -9.737889   \n",
       "98       3.0 -9.734209     98.0 -9.751837  16.0 -9.727593     90.0 -9.745402   \n",
       "99      51.0 -9.734209     96.0 -9.755458   7.0 -9.734209     94.0 -9.749751   \n",
       "\n",
       "label     14                                 15                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       22.0 -5.789740      0.0 -5.805620  74.0 -3.940301      0.0 -3.934020   \n",
       "1       68.0 -6.107600      1.0 -6.112395  83.0 -4.462110      2.0 -4.458435   \n",
       "2       91.0 -6.249234      2.0 -6.252928  86.0 -4.488357      3.0 -4.481386   \n",
       "3       96.0 -6.549222     11.0 -6.258662  48.0 -4.507672      4.0 -4.510556   \n",
       "4       75.0 -6.275874      3.0 -6.281922  22.0 -4.536525      5.0 -4.540329   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       8.0 -9.734209     99.0 -9.742003   4.0 -9.734209     95.0 -9.728175   \n",
       "96       7.0 -9.734209     94.0 -9.742458   1.0 -9.734209     93.0 -9.730686   \n",
       "97       4.0 -9.734209     95.0 -9.757664   7.0 -9.734209     94.0 -9.736979   \n",
       "98       2.0 -9.734209     92.0 -9.773057  51.0 -9.734209     96.0 -9.737529   \n",
       "99      12.0 -9.734209     97.0 -9.798615   2.0 -9.734209     92.0 -9.740290   \n",
       "\n",
       "label     16                                 17                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0        6.0 -5.983247      0.0 -5.991196  82.0 -6.077859      0.0 -6.072291   \n",
       "1       88.0 -6.158427      1.0 -6.172926  36.0 -6.161673      1.0 -6.162069   \n",
       "2       90.0 -6.221301      2.0 -6.223852  45.0 -6.619645     44.0 -6.169834   \n",
       "3       77.0 -6.324052      4.0 -6.326668  71.0 -6.174577      2.0 -6.183572   \n",
       "4       81.0 -6.805135     37.0 -6.462296  94.0 -6.202522      3.0 -6.205570   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      16.0 -9.727593     90.0 -9.736752   2.0 -9.734209     92.0 -9.744748   \n",
       "96      12.0 -9.734209     97.0 -9.740916   1.0 -9.734209     93.0 -9.745674   \n",
       "97       8.0 -9.734209     99.0 -9.745246   7.0 -9.734209     94.0 -9.784444   \n",
       "98       1.0 -9.734209     93.0 -9.747725   4.0 -9.734209     95.0 -9.812429   \n",
       "99       3.0 -9.734209     98.0 -9.752284  50.0 -9.727593     89.0 -9.815358   \n",
       "\n",
       "label     18                                 19                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       95.0 -6.196057      0.0 -6.237668  43.0 -6.070198      1.0 -6.083841   \n",
       "1       99.0 -6.455512      2.0 -6.438261  97.0 -6.219368      3.0 -6.203945   \n",
       "2       97.0 -6.464425      3.0 -6.464385  88.0 -6.618454     39.0 -6.215768   \n",
       "3       94.0 -6.454948      1.0 -6.475404  39.0 -6.572208     28.0 -6.216390   \n",
       "4       29.0 -6.586070      5.0 -6.588339  99.0 -6.209785      2.0 -6.228810   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      16.0 -9.727593     90.0 -9.742700  51.0 -9.734209     96.0 -9.730780   \n",
       "96       3.0 -9.734209     98.0 -9.744297   8.0 -9.734209     99.0 -9.736571   \n",
       "97       7.0 -9.734209     94.0 -9.745339   4.0 -9.734209     95.0 -9.736653   \n",
       "98      12.0 -9.734209     97.0 -9.746693   3.0 -9.734209     98.0 -9.740093   \n",
       "99       8.0 -9.734209     99.0 -9.761417  12.0 -9.734209     97.0 -9.745934   \n",
       "\n",
       "label     20                                 21                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       36.0 -6.006469      0.0 -6.007827  75.0 -5.770156      2.0 -5.778278   \n",
       "1        5.0 -6.039419      1.0 -6.032581  73.0 -5.807189      3.0 -5.814392   \n",
       "2       43.0 -6.372712     28.0 -6.037009  70.0 -5.815135      4.0 -5.819547   \n",
       "3       92.0 -6.110777      3.0 -6.113202   0.0 -5.728776      0.0 -5.827851   \n",
       "4       86.0 -6.119213      5.0 -6.119181  64.0 -5.842688      5.0 -5.849417   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       1.0 -9.734209     93.0 -9.736245   3.0 -9.734209     98.0 -9.730020   \n",
       "96       4.0 -9.734209     95.0 -9.737804  51.0 -9.734209     96.0 -9.737329   \n",
       "97      51.0 -9.734209     96.0 -9.753265   1.0 -9.734209     93.0 -9.739262   \n",
       "98       2.0 -9.734209     92.0 -9.780827   8.0 -9.734209     99.0 -9.743031   \n",
       "99       7.0 -9.734209     94.0 -9.789155  12.0 -9.734209     97.0 -9.748559   \n",
       "\n",
       "label     22                                 23                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       52.0 -5.245574      1.0 -5.248561  86.0 -5.542492      0.0 -5.536958   \n",
       "1       28.0 -5.266717      2.0 -5.268564  66.0 -5.580114      1.0 -5.579801   \n",
       "2       19.0 -5.288770      4.0 -5.295113  62.0 -5.639951      2.0 -5.641968   \n",
       "3       70.0 -5.302331      5.0 -5.305170  76.0 -5.644109      3.0 -5.644223   \n",
       "4       86.0 -5.273103      3.0 -5.314286  70.0 -5.655513      4.0 -5.658987   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       4.0 -9.734209     95.0 -9.733356   8.0 -9.734209     99.0 -9.734082   \n",
       "96       7.0 -9.734209     94.0 -9.735886   3.0 -9.734209     98.0 -9.738252   \n",
       "97      12.0 -9.734209     97.0 -9.741858   2.0 -9.734209     92.0 -9.743327   \n",
       "98       8.0 -9.734209     99.0 -9.742970  51.0 -9.734209     96.0 -9.746374   \n",
       "99       3.0 -9.734209     98.0 -9.745940   1.0 -9.734209     93.0 -9.910607   \n",
       "\n",
       "label     24                                 25                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       27.0 -5.703646      0.0 -5.705223   5.0 -6.717038     58.0 -5.601665   \n",
       "1       70.0 -5.769703      1.0 -5.777030  45.0 -5.765828      0.0 -5.761786   \n",
       "2       68.0 -5.819183      2.0 -5.819251  65.0 -6.212671      8.0 -5.965829   \n",
       "3       67.0 -5.826686      3.0 -5.822942  57.0 -6.049853      1.0 -6.048114   \n",
       "4       61.0 -5.901546      6.0 -5.899521  52.0 -6.057899      2.0 -6.062016   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      12.0 -9.734209     97.0 -9.721565   3.0 -9.734209     98.0 -9.734002   \n",
       "96       4.0 -9.734209     95.0 -9.731416   2.0 -9.734209     92.0 -9.737104   \n",
       "97      48.0 -9.727593     91.0 -9.732510   7.0 -9.734209     94.0 -9.737425   \n",
       "98       8.0 -9.734209     99.0 -9.734055   4.0 -9.734209     95.0 -9.740233   \n",
       "99      51.0 -9.734209     96.0 -9.736728  51.0 -9.734209     96.0 -9.787331   \n",
       "\n",
       "label     26                                 27                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       25.0 -5.507920      0.0 -5.510865  84.0 -5.930282      0.0 -5.927581   \n",
       "1       31.0 -5.951787      1.0 -5.954525  24.0 -6.232370      1.0 -6.245910   \n",
       "2       35.0 -7.591816     78.0 -6.204265  38.0 -6.257469      2.0 -6.251998   \n",
       "3       59.0 -6.990874     69.0 -6.221961  36.0 -6.259565      3.0 -6.257571   \n",
       "4       74.0 -6.267476      3.0 -6.262732  64.0 -6.620191     33.0 -6.302452   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       3.0 -9.734209     98.0 -9.733186   7.0 -9.734209     94.0 -9.739254   \n",
       "96      12.0 -9.734209     97.0 -9.740986   1.0 -9.734209     93.0 -9.739285   \n",
       "97      50.0 -9.727593     89.0 -9.741468   2.0 -9.734209     92.0 -9.744000   \n",
       "98       4.0 -9.734209     95.0 -9.741498  12.0 -9.734209     97.0 -9.748805   \n",
       "99       1.0 -9.734209     93.0 -9.806970   4.0 -9.734209     95.0 -9.749821   \n",
       "\n",
       "label     28                                 29                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       37.0 -6.028867      0.0 -6.030078  56.0 -6.134938      2.0 -6.143692   \n",
       "1       71.0 -6.044409      1.0 -6.056815  54.0 -6.143131      3.0 -6.147087   \n",
       "2       84.0 -6.195378      2.0 -6.207242  77.0 -6.324052     15.0 -6.150760   \n",
       "3       90.0 -6.221301      4.0 -6.227348  70.0 -6.202125      5.0 -6.202123   \n",
       "4       76.0 -6.221133      3.0 -6.230107  76.0 -6.221133      7.0 -6.223449   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       2.0 -9.734209     92.0 -9.744131   7.0 -9.734209     94.0 -9.738722   \n",
       "96       4.0 -9.734209     95.0 -9.744469  12.0 -9.734209     97.0 -9.739348   \n",
       "97      51.0 -9.734209     96.0 -9.747035   8.0 -9.734209     99.0 -9.742479   \n",
       "98      16.0 -9.727593     90.0 -9.760663   3.0 -9.734209     98.0 -9.743685   \n",
       "99      50.0 -9.727593     89.0 -9.823350  51.0 -9.734209     96.0 -9.749327   \n",
       "\n",
       "label     30                                 31                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       26.0 -5.849577      0.0 -5.856101  88.0 -6.158427      0.0 -6.153932   \n",
       "1        6.0 -5.983247      1.0 -5.984535  76.0 -6.221133      1.0 -6.235856   \n",
       "2       62.0 -6.228091      2.0 -6.227783  62.0 -6.228091      3.0 -6.238778   \n",
       "3       78.0 -6.691357     16.0 -6.465548  81.0 -6.235842      4.0 -6.249428   \n",
       "4       99.0 -6.455512      3.0 -6.466901  80.0 -6.313117      5.0 -6.317309   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       7.0 -9.734209     94.0 -9.738281   1.0 -9.734209     93.0 -9.737617   \n",
       "96      14.0 -9.727593     87.0 -9.738815   7.0 -9.734209     94.0 -9.737807   \n",
       "97       2.0 -9.734209     92.0 -9.740854  16.0 -9.727593     90.0 -9.739771   \n",
       "98      12.0 -9.734209     97.0 -9.745809   2.0 -9.734209     92.0 -9.740050   \n",
       "99      50.0 -9.727593     89.0 -9.848978  12.0 -9.734209     97.0 -9.741735   \n",
       "\n",
       "label     32                                 33                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       27.0 -5.374472      0.0 -5.366094  96.0 -6.600779     13.0 -6.036506   \n",
       "1       40.0 -5.911748      2.0 -5.805452  28.0 -6.282807      0.0 -6.310916   \n",
       "2       64.0 -7.128593     72.0 -5.965558  74.0 -6.370296      1.0 -6.383852   \n",
       "3       86.0 -6.009958      3.0 -6.012503  21.0 -6.411710      2.0 -6.413867   \n",
       "4       66.0 -6.043469      4.0 -6.052843  94.0 -6.454948      3.0 -6.447219   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       1.0 -9.734209     93.0 -9.737058   1.0 -9.734209     93.0 -9.734204   \n",
       "96      12.0 -9.734209     97.0 -9.739939   3.0 -9.734209     98.0 -9.735894   \n",
       "97       2.0 -9.734209     92.0 -9.868471  50.0 -9.727593     89.0 -9.737282   \n",
       "98      51.0 -9.734209     96.0 -9.887436   7.0 -9.734209     94.0 -9.747350   \n",
       "99       7.0 -9.734209     94.0 -9.975471   4.0 -9.734209     95.0 -9.749283   \n",
       "\n",
       "label     34                                 35                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       54.0 -5.874065      0.0 -5.871864  80.0 -6.313117      0.0 -6.334147   \n",
       "1       76.0 -6.588891     33.0 -6.050550  74.0 -6.370296      1.0 -6.390576   \n",
       "2       38.0 -6.257469      1.0 -6.269179  24.0 -6.476279      2.0 -6.495346   \n",
       "3       66.0 -6.539048     20.0 -6.273180  38.0 -6.500648      3.0 -6.502325   \n",
       "4       42.0 -6.309279      2.0 -6.309877  96.0 -6.549222      5.0 -6.539858   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       3.0 -9.734209     98.0 -9.733026  12.0 -9.734209     97.0 -9.731474   \n",
       "96       1.0 -9.734209     93.0 -9.733351  50.0 -9.727593     89.0 -9.732134   \n",
       "97      12.0 -9.734209     97.0 -9.739572   7.0 -9.734209     94.0 -9.736856   \n",
       "98      51.0 -9.734209     96.0 -9.743623   1.0 -9.734209     93.0 -9.737259   \n",
       "99       7.0 -9.734209     94.0 -9.744203  17.0 -9.727593     88.0 -9.754106   \n",
       "\n",
       "label     36                                 37                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       39.0 -6.140011      0.0 -6.140745  84.0 -5.766344      0.0 -5.767742   \n",
       "1       88.0 -6.158427      1.0 -6.163455  66.0 -6.402689     10.0 -6.155170   \n",
       "2       44.0 -6.182239      2.0 -6.201119  67.0 -6.511463     30.0 -6.343021   \n",
       "3       91.0 -6.249234      3.0 -6.250063  92.0 -6.364440      2.0 -6.361938   \n",
       "4       82.0 -6.253382      4.0 -6.259783  86.0 -6.372328      5.0 -6.369914   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      16.0 -9.727593     90.0 -9.727341   2.0 -9.734209     92.0 -9.733254   \n",
       "96       2.0 -9.734209     92.0 -9.734338   1.0 -9.734209     93.0 -9.734562   \n",
       "97       8.0 -9.734209     99.0 -9.740038   7.0 -9.734209     94.0 -9.737960   \n",
       "98      11.0 -9.727593     91.0 -9.742881   8.0 -9.734209     99.0 -9.738618   \n",
       "99      12.0 -9.734209     97.0 -9.747803   3.0 -9.734209     98.0 -9.743312   \n",
       "\n",
       "label     38                                 39                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       26.0 -5.849577      0.0 -5.855848  43.0 -6.070198      0.0 -6.075658   \n",
       "1        6.0 -5.983247      1.0 -5.987694  48.0 -6.216141      1.0 -6.221207   \n",
       "2       62.0 -6.228091      2.0 -6.231473  61.0 -6.240334      3.0 -6.227340   \n",
       "3       99.0 -6.455512      3.0 -6.463291  46.0 -6.230028      2.0 -6.230957   \n",
       "4       97.0 -6.464425      4.0 -6.467321  70.0 -6.675759     33.0 -6.270102   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       2.0 -9.734209     92.0 -9.736431  29.0 -9.727593     91.0 -9.721487   \n",
       "96       3.0 -9.734209     98.0 -9.737681   1.0 -9.734209     93.0 -9.728613   \n",
       "97      51.0 -9.734209     96.0 -9.739258   7.0 -9.734209     94.0 -9.743909   \n",
       "98       8.0 -9.734209     99.0 -9.742168   3.0 -9.734209     98.0 -9.746951   \n",
       "99      50.0 -9.727593     89.0 -9.801399  51.0 -9.734209     96.0 -9.748071   \n",
       "\n",
       "label     40                                 41                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       84.0 -6.195378      0.0 -6.216457  68.0 -6.107600      1.0 -6.121827   \n",
       "1       78.0 -6.438037      1.0 -6.432988  88.0 -6.158427      2.0 -6.163053   \n",
       "2       24.0 -6.476279      3.0 -6.471385  73.0 -6.217120      3.0 -6.210379   \n",
       "3       85.0 -6.468452      2.0 -6.483478  62.0 -6.228091      4.0 -6.222253   \n",
       "4       38.0 -6.500648      4.0 -6.519234  81.0 -6.235842      5.0 -6.230178   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       7.0 -9.734209     94.0 -9.737429   4.0 -9.734209     95.0 -9.746287   \n",
       "96       3.0 -9.734209     98.0 -9.738865  14.0 -9.727593     87.0 -9.747201   \n",
       "97      11.0 -9.727593     91.0 -9.740138   1.0 -9.734209     93.0 -9.751760   \n",
       "98      16.0 -9.727593     90.0 -9.746779   8.0 -9.734209     99.0 -9.773637   \n",
       "99      14.0 -9.727593     87.0 -9.752300  12.0 -9.734209     97.0 -9.780558   \n",
       "\n",
       "label     42                                 43                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       87.0 -6.146663      1.0 -6.165133   6.0 -5.983247      0.0 -5.989765   \n",
       "1       62.0 -6.228091      2.0 -6.242920  62.0 -6.228091      1.0 -6.238089   \n",
       "2       80.0 -6.313117      3.0 -6.312078  88.0 -6.833242     43.0 -6.443336   \n",
       "3       97.0 -6.464425      6.0 -6.451281  91.0 -6.799016     35.0 -6.497480   \n",
       "4       75.0 -6.784420     34.0 -6.454251  96.0 -6.549222      3.0 -6.544451   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      51.0 -9.734209     96.0 -9.742451   7.0 -9.734209     94.0 -9.734765   \n",
       "96       2.0 -9.734209     92.0 -9.745400   8.0 -9.734209     99.0 -9.735175   \n",
       "97       8.0 -9.734209     99.0 -9.745702   1.0 -9.734209     93.0 -9.741208   \n",
       "98      16.0 -9.727593     90.0 -9.764245   3.0 -9.734209     98.0 -9.743615   \n",
       "99      17.0 -9.727593     88.0 -9.801290  16.0 -9.727593     90.0 -9.748940   \n",
       "\n",
       "label     44                                 45                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       96.0 -6.549222      1.0 -6.550990  68.0 -5.836143      0.0 -5.833795   \n",
       "1       42.0 -6.548010      0.0 -6.554848  73.0 -5.952051      1.0 -5.943097   \n",
       "2       29.0 -6.586070      2.0 -6.586352  26.0 -6.161404      2.0 -6.155777   \n",
       "3       52.0 -6.627138      4.0 -6.617065  93.0 -6.524523     16.0 -6.360283   \n",
       "4       24.0 -6.662710      7.0 -6.617170  52.0 -6.392454      4.0 -6.382545   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      17.0 -9.727593     88.0 -9.737298   7.0 -9.734209     94.0 -9.731956   \n",
       "96       3.0 -9.734209     98.0 -9.738612   1.0 -9.734209     93.0 -9.735113   \n",
       "97       7.0 -9.734209     94.0 -9.739818   3.0 -9.734209     98.0 -9.739193   \n",
       "98       1.0 -9.734209     93.0 -9.742810   8.0 -9.734209     99.0 -9.739234   \n",
       "99       2.0 -9.734209     92.0 -9.750406  51.0 -9.734209     96.0 -9.739717   \n",
       "\n",
       "label     46                                 47                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       46.0 -5.901704      0.0 -5.920306  23.0 -5.586688      0.0 -5.599098   \n",
       "1       79.0 -6.130860      1.0 -6.132979  19.0 -6.079284      1.0 -6.078047   \n",
       "2       56.0 -6.134938      2.0 -6.144638  26.0 -6.161404      2.0 -6.160436   \n",
       "3       88.0 -6.158427      3.0 -6.168409  43.0 -6.740957     42.0 -6.160839   \n",
       "4       62.0 -6.228091      4.0 -6.226757  58.0 -6.238058      3.0 -6.229351   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      17.0 -9.727593     88.0 -9.728438   3.0 -9.734209     98.0 -9.729780   \n",
       "96      51.0 -9.734209     96.0 -9.731973  12.0 -9.734209     97.0 -9.736673   \n",
       "97      50.0 -9.727593     89.0 -9.733766   4.0 -9.734209     95.0 -9.740248   \n",
       "98       4.0 -9.734209     95.0 -9.735850   2.0 -9.734209     92.0 -9.752468   \n",
       "99       3.0 -9.734209     98.0 -9.741558  51.0 -9.734209     96.0 -9.755829   \n",
       "\n",
       "label     48                                 49                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       56.0 -6.134938      0.0 -6.145071  95.0 -6.196057      0.0 -6.221061   \n",
       "1       54.0 -6.143131      1.0 -6.156491  80.0 -6.313117      1.0 -6.321089   \n",
       "2       82.0 -6.253382      3.0 -6.261949  53.0 -6.359660      2.0 -6.384645   \n",
       "3       75.0 -6.275874      4.0 -6.286424  97.0 -6.464425      4.0 -6.451509   \n",
       "4       38.0 -6.500648      6.0 -6.489244  99.0 -6.455512      3.0 -6.454201   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      12.0 -9.734209     97.0 -9.737868   3.0 -9.734209     98.0 -9.737443   \n",
       "96      51.0 -9.734209     96.0 -9.738751   4.0 -9.734209     95.0 -9.743547   \n",
       "97      16.0 -9.727593     90.0 -9.751773   2.0 -9.734209     92.0 -9.744169   \n",
       "98       7.0 -9.734209     94.0 -9.760437  12.0 -9.734209     97.0 -9.746710   \n",
       "99      14.0 -9.727593     87.0 -9.845098   8.0 -9.734209     99.0 -9.754340   \n",
       "\n",
       "label     50                                 51                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       86.0 -6.365438      2.0 -6.397769  75.0 -6.111759      0.0 -6.105064   \n",
       "1       36.0 -6.643223     12.0 -6.443179   5.0 -6.976879     71.0 -6.221260   \n",
       "2       99.0 -6.455512      3.0 -6.459650  92.0 -6.261224      1.0 -6.256142   \n",
       "3       85.0 -6.468452      6.0 -6.470255  46.0 -6.477499     30.0 -6.262456   \n",
       "4       97.0 -6.464425      4.0 -6.471692  72.0 -6.268482      2.0 -6.279225   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      51.0 -9.734209     96.0 -9.737937   3.0 -9.734209     98.0 -9.736635   \n",
       "96      12.0 -9.734209     97.0 -9.739881  51.0 -9.734209     96.0 -9.738748   \n",
       "97       8.0 -9.734209     99.0 -9.741224   7.0 -9.734209     94.0 -9.749399   \n",
       "98      14.0 -9.727593     87.0 -9.741903   2.0 -9.734209     92.0 -9.754594   \n",
       "99       7.0 -9.734209     94.0 -9.743132   1.0 -9.734209     93.0 -9.756827   \n",
       "\n",
       "label     52                                 53                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       56.0 -6.134938      0.0 -6.150967  24.0 -6.476279      0.0 -6.491059   \n",
       "1       84.0 -6.195378      1.0 -6.209301  42.0 -6.548010      1.0 -6.546859   \n",
       "2       65.0 -6.329358      3.0 -6.338180  96.0 -6.549222      2.0 -6.557016   \n",
       "3       24.0 -6.476279      4.0 -6.472601  29.0 -6.566573      3.0 -6.569449   \n",
       "4       94.0 -6.677761     15.0 -6.478706  52.0 -6.627138      5.0 -6.619775   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       7.0 -9.734209     94.0 -9.733876   4.0 -9.734209     95.0 -9.735138   \n",
       "96       3.0 -9.734209     98.0 -9.735381   3.0 -9.734209     98.0 -9.735368   \n",
       "97      14.0 -9.727593     87.0 -9.747395  51.0 -9.734209     96.0 -9.737254   \n",
       "98       2.0 -9.734209     92.0 -9.754959   2.0 -9.734209     92.0 -9.739686   \n",
       "99      16.0 -9.727593     90.0 -9.766459   7.0 -9.734209     94.0 -9.740934   \n",
       "\n",
       "label     54                                 55                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0        6.0 -5.983247      0.0 -5.978225  26.0 -5.849577      0.0 -5.874820   \n",
       "1       62.0 -6.228091      2.0 -6.227862  83.0 -6.300496      2.0 -6.304437   \n",
       "2       83.0 -6.300496      3.0 -6.303432  42.0 -6.603251      9.0 -6.348537   \n",
       "3       86.0 -6.365438      4.0 -6.368578  86.0 -6.365438      3.0 -6.370860   \n",
       "4       24.0 -6.476279      8.0 -6.437866  24.0 -6.476279      4.0 -6.476952   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       7.0 -9.734209     94.0 -9.733182   4.0 -9.734209     95.0 -9.737107   \n",
       "96       1.0 -9.734209     93.0 -9.736837   7.0 -9.734209     94.0 -9.737754   \n",
       "97       8.0 -9.734209     99.0 -9.739243  50.0 -9.727593     89.0 -9.744504   \n",
       "98      50.0 -9.727593     89.0 -9.763390  12.0 -9.734209     97.0 -9.748107   \n",
       "99      11.0 -9.727593     91.0 -9.784596   8.0 -9.734209     99.0 -9.748240   \n",
       "\n",
       "label     56                                 57                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       75.0 -6.470216     45.0 -5.782003  20.0 -5.077253      0.0 -5.086127   \n",
       "1       35.0 -5.946779      4.0 -5.866240  55.0 -5.116639      1.0 -5.119152   \n",
       "2       72.0 -5.920697      1.0 -5.922410  89.0 -5.262535      2.0 -5.258935   \n",
       "3       53.0 -5.926846      2.0 -5.925239  34.0 -5.688428      4.0 -5.692982   \n",
       "4        0.0 -5.943341      3.0 -5.945606  19.0 -6.399796     26.0 -5.937406   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       3.0 -9.734209     98.0 -9.725956  50.0 -9.727593     89.0 -9.730526   \n",
       "96       1.0 -9.734209     93.0 -9.729997   1.0 -9.734209     93.0 -9.734992   \n",
       "97       4.0 -9.734209     95.0 -9.731354  12.0 -9.734209     97.0 -9.736590   \n",
       "98       2.0 -9.734209     92.0 -9.742269   7.0 -9.734209     94.0 -9.736703   \n",
       "99       7.0 -9.734209     94.0 -9.749172   8.0 -9.734209     99.0 -9.740966   \n",
       "\n",
       "label     58                                 59                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       67.0 -6.091972      0.0 -6.144179  88.0 -6.158427      0.0 -6.189448   \n",
       "1       87.0 -6.146663      1.0 -6.144928  35.0 -6.331505      3.0 -6.334547   \n",
       "2       84.0 -6.195378      2.0 -6.192425  77.0 -6.324052      2.0 -6.335538   \n",
       "3       82.0 -6.253382      5.0 -6.262632  99.0 -6.455512      4.0 -6.466951   \n",
       "4       35.0 -6.331505      7.0 -6.330876  57.0 -6.619365      9.0 -6.499627   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      50.0 -9.727593     89.0 -9.734692  11.0 -9.727593     91.0 -9.738967   \n",
       "96       7.0 -9.734209     94.0 -9.738513   8.0 -9.734209     99.0 -9.745404   \n",
       "97      17.0 -9.727593     88.0 -9.739035   3.0 -9.734209     98.0 -9.745927   \n",
       "98       1.0 -9.734209     93.0 -9.740134  16.0 -9.727593     90.0 -9.756600   \n",
       "99       2.0 -9.734209     92.0 -9.741769  12.0 -9.734209     97.0 -9.762114   \n",
       "\n",
       "label     60                                 61                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       65.0 -9.727593     90.0 -5.534416  26.0 -6.161404      0.0 -6.165813   \n",
       "1       69.0 -6.200252     23.0 -5.721776  85.0 -6.223698      1.0 -6.219057   \n",
       "2       32.0 -6.084221     13.0 -5.723261  58.0 -6.238058      2.0 -6.241138   \n",
       "3       98.0 -5.826158      0.0 -5.831306  49.0 -6.258624      3.0 -6.264011   \n",
       "4       42.0 -5.890154      2.0 -5.886685   6.0 -6.338272      4.0 -6.339762   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       3.0 -9.734209     98.0 -9.734627   7.0 -9.734209     94.0 -9.734056   \n",
       "96       4.0 -9.734209     95.0 -9.734641   8.0 -9.734209     99.0 -9.734358   \n",
       "97      12.0 -9.734209     97.0 -9.740032   2.0 -9.734209     92.0 -9.735862   \n",
       "98       2.0 -9.734209     92.0 -9.740938  12.0 -9.734209     97.0 -9.738839   \n",
       "99       1.0 -9.734209     93.0 -9.741757   4.0 -9.734209     95.0 -9.827401   \n",
       "\n",
       "label     62                                 63                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       74.0 -5.728308      0.0 -5.728362  58.0 -6.238058      1.0 -6.234853   \n",
       "1       72.0 -5.730041      1.0 -5.736298  29.0 -6.328879      4.0 -6.331000   \n",
       "2        0.0 -5.753846      2.0 -5.751369  68.0 -6.637797     34.0 -6.346422   \n",
       "3       64.0 -5.867534      3.0 -5.870164  52.0 -6.392454      6.0 -6.385984   \n",
       "4       67.0 -5.895584      4.0 -5.892632  57.0 -6.385644      5.0 -6.397864   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       7.0 -9.734209     94.0 -9.730145  12.0 -9.734209     97.0 -9.726907   \n",
       "96      12.0 -9.734209     97.0 -9.735061   3.0 -9.734209     98.0 -9.741680   \n",
       "97       8.0 -9.734209     99.0 -9.739370   4.0 -9.734209     95.0 -9.742630   \n",
       "98       4.0 -9.734209     95.0 -9.742396   8.0 -9.734209     99.0 -9.748480   \n",
       "99       3.0 -9.734209     98.0 -9.745969   1.0 -9.734209     93.0 -9.766183   \n",
       "\n",
       "label     64                                 65                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       98.0 -5.779319      0.0 -5.781091  37.0 -5.751393      0.0 -5.752360   \n",
       "1       22.0 -5.814093      1.0 -5.811885  88.0 -6.618454     39.0 -6.066234   \n",
       "2       26.0 -5.894030      2.0 -5.902766  43.0 -6.070198      3.0 -6.067514   \n",
       "3       99.0 -5.945722      3.0 -5.951723  77.0 -6.068260      2.0 -6.067588   \n",
       "4       93.0 -6.284039     16.0 -5.981733  22.0 -6.086826      4.0 -6.088886   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      51.0 -9.734209     96.0 -9.727899   7.0 -9.734209     94.0 -9.729106   \n",
       "96       4.0 -9.734209     95.0 -9.728675   8.0 -9.734209     99.0 -9.735067   \n",
       "97       1.0 -9.734209     93.0 -9.739616   1.0 -9.734209     93.0 -9.735845   \n",
       "98       3.0 -9.734209     98.0 -9.741485   4.0 -9.734209     95.0 -9.742193   \n",
       "99      12.0 -9.734209     97.0 -9.756805   3.0 -9.734209     98.0 -9.751494   \n",
       "\n",
       "label     66                                 67                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       62.0 -6.228091      1.0 -6.245189  60.0 -5.562530      0.0 -5.576107   \n",
       "1       90.0 -6.221301      0.0 -6.250992   6.0 -5.702554      1.0 -5.704838   \n",
       "2       66.0 -6.317314      3.0 -6.313829  79.0 -5.861041      3.0 -5.867354   \n",
       "3        0.0 -6.336077      4.0 -6.344388  64.0 -5.882263      4.0 -5.878037   \n",
       "4       24.0 -6.476279      5.0 -6.453732  84.0 -5.930282      5.0 -5.930590   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      11.0 -9.727593     91.0 -9.726359   3.0 -9.734209     98.0 -9.779644   \n",
       "96       3.0 -9.734209     98.0 -9.736040   8.0 -9.734209     99.0 -9.797387   \n",
       "97       8.0 -9.734209     99.0 -9.749786   7.0 -9.734209     94.0 -9.811434   \n",
       "98      51.0 -9.734209     96.0 -9.749865   2.0 -9.734209     92.0 -9.859339   \n",
       "99      17.0 -9.727593     88.0 -9.752332   1.0 -9.734209     93.0 -9.920288   \n",
       "\n",
       "label     68                                 69                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       62.0 -6.228091      0.0 -6.249218  17.0 -6.337839     35.0 -5.600626   \n",
       "1       74.0 -6.370296      2.0 -6.389161  64.0 -5.892754      0.0 -5.894948   \n",
       "2       97.0 -6.464425      5.0 -6.459091  54.0 -5.896406      1.0 -5.898395   \n",
       "3       99.0 -6.455512      4.0 -6.459464  56.0 -5.900869      2.0 -5.900371   \n",
       "4       84.0 -6.819258     40.0 -6.476225  71.0 -5.942923      3.0 -5.946708   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       3.0 -9.734209     98.0 -9.734325   1.0 -9.734209     93.0 -9.735436   \n",
       "96      17.0 -9.727593     88.0 -9.735950   3.0 -9.734209     98.0 -9.736580   \n",
       "97      11.0 -9.727593     91.0 -9.742347   8.0 -9.734209     99.0 -9.737024   \n",
       "98       7.0 -9.734209     94.0 -9.746536   2.0 -9.734209     92.0 -9.737098   \n",
       "99      51.0 -9.734209     96.0 -9.747378   7.0 -9.734209     94.0 -9.743192   \n",
       "\n",
       "label     70                                 71                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       24.0 -6.289662      0.0 -6.283247  37.0 -6.358535     26.0 -5.970652   \n",
       "1       85.0 -6.296583      1.0 -6.306055  57.0 -6.049853      0.0 -6.049420   \n",
       "2       99.0 -6.307454      3.0 -6.307156  52.0 -6.057899      1.0 -6.054447   \n",
       "3       92.0 -6.364440      4.0 -6.365460  49.0 -6.393664     29.0 -6.097986   \n",
       "4       72.0 -6.370844      5.0 -6.376408   5.0 -6.108628      2.0 -6.106754   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      12.0 -9.734209     97.0 -9.734463   4.0 -9.734209     95.0 -9.733220   \n",
       "96       8.0 -9.734209     99.0 -9.734673   8.0 -9.734209     99.0 -9.735376   \n",
       "97       7.0 -9.734209     94.0 -9.737544   3.0 -9.734209     98.0 -9.737366   \n",
       "98      51.0 -9.734209     96.0 -9.745873   1.0 -9.734209     93.0 -9.873932   \n",
       "99       4.0 -9.734209     95.0 -9.746218   2.0 -9.734209     92.0 -9.891241   \n",
       "\n",
       "label     72                                 73                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       90.0 -6.354778     11.0 -5.834315  63.0 -6.286141      1.0 -6.307220   \n",
       "1       31.0 -6.583543     38.0 -6.090720  80.0 -6.313117      2.0 -6.328473   \n",
       "2       25.0 -6.660027     45.0 -6.236250  65.0 -6.329358      3.0 -6.344307   \n",
       "3       21.0 -6.237360      1.0 -6.239362  92.0 -6.378193      5.0 -6.372351   \n",
       "4       76.0 -6.354255     10.0 -6.253492  74.0 -6.370296      4.0 -6.394812   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       4.0 -9.734209     95.0 -9.734617   2.0 -9.734209     92.0 -9.736211   \n",
       "96      51.0 -9.734209     96.0 -9.738548  11.0 -9.727593     91.0 -9.737751   \n",
       "97       7.0 -9.734209     94.0 -9.740950  12.0 -9.734209     97.0 -9.738492   \n",
       "98       8.0 -9.734209     99.0 -9.790779   4.0 -9.734209     95.0 -9.741970   \n",
       "99       2.0 -9.734209     92.0 -9.817722  17.0 -9.727593     88.0 -9.746170   \n",
       "\n",
       "label     74                                 75                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       86.0 -4.806090      0.0 -4.806323  34.0 -5.789685      0.0 -5.785295   \n",
       "1       70.0 -4.925375      1.0 -4.932771  97.0 -5.810853      2.0 -5.802298   \n",
       "2        0.0 -5.046092      4.0 -5.046387  25.0 -5.791017      1.0 -5.806690   \n",
       "3       18.0 -7.200351     88.0 -5.091616  99.0 -5.832678      3.0 -5.833019   \n",
       "4       55.0 -5.102791      5.0 -5.103552  89.0 -5.834847      4.0 -5.835123   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       7.0 -9.734209     94.0 -9.731956   8.0 -9.734209     99.0 -9.735878   \n",
       "96       2.0 -9.734209     92.0 -9.738721  12.0 -9.734209     97.0 -9.737626   \n",
       "97       4.0 -9.734209     95.0 -9.739339   3.0 -9.734209     98.0 -9.741815   \n",
       "98       1.0 -9.734209     93.0 -9.740574   1.0 -9.734209     93.0 -9.745522   \n",
       "99      12.0 -9.734209     97.0 -9.742110   2.0 -9.734209     92.0 -9.748466   \n",
       "\n",
       "label     76                                 77                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       72.0 -4.939904      2.0 -4.936449   0.0 -5.282387     12.0 -5.004199   \n",
       "1       48.0 -4.960993      3.0 -4.964064  53.0 -5.115004      0.0 -5.109031   \n",
       "2       83.0 -4.978734      4.0 -4.975702  66.0 -5.133687      1.0 -5.133000   \n",
       "3       61.0 -4.990871      5.0 -4.980806  35.0 -5.157475      3.0 -5.156066   \n",
       "4       30.0 -5.006681      6.0 -5.013330  83.0 -5.156481      2.0 -5.165165   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      51.0 -9.734209     96.0 -9.733600  51.0 -9.734209     96.0 -9.730465   \n",
       "96      77.0 -9.727593     91.0 -9.735757  12.0 -9.734209     97.0 -9.731701   \n",
       "97       4.0 -9.734209     95.0 -9.736565   2.0 -9.734209     92.0 -9.738268   \n",
       "98      12.0 -9.734209     97.0 -9.738027   4.0 -9.734209     95.0 -9.739939   \n",
       "99       3.0 -9.734209     98.0 -9.742846   1.0 -9.734209     93.0 -9.741092   \n",
       "\n",
       "label     78                                 79                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       50.0 -4.841265      0.0 -4.838974   9.0 -5.101474      0.0 -5.154175   \n",
       "1       17.0 -5.132164      1.0 -5.136580  33.0 -5.350877      2.0 -5.353909   \n",
       "2        9.0 -5.485133      3.0 -5.478284  86.0 -5.392830      3.0 -5.398625   \n",
       "3       61.0 -5.504945      4.0 -5.516371  60.0 -5.462380      5.0 -5.452002   \n",
       "4       66.0 -6.225242     51.0 -5.516737  13.0 -5.448400      4.0 -5.452592   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       8.0 -9.734209     99.0 -9.728991   2.0 -9.734209     92.0 -9.739847   \n",
       "96       3.0 -9.734209     98.0 -9.735601   1.0 -9.734209     93.0 -9.740124   \n",
       "97       4.0 -9.734209     95.0 -9.735865   8.0 -9.734209     99.0 -9.747544   \n",
       "98      51.0 -9.734209     96.0 -9.740923  51.0 -9.734209     96.0 -9.747748   \n",
       "99       1.0 -9.734209     93.0 -9.742655   7.0 -9.734209     94.0 -9.751253   \n",
       "\n",
       "label     80                                 81                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       30.0 -4.732475      0.0 -4.740738  26.0 -5.446089      1.0 -5.444146   \n",
       "1       40.0 -5.365047      2.0 -5.359856  82.0 -5.758117      3.0 -5.755056   \n",
       "2       27.0 -5.364374      1.0 -5.371370  34.0 -5.764222      4.0 -5.763424   \n",
       "3       86.0 -5.521792      4.0 -5.517632  43.0 -5.785132      5.0 -5.782202   \n",
       "4       20.0 -5.512191      3.0 -5.522265   9.0 -6.003216     16.0 -5.809843   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      51.0 -9.734209     96.0 -9.728591   7.0 -9.734209     94.0 -9.731763   \n",
       "96       2.0 -9.734209     92.0 -9.729023   3.0 -9.734209     98.0 -9.733335   \n",
       "97      12.0 -9.734209     97.0 -9.734732  12.0 -9.734209     97.0 -9.734577   \n",
       "98       3.0 -9.734209     98.0 -9.740969  51.0 -9.734209     96.0 -9.735214   \n",
       "99       7.0 -9.734209     94.0 -9.742553   4.0 -9.734209     95.0 -9.742047   \n",
       "\n",
       "label     82                                 83                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       34.0 -5.688428      0.0 -5.677827  86.0 -4.690676      0.0 -4.702187   \n",
       "1       45.0 -5.691516      1.0 -5.698607  70.0 -4.875638      1.0 -4.857039   \n",
       "2       58.0 -5.975066      3.0 -5.973187  22.0 -4.989712      3.0 -4.936715   \n",
       "3       96.0 -6.113518      4.0 -6.110330  83.0 -4.971684      2.0 -4.973066   \n",
       "4       77.0 -6.184637      5.0 -6.187559  67.0 -5.016879      4.0 -5.008533   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      10.0 -9.727593     89.0 -9.741066   1.0 -9.734209     93.0 -9.729050   \n",
       "96       2.0 -9.734209     92.0 -9.741921   7.0 -9.734209     94.0 -9.729384   \n",
       "97      51.0 -9.734209     96.0 -9.742312   4.0 -9.734209     95.0 -9.735067   \n",
       "98       1.0 -9.734209     93.0 -9.814561  12.0 -9.734209     97.0 -9.738807   \n",
       "99       4.0 -9.734209     95.0 -9.819942  51.0 -9.734209     96.0 -9.739064   \n",
       "\n",
       "label     84                                 85                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       50.0 -4.719597      0.0 -4.720963  18.0 -4.849282      0.0 -4.856553   \n",
       "1       14.0 -4.913362      1.0 -4.917946  23.0 -5.686593      1.0 -5.682671   \n",
       "2       48.0 -5.255649      2.0 -5.254946  46.0 -5.778876      5.0 -5.777435   \n",
       "3       61.0 -5.355205      4.0 -5.319679  61.0 -5.775953      4.0 -5.778328   \n",
       "4       40.0 -5.339369      3.0 -5.344602  22.0 -5.818552      8.0 -5.816669   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       2.0 -9.734209     92.0 -9.734412  90.0 -9.727593     91.0 -9.732044   \n",
       "96      12.0 -9.734209     97.0 -9.736106   3.0 -9.734209     98.0 -9.733565   \n",
       "97       3.0 -9.734209     98.0 -9.737699   2.0 -9.734209     92.0 -9.733966   \n",
       "98       4.0 -9.734209     95.0 -9.737867   4.0 -9.734209     95.0 -9.735077   \n",
       "99       7.0 -9.734209     94.0 -9.742714   7.0 -9.734209     94.0 -9.735802   \n",
       "\n",
       "label     86                                  87                               \\\n",
       "key2     idx      info act_rank       pred   idx      info act_rank      pred   \n",
       "tokens                                                                          \n",
       "0       22.0 -4.846297      0.0  -4.843096  18.0 -4.961876      1.0 -4.961539   \n",
       "1       70.0 -5.158384      2.0  -4.854918  72.0 -5.289307      2.0 -5.292850   \n",
       "2       68.0 -6.042273     48.0  -4.873288  13.0 -5.386950      4.0 -5.380569   \n",
       "3       86.0 -5.071329      1.0  -5.069152  86.0 -5.384874      3.0 -5.382573   \n",
       "4       91.0 -5.262899      4.0  -5.264668  82.0 -5.794258     27.0 -5.400883   \n",
       "...      ...       ...      ...        ...   ...       ...      ...       ...   \n",
       "95       7.0 -9.734209     94.0  -9.735693  12.0 -9.734209     97.0 -9.727961   \n",
       "96       2.0 -9.734209     92.0  -9.744117   1.0 -9.734209     93.0 -9.729630   \n",
       "97       3.0 -9.734209     98.0  -9.750275  51.0 -9.734209     96.0 -9.735549   \n",
       "98      12.0 -9.734209     97.0  -9.933986   4.0 -9.734209     95.0 -9.740797   \n",
       "99      51.0 -9.734209     96.0 -10.009768   2.0 -9.734209     92.0 -9.742281   \n",
       "\n",
       "label     88                                 89                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       86.0 -3.930341      0.0 -3.929331  82.0 -6.873151     63.0 -5.735173   \n",
       "1       82.0 -3.970979      1.0 -3.969098  55.0 -6.512794     42.0 -6.092467   \n",
       "2       90.0 -4.010327      2.0 -4.009221  98.0 -6.098917      2.0 -6.095601   \n",
       "3       70.0 -4.102417      3.0 -4.103675  83.0 -6.104436      3.0 -6.100065   \n",
       "4       93.0 -4.195492      5.0 -4.199290  80.0 -6.096283      1.0 -6.102666   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       3.0 -9.734209     98.0 -9.729873  12.0 -9.734209     97.0 -9.736639   \n",
       "96       7.0 -9.734209     94.0 -9.730498   8.0 -9.734209     99.0 -9.736886   \n",
       "97      12.0 -9.734209     97.0 -9.731700   2.0 -9.734209     92.0 -9.737006   \n",
       "98      51.0 -9.734209     96.0 -9.734659   3.0 -9.734209     98.0 -9.737267   \n",
       "99       8.0 -9.734209     99.0 -9.735478  51.0 -9.734209     96.0 -9.848498   \n",
       "\n",
       "label     90                                 91                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       89.0 -4.908507      0.0 -4.912350  37.0 -6.534252     32.0 -6.265768   \n",
       "1       58.0 -5.908459      1.0 -5.917121  84.0 -6.467428     20.0 -6.272301   \n",
       "2       64.0 -6.150773      2.0 -6.141796  71.0 -6.530053     31.0 -6.275233   \n",
       "3       44.0 -6.182239      3.0 -6.185272  34.0 -6.627779     42.0 -6.332142   \n",
       "4       84.0 -6.195378      4.0 -6.191125  86.0 -6.372328      4.0 -6.369525   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95      14.0 -9.727593     87.0 -9.732518  11.0 -9.727593     86.0 -9.733492   \n",
       "96      50.0 -9.727593     89.0 -9.737035   2.0 -9.734209     92.0 -9.734220   \n",
       "97       8.0 -9.734209     99.0 -9.740822  51.0 -9.734209     96.0 -9.738712   \n",
       "98       4.0 -9.734209     95.0 -9.749562   4.0 -9.734209     95.0 -9.739071   \n",
       "99      51.0 -9.734209     96.0 -9.766806  12.0 -9.734209     97.0 -9.750229   \n",
       "\n",
       "label     92                                 93                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       31.0 -5.719459      0.0 -5.722820  20.0 -6.070054     15.0 -5.759802   \n",
       "1       72.0 -5.962330      1.0 -5.962266  98.0 -5.797782      2.0 -5.794234   \n",
       "2       91.0 -6.039551      2.0 -6.039298  46.0 -5.795397      1.0 -5.797428   \n",
       "3       39.0 -6.096475      3.0 -6.095916  22.0 -5.833680      3.0 -5.833448   \n",
       "4       40.0 -6.343839     15.0 -6.110246  34.0 -5.863704      5.0 -5.861121   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       8.0 -9.734209     99.0 -9.734880   3.0 -9.734209     98.0 -9.732196   \n",
       "96       4.0 -9.734209     95.0 -9.736528   2.0 -9.734209     92.0 -9.734276   \n",
       "97      12.0 -9.734209     97.0 -9.740213  51.0 -9.734209     96.0 -9.735433   \n",
       "98       3.0 -9.734209     98.0 -9.843504   1.0 -9.734209     93.0 -9.735964   \n",
       "99       7.0 -9.734209     94.0 -9.934364   4.0 -9.734209     95.0 -9.742120   \n",
       "\n",
       "label     94                                 95                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       89.0 -5.099403      0.0 -5.100125  84.0 -5.623547      0.0 -5.616222   \n",
       "1       28.0 -6.024241      2.0 -6.027439  37.0 -5.727442      1.0 -5.726045   \n",
       "2       80.0 -6.056923      3.0 -6.049633  28.0 -6.649372     48.0 -5.730793   \n",
       "3       85.0 -6.223698      5.0 -6.217341  48.0 -5.782372      2.0 -5.777117   \n",
       "4        5.0 -6.222270      4.0 -6.219057  69.0 -5.969609      8.0 -5.813753   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       1.0 -9.734209     93.0 -9.732396   4.0 -9.734209     95.0 -9.731427   \n",
       "96       7.0 -9.734209     94.0 -9.736037  51.0 -9.734209     96.0 -9.731923   \n",
       "97       2.0 -9.734209     92.0 -9.742655  12.0 -9.734209     97.0 -9.732054   \n",
       "98      51.0 -9.734209     96.0 -9.743469   2.0 -9.734209     92.0 -9.738361   \n",
       "99      12.0 -9.734209     97.0 -9.749361   7.0 -9.734209     94.0 -9.744190   \n",
       "\n",
       "label     96                                 97                               \\\n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred   \n",
       "tokens                                                                         \n",
       "0       68.0 -6.771860     69.0 -5.219338  61.0 -5.299616      0.0 -5.303560   \n",
       "1        0.0 -6.245051     45.0 -5.355571  34.0 -5.383586      2.0 -5.384628   \n",
       "2       98.0 -6.324862     52.0 -5.527510  31.0 -5.452182      3.0 -5.452777   \n",
       "3       61.0 -5.641105      1.0 -5.642994  60.0 -5.492447      4.0 -5.496153   \n",
       "4       70.0 -7.245023     81.0 -5.683380  45.0 -5.510035      5.0 -5.513776   \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...   \n",
       "95       7.0 -9.734209     94.0 -9.733614   8.0 -9.734209     99.0 -9.732234   \n",
       "96       3.0 -9.734209     98.0 -9.734844   1.0 -9.734209     93.0 -9.733034   \n",
       "97       8.0 -9.734209     99.0 -9.737084   4.0 -9.734209     95.0 -9.734362   \n",
       "98      88.0 -9.727593     89.0 -9.737380   3.0 -9.734209     98.0 -9.734757   \n",
       "99      12.0 -9.734209     97.0 -9.742350  12.0 -9.734209     97.0 -9.745341   \n",
       "\n",
       "label     98                                 99                               \n",
       "key2     idx      info act_rank      pred   idx      info act_rank      pred  \n",
       "tokens                                                                        \n",
       "0       36.0 -7.353806     80.0 -5.779118  86.0 -4.959163     26.0 -4.489558  \n",
       "1       48.0 -6.480022     44.0 -5.847100  54.0 -4.977380     27.0 -4.505052  \n",
       "2       99.0 -5.945722      0.0 -5.945576  35.0 -4.511155      0.0 -4.519406  \n",
       "3       97.0 -5.955873      1.0 -5.959344  28.0 -4.586379      1.0 -4.583322  \n",
       "4       52.0 -6.142846      3.0 -6.135499  53.0 -4.603284      2.0 -4.602691  \n",
       "...      ...       ...      ...       ...   ...       ...      ...       ...  \n",
       "95       8.0 -9.734209     99.0 -9.735483   8.0 -9.734209     99.0 -9.733828  \n",
       "96       1.0 -9.734209     93.0 -9.736398   1.0 -9.734209     93.0 -9.735018  \n",
       "97       2.0 -9.734209     92.0 -9.736816   3.0 -9.734209     98.0 -9.737608  \n",
       "98      51.0 -9.734209     96.0 -9.739737   2.0 -9.734209     92.0 -9.742069  \n",
       "99       3.0 -9.734209     98.0 -9.739832   7.0 -9.734209     94.0 -9.742805  \n",
       "\n",
       "[100 rows x 400 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = pd.DataFrame(sorted_toks.reshape(sorted_toks.shape[0], sorted_toks.shape[1]*4), \n",
    "                                  index=range(sorted_toks.shape[0]), columns=columns)\n",
    "_df.index.name = 'tokens'\n",
    "# pd.set_option('display.max_rows',None)\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e21336-b43f-41b9-9c9a-1e5293f08844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| rmse: tensor(0.2114, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "rmse = torch.sqrt(torch.mean(torch.square(sorted_tok_vals.to(torch.device(\"cuda:0\")) - torch.as_tensor(sorted_toks_bcx_info, device=default_device()))))\n",
    "ic(rmse);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9b94a-5c65-4f01-9cb9-676f68d43647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| r_sqr: tensor(0.9634, device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "ss_res = torch.sum(torch.square(sorted_tok_vals.to(torch.device(\"cuda:0\")) - torch.as_tensor(sorted_toks_bcx_info, device=default_device())))\n",
    "y_bar = np.mean(sorted_toks_bcx_info)\n",
    "ss_tot = torch.sum(torch.square(torch.as_tensor(y_bar, device=default_device()) - torch.as_tensor(sorted_toks_bcx_info, device=default_device())))\n",
    "r_sqr = 1 - ss_res/ss_tot\n",
    "ic(r_sqr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95555428-7967-4d9d-9cf8-f18348eea3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b4815-8ef0-4ffe-a2ed-35062c980c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>key2</th>\n",
       "      <th>idx</th>\n",
       "      <th>info</th>\n",
       "      <th>act_rank</th>\n",
       "      <th>pred</th>\n",
       "      <th>gain</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20625.0</td>\n",
       "      <td>-6.853976</td>\n",
       "      <td>7735.0</td>\n",
       "      <td>-5.672819</td>\n",
       "      <td>49617.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20570.0</td>\n",
       "      <td>-6.853976</td>\n",
       "      <td>7732.0</td>\n",
       "      <td>-5.675634</td>\n",
       "      <td>49620.0</td>\n",
       "      <td>0.761463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20666.0</td>\n",
       "      <td>-6.853976</td>\n",
       "      <td>7740.0</td>\n",
       "      <td>-5.734933</td>\n",
       "      <td>49612.0</td>\n",
       "      <td>0.644561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20639.0</td>\n",
       "      <td>-6.853976</td>\n",
       "      <td>7738.0</td>\n",
       "      <td>-5.753483</td>\n",
       "      <td>49614.0</td>\n",
       "      <td>0.573504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20619.0</td>\n",
       "      <td>-6.853976</td>\n",
       "      <td>7734.0</td>\n",
       "      <td>-5.778982</td>\n",
       "      <td>49618.0</td>\n",
       "      <td>0.524981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57347</th>\n",
       "      <td>19758.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>57220.0</td>\n",
       "      <td>-8.628090</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.091266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57348</th>\n",
       "      <td>18966.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>57149.0</td>\n",
       "      <td>-8.680562</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.091266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57349</th>\n",
       "      <td>19035.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>57153.0</td>\n",
       "      <td>-8.726480</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.091266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57350</th>\n",
       "      <td>19075.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>57155.0</td>\n",
       "      <td>-8.748960</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.091266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57351</th>\n",
       "      <td>18857.0</td>\n",
       "      <td>-9.727593</td>\n",
       "      <td>57142.0</td>\n",
       "      <td>-8.804357</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.091266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57352 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "key2        idx      info  act_rank      pred     gain  discount\n",
       "tokens                                                          \n",
       "0       20625.0 -6.853976    7735.0 -5.672819  49617.0  1.000000\n",
       "1       20570.0 -6.853976    7732.0 -5.675634  49620.0  0.761463\n",
       "2       20666.0 -6.853976    7740.0 -5.734933  49612.0  0.644561\n",
       "3       20639.0 -6.853976    7738.0 -5.753483  49614.0  0.573504\n",
       "4       20619.0 -6.853976    7734.0 -5.778982  49618.0  0.524981\n",
       "...         ...       ...       ...       ...      ...       ...\n",
       "57347   19758.0 -9.727593   57220.0 -8.628090    132.0  0.091266\n",
       "57348   18966.0 -9.727593   57149.0 -8.680562    203.0  0.091266\n",
       "57349   19035.0 -9.727593   57153.0 -8.726480    199.0  0.091266\n",
       "57350   19075.0 -9.727593   57155.0 -8.748960    197.0  0.091266\n",
       "57351   18857.0 -9.727593   57142.0 -8.804357    210.0  0.091266\n",
       "\n",
       "[57352 rows x 6 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = _df[0].copy()\n",
    "df_0.loc[:, ['gain']] = len(df_0) - df_0['act_rank']\n",
    "df_0.loc[:, ['discount']] = 1/np.log(math.e + df_0.index)\n",
    "\n",
    "# df_0.loc[:, 'gain'] = len(df_0) - df_0['act_rank']\n",
    "# df_0.loc[:, 'act_rank']\n",
    "df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ba329-8617-4b3d-afdb-8a0833e3294b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172432851.6650227"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_0['gain'] * df_0['discount']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb7bf2-510c-438a-a0ef-bee58ddb0bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_0['info'].plot.kde();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa5ba0-2ae4-4688-9f42-44b83ba88cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_0['pred'].plot.kde();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f376b3b-e22e-4eb4-a571-db5e066d8fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087e633-a4a0-4017-89c3-cd8bccbc3f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3a6c3-8699-4246-8b55-e274a271b577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc4b646-fb55-4b65-b711-ef07f6b71031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffad0e3-284a-4dfe-832d-cba205782664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74e079a-b2b1-457f-85f6-4a8df729e310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002981424331665039"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.memory_usage().sum()/1024**3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397630ff-b124-4e69-8395-54c82640c67f",
   "metadata": {},
   "source": [
    "Fancy Indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161cbb6-8ded-4d3e-8100-4e2b28a67c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.empty((8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de54b7c-8cc8-42d1-89f6-420d6ff57ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    arr[i] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24dd7c-e6f5-481e-b3d2-f1fb63346427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2.],\n",
       "       [3., 3., 3., 3.],\n",
       "       [4., 4., 4., 4.],\n",
       "       [5., 5., 5., 5.],\n",
       "       [6., 6., 6., 6.],\n",
       "       [7., 7., 7., 7.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad56a4-7f1e-4184-b559-b2533d99ff0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4., 4., 4.],\n",
       "       [3., 3., 3., 3.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [6., 6., 6., 6.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[4, 3, 0, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec706fc-075d-44f9-9270-a326161c84ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 5., 5.],\n",
       "       [3., 3., 3., 3.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[-3, -5, -7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9276e-46ce-4efb-8742-205376e24c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(32).reshape((8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e25be4-b5ab-4ef1-8ab0-8ab400262802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19],\n",
       "       [20, 21, 22, 23],\n",
       "       [24, 25, 26, 27],\n",
       "       [28, 29, 30, 31]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486b957-1100-4e3f-ad92-253416962ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(arr[[1, 5, 7, 2], [0, 3, 1, 2]] , [arr[o] for o in list(zip([1, 5, 7, 2], [0, 3, 1, 2]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f72a6d-612e-4aa6-8bfd-2e7712c79795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5,  6,  7],\n",
       "       [20, 21, 22, 23],\n",
       "       [28, 29, 30, 31],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[1, 5, 7, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5472ca6-3d96-458e-b0de-3207db35c547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  7,  5,  6],\n",
       "       [20, 23, 21, 22],\n",
       "       [28, 31, 29, 30],\n",
       "       [ 8, 11,  9, 10]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f541d89-4bde-400a-8edb-07f8eafa1ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3, 1, 2], [2, 1, 3, 0], [0, 1, 2, 3], [3, 1, 2, 0]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = [[0,3,1,2], [2,1,3,0], [0,1,2,3], [3,1,2,0]]\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b63089-93dd-4af3-bb0f-108a262e25cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4,  7,  5,  6],\n",
       "        [ 6,  5,  7,  4],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 7,  5,  6,  4]],\n",
       "\n",
       "       [[20, 23, 21, 22],\n",
       "        [22, 21, 23, 20],\n",
       "        [20, 21, 22, 23],\n",
       "        [23, 21, 22, 20]],\n",
       "\n",
       "       [[28, 31, 29, 30],\n",
       "        [30, 29, 31, 28],\n",
       "        [28, 29, 30, 31],\n",
       "        [31, 29, 30, 28]],\n",
       "\n",
       "       [[ 8, 11,  9, 10],\n",
       "        [10,  9, 11,  8],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [11,  9, 10,  8]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[1, 5, 7, 2]][ :, ind ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8b61ff-5ae6-4248-a77d-1bdc0c66e968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [20, 21, 22, 23],\n",
       "       [28, 29, 30, 31]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[[1, 5, 7, 2]][[0, 3, 1, 2], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584ac9b-037c-4653-bfae-330235367156",
   "metadata": {},
   "source": [
    "Rearrange columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29448c55-8331-4d1d-9f47-b65e891b1ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30, 40, 50],\n",
       "       [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = array([[10, 20, 30, 40, 50],\n",
    "       [ 6,  7,  8,  9, 10]])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e9505-d079-436b-867b-1bde9611b3c3",
   "metadata": {},
   "source": [
    "change it to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add3ada-f0ac-4291-a30f-be01b7b79f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 30, 50, 40, 20],\n",
       "       [ 6,  8, 10,  9,  7]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array([[10, 30, 50, 40, 20],\n",
    "       [ 6,  8, 10,  9,  7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8736fe-85f0-46f1-a194-2508208b824a",
   "metadata": {},
   "source": [
    "by applying the permutation\n",
    "\n",
    "0 -> 0 \n",
    "\n",
    "1 -> 4\n",
    "\n",
    "2 -> 1\n",
    "\n",
    "3 -> 3\n",
    "\n",
    "4 -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587451de-7e64-4b9a-ac64-b556ccb79b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = [0,4,1,3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b70f50-4986-426e-8557-79302a3b54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.empty_like(permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df640d56-be91-4b9c-9c3a-b5de1d3146c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 3, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d33b3-b6d1-42bf-afb8-fd7bc30f087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx[permutation] = np.arange(len(permutation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5fb79-7e12-4734-ba0b-a2006947c658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 3, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82527563-4de5-4365-9155-85e0e01be0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 30, 40, 50],\n",
       "       [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e937fa54-43c6-44d4-b689-34dc97f00f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 30, 50, 40, 20],\n",
       "       [ 6,  8, 10,  9,  7]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04490561-bd09-442f-b676-d6bf6c7fa888",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:] = a[:,idx] # in-place modifcation of a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27050e-15c6-4142-a3c1-288e26a3ddab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 30, 50, 40, 20],\n",
       "       [ 6,  8, 10,  9,  7]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
